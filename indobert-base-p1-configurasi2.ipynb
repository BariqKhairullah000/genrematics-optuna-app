{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f44b691",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-19T08:39:46.089360Z",
     "iopub.status.busy": "2025-02-19T08:39:46.089123Z",
     "iopub.status.idle": "2025-02-19T08:39:47.009921Z",
     "shell.execute_reply": "2025-02-19T08:39:47.008489Z"
    },
    "papermill": {
     "duration": 0.927461,
     "end_time": "2025-02-19T08:39:47.011898",
     "exception": false,
     "start_time": "2025-02-19T08:39:46.084437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datasets-classificationsynopsis/final_combined_movies_5genres.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f212ba86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T08:39:47.026449Z",
     "iopub.status.busy": "2025-02-19T08:39:47.025882Z",
     "iopub.status.idle": "2025-02-19T08:39:51.978775Z",
     "shell.execute_reply": "2025-02-19T08:39:51.977771Z"
    },
    "papermill": {
     "duration": 4.960819,
     "end_time": "2025-02-19T08:39:51.980723",
     "exception": false,
     "start_time": "2025-02-19T08:39:47.019904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.2.0)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.1)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2.4.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->optuna) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Movie Genre Classification with IndoBERT\n",
    "Environment: Kaggle\n",
    "\"\"\"\n",
    "\n",
    "!pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63a7d4f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T08:39:51.988890Z",
     "iopub.status.busy": "2025-02-19T08:39:51.988665Z",
     "iopub.status.idle": "2025-02-19T08:40:04.490592Z",
     "shell.execute_reply": "2025-02-19T08:40:04.489880Z"
    },
    "papermill": {
     "duration": 12.507418,
     "end_time": "2025-02-19T08:40:04.491878",
     "exception": false,
     "start_time": "2025-02-19T08:39:51.984460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files in dataset directory:\n",
      "- final_combined_movies_5genres.csv\n",
      "GPU tersedia: Tesla T4\n",
      "GPU Memory: 15.83 GB\n",
      "Created directory: /kaggle/working/logs\n",
      "Created directory: /kaggle/working/backups\n",
      "Created directory: /kaggle/working/logs/experiments/20250219_084004\n",
      "Created directory: /kaggle/working/logs/experiments/20250219_084004/model\n",
      "Created directory: /kaggle/working/logs/experiments/20250219_084004/tokenizer\n",
      "Created directory: /kaggle/working/logs/experiments/20250219_084004/metrics\n",
      "Created directory: /kaggle/working/logs/experiments/20250219_084004/plots\n",
      "Created directory: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 08:40:04,475 - INFO - Log file created at: /kaggle/working/logs/experiments/20250219_084004/training.log\n",
      "2025-02-19 08:40:04,475 - INFO - System Information:\n",
      "2025-02-19 08:40:04,476 - INFO - Python Version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "2025-02-19 08:40:04,482 - INFO - CPU Count: 4\n",
      "2025-02-19 08:40:04,484 - INFO - Initial Memory Usage: 634.94 MB\n",
      "2025-02-19 08:40:04,485 - INFO - GPU Device: Tesla T4\n",
      "2025-02-19 08:40:04,485 - INFO - GPU Memory Total: 15.83 GB\n",
      "2025-02-19 08:40:04,486 - INFO - CUDA Version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# BAGIAN PERTAMA - Import dan Konfigurasi\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "import argparse\n",
    "import gc\n",
    "import sys\n",
    "import codecs\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import psutil\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "\n",
    "# Define Base Path for Kaggle\n",
    "BASE_PATH = Path('/kaggle/working')\n",
    "DATASETS_PATH = Path('/kaggle/input/datasets-classificationsynopsis')\n",
    "\n",
    "# Configuration Constants\n",
    "class Config:\n",
    "    # Model Parameters\n",
    "    MODEL_PARAMS = {\n",
    "        'EPOCHS': 100,\n",
    "        'BATCH_SIZE': 10,\n",
    "        'LEARNING_RATE': 1e-5,\n",
    "        'MAX_LENGTH': 512,\n",
    "        'TEST_SIZE': 0.15,\n",
    "        'WEIGHT_DECAY': 0.05,\n",
    "        'MIXUP_PROB': 0.5,\n",
    "        'PATIENCE': 5,\n",
    "        'SMOOTHING': 0.2\n",
    "    }\n",
    "\n",
    "    # Optimization Parameters\n",
    "    OPTIM_PARAMS = {\n",
    "        'batch_size': [2, 4, 8],\n",
    "        'learning_rate': [3e-6, 5e-6, 8e-6],\n",
    "        'weight_decay': [0.01, 0.02],\n",
    "        'mixup_prob': [0.2, 0.3],\n",
    "        'smoothing': [0.1, 0.15]\n",
    "    }\n",
    "\n",
    "    # Paths Configuration untuk Kaggle\n",
    "    BASE_DIR = BASE_PATH\n",
    "    DATA_PATH = Path('/kaggle/input/datasets-classificationsynopsis/final_combined_movies_5genres.csv')\n",
    "    LOG_DIR = BASE_DIR / 'logs'\n",
    "    BACKUP_DIR = BASE_DIR / 'backups'\n",
    "    TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    EXPERIMENT_DIR = LOG_DIR / 'experiments' / TIMESTAMP\n",
    "\n",
    "    # Model and Data Paths\n",
    "    MODEL_SAVE_DIR = EXPERIMENT_DIR / 'model'\n",
    "    TOKENIZER_SAVE_DIR = EXPERIMENT_DIR / 'tokenizer'\n",
    "    METRICS_DIR = EXPERIMENT_DIR / 'metrics'\n",
    "    PLOTS_DIR = EXPERIMENT_DIR / 'plots'\n",
    "    CM_DIR = PLOTS_DIR / 'confusion_matrices'\n",
    "\n",
    "    # Model Files\n",
    "    MODEL_BEST_ACC = MODEL_SAVE_DIR / \"best_accuracy\"\n",
    "    MODEL_BEST_LOSS = MODEL_SAVE_DIR / \"best_loss\"\n",
    "    TOKENIZER_BEST_ACC = TOKENIZER_SAVE_DIR / \"best_accuracy\"\n",
    "    TOKENIZER_BEST_LOSS = TOKENIZER_SAVE_DIR / \"best_loss\"\n",
    "    DATA_PATH = Path('/kaggle/input/datasets-classificationsynopsis/final_combined_movies_5genres.csv')  # Path langsung ke file CSV\n",
    "\n",
    "    # Device Configuration\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    SAMPLE_SIZE: Optional[int] = None\n",
    "\n",
    "    @classmethod\n",
    "    def create_directories(cls) -> None:\n",
    "        \"\"\"Create all necessary directories in Kaggle working directory\"\"\"\n",
    "        directories = [\n",
    "            cls.LOG_DIR, cls.BACKUP_DIR,\n",
    "            cls.EXPERIMENT_DIR, cls.MODEL_SAVE_DIR, cls.TOKENIZER_SAVE_DIR,\n",
    "            cls.METRICS_DIR, cls.PLOTS_DIR, cls.CM_DIR\n",
    "        ]\n",
    "        for dir_path in directories:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "    @classmethod\n",
    "    def setup_logging(cls) -> None:\n",
    "        \"\"\"Setup logging configuration untuk Kaggle\"\"\"\n",
    "        log_file = cls.EXPERIMENT_DIR / 'training.log'\n",
    "        for handler in logging.root.handlers[:]:\n",
    "            logging.root.removeHandler(handler)\n",
    "\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file, encoding='utf-8', mode='a'),\n",
    "                logging.StreamHandler(sys.stdout)\n",
    "            ]\n",
    "        )\n",
    "        logging.info(f\"Log file created at: {log_file}\")\n",
    "\n",
    "# Environment Check Function\n",
    "def check_environment() -> bool:\n",
    "    \"\"\"Verify Kaggle environment and paths\"\"\"\n",
    "    try:\n",
    "        # Check if datasets directory exists\n",
    "        if not DATASETS_PATH.exists():\n",
    "            raise RuntimeError(f\"Dataset directory tidak ditemukan di: {DATASETS_PATH}\")\n",
    "        \n",
    "        # List available files in dataset directory\n",
    "        print(\"\\nFiles in dataset directory:\")\n",
    "        for file in DATASETS_PATH.glob('*'):\n",
    "            print(f\"- {file.name}\")\n",
    "\n",
    "        # Check if dataset exists\n",
    "        if not Config.DATA_PATH.exists():\n",
    "            raise RuntimeError(f\"Dataset tidak ditemukan di: {Config.DATA_PATH}\")\n",
    "\n",
    "        # Check GPU availability\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n",
    "            print(f\"GPU tersedia: {gpu_name}\")\n",
    "            print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
    "        else:\n",
    "            print(\"WARNING: GPU tidak tersedia, menggunakan CPU\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error dalam setup environment: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Memory Management\n",
    "class ModelManager:\n",
    "    \"\"\"Context manager for model memory management\"\"\"\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.model, self.tokenizer\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        del self.model\n",
    "        del self.tokenizer\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# Error Handling\n",
    "def error_handler(func):\n",
    "    \"\"\"Decorator for consistent error handling\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in {func.__name__}: {str(e)}\")\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "# Utility Functions\n",
    "def get_memory_usage() -> float:\n",
    "    \"\"\"Get current memory usage of the program\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024  # in MB\n",
    "\n",
    "def log_memory(step_name: str) -> None:\n",
    "    \"\"\"Log memory usage with consistent format\"\"\"\n",
    "    memory = get_memory_usage()\n",
    "    logging.info(f\"Memory usage after {step_name}: {memory:.2f} MB\")\n",
    "\n",
    "def log_system_info() -> None:\n",
    "    \"\"\"Log system information including GPU details\"\"\"\n",
    "    logging.info(\"System Information:\")\n",
    "    logging.info(f\"Python Version: {sys.version}\")\n",
    "    logging.info(f\"CPU Count: {os.cpu_count()}\")\n",
    "    logging.info(f\"Initial Memory Usage: {get_memory_usage():.2f} MB\")\n",
    "    if torch.cuda.is_available():\n",
    "        logging.info(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "        logging.info(f\"GPU Memory Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        logging.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# Create directories and setup logging\n",
    "if check_environment():\n",
    "    Config.create_directories()\n",
    "    Config.setup_logging()\n",
    "    log_system_info()\n",
    "else:\n",
    "    print(\"Failed to initialize environment. Please check the setup.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdd384af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T08:40:04.501222Z",
     "iopub.status.busy": "2025-02-19T08:40:04.500844Z",
     "iopub.status.idle": "2025-02-19T08:40:04.519785Z",
     "shell.execute_reply": "2025-02-19T08:40:04.519110Z"
    },
    "papermill": {
     "duration": 0.024667,
     "end_time": "2025-02-19T08:40:04.520994",
     "exception": false,
     "start_time": "2025-02-19T08:40:04.496327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAGIAN KEDUA - Dataset dan Data Processing\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    \"\"\"Dataset class untuk movie genre classification\"\"\"\n",
    "    def __init__(self, texts: Union[List, np.ndarray],\n",
    "                 labels: Union[List, np.ndarray],\n",
    "                 tokenizer,\n",
    "                 max_length: int = 512):\n",
    "        # Input validation\n",
    "        if not isinstance(texts, (list, np.ndarray)):\n",
    "            raise ValueError(\"texts must be a list or numpy array\")\n",
    "        if not isinstance(labels, (list, np.ndarray)):\n",
    "            raise ValueError(\"labels must be a list or numpy array\")\n",
    "        if len(texts) != len(labels):\n",
    "            raise ValueError(\"texts and labels must have the same length\")\n",
    "\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten().long(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten().long(),\n",
    "            'labels': torch.FloatTensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Class for handling data preprocessing and loading\"\"\"\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"Clean and preprocess text data\"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "            text = re.sub(r'\\S+@\\S+', '', text)\n",
    "            text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            return text.strip().lower()\n",
    "        return ''\n",
    "\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def load_and_preprocess_data(data_path: Path, sample_size: Optional[int] = None) -> pd.DataFrame:\n",
    "        \"\"\"Load and preprocess data with proper encoding handling\"\"\"\n",
    "        if not data_path.exists():\n",
    "            raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "\n",
    "        if sample_size is not None and (not isinstance(sample_size, int) or sample_size <= 0):\n",
    "            raise ValueError(\"sample_size must be a positive integer\")\n",
    "\n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        log_memory(\"start\")\n",
    "        initial_size = None\n",
    "\n",
    "        # Try different encodings for Google Drive compatibility\n",
    "        encodings_to_try = ['utf-8', 'utf-8-sig', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "        df = None\n",
    "\n",
    "        for encoding in encodings_to_try:\n",
    "            try:\n",
    "                df = pd.read_csv(data_path, encoding=encoding)\n",
    "                logging.info(f\"Successfully loaded data using {encoding} encoding\")\n",
    "                initial_size = len(df)\n",
    "                break\n",
    "            except (UnicodeDecodeError, UnicodeError):\n",
    "                continue\n",
    "\n",
    "        if df is None:\n",
    "            raise UnicodeError(f\"Failed to read file with any of these encodings: {encodings_to_try}\")\n",
    "\n",
    "        log_memory(\"data loading\")\n",
    "\n",
    "        # Sample data if requested\n",
    "        if sample_size:\n",
    "            if sample_size > initial_size:\n",
    "                logging.warning(f\"Requested sample_size ({sample_size}) is larger than dataset size ({initial_size})\")\n",
    "                sample_size = initial_size\n",
    "            logging.info(f\"Taking sample of {sample_size} from {initial_size} total samples\")\n",
    "            df = df.head(sample_size)\n",
    "        else:\n",
    "            logging.info(f\"Using full dataset with {initial_size} samples\")\n",
    "\n",
    "        # Log sample data\n",
    "        logging.info(\"\\nSample data:\")\n",
    "        for i, row in df.head(3).iterrows():\n",
    "            logging.info(f\"\\nSample {i+1}:\")\n",
    "            logging.info(f\"Synopsis: {row['sinopsis'][:100]}...\")\n",
    "            logging.info(f\"Genre: {row['genre']}\")\n",
    "\n",
    "        # Preprocess data\n",
    "        logging.info(\"\\nPreprocessing text data...\")\n",
    "        tqdm.pandas()\n",
    "        df['sinopsis'] = df['sinopsis'].progress_apply(DataProcessor.clean_text)\n",
    "        df['genre'] = df['genre'].str.split(',')\n",
    "        df = df.dropna(subset=['sinopsis', 'genre'])\n",
    "\n",
    "        log_memory(\"preprocessing\")\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_data(df: pd.DataFrame, mlb: MultiLabelBinarizer) -> Tuple:\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        genre_labels = mlb.fit_transform(df['genre'])\n",
    "        return train_test_split(\n",
    "            df['sinopsis'].values,\n",
    "            genre_labels,\n",
    "            test_size=Config.MODEL_PARAMS['TEST_SIZE'],\n",
    "            random_state=42,\n",
    "            stratify=genre_labels if len(genre_labels.shape) == 1 else None\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def create_weighted_sampler(genre_labels: np.ndarray) -> WeightedRandomSampler:\n",
    "        \"\"\"Create weighted sampler for balanced batch sampling\"\"\"\n",
    "        logging.info(\"Creating weighted sampler for balanced batch sampling...\")\n",
    "\n",
    "        sample_weights = np.zeros(len(genre_labels))\n",
    "        for i in range(genre_labels.shape[1]):\n",
    "            sample_weights += genre_labels[:, i] * (1.0 / np.sum(genre_labels[:, i]))\n",
    "\n",
    "        sample_weights = sample_weights / sample_weights.sum()\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Created sampler with {len(sample_weights)} weights\")\n",
    "        return sampler\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_class_weights(genre_labels: np.ndarray, mlb: MultiLabelBinarizer) -> torch.Tensor:\n",
    "        \"\"\"Calculate class weights for handling imbalanced data\"\"\"\n",
    "        class_weights = []\n",
    "        logging.info(\"\\nCalculating class weights for handling imbalanced data...\")\n",
    "\n",
    "        for i in range(genre_labels.shape[1]):\n",
    "            genre = mlb.classes_[i]\n",
    "            positive_samples = np.sum(genre_labels[:, i])\n",
    "            total_samples = len(genre_labels)\n",
    "\n",
    "            weights = compute_class_weight(\n",
    "                class_weight='balanced',\n",
    "                classes=np.array([0, 1]),\n",
    "                y=genre_labels[:, i]\n",
    "            )\n",
    "            class_weights.append(weights[1])\n",
    "\n",
    "            logging.info(f\"{genre}:\")\n",
    "            logging.info(f\"  Positive samples: {positive_samples}\")\n",
    "            logging.info(f\"  Negative samples: {total_samples - positive_samples}\")\n",
    "            logging.info(f\"  Weight: {weights[1]:.2f}\")\n",
    "\n",
    "        return torch.FloatTensor(class_weights).to(Config.DEVICE)\n",
    "\n",
    "class ModelSetup:\n",
    "    \"\"\"Class for handling model setup and data loaders\"\"\"\n",
    "    @staticmethod\n",
    "    def setup_model_and_tokenizer(num_labels: int) -> Tuple:\n",
    "        \"\"\"Setup model dan tokenizer\"\"\"\n",
    "        logging.info(\"Setting up model and tokenizer...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p1',\n",
    "            num_labels=num_labels,\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        ).to(Config.DEVICE)\n",
    "        logging.info(\"Model and tokenizer setup completed\")\n",
    "        return model, tokenizer\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_dataloaders(X_train: np.ndarray,\n",
    "                         X_test: np.ndarray,\n",
    "                         y_train: np.ndarray,\n",
    "                         y_test: np.ndarray,\n",
    "                         tokenizer,\n",
    "                         batch_size: int) -> Tuple:\n",
    "        \"\"\"Setup data loaders\"\"\"\n",
    "        logging.info(\"Setting up data loaders...\")\n",
    "        train_dataset = MovieDataset(X_train, y_train, tokenizer)\n",
    "        val_dataset = MovieDataset(X_test, y_test, tokenizer)\n",
    "        sampler = DataProcessor.create_weighted_sampler(y_train)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            num_workers=0,  # Set to 0 for Colab compatibility\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0,  # Set to 0 for Colab compatibility\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Created data loaders with batch size {batch_size}\")\n",
    "        return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76e37876",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T08:40:04.529405Z",
     "iopub.status.busy": "2025-02-19T08:40:04.529206Z",
     "iopub.status.idle": "2025-02-19T08:40:04.554191Z",
     "shell.execute_reply": "2025-02-19T08:40:04.553378Z"
    },
    "papermill": {
     "duration": 0.030804,
     "end_time": "2025-02-19T08:40:04.555600",
     "exception": false,
     "start_time": "2025-02-19T08:40:04.524796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAGIAN KETIGA - Loss Functions dan Training\n",
    "\n",
    "class LossFunctions:\n",
    "    \"\"\"Class untuk menangani berbagai loss functions\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def focal_loss(predictions: torch.Tensor,\n",
    "                  targets: torch.Tensor,\n",
    "                  gamma: float = 2.0,\n",
    "                  alpha: float = 0.25) -> torch.Tensor:\n",
    "        \"\"\"Calculate focal loss for multi-label classification\"\"\"\n",
    "        ce_loss = F.binary_cross_entropy_with_logits(predictions, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = alpha * (1-pt)**gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def label_smoothing_loss(outputs: torch.Tensor,\n",
    "                           targets: torch.Tensor,\n",
    "                           smoothing: float) -> torch.Tensor:\n",
    "        \"\"\"Calculate loss with label smoothing\"\"\"\n",
    "        log_probs = F.log_softmax(outputs, dim=-1)\n",
    "        targets = torch.clamp(targets * (1.0 - smoothing), min=smoothing / (targets.size(-1) - 1))\n",
    "        return torch.mean(torch.sum(-targets * log_probs, dim=-1))\n",
    "\n",
    "class DataAugmentation:\n",
    "    \"\"\"Class untuk menangani augmentasi data\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_mixup(batch: Dict[str, torch.Tensor], alpha: float = 0.2) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Apply mixup augmentation to batch\"\"\"\n",
    "        # Move tensors to device\n",
    "        input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "        labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        mixed_input_ids = lam * input_ids + (1 - lam) * input_ids.flip(0)\n",
    "        mixed_attention_mask = lam * attention_mask + (1 - lam) * attention_mask.flip(0)\n",
    "        mixed_labels = lam * labels + (1 - lam) * labels.flip(0)\n",
    "\n",
    "        return {\n",
    "            'input_ids': mixed_input_ids.long(),\n",
    "            'attention_mask': mixed_attention_mask.long(),\n",
    "            'labels': mixed_labels\n",
    "        }\n",
    "\n",
    "class Visualization:\n",
    "    \"\"\"Class untuk menangani visualisasi\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_confusion_matrices(predictions: np.ndarray,\n",
    "                              labels: np.ndarray,\n",
    "                              classes: List[str]) -> None:\n",
    "        \"\"\"Plot detailed confusion matrices for each genre\"\"\"\n",
    "        logging.info(\"Generating detailed confusion matrices for each genre...\")\n",
    "\n",
    "        # Pastikan input dalam format yang benar\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        if len(predictions.shape) == 1:\n",
    "            predictions = predictions.reshape(-1, 1)\n",
    "        if len(labels.shape) == 1:\n",
    "            labels = labels.reshape(-1, 1)\n",
    "\n",
    "        for i, genre in enumerate(classes):\n",
    "            try:\n",
    "                genre_preds = predictions[:, i]\n",
    "                genre_labels = labels[:, i]\n",
    "\n",
    "                # Calculate confusion matrix\n",
    "                cm = confusion_matrix(genre_labels, genre_preds)\n",
    "\n",
    "                # Extract values\n",
    "                TN, FP = cm[0]\n",
    "                FN, TP = cm[1]\n",
    "\n",
    "                # Calculate metrics\n",
    "                accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "                precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "                recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "                f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "                # Create plot\n",
    "                plt.figure(figsize=(12, 8))\n",
    "\n",
    "                # Main confusion matrix plot\n",
    "                main_ax = plt.subplot2grid((3, 3), (0, 0), rowspan=2, colspan=2)\n",
    "\n",
    "                # Plot heatmap\n",
    "                plot_labels = [f'Non-{genre}', genre]\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                          xticklabels=plot_labels,\n",
    "                          yticklabels=plot_labels,\n",
    "                          ax=main_ax)\n",
    "\n",
    "                main_ax.set_title(f'Confusion Matrix - {genre}')\n",
    "                main_ax.set_ylabel('True Label')\n",
    "                main_ax.set_xlabel('Predicted Label')\n",
    "\n",
    "                # Create text box for detailed metrics\n",
    "                plt.subplot2grid((3, 3), (0, 2), rowspan=3)\n",
    "                plt.axis('off')\n",
    "\n",
    "                metrics_text = [\n",
    "                    f'Detailed Metrics for {genre}:\\n',\n",
    "                    f'\\nConfusion Matrix Values:',\n",
    "                    f'True Negative (TN): {TN}',\n",
    "                    f'False Positive (FP): {FP}',\n",
    "                    f'False Negative (FN): {FN}',\n",
    "                    f'True Positive (TP): {TP}',\n",
    "                    f'\\nPerformance Metrics:',\n",
    "                    f'Accuracy: {accuracy:.3f}',\n",
    "                    f'Precision: {precision:.3f}',\n",
    "                    f'Recall: {recall:.3f}',\n",
    "                    f'F1 Score: {f1:.3f}',\n",
    "                    f'\\nAdditional Information:',\n",
    "                    f'Total Samples: {len(genre_labels)}',\n",
    "                    f'Positive Samples: {np.sum(genre_labels)}',\n",
    "                    f'Negative Samples: {len(genre_labels) - np.sum(genre_labels)}'\n",
    "                ]\n",
    "\n",
    "                plt.text(0, 0.95, '\\n'.join(metrics_text),\n",
    "                        fontsize=10,\n",
    "                        verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round,pad=1', facecolor='white', alpha=0.8))\n",
    "\n",
    "                # Add interpretation text\n",
    "                interpretation_ax = plt.subplot2grid((3, 3), (2, 0), colspan=2)\n",
    "                interpretation_ax.axis('off')\n",
    "\n",
    "                interpretation_text = [\n",
    "                    'Matrix Interpretation:',\n",
    "                    f'• Model correctly identified {TN} non-{genre} movies (True Negatives)',\n",
    "                    f'• Model correctly identified {TP} {genre} movies (True Positives)',\n",
    "                    f'• Model incorrectly classified {FP} non-{genre} movies as {genre} (False Positives)',\n",
    "                    f'• Model failed to identify {FN} {genre} movies (False Negatives)'\n",
    "                ]\n",
    "\n",
    "                interpretation_ax.text(0, 0.5, '\\n'.join(interpretation_text),\n",
    "                                    fontsize=9,\n",
    "                                    verticalalignment='center',\n",
    "                                    bbox=dict(boxstyle='round,pad=1', facecolor='lightyellow', alpha=0.3))\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plot_path = Config.CM_DIR / f'confusion_matrix_{genre}.png'\n",
    "                plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error plotting confusion matrix for genre {genre}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        logging.info(f\"Confusion matrices saved in: {Config.CM_DIR}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_training_history(history_data: Dict) -> None:\n",
    "        \"\"\"Plot and save training metrics\"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Plot Loss\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history_data['epochs'], history_data['training_loss'],\n",
    "                label='Training Loss', marker='o')\n",
    "        plt.plot(history_data['epochs'], history_data['validation_loss'],\n",
    "                label='Validation Loss', marker='o')\n",
    "        plt.title('Training History - Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Plot Accuracy\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(history_data['epochs'], history_data['accuracy'],\n",
    "                label='Accuracy', marker='o', color='green')\n",
    "        plt.title('Training History - Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Plot Loss Difference\n",
    "        plt.subplot(1, 3, 3)\n",
    "        loss_diff = np.array(history_data['training_loss']) - np.array(history_data['validation_loss'])\n",
    "        plt.plot(history_data['epochs'], loss_diff,\n",
    "                label='Loss Difference', marker='o', color='red')\n",
    "        plt.title('Learning Curve (Train-Val Loss)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Difference')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plot_path = Config.PLOTS_DIR / 'training_history.png'\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        logging.info(f\"Saved training history plots to {plot_path}\")\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Class untuk evaluasi model\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def evaluate_model(model: torch.nn.Module,\n",
    "                      val_loader: DataLoader,\n",
    "                      mlb: MultiLabelBinarizer) -> Dict:\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        correct_predictions = 0\n",
    "        total_predictions = 0\n",
    "\n",
    "        logging.info(\"Starting model evaluation...\")\n",
    "        log_memory(\"evaluation start\")\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad(), tqdm(val_loader, desc=\"Evaluating\") as pbar:\n",
    "                for batch in pbar:\n",
    "                    input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                    attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                    labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "                    preds_binary = (preds > 0.5).astype(int)\n",
    "\n",
    "                    all_preds.extend(preds_binary)\n",
    "                    all_labels.extend(labels)\n",
    "\n",
    "                    correct_predictions += np.sum(preds_binary == labels)\n",
    "                    total_predictions += labels.size\n",
    "\n",
    "                    # Update progress bar\n",
    "                    pbar.set_postfix({'Accuracy': f'{(correct_predictions/total_predictions)*100:.2f}%'})\n",
    "\n",
    "            all_preds = np.array(all_preds)\n",
    "            all_labels = np.array(all_labels)\n",
    "            accuracy = correct_predictions / total_predictions\n",
    "\n",
    "            # Calculate per-genre metrics\n",
    "            genre_metrics = ModelEvaluator._calculate_genre_metrics(\n",
    "                all_preds, all_labels, mlb.classes_\n",
    "            )\n",
    "\n",
    "            # Calculate macro metrics\n",
    "            macro_metrics = ModelEvaluator._calculate_macro_metrics(genre_metrics)\n",
    "\n",
    "            # Save metrics\n",
    "            evaluation_metrics = {\n",
    "                'overall': macro_metrics,\n",
    "                'per_genre': genre_metrics\n",
    "            }\n",
    "\n",
    "            metrics_file = Config.METRICS_DIR / 'evaluation_metrics.json'\n",
    "            with open(metrics_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(evaluation_metrics, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            # Plot confusion matrices\n",
    "            Visualization.plot_confusion_matrices(all_preds, all_labels, mlb.classes_)\n",
    "\n",
    "            log_memory(\"evaluation end\")\n",
    "\n",
    "            return {\n",
    "                'accuracy': float(accuracy),\n",
    "                'macro_f1': float(macro_metrics['macro_f1']),\n",
    "                'genre_metrics': genre_metrics\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during model evaluation: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_genre_metrics(predictions: np.ndarray,\n",
    "                               labels: np.ndarray,\n",
    "                               classes: List[str]) -> Dict:\n",
    "        \"\"\"Calculate metrics for each genre\"\"\"\n",
    "        genre_metrics = {}\n",
    "        logging.info(\"\\nPer-genre Performance Metrics:\")\n",
    "\n",
    "        for i, genre in enumerate(classes):\n",
    "            genre_preds = predictions[:, i]\n",
    "            genre_labels = labels[:, i]\n",
    "\n",
    "            metrics = {\n",
    "                'accuracy': float(np.mean(genre_preds == genre_labels)),\n",
    "                'f1_score': float(f1_score(genre_labels, genre_preds, zero_division=0)),\n",
    "                'precision': float(precision_score(genre_labels, genre_preds, zero_division=0)),\n",
    "                'recall': float(recall_score(genre_labels, genre_preds, zero_division=0))\n",
    "            }\n",
    "\n",
    "            genre_metrics[genre] = metrics\n",
    "            logging.info(f\"\\nMetrics for {genre}:\")\n",
    "            for metric_name, value in metrics.items():\n",
    "                logging.info(f\"{metric_name.capitalize()}: {value:.4f}\")\n",
    "\n",
    "        return genre_metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_macro_metrics(genre_metrics: Dict) -> Dict:\n",
    "        \"\"\"Calculate macro-averaged metrics\"\"\"\n",
    "        return {\n",
    "            'accuracy': np.mean([metrics['accuracy'] for metrics in genre_metrics.values()]),\n",
    "            'macro_f1': np.mean([metrics['f1_score'] for metrics in genre_metrics.values()]),\n",
    "            'macro_precision': np.mean([metrics['precision'] for metrics in genre_metrics.values()]),\n",
    "            'macro_recall': np.mean([metrics['recall'] for metrics in genre_metrics.values()])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8679e78e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T08:40:04.564416Z",
     "iopub.status.busy": "2025-02-19T08:40:04.564185Z",
     "iopub.status.idle": "2025-02-19T11:18:15.150342Z",
     "shell.execute_reply": "2025-02-19T11:18:15.149340Z"
    },
    "papermill": {
     "duration": 9490.592675,
     "end_time": "2025-02-19T11:18:15.152104",
     "exception": false,
     "start_time": "2025-02-19T08:40:04.559429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files in dataset directory:\n",
      "- final_combined_movies_5genres.csv\n",
      "GPU tersedia: Tesla T4\n",
      "GPU Memory: 15.83 GB\n",
      "2025-02-19 08:40:04,613 - INFO - System Information:\n",
      "2025-02-19 08:40:04,614 - INFO - Python Version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "2025-02-19 08:40:04,616 - INFO - CPU Count: 4\n",
      "2025-02-19 08:40:04,617 - INFO - Initial Memory Usage: 635.94 MB\n",
      "2025-02-19 08:40:04,618 - INFO - GPU Device: Tesla T4\n",
      "2025-02-19 08:40:04,619 - INFO - GPU Memory Total: 15.83 GB\n",
      "2025-02-19 08:40:04,619 - INFO - CUDA Version: 12.1\n",
      "2025-02-19 08:40:04,620 - INFO - Starting movie genre classification with hyperparameter optimization\n",
      "2025-02-19 08:40:04,621 - INFO - Using device: cuda\n",
      "2025-02-19 08:40:04,622 - INFO - \n",
      "Initial Configuration:\n",
      "2025-02-19 08:40:04,623 - INFO - Sample Size: Full Dataset\n",
      "2025-02-19 08:40:04,624 - INFO - EPOCHS: 100\n",
      "2025-02-19 08:40:04,624 - INFO - BATCH_SIZE: 10\n",
      "2025-02-19 08:40:04,625 - INFO - LEARNING_RATE: 1e-05\n",
      "2025-02-19 08:40:04,626 - INFO - MAX_LENGTH: 512\n",
      "2025-02-19 08:40:04,627 - INFO - TEST_SIZE: 0.15\n",
      "2025-02-19 08:40:04,627 - INFO - WEIGHT_DECAY: 0.05\n",
      "2025-02-19 08:40:04,629 - INFO - MIXUP_PROB: 0.5\n",
      "2025-02-19 08:40:04,630 - INFO - PATIENCE: 5\n",
      "2025-02-19 08:40:04,631 - INFO - SMOOTHING: 0.2\n",
      "2025-02-19 08:40:04,632 - INFO - \n",
      "Loading and preprocessing data...\n",
      "2025-02-19 08:40:04,633 - INFO - Loading and preprocessing data...\n",
      "2025-02-19 08:40:04,634 - INFO - Memory usage after start: 636.06 MB\n",
      "2025-02-19 08:40:04,674 - INFO - Successfully loaded data using utf-8 encoding\n",
      "2025-02-19 08:40:04,676 - INFO - Memory usage after data loading: 638.63 MB\n",
      "2025-02-19 08:40:04,676 - INFO - Using full dataset with 1738 samples\n",
      "2025-02-19 08:40:04,677 - INFO - \n",
      "Sample data:\n",
      "2025-02-19 08:40:04,678 - INFO - \n",
      "Sample 1:\n",
      "2025-02-19 08:40:04,682 - INFO - Synopsis: Setelah kematian yang tampak, Siena mampu melihat tanda-tanda bahwa orang-orang akan meninggal. Namu...\n",
      "2025-02-19 08:40:04,683 - INFO - Genre: Horor\n",
      "2025-02-19 08:40:04,684 - INFO - \n",
      "Sample 2:\n",
      "2025-02-19 08:40:04,685 - INFO - Synopsis: Alfi (Al Ghazali) bertemu dengan Alana (Caitlin Halderman), seorang siswa baru di sekolahnya. Ternya...\n",
      "2025-02-19 08:40:04,686 - INFO - Genre: Drama\n",
      "2025-02-19 08:40:04,687 - INFO - \n",
      "Sample 3:\n",
      "2025-02-19 08:40:04,688 - INFO - Synopsis: Ketika gaji staf di sekolahnya dicuri, seorang guru baru yang enggan berusaha untuk mendapatkan kemb...\n",
      "2025-02-19 08:40:04,689 - INFO - Genre: Komedi\n",
      "2025-02-19 08:40:04,689 - INFO - \n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1738/1738 [00:00<00:00, 14951.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:40:04,822 - INFO - Memory usage after preprocessing: 640.25 MB\n",
      "2025-02-19 08:40:04,823 - INFO - \n",
      "Starting hyperparameter optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-02-19 08:40:04,824] A new study created in memory with name: no-name-9457c34d-6e47-491f-8672-3359143159fe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:40:04,825 - INFO - Starting hyperparameter optimization...\n",
      "2025-02-19 08:40:04,828 - INFO - Trial parameter set: {'batch_size': 4, 'learning_rate': 3e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}\n",
      "2025-02-19 08:40:04,834 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2c3c7249c743cb97f2d172bcf8edb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4370a82b5dda4ff1b71e2ec3656a12f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6f593f17514ed58079323a07392439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "885d1c3051a04fdb830a43f4f925b524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a1b0b29b6324479bb29904c5457bd16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:40:23,254 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 08:40:23,255 - INFO - Setting up data loaders...\n",
      "2025-02-19 08:40:23,256 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 08:40:23,259 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 08:40:23,260 - INFO - Created data loaders with batch size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:42:41,053 - INFO - Starting model evaluation...\n",
      "2025-02-19 08:42:41,056 - INFO - Memory usage after evaluation start: 1715.07 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.76it/s, Accuracy=57.85%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:42:48,596 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 08:42:48,605 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 08:42:48,606 - INFO - Accuracy: 0.4559\n",
      "2025-02-19 08:42:48,606 - INFO - F1_score: 0.4621\n",
      "2025-02-19 08:42:48,608 - INFO - Precision: 0.3211\n",
      "2025-02-19 08:42:48,608 - INFO - Recall: 0.8243\n",
      "2025-02-19 08:42:48,614 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 08:42:48,615 - INFO - Accuracy: 0.7280\n",
      "2025-02-19 08:42:48,615 - INFO - F1_score: 0.5644\n",
      "2025-02-19 08:42:48,616 - INFO - Precision: 0.4340\n",
      "2025-02-19 08:42:48,617 - INFO - Recall: 0.8070\n",
      "2025-02-19 08:42:48,623 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 08:42:48,624 - INFO - Accuracy: 0.6207\n",
      "2025-02-19 08:42:48,624 - INFO - F1_score: 0.4072\n",
      "2025-02-19 08:42:48,625 - INFO - Precision: 0.3119\n",
      "2025-02-19 08:42:48,626 - INFO - Recall: 0.5862\n",
      "2025-02-19 08:42:48,632 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 08:42:48,632 - INFO - Accuracy: 0.2912\n",
      "2025-02-19 08:42:48,633 - INFO - F1_score: 0.2570\n",
      "2025-02-19 08:42:48,633 - INFO - Precision: 0.1517\n",
      "2025-02-19 08:42:48,634 - INFO - Recall: 0.8421\n",
      "2025-02-19 08:42:48,640 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 08:42:48,641 - INFO - Accuracy: 0.7969\n",
      "2025-02-19 08:42:48,641 - INFO - F1_score: 0.3614\n",
      "2025-02-19 08:42:48,642 - INFO - Precision: 0.3061\n",
      "2025-02-19 08:42:48,643 - INFO - Recall: 0.4412\n",
      "2025-02-19 08:42:48,646 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:42:52,847 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 08:42:52,848 - INFO - Memory usage after evaluation end: 1788.38 MB\n",
      "2025-02-19 08:42:52,850 - INFO - Trial 0, Epoch 1: Loss = 1.5835, F1 = 0.4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:45:16,158 - INFO - Starting model evaluation...\n",
      "2025-02-19 08:45:16,160 - INFO - Memory usage after evaluation start: 1788.62 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.52it/s, Accuracy=60.69%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:45:23,913 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 08:45:23,918 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 08:45:23,919 - INFO - Accuracy: 0.5862\n",
      "2025-02-19 08:45:23,920 - INFO - F1_score: 0.5000\n",
      "2025-02-19 08:45:23,921 - INFO - Precision: 0.3803\n",
      "2025-02-19 08:45:23,921 - INFO - Recall: 0.7297\n",
      "2025-02-19 08:45:23,927 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 08:45:23,928 - INFO - Accuracy: 0.7280\n",
      "2025-02-19 08:45:23,929 - INFO - F1_score: 0.6077\n",
      "2025-02-19 08:45:23,929 - INFO - Precision: 0.4435\n",
      "2025-02-19 08:45:23,931 - INFO - Recall: 0.9649\n",
      "2025-02-19 08:45:23,937 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 08:45:23,937 - INFO - Accuracy: 0.4828\n",
      "2025-02-19 08:45:23,938 - INFO - F1_score: 0.4255\n",
      "2025-02-19 08:45:23,938 - INFO - Precision: 0.2825\n",
      "2025-02-19 08:45:23,939 - INFO - Recall: 0.8621\n",
      "2025-02-19 08:45:23,945 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 08:45:23,946 - INFO - Accuracy: 0.5594\n",
      "2025-02-19 08:45:23,946 - INFO - F1_score: 0.3114\n",
      "2025-02-19 08:45:23,947 - INFO - Precision: 0.2016\n",
      "2025-02-19 08:45:23,948 - INFO - Recall: 0.6842\n",
      "2025-02-19 08:45:23,954 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 08:45:23,954 - INFO - Accuracy: 0.6782\n",
      "2025-02-19 08:45:23,955 - INFO - F1_score: 0.3636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:45:23,955 - INFO - Precision: 0.2449\n",
      "2025-02-19 08:45:23,956 - INFO - Recall: 0.7059\n",
      "2025-02-19 08:45:23,959 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 08:45:28,041 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 08:45:28,042 - INFO - Memory usage after evaluation end: 1814.44 MB\n",
      "2025-02-19 08:45:28,043 - INFO - Trial 0, Epoch 2: Loss = 1.4657, F1 = 0.4417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:47:54,069 - INFO - Starting model evaluation...\n",
      "2025-02-19 08:47:54,071 - INFO - Memory usage after evaluation start: 1814.56 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.34it/s, Accuracy=62.30%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:48:01,988 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 08:48:01,994 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 08:48:01,994 - INFO - Accuracy: 0.5326\n",
      "2025-02-19 08:48:01,995 - INFO - F1_score: 0.5041\n",
      "2025-02-19 08:48:01,996 - INFO - Precision: 0.3605\n",
      "2025-02-19 08:48:01,997 - INFO - Recall: 0.8378\n",
      "2025-02-19 08:48:02,003 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 08:48:02,004 - INFO - Accuracy: 0.7816\n",
      "2025-02-19 08:48:02,004 - INFO - F1_score: 0.6545\n",
      "2025-02-19 08:48:02,005 - INFO - Precision: 0.5000\n",
      "2025-02-19 08:48:02,007 - INFO - Recall: 0.9474\n",
      "2025-02-19 08:48:02,013 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 08:48:02,013 - INFO - Accuracy: 0.3793\n",
      "2025-02-19 08:48:02,014 - INFO - F1_score: 0.4044\n",
      "2025-02-19 08:48:02,014 - INFO - Precision: 0.2570\n",
      "2025-02-19 08:48:02,015 - INFO - Recall: 0.9483\n",
      "2025-02-19 08:48:02,021 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 08:48:02,022 - INFO - Accuracy: 0.7816\n",
      "2025-02-19 08:48:02,022 - INFO - F1_score: 0.4124\n",
      "2025-02-19 08:48:02,024 - INFO - Precision: 0.3390\n",
      "2025-02-19 08:48:02,024 - INFO - Recall: 0.5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:48:02,031 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 08:48:02,031 - INFO - Accuracy: 0.6398\n",
      "2025-02-19 08:48:02,032 - INFO - F1_score: 0.3380\n",
      "2025-02-19 08:48:02,033 - INFO - Precision: 0.2222\n",
      "2025-02-19 08:48:02,034 - INFO - Recall: 0.7059\n",
      "2025-02-19 08:48:02,036 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 08:48:06,160 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 08:48:06,162 - INFO - Memory usage after evaluation end: 1812.09 MB\n",
      "2025-02-19 08:48:06,163 - INFO - Trial 0, Epoch 3: Loss = 1.3669, F1 = 0.4627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 08:48:07,244] Trial 0 finished with value: 0.46268431258728926 and parameters: {'batch_size': 4, 'learning_rate': 3e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 0 with value: 0.46268431258728926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:48:07,563 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}\n",
      "2025-02-19 08:48:07,567 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:48:08,435 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 08:48:08,436 - INFO - Setting up data loaders...\n",
      "2025-02-19 08:48:08,437 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 08:48:08,439 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 08:48:08,440 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:50:55,567 - INFO - Starting model evaluation...\n",
      "2025-02-19 08:50:55,570 - INFO - Memory usage after evaluation start: 1955.68 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:08<00:00, 16.31it/s, Accuracy=64.44%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:51:03,608 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 08:51:03,614 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 08:51:03,614 - INFO - Accuracy: 0.5785\n",
      "2025-02-19 08:51:03,615 - INFO - F1_score: 0.4860\n",
      "2025-02-19 08:51:03,616 - INFO - Precision: 0.3714\n",
      "2025-02-19 08:51:03,616 - INFO - Recall: 0.7027\n",
      "2025-02-19 08:51:03,623 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 08:51:03,623 - INFO - Accuracy: 0.8774\n",
      "2025-02-19 08:51:03,624 - INFO - F1_score: 0.7714\n",
      "2025-02-19 08:51:03,624 - INFO - Precision: 0.6506\n",
      "2025-02-19 08:51:03,625 - INFO - Recall: 0.9474\n",
      "2025-02-19 08:51:03,632 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 08:51:03,632 - INFO - Accuracy: 0.3410\n",
      "2025-02-19 08:51:03,633 - INFO - F1_score: 0.3723\n",
      "2025-02-19 08:51:03,634 - INFO - Precision: 0.2361\n",
      "2025-02-19 08:51:03,634 - INFO - Recall: 0.8793\n",
      "2025-02-19 08:51:03,640 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 08:51:03,641 - INFO - Accuracy: 0.6130\n",
      "2025-02-19 08:51:03,641 - INFO - F1_score: 0.3484\n",
      "2025-02-19 08:51:03,642 - INFO - Precision: 0.2308\n",
      "2025-02-19 08:51:03,643 - INFO - Recall: 0.7105\n",
      "2025-02-19 08:51:03,649 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 08:51:03,649 - INFO - Accuracy: 0.8123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:51:03,650 - INFO - F1_score: 0.4235\n",
      "2025-02-19 08:51:03,651 - INFO - Precision: 0.3529\n",
      "2025-02-19 08:51:03,653 - INFO - Recall: 0.5294\n",
      "2025-02-19 08:51:03,655 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 08:51:07,469 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 08:51:07,470 - INFO - Memory usage after evaluation end: 1960.05 MB\n",
      "2025-02-19 08:51:07,471 - INFO - Trial 1, Epoch 1: Loss = 1.4730, F1 = 0.4803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:53:55,183 - INFO - Starting model evaluation...\n",
      "2025-02-19 08:53:55,184 - INFO - Memory usage after evaluation start: 1960.05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:08<00:00, 16.25it/s, Accuracy=64.67%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:54:03,252 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 08:54:03,258 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 08:54:03,259 - INFO - Accuracy: 0.4253\n",
      "2025-02-19 08:54:03,260 - INFO - F1_score: 0.4755\n",
      "2025-02-19 08:54:03,261 - INFO - Precision: 0.3208\n",
      "2025-02-19 08:54:03,262 - INFO - Recall: 0.9189\n",
      "2025-02-19 08:54:03,268 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 08:54:03,269 - INFO - Accuracy: 0.7586\n",
      "2025-02-19 08:54:03,270 - INFO - F1_score: 0.6316\n",
      "2025-02-19 08:54:03,271 - INFO - Precision: 0.4737\n",
      "2025-02-19 08:54:03,271 - INFO - Recall: 0.9474\n",
      "2025-02-19 08:54:03,278 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 08:54:03,278 - INFO - Accuracy: 0.5096\n",
      "2025-02-19 08:54:03,279 - INFO - F1_score: 0.4336\n",
      "2025-02-19 08:54:03,280 - INFO - Precision: 0.2917\n",
      "2025-02-19 08:54:03,280 - INFO - Recall: 0.8448\n",
      "2025-02-19 08:54:03,286 - INFO - \n",
      "Metrics for Laga:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:54:03,287 - INFO - Accuracy: 0.7318\n",
      "2025-02-19 08:54:03,289 - INFO - F1_score: 0.3636\n",
      "2025-02-19 08:54:03,289 - INFO - Precision: 0.2778\n",
      "2025-02-19 08:54:03,290 - INFO - Recall: 0.5263\n",
      "2025-02-19 08:54:03,296 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 08:54:03,296 - INFO - Accuracy: 0.8084\n",
      "2025-02-19 08:54:03,297 - INFO - F1_score: 0.4444\n",
      "2025-02-19 08:54:03,298 - INFO - Precision: 0.3571\n",
      "2025-02-19 08:54:03,298 - INFO - Recall: 0.5882\n",
      "2025-02-19 08:54:03,301 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 08:54:07,159 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 08:54:07,161 - INFO - Memory usage after evaluation end: 1982.05 MB\n",
      "2025-02-19 08:54:07,162 - INFO - Trial 1, Epoch 2: Loss = 1.2482, F1 = 0.4698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:56:55,004 - INFO - Starting model evaluation...\n",
      "2025-02-19 08:56:55,005 - INFO - Memory usage after evaluation start: 1982.18 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:08<00:00, 16.27it/s, Accuracy=69.12%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:57:03,063 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 08:57:03,069 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 08:57:03,070 - INFO - Accuracy: 0.3640\n",
      "2025-02-19 08:57:03,070 - INFO - F1_score: 0.4575\n",
      "2025-02-19 08:57:03,071 - INFO - Precision: 0.3017\n",
      "2025-02-19 08:57:03,071 - INFO - Recall: 0.9459\n",
      "2025-02-19 08:57:03,078 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 08:57:03,078 - INFO - Accuracy: 0.7816\n",
      "2025-02-19 08:57:03,079 - INFO - F1_score: 0.6545\n",
      "2025-02-19 08:57:03,079 - INFO - Precision: 0.5000\n",
      "2025-02-19 08:57:03,080 - INFO - Recall: 0.9474\n",
      "2025-02-19 08:57:03,087 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 08:57:03,088 - INFO - Accuracy: 0.7280\n",
      "2025-02-19 08:57:03,089 - INFO - F1_score: 0.5298\n",
      "2025-02-19 08:57:03,089 - INFO - Precision: 0.4301\n",
      "2025-02-19 08:57:03,090 - INFO - Recall: 0.6897\n",
      "2025-02-19 08:57:03,096 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 08:57:03,097 - INFO - Accuracy: 0.7931\n",
      "2025-02-19 08:57:03,098 - INFO - F1_score: 0.4000\n",
      "2025-02-19 08:57:03,099 - INFO - Precision: 0.3462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:57:03,100 - INFO - Recall: 0.4737\n",
      "2025-02-19 08:57:03,107 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 08:57:03,107 - INFO - Accuracy: 0.7893\n",
      "2025-02-19 08:57:03,108 - INFO - F1_score: 0.4554\n",
      "2025-02-19 08:57:03,108 - INFO - Precision: 0.3433\n",
      "2025-02-19 08:57:03,109 - INFO - Recall: 0.6765\n",
      "2025-02-19 08:57:03,112 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 08:57:07,122 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 08:57:07,124 - INFO - Memory usage after evaluation end: 1972.30 MB\n",
      "2025-02-19 08:57:07,125 - INFO - Trial 1, Epoch 3: Loss = 1.1208, F1 = 0.4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 08:57:08,297] Trial 1 finished with value: 0.49946173269450045 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}. Best is trial 1 with value: 0.49946173269450045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:57:08,666 - INFO - Trial parameter set: {'batch_size': 4, 'learning_rate': 5e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-19 08:57:08,670 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:57:09,523 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 08:57:09,524 - INFO - Setting up data loaders...\n",
      "2025-02-19 08:57:09,525 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 08:57:09,527 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 08:57:09,528 - INFO - Created data loaders with batch size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:59:38,385 - INFO - Starting model evaluation...\n",
      "2025-02-19 08:59:38,386 - INFO - Memory usage after evaluation start: 2049.92 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.34it/s, Accuracy=58.31%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:59:46,305 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 08:59:46,312 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 08:59:46,312 - INFO - Accuracy: 0.5479\n",
      "2025-02-19 08:59:46,313 - INFO - F1_score: 0.5124\n",
      "2025-02-19 08:59:46,313 - INFO - Precision: 0.3690\n",
      "2025-02-19 08:59:46,315 - INFO - Recall: 0.8378\n",
      "2025-02-19 08:59:46,321 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 08:59:46,321 - INFO - Accuracy: 0.7548\n",
      "2025-02-19 08:59:46,322 - INFO - F1_score: 0.6322\n",
      "2025-02-19 08:59:46,323 - INFO - Precision: 0.4701\n",
      "2025-02-19 08:59:46,324 - INFO - Recall: 0.9649\n",
      "2025-02-19 08:59:46,329 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 08:59:46,330 - INFO - Accuracy: 0.4291\n",
      "2025-02-19 08:59:46,330 - INFO - F1_score: 0.4157\n",
      "2025-02-19 08:59:46,331 - INFO - Precision: 0.2690\n",
      "2025-02-19 08:59:46,332 - INFO - Recall: 0.9138\n",
      "2025-02-19 08:59:46,338 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 08:59:46,338 - INFO - Accuracy: 0.7816\n",
      "2025-02-19 08:59:46,339 - INFO - F1_score: 0.3736\n",
      "2025-02-19 08:59:46,339 - INFO - Precision: 0.3208\n",
      "2025-02-19 08:59:46,340 - INFO - Recall: 0.4474\n",
      "2025-02-19 08:59:46,347 - INFO - \n",
      "Metrics for Romantis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 08:59:46,348 - INFO - Accuracy: 0.4023\n",
      "2025-02-19 08:59:46,349 - INFO - F1_score: 0.2844\n",
      "2025-02-19 08:59:46,349 - INFO - Precision: 0.1685\n",
      "2025-02-19 08:59:46,350 - INFO - Recall: 0.9118\n",
      "2025-02-19 08:59:46,352 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 08:59:50,174 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 08:59:50,176 - INFO - Memory usage after evaluation end: 2054.55 MB\n",
      "2025-02-19 08:59:50,177 - INFO - Trial 2, Epoch 1: Loss = 1.5212, F1 = 0.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:02:19,542 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:02:19,544 - INFO - Memory usage after evaluation start: 2054.55 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.35it/s, Accuracy=63.37%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:02:27,454 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:02:27,460 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:02:27,460 - INFO - Accuracy: 0.4904\n",
      "2025-02-19 09:02:27,461 - INFO - F1_score: 0.4981\n",
      "2025-02-19 09:02:27,462 - INFO - Precision: 0.3455\n",
      "2025-02-19 09:02:27,463 - INFO - Recall: 0.8919\n",
      "2025-02-19 09:02:27,469 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:02:27,470 - INFO - Accuracy: 0.7701\n",
      "2025-02-19 09:02:27,470 - INFO - F1_score: 0.6429\n",
      "2025-02-19 09:02:27,471 - INFO - Precision: 0.4865\n",
      "2025-02-19 09:02:27,472 - INFO - Recall: 0.9474\n",
      "2025-02-19 09:02:27,478 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:02:27,478 - INFO - Accuracy: 0.5939\n",
      "2025-02-19 09:02:27,479 - INFO - F1_score: 0.4592\n",
      "2025-02-19 09:02:27,480 - INFO - Precision: 0.3261\n",
      "2025-02-19 09:02:27,481 - INFO - Recall: 0.7759\n",
      "2025-02-19 09:02:27,486 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:02:27,487 - INFO - Accuracy: 0.7548\n",
      "2025-02-19 09:02:27,488 - INFO - F1_score: 0.4074\n",
      "2025-02-19 09:02:27,489 - INFO - Precision: 0.3143\n",
      "2025-02-19 09:02:27,490 - INFO - Recall: 0.5789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:02:27,497 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:02:27,498 - INFO - Accuracy: 0.5594\n",
      "2025-02-19 09:02:27,499 - INFO - F1_score: 0.3353\n",
      "2025-02-19 09:02:27,500 - INFO - Precision: 0.2086\n",
      "2025-02-19 09:02:27,501 - INFO - Recall: 0.8529\n",
      "2025-02-19 09:02:27,503 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 09:02:31,345 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:02:31,346 - INFO - Memory usage after evaluation end: 2076.05 MB\n",
      "2025-02-19 09:02:31,347 - INFO - Trial 2, Epoch 2: Loss = 1.3426, F1 = 0.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:05:00,608 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:05:00,609 - INFO - Memory usage after evaluation start: 2076.17 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.35it/s, Accuracy=63.98%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:05:08,521 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:05:08,528 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:05:08,528 - INFO - Accuracy: 0.4215\n",
      "2025-02-19 09:05:08,529 - INFO - F1_score: 0.4811\n",
      "2025-02-19 09:05:08,530 - INFO - Precision: 0.3226\n",
      "2025-02-19 09:05:08,531 - INFO - Recall: 0.9459\n",
      "2025-02-19 09:05:08,537 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:05:08,538 - INFO - Accuracy: 0.8238\n",
      "2025-02-19 09:05:08,539 - INFO - F1_score: 0.6933\n",
      "2025-02-19 09:05:08,539 - INFO - Precision: 0.5591\n",
      "2025-02-19 09:05:08,541 - INFO - Recall: 0.9123\n",
      "2025-02-19 09:05:08,547 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:05:08,548 - INFO - Accuracy: 0.3678\n",
      "2025-02-19 09:05:08,549 - INFO - F1_score: 0.4043\n",
      "2025-02-19 09:05:08,550 - INFO - Precision: 0.2557\n",
      "2025-02-19 09:05:08,550 - INFO - Recall: 0.9655\n",
      "2025-02-19 09:05:08,557 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:05:08,558 - INFO - Accuracy: 0.7816\n",
      "2025-02-19 09:05:08,559 - INFO - F1_score: 0.4356\n",
      "2025-02-19 09:05:08,559 - INFO - Precision: 0.3492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:05:08,561 - INFO - Recall: 0.5789\n",
      "2025-02-19 09:05:08,568 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:05:08,569 - INFO - Accuracy: 0.8046\n",
      "2025-02-19 09:05:08,569 - INFO - F1_score: 0.4742\n",
      "2025-02-19 09:05:08,570 - INFO - Precision: 0.3651\n",
      "2025-02-19 09:05:08,571 - INFO - Recall: 0.6765\n",
      "2025-02-19 09:05:08,573 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 09:05:12,538 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:05:12,539 - INFO - Memory usage after evaluation end: 2081.92 MB\n",
      "2025-02-19 09:05:12,541 - INFO - Trial 2, Epoch 3: Loss = 1.2313, F1 = 0.4977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 09:05:13,933] Trial 2 finished with value: 0.49772709762695355 and parameters: {'batch_size': 4, 'learning_rate': 5e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}. Best is trial 1 with value: 0.49946173269450045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:05:14,366 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}\n",
      "2025-02-19 09:05:14,371 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:05:15,257 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 09:05:15,258 - INFO - Setting up data loaders...\n",
      "2025-02-19 09:05:15,259 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 09:05:15,261 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 09:05:15,262 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:07:31,138 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:07:31,140 - INFO - Memory usage after evaluation start: 2116.95 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.52it/s, Accuracy=56.02%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:07:38,450 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:07:38,456 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:07:38,457 - INFO - Accuracy: 0.4636\n",
      "2025-02-19 09:07:38,458 - INFO - F1_score: 0.4815\n",
      "2025-02-19 09:07:38,458 - INFO - Precision: 0.3316\n",
      "2025-02-19 09:07:38,459 - INFO - Recall: 0.8784\n",
      "2025-02-19 09:07:38,465 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:07:38,466 - INFO - Accuracy: 0.7433\n",
      "2025-02-19 09:07:38,466 - INFO - F1_score: 0.5732\n",
      "2025-02-19 09:07:38,467 - INFO - Precision: 0.4500\n",
      "2025-02-19 09:07:38,467 - INFO - Recall: 0.7895\n",
      "2025-02-19 09:07:38,475 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:07:38,475 - INFO - Accuracy: 0.3678\n",
      "2025-02-19 09:07:38,476 - INFO - F1_score: 0.4000\n",
      "2025-02-19 09:07:38,477 - INFO - Precision: 0.2535\n",
      "2025-02-19 09:07:38,477 - INFO - Recall: 0.9483\n",
      "2025-02-19 09:07:38,484 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:07:38,485 - INFO - Accuracy: 0.5057\n",
      "2025-02-19 09:07:38,485 - INFO - F1_score: 0.3385\n",
      "2025-02-19 09:07:38,486 - INFO - Precision: 0.2102\n",
      "2025-02-19 09:07:38,487 - INFO - Recall: 0.8684\n",
      "2025-02-19 09:07:38,494 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:07:38,494 - INFO - Accuracy: 0.7203\n",
      "2025-02-19 09:07:38,495 - INFO - F1_score: 0.3652\n",
      "2025-02-19 09:07:38,496 - INFO - Precision: 0.2593\n",
      "2025-02-19 09:07:38,497 - INFO - Recall: 0.6176\n",
      "2025-02-19 09:07:38,499 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:07:42,680 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:07:42,682 - INFO - Memory usage after evaluation end: 2120.64 MB\n",
      "2025-02-19 09:07:42,683 - INFO - Trial 3, Epoch 1: Loss = 1.5504, F1 = 0.4317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:09:58,367 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:09:58,368 - INFO - Memory usage after evaluation start: 2120.77 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.53it/s, Accuracy=64.83%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:10:05,650 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:10:05,656 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:10:05,657 - INFO - Accuracy: 0.4828\n",
      "2025-02-19 09:10:05,657 - INFO - F1_score: 0.4867\n",
      "2025-02-19 09:10:05,658 - INFO - Precision: 0.3386\n",
      "2025-02-19 09:10:05,659 - INFO - Recall: 0.8649\n",
      "2025-02-19 09:10:05,665 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:10:05,666 - INFO - Accuracy: 0.7280\n",
      "2025-02-19 09:10:05,666 - INFO - F1_score: 0.6034\n",
      "2025-02-19 09:10:05,667 - INFO - Precision: 0.4426\n",
      "2025-02-19 09:10:05,668 - INFO - Recall: 0.9474\n",
      "2025-02-19 09:10:05,675 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:10:05,675 - INFO - Accuracy: 0.6284\n",
      "2025-02-19 09:10:05,676 - INFO - F1_score: 0.4757\n",
      "2025-02-19 09:10:05,677 - INFO - Precision: 0.3465\n",
      "2025-02-19 09:10:05,678 - INFO - Recall: 0.7586\n",
      "2025-02-19 09:10:05,683 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:10:05,684 - INFO - Accuracy: 0.6743\n",
      "2025-02-19 09:10:05,684 - INFO - F1_score: 0.3796\n",
      "2025-02-19 09:10:05,685 - INFO - Precision: 0.2626\n",
      "2025-02-19 09:10:05,686 - INFO - Recall: 0.6842\n",
      "2025-02-19 09:10:05,692 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:10:05,693 - INFO - Accuracy: 0.7280\n",
      "2025-02-19 09:10:05,694 - INFO - F1_score: 0.4228\n",
      "2025-02-19 09:10:05,695 - INFO - Precision: 0.2921\n",
      "2025-02-19 09:10:05,696 - INFO - Recall: 0.7647\n",
      "2025-02-19 09:10:05,698 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:10:09,891 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:10:09,892 - INFO - Memory usage after evaluation end: 2126.38 MB\n",
      "2025-02-19 09:10:09,893 - INFO - Trial 3, Epoch 2: Loss = 1.4210, F1 = 0.4736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:12:25,554 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:12:25,556 - INFO - Memory usage after evaluation start: 2126.38 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.54it/s, Accuracy=65.36%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:12:32,829 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:12:32,836 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:12:32,836 - INFO - Accuracy: 0.4330\n",
      "2025-02-19 09:12:32,837 - INFO - F1_score: 0.4638\n",
      "2025-02-19 09:12:32,837 - INFO - Precision: 0.3168\n",
      "2025-02-19 09:12:32,838 - INFO - Recall: 0.8649\n",
      "2025-02-19 09:12:32,844 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:12:32,845 - INFO - Accuracy: 0.6973\n",
      "2025-02-19 09:12:32,845 - INFO - F1_score: 0.5820\n",
      "2025-02-19 09:12:32,846 - INFO - Precision: 0.4167\n",
      "2025-02-19 09:12:32,847 - INFO - Recall: 0.9649\n",
      "2025-02-19 09:12:32,853 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:12:32,854 - INFO - Accuracy: 0.5134\n",
      "2025-02-19 09:12:32,855 - INFO - F1_score: 0.4549\n",
      "2025-02-19 09:12:32,856 - INFO - Precision: 0.3029\n",
      "2025-02-19 09:12:32,857 - INFO - Recall: 0.9138\n",
      "2025-02-19 09:12:32,863 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:12:32,863 - INFO - Accuracy: 0.7816\n",
      "2025-02-19 09:12:32,864 - INFO - F1_score: 0.4242\n",
      "2025-02-19 09:12:32,864 - INFO - Precision: 0.3443\n",
      "2025-02-19 09:12:32,865 - INFO - Recall: 0.5526\n",
      "2025-02-19 09:12:32,872 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:12:32,872 - INFO - Accuracy: 0.8429\n",
      "2025-02-19 09:12:32,873 - INFO - F1_score: 0.4533\n",
      "2025-02-19 09:12:32,873 - INFO - Precision: 0.4146\n",
      "2025-02-19 09:12:32,875 - INFO - Recall: 0.5000\n",
      "2025-02-19 09:12:32,877 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:12:37,017 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:12:37,018 - INFO - Memory usage after evaluation end: 2148.03 MB\n",
      "2025-02-19 09:12:37,019 - INFO - Trial 3, Epoch 3: Loss = 1.2760, F1 = 0.4757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 09:12:38,577] Trial 3 finished with value: 0.475658015569193 and parameters: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 1 with value: 0.49946173269450045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:12:39,055 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 5e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}\n",
      "2025-02-19 09:12:39,059 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:12:39,923 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 09:12:39,924 - INFO - Setting up data loaders...\n",
      "2025-02-19 09:12:39,925 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 09:12:39,928 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 09:12:39,929 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:14:54,962 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:14:54,964 - INFO - Memory usage after evaluation start: 2201.82 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.54it/s, Accuracy=54.87%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:15:02,245 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:15:02,252 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:15:02,252 - INFO - Accuracy: 0.5670\n",
      "2025-02-19 09:15:02,253 - INFO - F1_score: 0.4978\n",
      "2025-02-19 09:15:02,253 - INFO - Precision: 0.3709\n",
      "2025-02-19 09:15:02,255 - INFO - Recall: 0.7568\n",
      "2025-02-19 09:15:02,261 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:15:02,261 - INFO - Accuracy: 0.5172\n",
      "2025-02-19 09:15:02,262 - INFO - F1_score: 0.4375\n",
      "2025-02-19 09:15:02,264 - INFO - Precision: 0.2934\n",
      "2025-02-19 09:15:02,264 - INFO - Recall: 0.8596\n",
      "2025-02-19 09:15:02,270 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:15:02,271 - INFO - Accuracy: 0.5249\n",
      "2025-02-19 09:15:02,272 - INFO - F1_score: 0.3981\n",
      "2025-02-19 09:15:02,272 - INFO - Precision: 0.2770\n",
      "2025-02-19 09:15:02,273 - INFO - Recall: 0.7069\n",
      "2025-02-19 09:15:02,280 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:15:02,280 - INFO - Accuracy: 0.4100\n",
      "2025-02-19 09:15:02,281 - INFO - F1_score: 0.2596\n",
      "2025-02-19 09:15:02,281 - INFO - Precision: 0.1588\n",
      "2025-02-19 09:15:02,282 - INFO - Recall: 0.7105\n",
      "2025-02-19 09:15:02,289 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:15:02,289 - INFO - Accuracy: 0.7241\n",
      "2025-02-19 09:15:02,290 - INFO - F1_score: 0.3898\n",
      "2025-02-19 09:15:02,290 - INFO - Precision: 0.2738\n",
      "2025-02-19 09:15:02,291 - INFO - Recall: 0.6765\n",
      "2025-02-19 09:15:02,293 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:15:06,447 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:15:06,449 - INFO - Memory usage after evaluation end: 2221.44 MB\n",
      "2025-02-19 09:15:06,450 - INFO - Trial 4, Epoch 1: Loss = 1.5618, F1 = 0.3966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:17:22,136 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:17:22,138 - INFO - Memory usage after evaluation start: 2221.44 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.53it/s, Accuracy=63.98%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:17:29,424 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:17:29,430 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:17:29,431 - INFO - Accuracy: 0.6360\n",
      "2025-02-19 09:17:29,432 - INFO - F1_score: 0.5226\n",
      "2025-02-19 09:17:29,433 - INFO - Precision: 0.4160\n",
      "2025-02-19 09:17:29,433 - INFO - Recall: 0.7027\n",
      "2025-02-19 09:17:29,440 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:17:29,441 - INFO - Accuracy: 0.6552\n",
      "2025-02-19 09:17:29,441 - INFO - F1_score: 0.5500\n",
      "2025-02-19 09:17:29,442 - INFO - Precision: 0.3846\n",
      "2025-02-19 09:17:29,443 - INFO - Recall: 0.9649\n",
      "2025-02-19 09:17:29,449 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:17:29,450 - INFO - Accuracy: 0.4828\n",
      "2025-02-19 09:17:29,450 - INFO - F1_score: 0.4304\n",
      "2025-02-19 09:17:29,451 - INFO - Precision: 0.2849\n",
      "2025-02-19 09:17:29,452 - INFO - Recall: 0.8793\n",
      "2025-02-19 09:17:29,459 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:17:29,459 - INFO - Accuracy: 0.7011\n",
      "2025-02-19 09:17:29,460 - INFO - F1_score: 0.3710\n",
      "2025-02-19 09:17:29,460 - INFO - Precision: 0.2674\n",
      "2025-02-19 09:17:29,461 - INFO - Recall: 0.6053\n",
      "2025-02-19 09:17:29,467 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:17:29,468 - INFO - Accuracy: 0.7241\n",
      "2025-02-19 09:17:29,468 - INFO - F1_score: 0.4000\n",
      "2025-02-19 09:17:29,469 - INFO - Precision: 0.2791\n",
      "2025-02-19 09:17:29,470 - INFO - Recall: 0.7059\n",
      "2025-02-19 09:17:29,472 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:17:33,523 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:17:33,525 - INFO - Memory usage after evaluation end: 2227.15 MB\n",
      "2025-02-19 09:17:33,525 - INFO - Trial 4, Epoch 2: Loss = 1.4419, F1 = 0.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:19:49,207 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:19:49,209 - INFO - Memory usage after evaluation start: 2227.15 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.54it/s, Accuracy=63.22%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:19:56,482 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:19:56,488 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:19:56,489 - INFO - Accuracy: 0.5632\n",
      "2025-02-19 09:19:56,489 - INFO - F1_score: 0.5210\n",
      "2025-02-19 09:19:56,490 - INFO - Precision: 0.3780\n",
      "2025-02-19 09:19:56,492 - INFO - Recall: 0.8378\n",
      "2025-02-19 09:19:56,497 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:19:56,498 - INFO - Accuracy: 0.8429\n",
      "2025-02-19 09:19:56,499 - INFO - F1_score: 0.7211\n",
      "2025-02-19 09:19:56,499 - INFO - Precision: 0.5889\n",
      "2025-02-19 09:19:56,501 - INFO - Recall: 0.9298\n",
      "2025-02-19 09:19:56,507 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:19:56,507 - INFO - Accuracy: 0.5019\n",
      "2025-02-19 09:19:56,508 - INFO - F1_score: 0.4298\n",
      "2025-02-19 09:19:56,509 - INFO - Precision: 0.2882\n",
      "2025-02-19 09:19:56,510 - INFO - Recall: 0.8448\n",
      "2025-02-19 09:19:56,516 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:19:56,517 - INFO - Accuracy: 0.6169\n",
      "2025-02-19 09:19:56,517 - INFO - F1_score: 0.3421\n",
      "2025-02-19 09:19:56,518 - INFO - Precision: 0.2281\n",
      "2025-02-19 09:19:56,519 - INFO - Recall: 0.6842\n",
      "2025-02-19 09:19:56,525 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:19:56,526 - INFO - Accuracy: 0.6360\n",
      "2025-02-19 09:19:56,527 - INFO - F1_score: 0.3448\n",
      "2025-02-19 09:19:56,527 - INFO - Precision: 0.2252\n",
      "2025-02-19 09:19:56,529 - INFO - Recall: 0.7353\n",
      "2025-02-19 09:19:56,530 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:20:00,681 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:20:00,682 - INFO - Memory usage after evaluation end: 2232.89 MB\n",
      "2025-02-19 09:20:00,683 - INFO - Trial 4, Epoch 3: Loss = 1.3503, F1 = 0.4718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 09:20:02,383] Trial 4 finished with value: 0.47177084990075874 and parameters: {'batch_size': 8, 'learning_rate': 5e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 1 with value: 0.49946173269450045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:20:02,914 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-19 09:20:02,918 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:20:03,801 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 09:20:03,803 - INFO - Setting up data loaders...\n",
      "2025-02-19 09:20:03,804 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 09:20:03,806 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 09:20:03,807 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:22:18,747 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:22:18,749 - INFO - Memory usage after evaluation start: 2348.67 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.55it/s, Accuracy=67.66%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:22:26,004 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:22:26,011 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:22:26,011 - INFO - Accuracy: 0.6284\n",
      "2025-02-19 09:22:26,012 - INFO - F1_score: 0.5403\n",
      "2025-02-19 09:22:26,013 - INFO - Precision: 0.4161\n",
      "2025-02-19 09:22:26,014 - INFO - Recall: 0.7703\n",
      "2025-02-19 09:22:26,019 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:22:26,020 - INFO - Accuracy: 0.7471\n",
      "2025-02-19 09:22:26,021 - INFO - F1_score: 0.6207\n",
      "2025-02-19 09:22:26,021 - INFO - Precision: 0.4615\n",
      "2025-02-19 09:22:26,022 - INFO - Recall: 0.9474\n",
      "2025-02-19 09:22:26,028 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:22:26,029 - INFO - Accuracy: 0.7471\n",
      "2025-02-19 09:22:26,030 - INFO - F1_score: 0.3774\n",
      "2025-02-19 09:22:26,030 - INFO - Precision: 0.4167\n",
      "2025-02-19 09:22:26,031 - INFO - Recall: 0.3448\n",
      "2025-02-19 09:22:26,037 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:22:26,037 - INFO - Accuracy: 0.6897\n",
      "2025-02-19 09:22:26,038 - INFO - F1_score: 0.3910\n",
      "2025-02-19 09:22:26,040 - INFO - Precision: 0.2737\n",
      "2025-02-19 09:22:26,040 - INFO - Recall: 0.6842\n",
      "2025-02-19 09:22:26,046 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:22:26,047 - INFO - Accuracy: 0.5709\n",
      "2025-02-19 09:22:26,048 - INFO - F1_score: 0.3171\n",
      "2025-02-19 09:22:26,048 - INFO - Precision: 0.2000\n",
      "2025-02-19 09:22:26,049 - INFO - Recall: 0.7647\n",
      "2025-02-19 09:22:26,051 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:22:30,225 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:22:30,227 - INFO - Memory usage after evaluation end: 2353.39 MB\n",
      "2025-02-19 09:22:30,228 - INFO - Trial 5, Epoch 1: Loss = 1.5273, F1 = 0.4493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:24:45,930 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:24:45,932 - INFO - Memory usage after evaluation start: 2353.52 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.53it/s, Accuracy=68.89%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:24:53,221 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:24:53,227 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:24:53,228 - INFO - Accuracy: 0.6858\n",
      "2025-02-19 09:24:53,229 - INFO - F1_score: 0.5638\n",
      "2025-02-19 09:24:53,230 - INFO - Precision: 0.4649\n",
      "2025-02-19 09:24:53,231 - INFO - Recall: 0.7162\n",
      "2025-02-19 09:24:53,236 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:24:53,237 - INFO - Accuracy: 0.6935\n",
      "2025-02-19 09:24:53,238 - INFO - F1_score: 0.5789\n",
      "2025-02-19 09:24:53,238 - INFO - Precision: 0.4135\n",
      "2025-02-19 09:24:53,239 - INFO - Recall: 0.9649\n",
      "2025-02-19 09:24:53,246 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:24:53,247 - INFO - Accuracy: 0.5326\n",
      "2025-02-19 09:24:53,248 - INFO - F1_score: 0.4602\n",
      "2025-02-19 09:24:53,248 - INFO - Precision: 0.3095\n",
      "2025-02-19 09:24:53,249 - INFO - Recall: 0.8966\n",
      "2025-02-19 09:24:53,255 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:24:53,256 - INFO - Accuracy: 0.7778\n",
      "2025-02-19 09:24:53,256 - INFO - F1_score: 0.4630\n",
      "2025-02-19 09:24:53,258 - INFO - Precision: 0.3571\n",
      "2025-02-19 09:24:53,258 - INFO - Recall: 0.6579\n",
      "2025-02-19 09:24:53,264 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:24:53,265 - INFO - Accuracy: 0.7548\n",
      "2025-02-19 09:24:53,265 - INFO - F1_score: 0.4286\n",
      "2025-02-19 09:24:53,266 - INFO - Precision: 0.3077\n",
      "2025-02-19 09:24:53,267 - INFO - Recall: 0.7059\n",
      "2025-02-19 09:24:53,269 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:24:57,361 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:24:57,362 - INFO - Memory usage after evaluation end: 2359.23 MB\n",
      "2025-02-19 09:24:57,363 - INFO - Trial 5, Epoch 2: Loss = 1.3212, F1 = 0.4989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:27:13,248 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:27:13,250 - INFO - Memory usage after evaluation start: 2359.23 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.54it/s, Accuracy=69.27%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:27:20,532 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:27:20,539 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:27:20,539 - INFO - Accuracy: 0.5824\n",
      "2025-02-19 09:27:20,540 - INFO - F1_score: 0.5439\n",
      "2025-02-19 09:27:20,540 - INFO - Precision: 0.3939\n",
      "2025-02-19 09:27:20,541 - INFO - Recall: 0.8784\n",
      "2025-02-19 09:27:20,547 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:27:20,548 - INFO - Accuracy: 0.8391\n",
      "2025-02-19 09:27:20,549 - INFO - F1_score: 0.7200\n",
      "2025-02-19 09:27:20,549 - INFO - Precision: 0.5806\n",
      "2025-02-19 09:27:20,550 - INFO - Recall: 0.9474\n",
      "2025-02-19 09:27:20,557 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:27:20,557 - INFO - Accuracy: 0.6015\n",
      "2025-02-19 09:27:20,558 - INFO - F1_score: 0.4747\n",
      "2025-02-19 09:27:20,559 - INFO - Precision: 0.3357\n",
      "2025-02-19 09:27:20,560 - INFO - Recall: 0.8103\n",
      "2025-02-19 09:27:20,566 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:27:20,567 - INFO - Accuracy: 0.7165\n",
      "2025-02-19 09:27:20,568 - INFO - F1_score: 0.4127\n",
      "2025-02-19 09:27:20,569 - INFO - Precision: 0.2955\n",
      "2025-02-19 09:27:20,569 - INFO - Recall: 0.6842\n",
      "2025-02-19 09:27:20,576 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:27:20,576 - INFO - Accuracy: 0.7241\n",
      "2025-02-19 09:27:20,577 - INFO - F1_score: 0.4098\n",
      "2025-02-19 09:27:20,578 - INFO - Precision: 0.2841\n",
      "2025-02-19 09:27:20,578 - INFO - Recall: 0.7353\n",
      "2025-02-19 09:27:20,581 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:27:24,767 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:27:24,768 - INFO - Memory usage after evaluation end: 2364.93 MB\n",
      "2025-02-19 09:27:24,769 - INFO - Trial 5, Epoch 3: Loss = 1.2059, F1 = 0.5122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 09:27:26,601] Trial 5 finished with value: 0.5122430014825927 and parameters: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.1}. Best is trial 5 with value: 0.5122430014825927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:27:27,187 - INFO - Trial parameter set: {'batch_size': 4, 'learning_rate': 5e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-19 09:27:27,194 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:27:28,082 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 09:27:28,083 - INFO - Setting up data loaders...\n",
      "2025-02-19 09:27:28,084 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 09:27:28,086 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 09:27:28,087 - INFO - Created data loaders with batch size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:29:52,943 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:29:52,945 - INFO - Memory usage after evaluation start: 2367.12 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.43it/s, Accuracy=54.18%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:30:00,784 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:30:00,791 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:30:00,792 - INFO - Accuracy: 0.5019\n",
      "2025-02-19 09:30:00,793 - INFO - F1_score: 0.5000\n",
      "2025-02-19 09:30:00,794 - INFO - Precision: 0.3495\n",
      "2025-02-19 09:30:00,795 - INFO - Recall: 0.8784\n",
      "2025-02-19 09:30:00,801 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:30:00,802 - INFO - Accuracy: 0.8506\n",
      "2025-02-19 09:30:00,803 - INFO - F1_score: 0.6723\n",
      "2025-02-19 09:30:00,804 - INFO - Precision: 0.6452\n",
      "2025-02-19 09:30:00,805 - INFO - Recall: 0.7018\n",
      "2025-02-19 09:30:00,812 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:30:00,812 - INFO - Accuracy: 0.4138\n",
      "2025-02-19 09:30:00,813 - INFO - F1_score: 0.4183\n",
      "2025-02-19 09:30:00,814 - INFO - Precision: 0.2683\n",
      "2025-02-19 09:30:00,815 - INFO - Recall: 0.9483\n",
      "2025-02-19 09:30:00,821 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:30:00,822 - INFO - Accuracy: 0.3525\n",
      "2025-02-19 09:30:00,823 - INFO - F1_score: 0.2869\n",
      "2025-02-19 09:30:00,824 - INFO - Precision: 0.1709\n",
      "2025-02-19 09:30:00,824 - INFO - Recall: 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:30:00,834 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:30:00,834 - INFO - Accuracy: 0.5900\n",
      "2025-02-19 09:30:00,835 - INFO - F1_score: 0.3436\n",
      "2025-02-19 09:30:00,836 - INFO - Precision: 0.2171\n",
      "2025-02-19 09:30:00,836 - INFO - Recall: 0.8235\n",
      "2025-02-19 09:30:00,838 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 09:30:05,012 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:30:05,013 - INFO - Memory usage after evaluation end: 2370.86 MB\n",
      "2025-02-19 09:30:05,014 - INFO - Trial 6, Epoch 1: Loss = 1.5199, F1 = 0.4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:32:30,908 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:32:30,910 - INFO - Memory usage after evaluation start: 2370.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.44it/s, Accuracy=65.52%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:32:38,739 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:32:38,745 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:32:38,746 - INFO - Accuracy: 0.5364\n",
      "2025-02-19 09:32:38,747 - INFO - F1_score: 0.4895\n",
      "2025-02-19 09:32:38,747 - INFO - Precision: 0.3558\n",
      "2025-02-19 09:32:38,748 - INFO - Recall: 0.7838\n",
      "2025-02-19 09:32:38,755 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:32:38,756 - INFO - Accuracy: 0.8008\n",
      "2025-02-19 09:32:38,756 - INFO - F1_score: 0.6750\n",
      "2025-02-19 09:32:38,758 - INFO - Precision: 0.5243\n",
      "2025-02-19 09:32:38,759 - INFO - Recall: 0.9474\n",
      "2025-02-19 09:32:38,765 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:32:38,766 - INFO - Accuracy: 0.6245\n",
      "2025-02-19 09:32:38,767 - INFO - F1_score: 0.4948\n",
      "2025-02-19 09:32:38,767 - INFO - Precision: 0.3529\n",
      "2025-02-19 09:32:38,768 - INFO - Recall: 0.8276\n",
      "2025-02-19 09:32:38,775 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:32:38,775 - INFO - Accuracy: 0.6207\n",
      "2025-02-19 09:32:38,776 - INFO - F1_score: 0.3529\n",
      "2025-02-19 09:32:38,777 - INFO - Precision: 0.2348\n",
      "2025-02-19 09:32:38,778 - INFO - Recall: 0.7105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:32:38,786 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:32:38,787 - INFO - Accuracy: 0.6935\n",
      "2025-02-19 09:32:38,787 - INFO - F1_score: 0.3846\n",
      "2025-02-19 09:32:38,789 - INFO - Precision: 0.2604\n",
      "2025-02-19 09:32:38,789 - INFO - Recall: 0.7353\n",
      "2025-02-19 09:32:38,791 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 09:32:43,013 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:32:43,015 - INFO - Memory usage after evaluation end: 2344.84 MB\n",
      "2025-02-19 09:32:43,016 - INFO - Trial 6, Epoch 2: Loss = 1.2975, F1 = 0.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:35:09,150 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:35:09,152 - INFO - Memory usage after evaluation start: 2344.84 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.45it/s, Accuracy=65.29%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:35:16,970 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:35:16,976 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:35:16,977 - INFO - Accuracy: 0.5172\n",
      "2025-02-19 09:35:16,977 - INFO - F1_score: 0.5078\n",
      "2025-02-19 09:35:16,978 - INFO - Precision: 0.3571\n",
      "2025-02-19 09:35:16,979 - INFO - Recall: 0.8784\n",
      "2025-02-19 09:35:16,985 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:35:16,986 - INFO - Accuracy: 0.8199\n",
      "2025-02-19 09:35:16,986 - INFO - F1_score: 0.6968\n",
      "2025-02-19 09:35:16,987 - INFO - Precision: 0.5510\n",
      "2025-02-19 09:35:16,989 - INFO - Recall: 0.9474\n",
      "2025-02-19 09:35:16,995 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:35:16,996 - INFO - Accuracy: 0.4866\n",
      "2025-02-19 09:35:16,998 - INFO - F1_score: 0.4370\n",
      "2025-02-19 09:35:16,999 - INFO - Precision: 0.2889\n",
      "2025-02-19 09:35:17,000 - INFO - Recall: 0.8966\n",
      "2025-02-19 09:35:17,007 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:35:17,008 - INFO - Accuracy: 0.6782\n",
      "2025-02-19 09:35:17,008 - INFO - F1_score: 0.3636\n",
      "2025-02-19 09:35:17,009 - INFO - Precision: 0.2553\n",
      "2025-02-19 09:35:17,010 - INFO - Recall: 0.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:35:17,017 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:35:17,017 - INFO - Accuracy: 0.7625\n",
      "2025-02-19 09:35:17,018 - INFO - F1_score: 0.4364\n",
      "2025-02-19 09:35:17,020 - INFO - Precision: 0.3158\n",
      "2025-02-19 09:35:17,020 - INFO - Recall: 0.7059\n",
      "2025-02-19 09:35:17,022 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 09:35:21,306 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:35:21,308 - INFO - Memory usage after evaluation end: 2368.66 MB\n",
      "2025-02-19 09:35:21,309 - INFO - Trial 6, Epoch 3: Loss = 1.1415, F1 = 0.4883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 09:35:23,265] Trial 6 finished with value: 0.4883122966928707 and parameters: {'batch_size': 4, 'learning_rate': 5e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 5 with value: 0.5122430014825927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:35:23,889 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 5e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-19 09:35:23,893 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:35:24,765 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 09:35:24,766 - INFO - Setting up data loaders...\n",
      "2025-02-19 09:35:24,767 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 09:35:24,769 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 09:35:24,770 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:37:39,925 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:37:39,926 - INFO - Memory usage after evaluation start: 2477.98 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.54it/s, Accuracy=52.72%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:37:47,204 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:37:47,211 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:37:47,211 - INFO - Accuracy: 0.5479\n",
      "2025-02-19 09:37:47,212 - INFO - F1_score: 0.5042\n",
      "2025-02-19 09:37:47,212 - INFO - Precision: 0.3659\n",
      "2025-02-19 09:37:47,213 - INFO - Recall: 0.8108\n",
      "2025-02-19 09:37:47,220 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:37:47,221 - INFO - Accuracy: 0.7203\n",
      "2025-02-19 09:37:47,221 - INFO - F1_score: 0.6011\n",
      "2025-02-19 09:37:47,223 - INFO - Precision: 0.4365\n",
      "2025-02-19 09:37:47,224 - INFO - Recall: 0.9649\n",
      "2025-02-19 09:37:47,230 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:37:47,230 - INFO - Accuracy: 0.3103\n",
      "2025-02-19 09:37:47,231 - INFO - F1_score: 0.3617\n",
      "2025-02-19 09:37:47,233 - INFO - Precision: 0.2277\n",
      "2025-02-19 09:37:47,233 - INFO - Recall: 0.8793\n",
      "2025-02-19 09:37:47,239 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:37:47,239 - INFO - Accuracy: 0.5249\n",
      "2025-02-19 09:37:47,240 - INFO - F1_score: 0.3261\n",
      "2025-02-19 09:37:47,241 - INFO - Precision: 0.2055\n",
      "2025-02-19 09:37:47,241 - INFO - Recall: 0.7895\n",
      "2025-02-19 09:37:47,248 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:37:47,248 - INFO - Accuracy: 0.5326\n",
      "2025-02-19 09:37:47,249 - INFO - F1_score: 0.3222\n",
      "2025-02-19 09:37:47,249 - INFO - Precision: 0.1986\n",
      "2025-02-19 09:37:47,250 - INFO - Recall: 0.8529\n",
      "2025-02-19 09:37:47,252 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:37:51,474 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:37:51,476 - INFO - Memory usage after evaluation end: 2482.52 MB\n",
      "2025-02-19 09:37:51,477 - INFO - Trial 7, Epoch 1: Loss = 1.5323, F1 = 0.4231\n",
      "2025-02-19 09:37:51,479 - ERROR - Error in trial training: \n",
      "2025-02-19 09:37:52,242 - ERROR - Error in optimization objective: \n",
      "2025-02-19 09:37:52,244 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 09:37:52,245] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:37:52,908 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.15}\n",
      "2025-02-19 09:37:52,912 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:37:53,780 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 09:37:53,781 - INFO - Setting up data loaders...\n",
      "2025-02-19 09:37:53,782 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 09:37:53,784 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 09:37:53,785 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:40:38,216 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:40:38,219 - INFO - Memory usage after evaluation start: 2670.25 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.55it/s, Accuracy=63.98%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:40:46,140 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:40:46,146 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:40:46,147 - INFO - Accuracy: 0.7050\n",
      "2025-02-19 09:40:46,147 - INFO - F1_score: 0.5276\n",
      "2025-02-19 09:40:46,148 - INFO - Precision: 0.4831\n",
      "2025-02-19 09:40:46,150 - INFO - Recall: 0.5811\n",
      "2025-02-19 09:40:46,155 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:40:46,156 - INFO - Accuracy: 0.7356\n",
      "2025-02-19 09:40:46,156 - INFO - F1_score: 0.6145\n",
      "2025-02-19 09:40:46,157 - INFO - Precision: 0.4508\n",
      "2025-02-19 09:40:46,158 - INFO - Recall: 0.9649\n",
      "2025-02-19 09:40:46,164 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:40:46,165 - INFO - Accuracy: 0.5824\n",
      "2025-02-19 09:40:46,165 - INFO - F1_score: 0.4734\n",
      "2025-02-19 09:40:46,166 - INFO - Precision: 0.3289\n",
      "2025-02-19 09:40:46,167 - INFO - Recall: 0.8448\n",
      "2025-02-19 09:40:46,173 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:40:46,173 - INFO - Accuracy: 0.6858\n",
      "2025-02-19 09:40:46,174 - INFO - F1_score: 0.3881\n",
      "2025-02-19 09:40:46,175 - INFO - Precision: 0.2708\n",
      "2025-02-19 09:40:46,176 - INFO - Recall: 0.6842\n",
      "2025-02-19 09:40:46,182 - INFO - \n",
      "Metrics for Romantis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:40:46,183 - INFO - Accuracy: 0.4904\n",
      "2025-02-19 09:40:46,183 - INFO - F1_score: 0.3179\n",
      "2025-02-19 09:40:46,184 - INFO - Precision: 0.1925\n",
      "2025-02-19 09:40:46,185 - INFO - Recall: 0.9118\n",
      "2025-02-19 09:40:46,187 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 09:40:50,177 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:40:50,178 - INFO - Memory usage after evaluation end: 2688.80 MB\n",
      "2025-02-19 09:40:50,179 - INFO - Trial 8, Epoch 1: Loss = 1.4403, F1 = 0.4643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:43:35,458 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:43:35,460 - INFO - Memory usage after evaluation start: 2688.93 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.55it/s, Accuracy=62.68%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:43:43,379 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:43:43,385 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:43:43,386 - INFO - Accuracy: 0.3985\n",
      "2025-02-19 09:43:43,387 - INFO - F1_score: 0.4714\n",
      "2025-02-19 09:43:43,388 - INFO - Precision: 0.3139\n",
      "2025-02-19 09:43:43,389 - INFO - Recall: 0.9459\n",
      "2025-02-19 09:43:43,395 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:43:43,395 - INFO - Accuracy: 0.8736\n",
      "2025-02-19 09:43:43,396 - INFO - F1_score: 0.7481\n",
      "2025-02-19 09:43:43,396 - INFO - Precision: 0.6622\n",
      "2025-02-19 09:43:43,397 - INFO - Recall: 0.8596\n",
      "2025-02-19 09:43:43,404 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:43:43,404 - INFO - Accuracy: 0.5785\n",
      "2025-02-19 09:43:43,405 - INFO - F1_score: 0.4608\n",
      "2025-02-19 09:43:43,406 - INFO - Precision: 0.3219\n",
      "2025-02-19 09:43:43,406 - INFO - Recall: 0.8103\n",
      "2025-02-19 09:43:43,413 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:43:43,414 - INFO - Accuracy: 0.5709\n",
      "2025-02-19 09:43:43,414 - INFO - F1_score: 0.3488\n",
      "2025-02-19 09:43:43,415 - INFO - Precision: 0.2239\n",
      "2025-02-19 09:43:43,416 - INFO - Recall: 0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:43:43,423 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:43:43,424 - INFO - Accuracy: 0.7126\n",
      "2025-02-19 09:43:43,425 - INFO - F1_score: 0.3697\n",
      "2025-02-19 09:43:43,425 - INFO - Precision: 0.2588\n",
      "2025-02-19 09:43:43,426 - INFO - Recall: 0.6471\n",
      "2025-02-19 09:43:43,429 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 09:43:47,470 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:43:47,471 - INFO - Memory usage after evaluation end: 2694.57 MB\n",
      "2025-02-19 09:43:47,473 - INFO - Trial 8, Epoch 2: Loss = 1.2426, F1 = 0.4798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:46:32,738 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:46:32,741 - INFO - Memory usage after evaluation start: 2694.57 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.53it/s, Accuracy=68.28%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:46:40,668 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:46:40,674 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:46:40,675 - INFO - Accuracy: 0.5134\n",
      "2025-02-19 09:46:40,676 - INFO - F1_score: 0.4940\n",
      "2025-02-19 09:46:40,676 - INFO - Precision: 0.3503\n",
      "2025-02-19 09:46:40,678 - INFO - Recall: 0.8378\n",
      "2025-02-19 09:46:40,684 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:46:40,684 - INFO - Accuracy: 0.8161\n",
      "2025-02-19 09:46:40,685 - INFO - F1_score: 0.6842\n",
      "2025-02-19 09:46:40,686 - INFO - Precision: 0.5474\n",
      "2025-02-19 09:46:40,687 - INFO - Recall: 0.9123\n",
      "2025-02-19 09:46:40,693 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:46:40,694 - INFO - Accuracy: 0.6130\n",
      "2025-02-19 09:46:40,694 - INFO - F1_score: 0.4925\n",
      "2025-02-19 09:46:40,695 - INFO - Precision: 0.3475\n",
      "2025-02-19 09:46:40,695 - INFO - Recall: 0.8448\n",
      "2025-02-19 09:46:40,702 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:46:40,702 - INFO - Accuracy: 0.7088\n",
      "2025-02-19 09:46:40,703 - INFO - F1_score: 0.3667\n",
      "2025-02-19 09:46:40,703 - INFO - Precision: 0.2683\n",
      "2025-02-19 09:46:40,705 - INFO - Recall: 0.5789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:46:40,712 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:46:40,713 - INFO - Accuracy: 0.7625\n",
      "2025-02-19 09:46:40,714 - INFO - F1_score: 0.4561\n",
      "2025-02-19 09:46:40,714 - INFO - Precision: 0.3250\n",
      "2025-02-19 09:46:40,715 - INFO - Recall: 0.7647\n",
      "2025-02-19 09:46:40,717 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 09:46:44,780 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:46:44,782 - INFO - Memory usage after evaluation end: 2700.21 MB\n",
      "2025-02-19 09:46:44,783 - INFO - Trial 8, Epoch 3: Loss = 1.1345, F1 = 0.4987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 09:46:46,898] Trial 8 finished with value: 0.49870075195998165 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.15}. Best is trial 5 with value: 0.5122430014825927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:46:47,600 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 5e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-19 09:46:47,606 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:46:48,530 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 09:46:48,531 - INFO - Setting up data loaders...\n",
      "2025-02-19 09:46:48,532 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 09:46:48,535 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 09:46:48,536 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:49:06,028 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:49:06,030 - INFO - Memory usage after evaluation start: 2849.62 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.45it/s, Accuracy=52.72%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:49:13,454 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:49:13,461 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:49:13,461 - INFO - Accuracy: 0.4636\n",
      "2025-02-19 09:49:13,462 - INFO - F1_score: 0.4776\n",
      "2025-02-19 09:49:13,463 - INFO - Precision: 0.3299\n",
      "2025-02-19 09:49:13,464 - INFO - Recall: 0.8649\n",
      "2025-02-19 09:49:13,470 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:49:13,471 - INFO - Accuracy: 0.3908\n",
      "2025-02-19 09:49:13,471 - INFO - F1_score: 0.4133\n",
      "2025-02-19 09:49:13,472 - INFO - Precision: 0.2617\n",
      "2025-02-19 09:49:13,473 - INFO - Recall: 0.9825\n",
      "2025-02-19 09:49:13,479 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:49:13,480 - INFO - Accuracy: 0.4636\n",
      "2025-02-19 09:49:13,480 - INFO - F1_score: 0.4167\n",
      "2025-02-19 09:49:13,481 - INFO - Precision: 0.2747\n",
      "2025-02-19 09:49:13,482 - INFO - Recall: 0.8621\n",
      "2025-02-19 09:49:13,488 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:49:13,489 - INFO - Accuracy: 0.5096\n",
      "2025-02-19 09:49:13,490 - INFO - F1_score: 0.3191\n",
      "2025-02-19 09:49:13,490 - INFO - Precision: 0.2000\n",
      "2025-02-19 09:49:13,491 - INFO - Recall: 0.7895\n",
      "2025-02-19 09:49:13,497 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:49:13,498 - INFO - Accuracy: 0.8084\n",
      "2025-02-19 09:49:13,499 - INFO - F1_score: 0.4048\n",
      "2025-02-19 09:49:13,500 - INFO - Precision: 0.3400\n",
      "2025-02-19 09:49:13,501 - INFO - Recall: 0.5000\n",
      "2025-02-19 09:49:13,503 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:49:17,352 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:49:17,354 - INFO - Memory usage after evaluation end: 2854.12 MB\n",
      "2025-02-19 09:49:17,355 - INFO - Trial 9, Epoch 1: Loss = 1.5398, F1 = 0.4063\n",
      "2025-02-19 09:49:17,357 - ERROR - Error in trial training: \n",
      "2025-02-19 09:49:18,219 - ERROR - Error in optimization objective: \n",
      "2025-02-19 09:49:18,220 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 09:49:18,222] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:49:18,958 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 3e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-19 09:49:18,962 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:49:19,927 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 09:49:19,928 - INFO - Setting up data loaders...\n",
      "2025-02-19 09:49:19,928 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 09:49:19,930 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 09:49:19,932 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:51:38,953 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:51:38,955 - INFO - Memory usage after evaluation start: 2857.90 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.43it/s, Accuracy=60.31%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:51:46,401 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:51:46,408 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:51:46,408 - INFO - Accuracy: 0.5096\n",
      "2025-02-19 09:51:46,409 - INFO - F1_score: 0.5039\n",
      "2025-02-19 09:51:46,410 - INFO - Precision: 0.3533\n",
      "2025-02-19 09:51:46,411 - INFO - Recall: 0.8784\n",
      "2025-02-19 09:51:46,418 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:51:46,418 - INFO - Accuracy: 0.7126\n",
      "2025-02-19 09:51:46,419 - INFO - F1_score: 0.5399\n",
      "2025-02-19 09:51:46,420 - INFO - Precision: 0.4151\n",
      "2025-02-19 09:51:46,421 - INFO - Recall: 0.7719\n",
      "2025-02-19 09:51:46,428 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:51:46,428 - INFO - Accuracy: 0.5939\n",
      "2025-02-19 09:51:46,429 - INFO - F1_score: 0.4592\n",
      "2025-02-19 09:51:46,431 - INFO - Precision: 0.3261\n",
      "2025-02-19 09:51:46,431 - INFO - Recall: 0.7759\n",
      "2025-02-19 09:51:46,437 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:51:46,438 - INFO - Accuracy: 0.4559\n",
      "2025-02-19 09:51:46,438 - INFO - F1_score: 0.2970\n",
      "2025-02-19 09:51:46,439 - INFO - Precision: 0.1829\n",
      "2025-02-19 09:51:46,440 - INFO - Recall: 0.7895\n",
      "2025-02-19 09:51:46,446 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:51:46,447 - INFO - Accuracy: 0.7433\n",
      "2025-02-19 09:51:46,448 - INFO - F1_score: 0.3495\n",
      "2025-02-19 09:51:46,449 - INFO - Precision: 0.2609\n",
      "2025-02-19 09:51:46,451 - INFO - Recall: 0.5294\n",
      "2025-02-19 09:51:46,452 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:51:50,279 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:51:50,280 - INFO - Memory usage after evaluation end: 2861.52 MB\n",
      "2025-02-19 09:51:50,282 - INFO - Trial 10, Epoch 1: Loss = 1.5632, F1 = 0.4299\n",
      "2025-02-19 09:51:50,283 - ERROR - Error in trial training: \n",
      "2025-02-19 09:51:51,147 - ERROR - Error in optimization objective: \n",
      "2025-02-19 09:51:51,148 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 09:51:51,149] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:51:51,874 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}\n",
      "2025-02-19 09:51:51,878 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:51:52,847 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 09:51:52,848 - INFO - Setting up data loaders...\n",
      "2025-02-19 09:51:52,848 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 09:51:52,851 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 09:51:52,852 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:54:40,515 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:54:40,517 - INFO - Memory usage after evaluation start: 2874.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:08<00:00, 16.26it/s, Accuracy=61.15%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:54:48,578 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:54:48,585 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:54:48,585 - INFO - Accuracy: 0.5287\n",
      "2025-02-19 09:54:48,586 - INFO - F1_score: 0.4896\n",
      "2025-02-19 09:54:48,586 - INFO - Precision: 0.3533\n",
      "2025-02-19 09:54:48,588 - INFO - Recall: 0.7973\n",
      "2025-02-19 09:54:48,593 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:54:48,594 - INFO - Accuracy: 0.8544\n",
      "2025-02-19 09:54:48,594 - INFO - F1_score: 0.7206\n",
      "2025-02-19 09:54:48,595 - INFO - Precision: 0.6203\n",
      "2025-02-19 09:54:48,596 - INFO - Recall: 0.8596\n",
      "2025-02-19 09:54:48,603 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:54:48,603 - INFO - Accuracy: 0.3142\n",
      "2025-02-19 09:54:48,604 - INFO - F1_score: 0.3849\n",
      "2025-02-19 09:54:48,605 - INFO - Precision: 0.2403\n",
      "2025-02-19 09:54:48,606 - INFO - Recall: 0.9655\n",
      "2025-02-19 09:54:48,611 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:54:48,612 - INFO - Accuracy: 0.6513\n",
      "2025-02-19 09:54:48,613 - INFO - F1_score: 0.3636\n",
      "2025-02-19 09:54:48,613 - INFO - Precision: 0.2476\n",
      "2025-02-19 09:54:48,614 - INFO - Recall: 0.6842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:54:48,622 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:54:48,622 - INFO - Accuracy: 0.7088\n",
      "2025-02-19 09:54:48,623 - INFO - F1_score: 0.4154\n",
      "2025-02-19 09:54:48,624 - INFO - Precision: 0.2812\n",
      "2025-02-19 09:54:48,625 - INFO - Recall: 0.7941\n",
      "2025-02-19 09:54:48,627 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 09:54:52,434 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:54:52,436 - INFO - Memory usage after evaluation end: 2878.74 MB\n",
      "2025-02-19 09:54:52,437 - INFO - Trial 11, Epoch 1: Loss = 1.4629, F1 = 0.4748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:57:40,712 - INFO - Starting model evaluation...\n",
      "2025-02-19 09:57:40,714 - INFO - Memory usage after evaluation start: 2878.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:08<00:00, 16.32it/s, Accuracy=63.91%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:57:48,747 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 09:57:48,753 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 09:57:48,753 - INFO - Accuracy: 0.5211\n",
      "2025-02-19 09:57:48,754 - INFO - F1_score: 0.4898\n",
      "2025-02-19 09:57:48,755 - INFO - Precision: 0.3509\n",
      "2025-02-19 09:57:48,756 - INFO - Recall: 0.8108\n",
      "2025-02-19 09:57:48,763 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 09:57:48,763 - INFO - Accuracy: 0.8161\n",
      "2025-02-19 09:57:48,764 - INFO - F1_score: 0.6883\n",
      "2025-02-19 09:57:48,765 - INFO - Precision: 0.5464\n",
      "2025-02-19 09:57:48,766 - INFO - Recall: 0.9298\n",
      "2025-02-19 09:57:48,773 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 09:57:48,773 - INFO - Accuracy: 0.3985\n",
      "2025-02-19 09:57:48,774 - INFO - F1_score: 0.4030\n",
      "2025-02-19 09:57:48,774 - INFO - Precision: 0.2585\n",
      "2025-02-19 09:57:48,775 - INFO - Recall: 0.9138\n",
      "2025-02-19 09:57:48,782 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 09:57:48,783 - INFO - Accuracy: 0.7816\n",
      "2025-02-19 09:57:48,784 - INFO - F1_score: 0.4124\n",
      "2025-02-19 09:57:48,785 - INFO - Precision: 0.3390\n",
      "2025-02-19 09:57:48,786 - INFO - Recall: 0.5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 09:57:48,793 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 09:57:48,794 - INFO - Accuracy: 0.6782\n",
      "2025-02-19 09:57:48,795 - INFO - F1_score: 0.3731\n",
      "2025-02-19 09:57:48,795 - INFO - Precision: 0.2500\n",
      "2025-02-19 09:57:48,796 - INFO - Recall: 0.7353\n",
      "2025-02-19 09:57:48,798 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 09:57:52,587 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 09:57:52,589 - INFO - Memory usage after evaluation end: 2884.36 MB\n",
      "2025-02-19 09:57:52,590 - INFO - Trial 11, Epoch 2: Loss = 1.2498, F1 = 0.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:00:40,649 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:00:40,651 - INFO - Memory usage after evaluation start: 2884.61 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:08<00:00, 16.29it/s, Accuracy=68.66%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:00:48,696 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:00:48,701 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:00:48,702 - INFO - Accuracy: 0.5211\n",
      "2025-02-19 10:00:48,703 - INFO - F1_score: 0.5098\n",
      "2025-02-19 10:00:48,704 - INFO - Precision: 0.3591\n",
      "2025-02-19 10:00:48,705 - INFO - Recall: 0.8784\n",
      "2025-02-19 10:00:48,711 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:00:48,711 - INFO - Accuracy: 0.7931\n",
      "2025-02-19 10:00:48,712 - INFO - F1_score: 0.6538\n",
      "2025-02-19 10:00:48,713 - INFO - Precision: 0.5152\n",
      "2025-02-19 10:00:48,713 - INFO - Recall: 0.8947\n",
      "2025-02-19 10:00:48,719 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:00:48,720 - INFO - Accuracy: 0.6360\n",
      "2025-02-19 10:00:48,720 - INFO - F1_score: 0.4809\n",
      "2025-02-19 10:00:48,721 - INFO - Precision: 0.3520\n",
      "2025-02-19 10:00:48,722 - INFO - Recall: 0.7586\n",
      "2025-02-19 10:00:48,728 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:00:48,728 - INFO - Accuracy: 0.7510\n",
      "2025-02-19 10:00:48,729 - INFO - F1_score: 0.4144\n",
      "2025-02-19 10:00:48,730 - INFO - Precision: 0.3151\n",
      "2025-02-19 10:00:48,731 - INFO - Recall: 0.6053\n",
      "2025-02-19 10:00:48,737 - INFO - \n",
      "Metrics for Romantis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:00:48,738 - INFO - Accuracy: 0.7318\n",
      "2025-02-19 10:00:48,739 - INFO - F1_score: 0.4531\n",
      "2025-02-19 10:00:48,740 - INFO - Precision: 0.3085\n",
      "2025-02-19 10:00:48,742 - INFO - Recall: 0.8529\n",
      "2025-02-19 10:00:48,743 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:00:52,525 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:00:52,527 - INFO - Memory usage after evaluation end: 2890.24 MB\n",
      "2025-02-19 10:00:52,527 - INFO - Trial 11, Epoch 3: Loss = 1.0898, F1 = 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 10:00:54,854] Trial 11 finished with value: 0.5024127613538173 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}. Best is trial 5 with value: 0.5122430014825927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:00:55,609 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-19 10:00:55,613 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:00:56,543 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 10:00:56,544 - INFO - Setting up data loaders...\n",
      "2025-02-19 10:00:56,545 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 10:00:56,547 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 10:00:56,548 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:03:44,174 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:03:44,176 - INFO - Memory usage after evaluation start: 2979.46 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:08<00:00, 16.18it/s, Accuracy=71.80%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:03:52,277 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:03:52,283 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:03:52,284 - INFO - Accuracy: 0.6513\n",
      "2025-02-19 10:03:52,284 - INFO - F1_score: 0.5517\n",
      "2025-02-19 10:03:52,285 - INFO - Precision: 0.4341\n",
      "2025-02-19 10:03:52,286 - INFO - Recall: 0.7568\n",
      "2025-02-19 10:03:52,292 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:03:52,293 - INFO - Accuracy: 0.7893\n",
      "2025-02-19 10:03:52,293 - INFO - F1_score: 0.6541\n",
      "2025-02-19 10:03:52,294 - INFO - Precision: 0.5098\n",
      "2025-02-19 10:03:52,295 - INFO - Recall: 0.9123\n",
      "2025-02-19 10:03:52,302 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:03:52,302 - INFO - Accuracy: 0.7241\n",
      "2025-02-19 10:03:52,303 - INFO - F1_score: 0.5610\n",
      "2025-02-19 10:03:52,303 - INFO - Precision: 0.4340\n",
      "2025-02-19 10:03:52,304 - INFO - Recall: 0.7931\n",
      "2025-02-19 10:03:52,310 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:03:52,311 - INFO - Accuracy: 0.7433\n",
      "2025-02-19 10:03:52,311 - INFO - F1_score: 0.3964\n",
      "2025-02-19 10:03:52,312 - INFO - Precision: 0.3014\n",
      "2025-02-19 10:03:52,312 - INFO - Recall: 0.5789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:03:52,320 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:03:52,321 - INFO - Accuracy: 0.6820\n",
      "2025-02-19 10:03:52,321 - INFO - F1_score: 0.3759\n",
      "2025-02-19 10:03:52,322 - INFO - Precision: 0.2525\n",
      "2025-02-19 10:03:52,324 - INFO - Recall: 0.7353\n",
      "2025-02-19 10:03:52,325 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:03:56,309 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:03:56,310 - INFO - Memory usage after evaluation end: 2984.09 MB\n",
      "2025-02-19 10:03:56,311 - INFO - Trial 12, Epoch 1: Loss = 1.4341, F1 = 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:06:43,219 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:06:43,221 - INFO - Memory usage after evaluation start: 2984.21 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.53it/s, Accuracy=70.65%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:06:51,148 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:06:51,154 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:06:51,155 - INFO - Accuracy: 0.5594\n",
      "2025-02-19 10:06:51,156 - INFO - F1_score: 0.5306\n",
      "2025-02-19 10:06:51,156 - INFO - Precision: 0.3801\n",
      "2025-02-19 10:06:51,157 - INFO - Recall: 0.8784\n",
      "2025-02-19 10:06:51,164 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:06:51,165 - INFO - Accuracy: 0.8161\n",
      "2025-02-19 10:06:51,165 - INFO - F1_score: 0.6883\n",
      "2025-02-19 10:06:51,167 - INFO - Precision: 0.5464\n",
      "2025-02-19 10:06:51,167 - INFO - Recall: 0.9298\n",
      "2025-02-19 10:06:51,173 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:06:51,174 - INFO - Accuracy: 0.6475\n",
      "2025-02-19 10:06:51,175 - INFO - F1_score: 0.5208\n",
      "2025-02-19 10:06:51,175 - INFO - Precision: 0.3731\n",
      "2025-02-19 10:06:51,177 - INFO - Recall: 0.8621\n",
      "2025-02-19 10:06:51,182 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:06:51,183 - INFO - Accuracy: 0.7050\n",
      "2025-02-19 10:06:51,184 - INFO - F1_score: 0.3937\n",
      "2025-02-19 10:06:51,185 - INFO - Precision: 0.2809\n",
      "2025-02-19 10:06:51,186 - INFO - Recall: 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:06:51,192 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:06:51,193 - INFO - Accuracy: 0.8046\n",
      "2025-02-19 10:06:51,194 - INFO - F1_score: 0.4632\n",
      "2025-02-19 10:06:51,195 - INFO - Precision: 0.3607\n",
      "2025-02-19 10:06:51,196 - INFO - Recall: 0.6471\n",
      "2025-02-19 10:06:51,198 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:06:55,063 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:06:55,065 - INFO - Memory usage after evaluation end: 2989.84 MB\n",
      "2025-02-19 10:06:55,066 - INFO - Trial 12, Epoch 2: Loss = 1.1741, F1 = 0.5193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:09:40,696 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:09:40,698 - INFO - Memory usage after evaluation start: 2989.96 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.52it/s, Accuracy=70.57%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:09:48,631 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:09:48,637 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:09:48,638 - INFO - Accuracy: 0.6437\n",
      "2025-02-19 10:09:48,639 - INFO - F1_score: 0.5419\n",
      "2025-02-19 10:09:48,640 - INFO - Precision: 0.4264\n",
      "2025-02-19 10:09:48,641 - INFO - Recall: 0.7432\n",
      "2025-02-19 10:09:48,647 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:09:48,648 - INFO - Accuracy: 0.6858\n",
      "2025-02-19 10:09:48,648 - INFO - F1_score: 0.5729\n",
      "2025-02-19 10:09:48,649 - INFO - Precision: 0.4074\n",
      "2025-02-19 10:09:48,649 - INFO - Recall: 0.9649\n",
      "2025-02-19 10:09:48,656 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:09:48,656 - INFO - Accuracy: 0.5900\n",
      "2025-02-19 10:09:48,657 - INFO - F1_score: 0.4880\n",
      "2025-02-19 10:09:48,657 - INFO - Precision: 0.3377\n",
      "2025-02-19 10:09:48,658 - INFO - Recall: 0.8793\n",
      "2025-02-19 10:09:48,664 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:09:48,665 - INFO - Accuracy: 0.7931\n",
      "2025-02-19 10:09:48,666 - INFO - F1_score: 0.3077\n",
      "2025-02-19 10:09:48,666 - INFO - Precision: 0.3000\n",
      "2025-02-19 10:09:48,668 - INFO - Recall: 0.3158\n",
      "2025-02-19 10:09:48,674 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:09:48,674 - INFO - Accuracy: 0.8161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:09:48,675 - INFO - F1_score: 0.5000\n",
      "2025-02-19 10:09:48,676 - INFO - Precision: 0.3871\n",
      "2025-02-19 10:09:48,677 - INFO - Recall: 0.7059\n",
      "2025-02-19 10:09:48,679 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:09:52,673 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:09:52,674 - INFO - Memory usage after evaluation end: 2995.46 MB\n",
      "2025-02-19 10:09:52,675 - INFO - Trial 12, Epoch 3: Loss = 0.9537, F1 = 0.4821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 10:09:55,202] Trial 12 finished with value: 0.5193231897362796 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 12 with value: 0.5193231897362796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:09:56,022 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-19 10:09:56,027 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:09:56,979 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 10:09:56,980 - INFO - Setting up data loaders...\n",
      "2025-02-19 10:09:56,980 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 10:09:56,982 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 10:09:56,983 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:12:41,502 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:12:41,503 - INFO - Memory usage after evaluation start: 3186.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.55it/s, Accuracy=66.36%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:12:49,424 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:12:49,431 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:12:49,431 - INFO - Accuracy: 0.5441\n",
      "2025-02-19 10:12:49,432 - INFO - F1_score: 0.4936\n",
      "2025-02-19 10:12:49,432 - INFO - Precision: 0.3602\n",
      "2025-02-19 10:12:49,433 - INFO - Recall: 0.7838\n",
      "2025-02-19 10:12:49,439 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:12:49,440 - INFO - Accuracy: 0.7969\n",
      "2025-02-19 10:12:49,441 - INFO - F1_score: 0.6708\n",
      "2025-02-19 10:12:49,442 - INFO - Precision: 0.5192\n",
      "2025-02-19 10:12:49,443 - INFO - Recall: 0.9474\n",
      "2025-02-19 10:12:49,449 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:12:49,450 - INFO - Accuracy: 0.5057\n",
      "2025-02-19 10:12:49,451 - INFO - F1_score: 0.4367\n",
      "2025-02-19 10:12:49,451 - INFO - Precision: 0.2924\n",
      "2025-02-19 10:12:49,452 - INFO - Recall: 0.8621\n",
      "2025-02-19 10:12:49,458 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:12:49,459 - INFO - Accuracy: 0.6667\n",
      "2025-02-19 10:12:49,459 - INFO - F1_score: 0.3650\n",
      "2025-02-19 10:12:49,460 - INFO - Precision: 0.2525\n",
      "2025-02-19 10:12:49,461 - INFO - Recall: 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:12:49,468 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:12:49,469 - INFO - Accuracy: 0.8046\n",
      "2025-02-19 10:12:49,470 - INFO - F1_score: 0.4632\n",
      "2025-02-19 10:12:49,471 - INFO - Precision: 0.3607\n",
      "2025-02-19 10:12:49,473 - INFO - Recall: 0.6471\n",
      "2025-02-19 10:12:49,475 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:12:53,403 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:12:53,405 - INFO - Memory usage after evaluation end: 3190.66 MB\n",
      "2025-02-19 10:12:53,407 - INFO - Trial 13, Epoch 1: Loss = 1.4711, F1 = 0.4858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:15:38,920 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:15:38,922 - INFO - Memory usage after evaluation start: 3190.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.53it/s, Accuracy=68.28%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:15:46,849 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:15:46,855 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:15:46,856 - INFO - Accuracy: 0.4828\n",
      "2025-02-19 10:15:46,856 - INFO - F1_score: 0.4788\n",
      "2025-02-19 10:15:46,857 - INFO - Precision: 0.3351\n",
      "2025-02-19 10:15:46,858 - INFO - Recall: 0.8378\n",
      "2025-02-19 10:15:46,864 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:15:46,865 - INFO - Accuracy: 0.7433\n",
      "2025-02-19 10:15:46,866 - INFO - F1_score: 0.6171\n",
      "2025-02-19 10:15:46,866 - INFO - Precision: 0.4576\n",
      "2025-02-19 10:15:46,867 - INFO - Recall: 0.9474\n",
      "2025-02-19 10:15:46,874 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:15:46,875 - INFO - Accuracy: 0.6475\n",
      "2025-02-19 10:15:46,875 - INFO - F1_score: 0.4889\n",
      "2025-02-19 10:15:46,876 - INFO - Precision: 0.3607\n",
      "2025-02-19 10:15:46,877 - INFO - Recall: 0.7586\n",
      "2025-02-19 10:15:46,883 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:15:46,884 - INFO - Accuracy: 0.6782\n",
      "2025-02-19 10:15:46,885 - INFO - F1_score: 0.3731\n",
      "2025-02-19 10:15:46,886 - INFO - Precision: 0.2604\n",
      "2025-02-19 10:15:46,887 - INFO - Recall: 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:15:46,893 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:15:46,894 - INFO - Accuracy: 0.8621\n",
      "2025-02-19 10:15:46,895 - INFO - F1_score: 0.5385\n",
      "2025-02-19 10:15:46,896 - INFO - Precision: 0.4773\n",
      "2025-02-19 10:15:46,897 - INFO - Recall: 0.6176\n",
      "2025-02-19 10:15:46,899 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:15:50,873 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:15:50,875 - INFO - Memory usage after evaluation end: 3196.41 MB\n",
      "2025-02-19 10:15:50,876 - INFO - Trial 13, Epoch 2: Loss = 1.2497, F1 = 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:18:36,350 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:18:36,351 - INFO - Memory usage after evaluation start: 3196.53 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.51it/s, Accuracy=68.12%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:18:44,291 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:18:44,297 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:18:44,298 - INFO - Accuracy: 0.3831\n",
      "2025-02-19 10:18:44,299 - INFO - F1_score: 0.4615\n",
      "2025-02-19 10:18:44,300 - INFO - Precision: 0.3067\n",
      "2025-02-19 10:18:44,301 - INFO - Recall: 0.9324\n",
      "2025-02-19 10:18:44,306 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:18:44,307 - INFO - Accuracy: 0.7854\n",
      "2025-02-19 10:18:44,307 - INFO - F1_score: 0.6456\n",
      "2025-02-19 10:18:44,308 - INFO - Precision: 0.5050\n",
      "2025-02-19 10:18:44,309 - INFO - Recall: 0.8947\n",
      "2025-02-19 10:18:44,315 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:18:44,316 - INFO - Accuracy: 0.6820\n",
      "2025-02-19 10:18:44,317 - INFO - F1_score: 0.5257\n",
      "2025-02-19 10:18:44,317 - INFO - Precision: 0.3932\n",
      "2025-02-19 10:18:44,318 - INFO - Recall: 0.7931\n",
      "2025-02-19 10:18:44,325 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:18:44,325 - INFO - Accuracy: 0.7011\n",
      "2025-02-19 10:18:44,326 - INFO - F1_score: 0.3710\n",
      "2025-02-19 10:18:44,326 - INFO - Precision: 0.2674\n",
      "2025-02-19 10:18:44,327 - INFO - Recall: 0.6053\n",
      "2025-02-19 10:18:44,333 - INFO - \n",
      "Metrics for Romantis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:18:44,334 - INFO - Accuracy: 0.8544\n",
      "2025-02-19 10:18:44,335 - INFO - F1_score: 0.5250\n",
      "2025-02-19 10:18:44,335 - INFO - Precision: 0.4565\n",
      "2025-02-19 10:18:44,336 - INFO - Recall: 0.6176\n",
      "2025-02-19 10:18:44,339 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:18:48,281 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:18:48,282 - INFO - Memory usage after evaluation end: 3202.03 MB\n",
      "2025-02-19 10:18:48,283 - INFO - Trial 13, Epoch 3: Loss = 1.1018, F1 = 0.5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 10:18:50,957] Trial 13 finished with value: 0.5057580218882791 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}. Best is trial 12 with value: 0.5193231897362796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:18:51,825 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-19 10:18:51,830 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:18:52,871 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 10:18:52,873 - INFO - Setting up data loaders...\n",
      "2025-02-19 10:18:52,873 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 10:18:52,875 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 10:18:52,878 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:21:37,203 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:21:37,204 - INFO - Memory usage after evaluation start: 3269.64 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.56it/s, Accuracy=64.29%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:21:45,122 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:21:45,128 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:21:45,129 - INFO - Accuracy: 0.5709\n",
      "2025-02-19 10:21:45,129 - INFO - F1_score: 0.5294\n",
      "2025-02-19 10:21:45,130 - INFO - Precision: 0.3841\n",
      "2025-02-19 10:21:45,131 - INFO - Recall: 0.8514\n",
      "2025-02-19 10:21:45,138 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:21:45,139 - INFO - Accuracy: 0.8467\n",
      "2025-02-19 10:21:45,140 - INFO - F1_score: 0.7101\n",
      "2025-02-19 10:21:45,140 - INFO - Precision: 0.6049\n",
      "2025-02-19 10:21:45,141 - INFO - Recall: 0.8596\n",
      "2025-02-19 10:21:45,148 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:21:45,149 - INFO - Accuracy: 0.5517\n",
      "2025-02-19 10:21:45,150 - INFO - F1_score: 0.4658\n",
      "2025-02-19 10:21:45,151 - INFO - Precision: 0.3168\n",
      "2025-02-19 10:21:45,151 - INFO - Recall: 0.8793\n",
      "2025-02-19 10:21:45,157 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:21:45,158 - INFO - Accuracy: 0.7241\n",
      "2025-02-19 10:21:45,158 - INFO - F1_score: 0.4000\n",
      "2025-02-19 10:21:45,159 - INFO - Precision: 0.2927\n",
      "2025-02-19 10:21:45,160 - INFO - Recall: 0.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:21:45,167 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:21:45,168 - INFO - Accuracy: 0.5211\n",
      "2025-02-19 10:21:45,168 - INFO - F1_score: 0.3094\n",
      "2025-02-19 10:21:45,169 - INFO - Precision: 0.1905\n",
      "2025-02-19 10:21:45,170 - INFO - Recall: 0.8235\n",
      "2025-02-19 10:21:45,172 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:21:49,103 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:21:49,105 - INFO - Memory usage after evaluation end: 3273.39 MB\n",
      "2025-02-19 10:21:49,106 - INFO - Trial 14, Epoch 1: Loss = 1.4688, F1 = 0.4829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:24:34,549 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:24:34,551 - INFO - Memory usage after evaluation start: 3273.52 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.57it/s, Accuracy=65.29%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:24:42,463 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:24:42,469 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:24:42,469 - INFO - Accuracy: 0.4904\n",
      "2025-02-19 10:24:42,470 - INFO - F1_score: 0.4904\n",
      "2025-02-19 10:24:42,471 - INFO - Precision: 0.3422\n",
      "2025-02-19 10:24:42,472 - INFO - Recall: 0.8649\n",
      "2025-02-19 10:24:42,478 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:24:42,479 - INFO - Accuracy: 0.8199\n",
      "2025-02-19 10:24:42,479 - INFO - F1_score: 0.6803\n",
      "2025-02-19 10:24:42,480 - INFO - Precision: 0.5556\n",
      "2025-02-19 10:24:42,481 - INFO - Recall: 0.8772\n",
      "2025-02-19 10:24:42,487 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:24:42,488 - INFO - Accuracy: 0.6092\n",
      "2025-02-19 10:24:42,488 - INFO - F1_score: 0.4457\n",
      "2025-02-19 10:24:42,489 - INFO - Precision: 0.3254\n",
      "2025-02-19 10:24:42,491 - INFO - Recall: 0.7069\n",
      "2025-02-19 10:24:42,497 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:24:42,497 - INFO - Accuracy: 0.5824\n",
      "2025-02-19 10:24:42,498 - INFO - F1_score: 0.3394\n",
      "2025-02-19 10:24:42,499 - INFO - Precision: 0.2205\n",
      "2025-02-19 10:24:42,500 - INFO - Recall: 0.7368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:24:42,506 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:24:42,507 - INFO - Accuracy: 0.7625\n",
      "2025-02-19 10:24:42,508 - INFO - F1_score: 0.4259\n",
      "2025-02-19 10:24:42,509 - INFO - Precision: 0.3108\n",
      "2025-02-19 10:24:42,510 - INFO - Recall: 0.6765\n",
      "2025-02-19 10:24:42,512 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:24:46,332 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:24:46,333 - INFO - Memory usage after evaluation end: 3279.14 MB\n",
      "2025-02-19 10:24:46,334 - INFO - Trial 14, Epoch 2: Loss = 1.1864, F1 = 0.4763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:27:31,722 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:27:31,723 - INFO - Memory usage after evaluation start: 3279.27 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.55it/s, Accuracy=66.59%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:27:39,642 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:27:39,648 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:27:39,649 - INFO - Accuracy: 0.5326\n",
      "2025-02-19 10:27:39,650 - INFO - F1_score: 0.5081\n",
      "2025-02-19 10:27:39,651 - INFO - Precision: 0.3621\n",
      "2025-02-19 10:27:39,652 - INFO - Recall: 0.8514\n",
      "2025-02-19 10:27:39,657 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:27:39,657 - INFO - Accuracy: 0.8391\n",
      "2025-02-19 10:27:39,658 - INFO - F1_score: 0.7083\n",
      "2025-02-19 10:27:39,659 - INFO - Precision: 0.5862\n",
      "2025-02-19 10:27:39,660 - INFO - Recall: 0.8947\n",
      "2025-02-19 10:27:39,666 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:27:39,667 - INFO - Accuracy: 0.4789\n",
      "2025-02-19 10:27:39,667 - INFO - F1_score: 0.4380\n",
      "2025-02-19 10:27:39,668 - INFO - Precision: 0.2880\n",
      "2025-02-19 10:27:39,668 - INFO - Recall: 0.9138\n",
      "2025-02-19 10:27:39,674 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:27:39,675 - INFO - Accuracy: 0.7241\n",
      "2025-02-19 10:27:39,676 - INFO - F1_score: 0.4000\n",
      "2025-02-19 10:27:39,676 - INFO - Precision: 0.2927\n",
      "2025-02-19 10:27:39,678 - INFO - Recall: 0.6316\n",
      "2025-02-19 10:27:39,683 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:27:39,684 - INFO - Accuracy: 0.7548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:27:39,685 - INFO - F1_score: 0.3962\n",
      "2025-02-19 10:27:39,686 - INFO - Precision: 0.2917\n",
      "2025-02-19 10:27:39,686 - INFO - Recall: 0.6176\n",
      "2025-02-19 10:27:39,689 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:27:43,549 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:27:43,550 - INFO - Memory usage after evaluation end: 3284.89 MB\n",
      "2025-02-19 10:27:43,552 - INFO - Trial 14, Epoch 3: Loss = 1.0667, F1 = 0.4901\n",
      "2025-02-19 10:27:43,553 - ERROR - Error in trial training: \n",
      "2025-02-19 10:27:44,479 - ERROR - Error in optimization objective: \n",
      "2025-02-19 10:27:44,480 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 10:27:44,481] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:27:45,433 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-19 10:27:45,437 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:27:46,430 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 10:27:46,431 - INFO - Setting up data loaders...\n",
      "2025-02-19 10:27:46,431 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 10:27:46,433 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 10:27:46,434 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:30:01,154 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:30:01,156 - INFO - Memory usage after evaluation start: 3140.21 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.53it/s, Accuracy=63.45%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:30:08,452 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:30:08,459 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:30:08,460 - INFO - Accuracy: 0.5441\n",
      "2025-02-19 10:30:08,460 - INFO - F1_score: 0.4979\n",
      "2025-02-19 10:30:08,461 - INFO - Precision: 0.3620\n",
      "2025-02-19 10:30:08,462 - INFO - Recall: 0.7973\n",
      "2025-02-19 10:30:08,468 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:30:08,468 - INFO - Accuracy: 0.6782\n",
      "2025-02-19 10:30:08,469 - INFO - F1_score: 0.4815\n",
      "2025-02-19 10:30:08,470 - INFO - Precision: 0.3714\n",
      "2025-02-19 10:30:08,470 - INFO - Recall: 0.6842\n",
      "2025-02-19 10:30:08,477 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:30:08,477 - INFO - Accuracy: 0.6743\n",
      "2025-02-19 10:30:08,478 - INFO - F1_score: 0.3411\n",
      "2025-02-19 10:30:08,478 - INFO - Precision: 0.3099\n",
      "2025-02-19 10:30:08,479 - INFO - Recall: 0.3793\n",
      "2025-02-19 10:30:08,486 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:30:08,487 - INFO - Accuracy: 0.5019\n",
      "2025-02-19 10:30:08,487 - INFO - F1_score: 0.3299\n",
      "2025-02-19 10:30:08,488 - INFO - Precision: 0.2051\n",
      "2025-02-19 10:30:08,489 - INFO - Recall: 0.8421\n",
      "2025-02-19 10:30:08,495 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:30:08,496 - INFO - Accuracy: 0.7739\n",
      "2025-02-19 10:30:08,496 - INFO - F1_score: 0.3656\n",
      "2025-02-19 10:30:08,497 - INFO - Precision: 0.2881\n",
      "2025-02-19 10:30:08,497 - INFO - Recall: 0.5000\n",
      "2025-02-19 10:30:08,500 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:30:12,441 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:30:12,442 - INFO - Memory usage after evaluation end: 3143.84 MB\n",
      "2025-02-19 10:30:12,444 - INFO - Trial 15, Epoch 1: Loss = 1.5864, F1 = 0.4032\n",
      "2025-02-19 10:30:12,445 - ERROR - Error in trial training: \n",
      "2025-02-19 10:30:13,540 - ERROR - Error in optimization objective: \n",
      "2025-02-19 10:30:13,541 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 10:30:13,542] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:30:14,495 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-19 10:30:14,498 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:30:15,425 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 10:30:15,427 - INFO - Setting up data loaders...\n",
      "2025-02-19 10:30:15,428 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 10:30:15,430 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 10:30:15,431 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:32:59,848 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:32:59,851 - INFO - Memory usage after evaluation start: 3377.82 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.56it/s, Accuracy=62.30%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:33:07,767 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:33:07,773 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:33:07,774 - INFO - Accuracy: 0.5402\n",
      "2025-02-19 10:33:07,774 - INFO - F1_score: 0.4872\n",
      "2025-02-19 10:33:07,775 - INFO - Precision: 0.3563\n",
      "2025-02-19 10:33:07,776 - INFO - Recall: 0.7703\n",
      "2025-02-19 10:33:07,782 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:33:07,783 - INFO - Accuracy: 0.8046\n",
      "2025-02-19 10:33:07,783 - INFO - F1_score: 0.6752\n",
      "2025-02-19 10:33:07,784 - INFO - Precision: 0.5300\n",
      "2025-02-19 10:33:07,785 - INFO - Recall: 0.9298\n",
      "2025-02-19 10:33:07,792 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:33:07,793 - INFO - Accuracy: 0.4521\n",
      "2025-02-19 10:33:07,793 - INFO - F1_score: 0.4392\n",
      "2025-02-19 10:33:07,794 - INFO - Precision: 0.2843\n",
      "2025-02-19 10:33:07,795 - INFO - Recall: 0.9655\n",
      "2025-02-19 10:33:07,801 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:33:07,802 - INFO - Accuracy: 0.6628\n",
      "2025-02-19 10:33:07,803 - INFO - F1_score: 0.4133\n",
      "2025-02-19 10:33:07,803 - INFO - Precision: 0.2768\n",
      "2025-02-19 10:33:07,805 - INFO - Recall: 0.8158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:33:07,812 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:33:07,813 - INFO - Accuracy: 0.6552\n",
      "2025-02-19 10:33:07,814 - INFO - F1_score: 0.3662\n",
      "2025-02-19 10:33:07,815 - INFO - Precision: 0.2407\n",
      "2025-02-19 10:33:07,815 - INFO - Recall: 0.7647\n",
      "2025-02-19 10:33:07,817 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:33:11,767 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:33:11,769 - INFO - Memory usage after evaluation end: 3381.70 MB\n",
      "2025-02-19 10:33:11,770 - INFO - Trial 16, Epoch 1: Loss = 1.4523, F1 = 0.4762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:35:57,237 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:35:57,240 - INFO - Memory usage after evaluation start: 3381.70 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.55it/s, Accuracy=63.52%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:36:05,162 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:36:05,168 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:36:05,168 - INFO - Accuracy: 0.5134\n",
      "2025-02-19 10:36:05,169 - INFO - F1_score: 0.5097\n",
      "2025-02-19 10:36:05,169 - INFO - Precision: 0.3568\n",
      "2025-02-19 10:36:05,171 - INFO - Recall: 0.8919\n",
      "2025-02-19 10:36:05,177 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:36:05,177 - INFO - Accuracy: 0.7050\n",
      "2025-02-19 10:36:05,178 - INFO - F1_score: 0.5882\n",
      "2025-02-19 10:36:05,178 - INFO - Precision: 0.4231\n",
      "2025-02-19 10:36:05,179 - INFO - Recall: 0.9649\n",
      "2025-02-19 10:36:05,185 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:36:05,186 - INFO - Accuracy: 0.5900\n",
      "2025-02-19 10:36:05,187 - INFO - F1_score: 0.4880\n",
      "2025-02-19 10:36:05,187 - INFO - Precision: 0.3377\n",
      "2025-02-19 10:36:05,189 - INFO - Recall: 0.8793\n",
      "2025-02-19 10:36:05,195 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:36:05,195 - INFO - Accuracy: 0.5517\n",
      "2025-02-19 10:36:05,196 - INFO - F1_score: 0.3314\n",
      "2025-02-19 10:36:05,197 - INFO - Precision: 0.2117\n",
      "2025-02-19 10:36:05,198 - INFO - Recall: 0.7632\n",
      "2025-02-19 10:36:05,204 - INFO - \n",
      "Metrics for Romantis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:36:05,204 - INFO - Accuracy: 0.8161\n",
      "2025-02-19 10:36:05,205 - INFO - F1_score: 0.4419\n",
      "2025-02-19 10:36:05,205 - INFO - Precision: 0.3654\n",
      "2025-02-19 10:36:05,207 - INFO - Recall: 0.5588\n",
      "2025-02-19 10:36:05,208 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:36:09,084 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:36:09,085 - INFO - Memory usage after evaluation end: 3387.20 MB\n",
      "2025-02-19 10:36:09,086 - INFO - Trial 16, Epoch 2: Loss = 1.1865, F1 = 0.4718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:38:54,592 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:38:54,593 - INFO - Memory usage after evaluation start: 3387.32 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.52it/s, Accuracy=67.97%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:39:02,529 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:39:02,535 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:39:02,536 - INFO - Accuracy: 0.4828\n",
      "2025-02-19 10:39:02,536 - INFO - F1_score: 0.4906\n",
      "2025-02-19 10:39:02,537 - INFO - Precision: 0.3403\n",
      "2025-02-19 10:39:02,538 - INFO - Recall: 0.8784\n",
      "2025-02-19 10:39:02,544 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:39:02,545 - INFO - Accuracy: 0.8161\n",
      "2025-02-19 10:39:02,546 - INFO - F1_score: 0.6800\n",
      "2025-02-19 10:39:02,547 - INFO - Precision: 0.5484\n",
      "2025-02-19 10:39:02,547 - INFO - Recall: 0.8947\n",
      "2025-02-19 10:39:02,553 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:39:02,554 - INFO - Accuracy: 0.6284\n",
      "2025-02-19 10:39:02,554 - INFO - F1_score: 0.5026\n",
      "2025-02-19 10:39:02,555 - INFO - Precision: 0.3577\n",
      "2025-02-19 10:39:02,556 - INFO - Recall: 0.8448\n",
      "2025-02-19 10:39:02,562 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:39:02,563 - INFO - Accuracy: 0.6897\n",
      "2025-02-19 10:39:02,564 - INFO - F1_score: 0.4088\n",
      "2025-02-19 10:39:02,564 - INFO - Precision: 0.2828\n",
      "2025-02-19 10:39:02,565 - INFO - Recall: 0.7368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:39:02,573 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:39:02,573 - INFO - Accuracy: 0.7816\n",
      "2025-02-19 10:39:02,574 - INFO - F1_score: 0.4571\n",
      "2025-02-19 10:39:02,576 - INFO - Precision: 0.3380\n",
      "2025-02-19 10:39:02,576 - INFO - Recall: 0.7059\n",
      "2025-02-19 10:39:02,578 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:39:06,415 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:39:06,416 - INFO - Memory usage after evaluation end: 3392.95 MB\n",
      "2025-02-19 10:39:06,417 - INFO - Trial 16, Epoch 3: Loss = 1.0191, F1 = 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 10:39:09,393] Trial 16 finished with value: 0.50780642430608 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 12 with value: 0.5193231897362796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:39:10,376 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 3e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-19 10:39:10,380 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:39:11,484 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 10:39:11,485 - INFO - Setting up data loaders...\n",
      "2025-02-19 10:39:11,486 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 10:39:11,488 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 10:39:11,489 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:41:55,587 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:41:55,589 - INFO - Memory usage after evaluation start: 3456.31 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.53it/s, Accuracy=66.05%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:42:03,519 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:42:03,526 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:42:03,527 - INFO - Accuracy: 0.6513\n",
      "2025-02-19 10:42:03,528 - INFO - F1_score: 0.5081\n",
      "2025-02-19 10:42:03,529 - INFO - Precision: 0.4234\n",
      "2025-02-19 10:42:03,529 - INFO - Recall: 0.6351\n",
      "2025-02-19 10:42:03,535 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:42:03,536 - INFO - Accuracy: 0.6437\n",
      "2025-02-19 10:42:03,537 - INFO - F1_score: 0.5419\n",
      "2025-02-19 10:42:03,538 - INFO - Precision: 0.3767\n",
      "2025-02-19 10:42:03,539 - INFO - Recall: 0.9649\n",
      "2025-02-19 10:42:03,546 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:42:03,546 - INFO - Accuracy: 0.6782\n",
      "2025-02-19 10:42:03,547 - INFO - F1_score: 0.4085\n",
      "2025-02-19 10:42:03,548 - INFO - Precision: 0.3452\n",
      "2025-02-19 10:42:03,549 - INFO - Recall: 0.5000\n",
      "2025-02-19 10:42:03,555 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:42:03,556 - INFO - Accuracy: 0.5594\n",
      "2025-02-19 10:42:03,557 - INFO - F1_score: 0.3353\n",
      "2025-02-19 10:42:03,558 - INFO - Precision: 0.2148\n",
      "2025-02-19 10:42:03,559 - INFO - Recall: 0.7632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:42:03,567 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:42:03,568 - INFO - Accuracy: 0.7701\n",
      "2025-02-19 10:42:03,569 - INFO - F1_score: 0.4231\n",
      "2025-02-19 10:42:03,570 - INFO - Precision: 0.3143\n",
      "2025-02-19 10:42:03,570 - INFO - Recall: 0.6471\n",
      "2025-02-19 10:42:03,573 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:42:07,424 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:42:07,426 - INFO - Memory usage after evaluation end: 3459.93 MB\n",
      "2025-02-19 10:42:07,426 - INFO - Trial 17, Epoch 1: Loss = 1.5410, F1 = 0.4434\n",
      "2025-02-19 10:42:07,429 - ERROR - Error in trial training: \n",
      "2025-02-19 10:42:08,561 - ERROR - Error in optimization objective: \n",
      "2025-02-19 10:42:08,563 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 10:42:08,564] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:42:09,578 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-19 10:42:09,582 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:42:10,598 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 10:42:10,599 - INFO - Setting up data loaders...\n",
      "2025-02-19 10:42:10,600 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 10:42:10,602 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 10:42:10,603 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:44:25,520 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:44:25,522 - INFO - Memory usage after evaluation start: 3484.76 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.54it/s, Accuracy=47.59%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:44:32,802 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:44:32,810 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:44:32,810 - INFO - Accuracy: 0.5019\n",
      "2025-02-19 10:44:32,811 - INFO - F1_score: 0.4800\n",
      "2025-02-19 10:44:32,812 - INFO - Precision: 0.3409\n",
      "2025-02-19 10:44:32,812 - INFO - Recall: 0.8108\n",
      "2025-02-19 10:44:32,820 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:44:32,821 - INFO - Accuracy: 0.3640\n",
      "2025-02-19 10:44:32,821 - INFO - F1_score: 0.4029\n",
      "2025-02-19 10:44:32,822 - INFO - Precision: 0.2534\n",
      "2025-02-19 10:44:32,823 - INFO - Recall: 0.9825\n",
      "2025-02-19 10:44:32,831 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:44:32,832 - INFO - Accuracy: 0.3716\n",
      "2025-02-19 10:44:32,832 - INFO - F1_score: 0.3881\n",
      "2025-02-19 10:44:32,833 - INFO - Precision: 0.2476\n",
      "2025-02-19 10:44:32,834 - INFO - Recall: 0.8966\n",
      "2025-02-19 10:44:32,840 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:44:32,841 - INFO - Accuracy: 0.6284\n",
      "2025-02-19 10:44:32,842 - INFO - F1_score: 0.3217\n",
      "2025-02-19 10:44:32,843 - INFO - Precision: 0.2190\n",
      "2025-02-19 10:44:32,843 - INFO - Recall: 0.6053\n",
      "2025-02-19 10:44:32,850 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:44:32,851 - INFO - Accuracy: 0.5134\n",
      "2025-02-19 10:44:32,851 - INFO - F1_score: 0.3135\n",
      "2025-02-19 10:44:32,852 - INFO - Precision: 0.1921\n",
      "2025-02-19 10:44:32,853 - INFO - Recall: 0.8529\n",
      "2025-02-19 10:44:32,855 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:44:36,738 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:44:36,739 - INFO - Memory usage after evaluation end: 3488.26 MB\n",
      "2025-02-19 10:44:36,740 - INFO - Trial 18, Epoch 1: Loss = 1.5425, F1 = 0.3812\n",
      "2025-02-19 10:44:36,742 - ERROR - Error in trial training: \n",
      "2025-02-19 10:44:37,950 - ERROR - Error in optimization objective: \n",
      "2025-02-19 10:44:37,951 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 10:44:37,953] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:44:38,980 - INFO - Trial parameter set: {'batch_size': 4, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-19 10:44:38,984 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:44:39,999 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 10:44:40,001 - INFO - Setting up data loaders...\n",
      "2025-02-19 10:44:40,002 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 10:44:40,004 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 10:44:40,005 - INFO - Created data loaders with batch size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:47:04,804 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:47:04,807 - INFO - Memory usage after evaluation start: 3509.56 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.47it/s, Accuracy=63.83%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:47:12,602 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:47:12,609 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:47:12,610 - INFO - Accuracy: 0.3525\n",
      "2025-02-19 10:47:12,610 - INFO - F1_score: 0.4566\n",
      "2025-02-19 10:47:12,612 - INFO - Precision: 0.2996\n",
      "2025-02-19 10:47:12,613 - INFO - Recall: 0.9595\n",
      "2025-02-19 10:47:12,619 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:47:12,619 - INFO - Accuracy: 0.8046\n",
      "2025-02-19 10:47:12,620 - INFO - F1_score: 0.6710\n",
      "2025-02-19 10:47:12,621 - INFO - Precision: 0.5306\n",
      "2025-02-19 10:47:12,622 - INFO - Recall: 0.9123\n",
      "2025-02-19 10:47:12,627 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:47:12,628 - INFO - Accuracy: 0.7548\n",
      "2025-02-19 10:47:12,629 - INFO - F1_score: 0.3725\n",
      "2025-02-19 10:47:12,629 - INFO - Precision: 0.4318\n",
      "2025-02-19 10:47:12,631 - INFO - Recall: 0.3276\n",
      "2025-02-19 10:47:12,637 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:47:12,638 - INFO - Accuracy: 0.5479\n",
      "2025-02-19 10:47:12,638 - INFO - F1_score: 0.3295\n",
      "2025-02-19 10:47:12,639 - INFO - Precision: 0.2101\n",
      "2025-02-19 10:47:12,640 - INFO - Recall: 0.7632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:47:12,648 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:47:12,648 - INFO - Accuracy: 0.7318\n",
      "2025-02-19 10:47:12,649 - INFO - F1_score: 0.4167\n",
      "2025-02-19 10:47:12,650 - INFO - Precision: 0.2907\n",
      "2025-02-19 10:47:12,650 - INFO - Recall: 0.7353\n",
      "2025-02-19 10:47:12,653 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-19 10:47:16,497 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:47:16,498 - INFO - Memory usage after evaluation end: 3514.31 MB\n",
      "2025-02-19 10:47:16,499 - INFO - Trial 19, Epoch 1: Loss = 1.4472, F1 = 0.4493\n",
      "2025-02-19 10:47:16,501 - ERROR - Error in trial training: \n",
      "2025-02-19 10:47:17,746 - ERROR - Error in optimization objective: \n",
      "2025-02-19 10:47:17,747 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-19 10:47:17,748] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:47:18,787 - INFO - \n",
      "Hyperparameter Optimization Results:\n",
      "2025-02-19 10:47:18,790 - INFO - Best trial number: 12\n",
      "2025-02-19 10:47:18,791 - INFO - Best F1-score: 0.5193\n",
      "2025-02-19 10:47:18,791 - INFO - \n",
      "Best hyperparameters:\n",
      "2025-02-19 10:47:18,792 - INFO - batch_size: 2\n",
      "2025-02-19 10:47:18,793 - INFO - learning_rate: 8e-06\n",
      "2025-02-19 10:47:18,794 - INFO - weight_decay: 0.01\n",
      "2025-02-19 10:47:18,795 - INFO - mixup_prob: 0.2\n",
      "2025-02-19 10:47:18,796 - INFO - smoothing: 0.1\n",
      "2025-02-19 10:47:19,729 - WARNING - Could not create optimization plots: \n",
      "Image export using the \"kaleido\" engine requires the kaleido package,\n",
      "which can be installed using pip:\n",
      "    $ pip install -U kaleido\n",
      "\n",
      "2025-02-19 10:47:20,845 - INFO - \n",
      "Best Hyperparameters found:\n",
      "2025-02-19 10:47:20,846 - INFO - batch_size: 2\n",
      "2025-02-19 10:47:20,846 - INFO - learning_rate: 8e-06\n",
      "2025-02-19 10:47:20,847 - INFO - weight_decay: 0.01\n",
      "2025-02-19 10:47:20,848 - INFO - mixup_prob: 0.2\n",
      "2025-02-19 10:47:20,849 - INFO - smoothing: 0.1\n",
      "2025-02-19 10:47:20,849 - INFO - \n",
      "Training final model with optimized parameters...\n",
      "2025-02-19 10:47:20,850 - INFO - Starting model training\n",
      "2025-02-19 10:47:20,853 - INFO - Memory usage after training start: 3523.69 MB\n",
      "2025-02-19 10:47:20,862 - INFO - Loading and preprocessing data...\n",
      "2025-02-19 10:47:20,863 - INFO - Memory usage after start: 3523.69 MB\n",
      "2025-02-19 10:47:20,878 - INFO - Successfully loaded data using utf-8 encoding\n",
      "2025-02-19 10:47:20,879 - INFO - Memory usage after data loading: 3523.94 MB\n",
      "2025-02-19 10:47:20,880 - INFO - Using full dataset with 1738 samples\n",
      "2025-02-19 10:47:20,881 - INFO - \n",
      "Sample data:\n",
      "2025-02-19 10:47:20,882 - INFO - \n",
      "Sample 1:\n",
      "2025-02-19 10:47:20,883 - INFO - Synopsis: Setelah kematian yang tampak, Siena mampu melihat tanda-tanda bahwa orang-orang akan meninggal. Namu...\n",
      "2025-02-19 10:47:20,884 - INFO - Genre: Horor\n",
      "2025-02-19 10:47:20,885 - INFO - \n",
      "Sample 2:\n",
      "2025-02-19 10:47:20,885 - INFO - Synopsis: Alfi (Al Ghazali) bertemu dengan Alana (Caitlin Halderman), seorang siswa baru di sekolahnya. Ternya...\n",
      "2025-02-19 10:47:20,887 - INFO - Genre: Drama\n",
      "2025-02-19 10:47:20,888 - INFO - \n",
      "Sample 3:\n",
      "2025-02-19 10:47:20,888 - INFO - Synopsis: Ketika gaji staf di sekolahnya dicuri, seorang guru baru yang enggan berusaha untuk mendapatkan kemb...\n",
      "2025-02-19 10:47:20,889 - INFO - Genre: Komedi\n",
      "2025-02-19 10:47:20,890 - INFO - \n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1738/1738 [00:00<00:00, 14936.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:47:21,015 - INFO - Memory usage after preprocessing: 3524.56 MB\n",
      "2025-02-19 10:47:21,016 - INFO - \n",
      "Dataset statistics:\n",
      "2025-02-19 10:47:21,017 - INFO - Total samples after preprocessing: 1738\n",
      "2025-02-19 10:47:21,022 - INFO - Genre 'Drama': 510 samples\n",
      "2025-02-19 10:47:21,023 - INFO - Genre 'Horor': 349 samples\n",
      "2025-02-19 10:47:21,023 - INFO - Genre 'Komedi': 374 samples\n",
      "2025-02-19 10:47:21,024 - INFO - Genre 'Laga': 297 samples\n",
      "2025-02-19 10:47:21,025 - INFO - Genre 'Romantis': 208 samples\n",
      "2025-02-19 10:47:21,026 - INFO - \n",
      "Training set size: 1477\n",
      "2025-02-19 10:47:21,026 - INFO - Testing set size: 261\n",
      "2025-02-19 10:47:21,027 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:47:22,058 - INFO - Model and tokenizer setup completed\n",
      "2025-02-19 10:47:22,059 - INFO - Setting up data loaders...\n",
      "2025-02-19 10:47:22,060 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-19 10:47:22,062 - INFO - Created sampler with 1477 weights\n",
      "2025-02-19 10:47:22,063 - INFO - Created data loaders with batch size 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=1.8541]\u001b[A\n",
      "Epoch 1:   1%|          | 1/148 [00:01<02:43,  1.11s/it, training_loss=1.8541]\u001b[A\n",
      "Epoch 1:   1%|          | 1/148 [00:01<02:43,  1.11s/it, training_loss=1.6993]\u001b[A\n",
      "Epoch 1:   1%|▏         | 2/148 [00:01<02:22,  1.02it/s, training_loss=1.6993]\u001b[A\n",
      "Epoch 1:   1%|▏         | 2/148 [00:02<02:22,  1.02it/s, training_loss=1.7109]\u001b[A\n",
      "Epoch 1:   2%|▏         | 3/148 [00:02<02:15,  1.07it/s, training_loss=1.7109]\u001b[A\n",
      "Epoch 1:   2%|▏         | 3/148 [00:03<02:15,  1.07it/s, training_loss=1.6743]\u001b[A\n",
      "Epoch 1:   3%|▎         | 4/148 [00:03<02:12,  1.09it/s, training_loss=1.6743]\u001b[A\n",
      "Epoch 1:   3%|▎         | 4/148 [00:04<02:12,  1.09it/s, training_loss=1.6275]\u001b[A\n",
      "Epoch 1:   3%|▎         | 5/148 [00:04<02:09,  1.10it/s, training_loss=1.6275]\u001b[A\n",
      "Epoch 1:   3%|▎         | 5/148 [00:05<02:09,  1.10it/s, training_loss=1.6878]\u001b[A\n",
      "Epoch 1:   4%|▍         | 6/148 [00:05<02:07,  1.11it/s, training_loss=1.6878]\u001b[A\n",
      "Epoch 1:   4%|▍         | 6/148 [00:06<02:07,  1.11it/s, training_loss=1.6418]\u001b[A\n",
      "Epoch 1:   5%|▍         | 7/148 [00:06<02:06,  1.12it/s, training_loss=1.6418]\u001b[A\n",
      "Epoch 1:   5%|▍         | 7/148 [00:07<02:06,  1.12it/s, training_loss=1.5351]\u001b[A\n",
      "Epoch 1:   5%|▌         | 8/148 [00:07<02:04,  1.12it/s, training_loss=1.5351]\u001b[A\n",
      "Epoch 1:   5%|▌         | 8/148 [00:08<02:04,  1.12it/s, training_loss=1.6431]\u001b[A\n",
      "Epoch 1:   6%|▌         | 9/148 [00:08<02:03,  1.12it/s, training_loss=1.6431]\u001b[A\n",
      "Epoch 1:   6%|▌         | 9/148 [00:09<02:03,  1.12it/s, training_loss=1.5752]\u001b[A\n",
      "Epoch 1:   7%|▋         | 10/148 [00:09<02:02,  1.13it/s, training_loss=1.5752]\u001b[A\n",
      "Epoch 1:   7%|▋         | 10/148 [00:09<02:02,  1.13it/s, training_loss=1.6303]\u001b[A\n",
      "Epoch 1:   7%|▋         | 11/148 [00:09<02:01,  1.13it/s, training_loss=1.6303]\u001b[A\n",
      "Epoch 1:   7%|▋         | 11/148 [00:10<02:01,  1.13it/s, training_loss=1.5769]\u001b[A\n",
      "Epoch 1:   8%|▊         | 12/148 [00:10<02:00,  1.13it/s, training_loss=1.5769]\u001b[A\n",
      "Epoch 1:   8%|▊         | 12/148 [00:11<02:00,  1.13it/s, training_loss=1.6128]\u001b[A\n",
      "Epoch 1:   9%|▉         | 13/148 [00:11<02:00,  1.12it/s, training_loss=1.6128]\u001b[A\n",
      "Epoch 1:   9%|▉         | 13/148 [00:12<02:00,  1.12it/s, training_loss=1.6010]\u001b[A\n",
      "Epoch 1:   9%|▉         | 14/148 [00:12<01:59,  1.12it/s, training_loss=1.6010]\u001b[A\n",
      "Epoch 1:   9%|▉         | 14/148 [00:13<01:59,  1.12it/s, training_loss=1.6344]\u001b[A\n",
      "Epoch 1:  10%|█         | 15/148 [00:13<01:59,  1.12it/s, training_loss=1.6344]\u001b[A\n",
      "Epoch 1:  10%|█         | 15/148 [00:14<01:59,  1.12it/s, training_loss=1.6358]\u001b[A\n",
      "Epoch 1:  11%|█         | 16/148 [00:14<01:57,  1.12it/s, training_loss=1.6358]\u001b[A\n",
      "Epoch 1:  11%|█         | 16/148 [00:15<01:57,  1.12it/s, training_loss=1.5615]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 17/148 [00:15<01:57,  1.12it/s, training_loss=1.5615]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 17/148 [00:16<01:57,  1.12it/s, training_loss=1.5807]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 18/148 [00:16<01:56,  1.12it/s, training_loss=1.5807]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 18/148 [00:17<01:56,  1.12it/s, training_loss=1.5038]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 19/148 [00:17<01:55,  1.12it/s, training_loss=1.5038]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 19/148 [00:18<01:55,  1.12it/s, training_loss=1.8524]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 20/148 [00:18<01:54,  1.12it/s, training_loss=1.8524]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 20/148 [00:18<01:54,  1.12it/s, training_loss=1.7155]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 21/148 [00:18<01:53,  1.12it/s, training_loss=1.7155]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 21/148 [00:19<01:53,  1.12it/s, training_loss=1.5646]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 22/148 [00:19<01:52,  1.12it/s, training_loss=1.5646]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 22/148 [00:20<01:52,  1.12it/s, training_loss=1.6122]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 23/148 [00:20<01:52,  1.11it/s, training_loss=1.6122]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 23/148 [00:21<01:52,  1.11it/s, training_loss=1.7526]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 24/148 [00:21<01:51,  1.11it/s, training_loss=1.7526]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 24/148 [00:22<01:51,  1.11it/s, training_loss=1.5173]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 25/148 [00:22<01:50,  1.11it/s, training_loss=1.5173]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 25/148 [00:23<01:50,  1.11it/s, training_loss=1.5211]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 26/148 [00:23<01:50,  1.11it/s, training_loss=1.5211]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 26/148 [00:24<01:50,  1.11it/s, training_loss=1.5086]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 27/148 [00:24<01:49,  1.11it/s, training_loss=1.5086]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 27/148 [00:25<01:49,  1.11it/s, training_loss=1.6525]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 28/148 [00:25<01:48,  1.11it/s, training_loss=1.6525]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 28/148 [00:26<01:48,  1.11it/s, training_loss=1.5897]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 29/148 [00:26<01:47,  1.11it/s, training_loss=1.5897]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 29/148 [00:27<01:47,  1.11it/s, training_loss=1.6131]\u001b[A\n",
      "Epoch 1:  20%|██        | 30/148 [00:27<01:46,  1.10it/s, training_loss=1.6131]\u001b[A\n",
      "Epoch 1:  20%|██        | 30/148 [00:27<01:46,  1.10it/s, training_loss=1.5283]\u001b[A\n",
      "Epoch 1:  21%|██        | 31/148 [00:27<01:45,  1.11it/s, training_loss=1.5283]\u001b[A\n",
      "Epoch 1:  21%|██        | 31/148 [00:28<01:45,  1.11it/s, training_loss=1.6299]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 32/148 [00:28<01:44,  1.11it/s, training_loss=1.6299]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 32/148 [00:29<01:44,  1.11it/s, training_loss=1.6935]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 33/148 [00:29<01:43,  1.11it/s, training_loss=1.6935]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 33/148 [00:30<01:43,  1.11it/s, training_loss=1.6063]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 34/148 [00:30<01:42,  1.11it/s, training_loss=1.6063]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 34/148 [00:31<01:42,  1.11it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 35/148 [00:31<01:42,  1.10it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 35/148 [00:32<01:42,  1.10it/s, training_loss=1.4605]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 36/148 [00:32<01:41,  1.10it/s, training_loss=1.4605]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 36/148 [00:33<01:41,  1.10it/s, training_loss=1.6005]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 37/148 [00:33<01:41,  1.09it/s, training_loss=1.6005]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 37/148 [00:34<01:41,  1.09it/s, training_loss=1.5741]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 38/148 [00:34<01:41,  1.09it/s, training_loss=1.5741]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 38/148 [00:35<01:41,  1.09it/s, training_loss=1.6498]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 39/148 [00:35<01:40,  1.09it/s, training_loss=1.6498]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 39/148 [00:36<01:40,  1.09it/s, training_loss=1.7582]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 40/148 [00:36<01:39,  1.09it/s, training_loss=1.7582]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 40/148 [00:37<01:39,  1.09it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=1.5394]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=1.5394]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=1.5784]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 43/148 [00:38<01:36,  1.08it/s, training_loss=1.5784]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 43/148 [00:39<01:36,  1.08it/s, training_loss=1.7114]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 44/148 [00:39<01:36,  1.08it/s, training_loss=1.7114]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 44/148 [00:40<01:36,  1.08it/s, training_loss=1.6023]\u001b[A\n",
      "Epoch 1:  30%|███       | 45/148 [00:40<01:35,  1.08it/s, training_loss=1.6023]\u001b[A\n",
      "Epoch 1:  30%|███       | 45/148 [00:41<01:35,  1.08it/s, training_loss=1.7371]\u001b[A\n",
      "Epoch 1:  31%|███       | 46/148 [00:41<01:34,  1.07it/s, training_loss=1.7371]\u001b[A\n",
      "Epoch 1:  31%|███       | 46/148 [00:42<01:34,  1.07it/s, training_loss=1.5293]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 47/148 [00:42<01:34,  1.07it/s, training_loss=1.5293]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 47/148 [00:43<01:34,  1.07it/s, training_loss=1.4989]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 48/148 [00:43<01:33,  1.07it/s, training_loss=1.4989]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 48/148 [00:44<01:33,  1.07it/s, training_loss=1.5546]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 49/148 [00:44<01:32,  1.07it/s, training_loss=1.5546]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 49/148 [00:45<01:32,  1.07it/s, training_loss=1.4744]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 50/148 [00:45<01:31,  1.07it/s, training_loss=1.4744]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 50/148 [00:46<01:31,  1.07it/s, training_loss=1.4908]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 51/148 [00:46<01:31,  1.06it/s, training_loss=1.4908]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 51/148 [00:47<01:31,  1.06it/s, training_loss=1.6272]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 52/148 [00:47<01:30,  1.07it/s, training_loss=1.6272]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 52/148 [00:48<01:30,  1.07it/s, training_loss=1.5112]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 53/148 [00:48<01:29,  1.07it/s, training_loss=1.5112]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 53/148 [00:49<01:29,  1.07it/s, training_loss=1.5045]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 54/148 [00:49<01:28,  1.06it/s, training_loss=1.5045]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 54/148 [00:50<01:28,  1.06it/s, training_loss=1.6754]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 55/148 [00:50<01:27,  1.06it/s, training_loss=1.6754]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 55/148 [00:51<01:27,  1.06it/s, training_loss=1.5387]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 56/148 [00:51<01:26,  1.07it/s, training_loss=1.5387]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 56/148 [00:52<01:26,  1.07it/s, training_loss=1.5782]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 57/148 [00:52<01:25,  1.07it/s, training_loss=1.5782]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 57/148 [00:53<01:25,  1.07it/s, training_loss=1.5055]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 58/148 [00:53<01:24,  1.06it/s, training_loss=1.5055]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 58/148 [00:53<01:24,  1.06it/s, training_loss=1.6904]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 59/148 [00:53<01:23,  1.06it/s, training_loss=1.6904]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 59/148 [00:54<01:23,  1.06it/s, training_loss=1.6218]\u001b[A\n",
      "Epoch 1:  41%|████      | 60/148 [00:54<01:22,  1.06it/s, training_loss=1.6218]\u001b[A\n",
      "Epoch 1:  41%|████      | 60/148 [00:55<01:22,  1.06it/s, training_loss=1.5384]\u001b[A\n",
      "Epoch 1:  41%|████      | 61/148 [00:55<01:21,  1.06it/s, training_loss=1.5384]\u001b[A\n",
      "Epoch 1:  41%|████      | 61/148 [00:56<01:21,  1.06it/s, training_loss=1.5479]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 62/148 [00:56<01:21,  1.06it/s, training_loss=1.5479]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 62/148 [00:57<01:21,  1.06it/s, training_loss=1.5806]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 63/148 [00:57<01:20,  1.06it/s, training_loss=1.5806]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 63/148 [00:58<01:20,  1.06it/s, training_loss=1.5130]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 64/148 [00:58<01:19,  1.06it/s, training_loss=1.5130]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 64/148 [00:59<01:19,  1.06it/s, training_loss=1.4620]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 65/148 [00:59<01:18,  1.06it/s, training_loss=1.4620]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 65/148 [01:00<01:18,  1.06it/s, training_loss=1.5832]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 66/148 [01:00<01:17,  1.06it/s, training_loss=1.5832]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 66/148 [01:01<01:17,  1.06it/s, training_loss=1.5178]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 67/148 [01:01<01:16,  1.06it/s, training_loss=1.5178]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 67/148 [01:02<01:16,  1.06it/s, training_loss=1.5751]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 68/148 [01:02<01:15,  1.06it/s, training_loss=1.5751]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 68/148 [01:03<01:15,  1.06it/s, training_loss=1.6270]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 69/148 [01:03<01:14,  1.07it/s, training_loss=1.6270]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 69/148 [01:04<01:14,  1.07it/s, training_loss=1.5294]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 70/148 [01:04<01:13,  1.07it/s, training_loss=1.5294]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 70/148 [01:05<01:13,  1.07it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 71/148 [01:05<01:11,  1.07it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 71/148 [01:06<01:11,  1.07it/s, training_loss=1.6863]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 72/148 [01:06<01:10,  1.07it/s, training_loss=1.6863]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 72/148 [01:07<01:10,  1.07it/s, training_loss=1.4987]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 73/148 [01:07<01:09,  1.07it/s, training_loss=1.4987]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 73/148 [01:08<01:09,  1.07it/s, training_loss=1.6555]\u001b[A\n",
      "Epoch 1:  50%|█████     | 74/148 [01:08<01:08,  1.08it/s, training_loss=1.6555]\u001b[A\n",
      "Epoch 1:  50%|█████     | 74/148 [01:08<01:08,  1.08it/s, training_loss=1.4347]\u001b[A\n",
      "Epoch 1:  51%|█████     | 75/148 [01:08<01:07,  1.08it/s, training_loss=1.4347]\u001b[A\n",
      "Epoch 1:  51%|█████     | 75/148 [01:09<01:07,  1.08it/s, training_loss=1.6742]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 76/148 [01:09<01:06,  1.08it/s, training_loss=1.6742]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 76/148 [01:10<01:06,  1.08it/s, training_loss=1.6337]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 77/148 [01:10<01:05,  1.08it/s, training_loss=1.6337]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 77/148 [01:11<01:05,  1.08it/s, training_loss=1.4659]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 78/148 [01:11<01:04,  1.08it/s, training_loss=1.4659]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 78/148 [01:12<01:04,  1.08it/s, training_loss=1.6226]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 79/148 [01:12<01:03,  1.08it/s, training_loss=1.6226]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 79/148 [01:13<01:03,  1.08it/s, training_loss=1.4673]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 80/148 [01:13<01:03,  1.08it/s, training_loss=1.4673]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 80/148 [01:14<01:03,  1.08it/s, training_loss=1.4884]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 81/148 [01:14<01:02,  1.08it/s, training_loss=1.4884]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 81/148 [01:15<01:02,  1.08it/s, training_loss=1.5350]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.5350]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.5513]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=1.5513]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 83/148 [01:17<00:59,  1.09it/s, training_loss=1.4925]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=1.4925]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 84/148 [01:18<00:58,  1.09it/s, training_loss=1.6195]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.6195]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 85/148 [01:19<00:57,  1.09it/s, training_loss=1.6670]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.6670]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 86/148 [01:20<00:56,  1.09it/s, training_loss=1.5291]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 87/148 [01:20<00:55,  1.09it/s, training_loss=1.5291]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 87/148 [01:20<00:55,  1.09it/s, training_loss=1.6508]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 88/148 [01:20<00:55,  1.09it/s, training_loss=1.6508]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.5921]\u001b[A\n",
      "Epoch 1:  60%|██████    | 89/148 [01:21<00:54,  1.09it/s, training_loss=1.5921]\u001b[A\n",
      "Epoch 1:  60%|██████    | 89/148 [01:22<00:54,  1.09it/s, training_loss=1.5434]\u001b[A\n",
      "Epoch 1:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=1.5434]\u001b[A\n",
      "Epoch 1:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=1.5331]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=1.5331]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.6291]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.6291]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=1.5276]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.5276]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.7325]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=1.7325]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.6078]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.6078]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=1.3509]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 96/148 [01:28<00:47,  1.10it/s, training_loss=1.3509]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 96/148 [01:29<00:47,  1.10it/s, training_loss=1.4814]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 97/148 [01:29<00:46,  1.10it/s, training_loss=1.4814]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 97/148 [01:30<00:46,  1.10it/s, training_loss=1.6000]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 98/148 [01:30<00:45,  1.10it/s, training_loss=1.6000]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 98/148 [01:30<00:45,  1.10it/s, training_loss=1.5173]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 99/148 [01:30<00:44,  1.10it/s, training_loss=1.5173]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 99/148 [01:31<00:44,  1.10it/s, training_loss=1.6352]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 100/148 [01:31<00:43,  1.10it/s, training_loss=1.6352]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 100/148 [01:32<00:43,  1.10it/s, training_loss=1.5929]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 101/148 [01:32<00:42,  1.10it/s, training_loss=1.5929]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 101/148 [01:33<00:42,  1.10it/s, training_loss=1.5314]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 102/148 [01:33<00:41,  1.10it/s, training_loss=1.5314]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 102/148 [01:34<00:41,  1.10it/s, training_loss=1.3506]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 103/148 [01:34<00:40,  1.10it/s, training_loss=1.3506]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 103/148 [01:35<00:40,  1.10it/s, training_loss=1.5031]\u001b[A\n",
      "Epoch 1:  70%|███████   | 104/148 [01:35<00:40,  1.10it/s, training_loss=1.5031]\u001b[A\n",
      "Epoch 1:  70%|███████   | 104/148 [01:36<00:40,  1.10it/s, training_loss=1.7075]\u001b[A\n",
      "Epoch 1:  71%|███████   | 105/148 [01:36<00:39,  1.10it/s, training_loss=1.7075]\u001b[A\n",
      "Epoch 1:  71%|███████   | 105/148 [01:37<00:39,  1.10it/s, training_loss=1.5587]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 106/148 [01:37<00:38,  1.10it/s, training_loss=1.5587]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 106/148 [01:38<00:38,  1.10it/s, training_loss=1.5503]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 107/148 [01:38<00:37,  1.10it/s, training_loss=1.5503]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 107/148 [01:39<00:37,  1.10it/s, training_loss=1.5818]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 108/148 [01:39<00:36,  1.10it/s, training_loss=1.5818]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 108/148 [01:40<00:36,  1.10it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 109/148 [01:41<00:35,  1.09it/s, training_loss=1.4202]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.4202]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.6016]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 111/148 [01:41<00:33,  1.09it/s, training_loss=1.6016]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=1.5140]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 112/148 [01:42<00:32,  1.10it/s, training_loss=1.5140]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 112/148 [01:43<00:32,  1.10it/s, training_loss=1.3705]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 113/148 [01:43<00:31,  1.10it/s, training_loss=1.3705]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 113/148 [01:44<00:31,  1.10it/s, training_loss=1.4226]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.4226]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.5935]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.5935]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=1.5813]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.5813]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=1.6144]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.6144]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.6131]\u001b[A\n",
      "Epoch 1:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.6131]\u001b[A\n",
      "Epoch 1:  80%|████████  | 119/148 [01:50<00:26,  1.09it/s, training_loss=1.2868]\u001b[A\n",
      "Epoch 1:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.2868]\u001b[A\n",
      "Epoch 1:  81%|████████  | 120/148 [01:51<00:25,  1.09it/s, training_loss=1.4815]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.4815]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 121/148 [01:52<00:24,  1.09it/s, training_loss=1.4318]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.4318]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.4791]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 123/148 [01:52<00:22,  1.09it/s, training_loss=1.4791]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=1.5172]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 124/148 [01:53<00:22,  1.09it/s, training_loss=1.5172]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 124/148 [01:54<00:22,  1.09it/s, training_loss=1.6444]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 125/148 [01:54<00:21,  1.09it/s, training_loss=1.6444]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=1.4573]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 126/148 [01:55<00:20,  1.09it/s, training_loss=1.4573]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=1.4870]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=1.4870]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.6995]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.6995]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.5775]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.5775]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=1.4734]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.4734]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=1.4530]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.4530]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=1.5059]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.5059]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 132/148 [02:02<00:14,  1.09it/s, training_loss=1.4664]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.4664]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 133/148 [02:03<00:13,  1.09it/s, training_loss=1.5728]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.5728]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.3997]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 135/148 [02:03<00:11,  1.08it/s, training_loss=1.3997]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 135/148 [02:04<00:11,  1.08it/s, training_loss=1.4788]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 136/148 [02:04<00:11,  1.08it/s, training_loss=1.4788]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 136/148 [02:05<00:11,  1.08it/s, training_loss=1.5986]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 137/148 [02:05<00:10,  1.08it/s, training_loss=1.5986]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 137/148 [02:06<00:10,  1.08it/s, training_loss=1.3201]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 138/148 [02:06<00:09,  1.08it/s, training_loss=1.3201]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 138/148 [02:07<00:09,  1.08it/s, training_loss=1.6267]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.6267]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.5143]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 140/148 [02:08<00:07,  1.08it/s, training_loss=1.5143]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 140/148 [02:09<00:07,  1.08it/s, training_loss=1.5426]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 141/148 [02:09<00:06,  1.08it/s, training_loss=1.5426]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 141/148 [02:10<00:06,  1.08it/s, training_loss=1.5867]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 142/148 [02:10<00:05,  1.08it/s, training_loss=1.5867]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 142/148 [02:11<00:05,  1.08it/s, training_loss=1.5931]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 143/148 [02:11<00:04,  1.08it/s, training_loss=1.5931]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 143/148 [02:12<00:04,  1.08it/s, training_loss=1.6244]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 144/148 [02:12<00:03,  1.08it/s, training_loss=1.6244]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 144/148 [02:13<00:03,  1.08it/s, training_loss=1.5854]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 145/148 [02:13<00:02,  1.08it/s, training_loss=1.5854]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 145/148 [02:14<00:02,  1.08it/s, training_loss=1.6205]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 146/148 [02:14<00:01,  1.08it/s, training_loss=1.6205]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 146/148 [02:15<00:01,  1.08it/s, training_loss=1.6502]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.6502]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.5297]\u001b[A\n",
      "Epoch 1: 100%|██████████| 148/148 [02:15<00:00,  1.17it/s, training_loss=1.5297]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:49:37,815 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:49:37,816 - INFO - Memory usage after evaluation start: 3564.16 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=66.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.53it/s, Accuracy=66.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.53it/s, Accuracy=67.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:07,  3.54it/s, Accuracy=67.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:07,  3.54it/s, Accuracy=63.33%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.54it/s, Accuracy=63.33%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.54it/s, Accuracy=62.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.52it/s, Accuracy=62.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.52it/s, Accuracy=63.20%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.53it/s, Accuracy=63.20%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.53it/s, Accuracy=64.33%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.53it/s, Accuracy=64.33%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.53it/s, Accuracy=63.43%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.53it/s, Accuracy=63.43%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.53it/s, Accuracy=63.00%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.53it/s, Accuracy=63.00%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.53it/s, Accuracy=62.67%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.54it/s, Accuracy=62.67%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.54it/s, Accuracy=62.20%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.53it/s, Accuracy=62.20%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.53it/s, Accuracy=62.36%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.54it/s, Accuracy=62.36%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.54it/s, Accuracy=62.17%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.54it/s, Accuracy=62.17%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.54it/s, Accuracy=62.00%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.54it/s, Accuracy=62.00%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.54it/s, Accuracy=61.71%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.55it/s, Accuracy=61.71%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.55it/s, Accuracy=61.60%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.54it/s, Accuracy=61.60%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.54it/s, Accuracy=61.12%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.53it/s, Accuracy=61.12%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.53it/s, Accuracy=60.94%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.54it/s, Accuracy=60.94%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:02,  3.54it/s, Accuracy=60.67%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.54it/s, Accuracy=60.67%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.54it/s, Accuracy=60.53%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.54it/s, Accuracy=60.53%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.54it/s, Accuracy=60.70%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.54it/s, Accuracy=60.70%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.54it/s, Accuracy=60.76%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.53it/s, Accuracy=60.76%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.53it/s, Accuracy=60.45%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.53it/s, Accuracy=60.45%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.53it/s, Accuracy=60.61%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.53it/s, Accuracy=60.61%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.53it/s, Accuracy=60.42%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.54it/s, Accuracy=60.42%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:07<00:00,  3.54it/s, Accuracy=60.24%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.53it/s, Accuracy=60.24%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.53it/s, Accuracy=60.38%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.53it/s, Accuracy=60.38%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.65it/s, Accuracy=60.38%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:49:45,213 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:49:45,220 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:49:45,221 - INFO - Accuracy: 0.5556\n",
      "2025-02-19 10:49:45,221 - INFO - F1_score: 0.5000\n",
      "2025-02-19 10:49:45,222 - INFO - Precision: 0.3671\n",
      "2025-02-19 10:49:45,223 - INFO - Recall: 0.7838\n",
      "2025-02-19 10:49:45,229 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:49:45,230 - INFO - Accuracy: 0.6935\n",
      "2025-02-19 10:49:45,230 - INFO - F1_score: 0.5652\n",
      "2025-02-19 10:49:45,232 - INFO - Precision: 0.4094\n",
      "2025-02-19 10:49:45,232 - INFO - Recall: 0.9123\n",
      "2025-02-19 10:49:45,238 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:49:45,238 - INFO - Accuracy: 0.4751\n",
      "2025-02-19 10:49:45,239 - INFO - F1_score: 0.4219\n",
      "2025-02-19 10:49:45,240 - INFO - Precision: 0.2793\n",
      "2025-02-19 10:49:45,241 - INFO - Recall: 0.8621\n",
      "2025-02-19 10:49:45,247 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:49:45,248 - INFO - Accuracy: 0.6513\n",
      "2025-02-19 10:49:45,249 - INFO - F1_score: 0.3158\n",
      "2025-02-19 10:49:45,249 - INFO - Precision: 0.2211\n",
      "2025-02-19 10:49:45,251 - INFO - Recall: 0.5526\n",
      "2025-02-19 10:49:45,256 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:49:45,257 - INFO - Accuracy: 0.6437\n",
      "2025-02-19 10:49:45,257 - INFO - F1_score: 0.3586\n",
      "2025-02-19 10:49:45,258 - INFO - Precision: 0.2342\n",
      "2025-02-19 10:49:45,259 - INFO - Recall: 0.7647\n",
      "2025-02-19 10:49:45,261 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:49:49,072 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:49:49,073 - INFO - Memory usage after evaluation end: 3568.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [02:34<?, ?it/s, Train Loss=1.5694, Val Loss=0.0439, Accuracy=0.6038]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:49:56,419 - INFO - New best accuracy: 0.6038\n",
      "2025-02-19 10:49:57,321 - INFO - New best loss: 0.0439\n",
      "2025-02-19 10:49:57,908 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 1/100 [02:35<4:17:08, 155.84s/it, Train Loss=1.5694, Val Loss=0.0439, Accuracy=0.6038]\n",
      "Epoch 2:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.5767]\u001b[A\n",
      "Epoch 2:   1%|          | 1/148 [00:00<02:12,  1.11it/s, training_loss=1.5767]\u001b[A\n",
      "Epoch 2:   1%|          | 1/148 [00:01<02:12,  1.11it/s, training_loss=1.6365]\u001b[A\n",
      "Epoch 2:   1%|▏         | 2/148 [00:01<02:12,  1.10it/s, training_loss=1.6365]\u001b[A\n",
      "Epoch 2:   1%|▏         | 2/148 [00:02<02:12,  1.10it/s, training_loss=1.3667]\u001b[A\n",
      "Epoch 2:   2%|▏         | 3/148 [00:02<02:12,  1.09it/s, training_loss=1.3667]\u001b[A\n",
      "Epoch 2:   2%|▏         | 3/148 [00:03<02:12,  1.09it/s, training_loss=1.4103]\u001b[A\n",
      "Epoch 2:   3%|▎         | 4/148 [00:03<02:12,  1.09it/s, training_loss=1.4103]\u001b[A\n",
      "Epoch 2:   3%|▎         | 4/148 [00:04<02:12,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 2:   3%|▎         | 5/148 [00:04<02:11,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 2:   3%|▎         | 5/148 [00:05<02:11,  1.09it/s, training_loss=1.5661]\u001b[A\n",
      "Epoch 2:   4%|▍         | 6/148 [00:05<02:10,  1.09it/s, training_loss=1.5661]\u001b[A\n",
      "Epoch 2:   4%|▍         | 6/148 [00:06<02:10,  1.09it/s, training_loss=1.4789]\u001b[A\n",
      "Epoch 2:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=1.4789]\u001b[A\n",
      "Epoch 2:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=1.3990]\u001b[A\n",
      "Epoch 2:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=1.3990]\u001b[A\n",
      "Epoch 2:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=1.6058]\u001b[A\n",
      "Epoch 2:   6%|▌         | 9/148 [00:08<02:07,  1.09it/s, training_loss=1.6058]\u001b[A\n",
      "Epoch 2:   6%|▌         | 9/148 [00:09<02:07,  1.09it/s, training_loss=1.5857]\u001b[A\n",
      "Epoch 2:   7%|▋         | 10/148 [00:09<02:06,  1.09it/s, training_loss=1.5857]\u001b[A\n",
      "Epoch 2:   7%|▋         | 10/148 [00:10<02:06,  1.09it/s, training_loss=1.5293]\u001b[A\n",
      "Epoch 2:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.5293]\u001b[A\n",
      "Epoch 2:   7%|▋         | 11/148 [00:11<02:05,  1.09it/s, training_loss=1.4582]\u001b[A\n",
      "Epoch 2:   8%|▊         | 12/148 [00:11<02:05,  1.09it/s, training_loss=1.4582]\u001b[A\n",
      "Epoch 2:   8%|▊         | 12/148 [00:11<02:05,  1.09it/s, training_loss=1.6277]\u001b[A\n",
      "Epoch 2:   9%|▉         | 13/148 [00:11<02:04,  1.09it/s, training_loss=1.6277]\u001b[A\n",
      "Epoch 2:   9%|▉         | 13/148 [00:12<02:04,  1.09it/s, training_loss=1.6186]\u001b[A\n",
      "Epoch 2:   9%|▉         | 14/148 [00:12<02:03,  1.09it/s, training_loss=1.6186]\u001b[A\n",
      "Epoch 2:   9%|▉         | 14/148 [00:13<02:03,  1.09it/s, training_loss=1.7052]\u001b[A\n",
      "Epoch 2:  10%|█         | 15/148 [00:13<02:01,  1.09it/s, training_loss=1.7052]\u001b[A\n",
      "Epoch 2:  10%|█         | 15/148 [00:14<02:01,  1.09it/s, training_loss=1.4475]\u001b[A\n",
      "Epoch 2:  11%|█         | 16/148 [00:14<02:01,  1.09it/s, training_loss=1.4475]\u001b[A\n",
      "Epoch 2:  11%|█         | 16/148 [00:15<02:01,  1.09it/s, training_loss=1.4664]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 17/148 [00:15<02:01,  1.08it/s, training_loss=1.4664]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 17/148 [00:16<02:01,  1.08it/s, training_loss=1.5395]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 18/148 [00:16<01:59,  1.08it/s, training_loss=1.5395]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 18/148 [00:17<01:59,  1.08it/s, training_loss=1.6694]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 19/148 [00:17<01:59,  1.08it/s, training_loss=1.6694]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 19/148 [00:18<01:59,  1.08it/s, training_loss=1.4661]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 20/148 [00:18<01:58,  1.08it/s, training_loss=1.4661]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 20/148 [00:19<01:58,  1.08it/s, training_loss=1.4974]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 21/148 [00:19<01:57,  1.08it/s, training_loss=1.4974]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 21/148 [00:20<01:57,  1.08it/s, training_loss=1.3821]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 22/148 [00:20<01:56,  1.08it/s, training_loss=1.3821]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 22/148 [00:21<01:56,  1.08it/s, training_loss=1.4012]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 23/148 [00:21<01:55,  1.08it/s, training_loss=1.4012]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 23/148 [00:22<01:55,  1.08it/s, training_loss=1.6053]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 24/148 [00:22<01:55,  1.08it/s, training_loss=1.6053]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 24/148 [00:23<01:55,  1.08it/s, training_loss=1.6029]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.6029]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.3442]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 26/148 [00:23<01:53,  1.08it/s, training_loss=1.3442]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 26/148 [00:24<01:53,  1.08it/s, training_loss=1.3421]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 27/148 [00:24<01:52,  1.07it/s, training_loss=1.3421]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 27/148 [00:25<01:52,  1.07it/s, training_loss=1.3020]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 28/148 [00:25<01:51,  1.08it/s, training_loss=1.3020]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 28/148 [00:26<01:51,  1.08it/s, training_loss=1.2697]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 29/148 [00:26<01:50,  1.08it/s, training_loss=1.2697]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 29/148 [00:27<01:50,  1.08it/s, training_loss=1.4487]\u001b[A\n",
      "Epoch 2:  20%|██        | 30/148 [00:27<01:50,  1.07it/s, training_loss=1.4487]\u001b[A\n",
      "Epoch 2:  20%|██        | 30/148 [00:28<01:50,  1.07it/s, training_loss=1.6179]\u001b[A\n",
      "Epoch 2:  21%|██        | 31/148 [00:28<01:49,  1.07it/s, training_loss=1.6179]\u001b[A\n",
      "Epoch 2:  21%|██        | 31/148 [00:29<01:49,  1.07it/s, training_loss=1.5134]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 32/148 [00:29<01:47,  1.07it/s, training_loss=1.5134]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 32/148 [00:30<01:47,  1.07it/s, training_loss=1.5491]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 33/148 [00:30<01:46,  1.08it/s, training_loss=1.5491]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 33/148 [00:31<01:46,  1.08it/s, training_loss=1.5366]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 34/148 [00:31<01:45,  1.08it/s, training_loss=1.5366]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 34/148 [00:32<01:45,  1.08it/s, training_loss=1.6152]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 35/148 [00:32<01:44,  1.08it/s, training_loss=1.6152]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 35/148 [00:33<01:44,  1.08it/s, training_loss=1.4156]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 36/148 [00:33<01:43,  1.08it/s, training_loss=1.4156]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 36/148 [00:34<01:43,  1.08it/s, training_loss=1.4338]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=1.4338]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 37/148 [00:35<01:42,  1.08it/s, training_loss=1.5089]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 38/148 [00:35<01:42,  1.08it/s, training_loss=1.5089]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 38/148 [00:36<01:42,  1.08it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 39/148 [00:36<01:40,  1.08it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 39/148 [00:36<01:40,  1.08it/s, training_loss=1.6618]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 40/148 [00:36<01:39,  1.08it/s, training_loss=1.6618]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 40/148 [00:37<01:39,  1.08it/s, training_loss=1.3912]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 41/148 [00:37<01:38,  1.08it/s, training_loss=1.3912]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 41/148 [00:38<01:38,  1.08it/s, training_loss=1.3530]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 42/148 [00:38<01:37,  1.08it/s, training_loss=1.3530]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 42/148 [00:39<01:37,  1.08it/s, training_loss=1.5377]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 43/148 [00:39<01:37,  1.08it/s, training_loss=1.5377]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 43/148 [00:40<01:37,  1.08it/s, training_loss=1.5530]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 44/148 [00:40<01:36,  1.08it/s, training_loss=1.5530]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 44/148 [00:41<01:36,  1.08it/s, training_loss=1.5576]\u001b[A\n",
      "Epoch 2:  30%|███       | 45/148 [00:41<01:35,  1.08it/s, training_loss=1.5576]\u001b[A\n",
      "Epoch 2:  30%|███       | 45/148 [00:42<01:35,  1.08it/s, training_loss=1.2908]\u001b[A\n",
      "Epoch 2:  31%|███       | 46/148 [00:42<01:34,  1.08it/s, training_loss=1.2908]\u001b[A\n",
      "Epoch 2:  31%|███       | 46/148 [00:43<01:34,  1.08it/s, training_loss=1.5581]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.5581]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.4454]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 48/148 [00:44<01:32,  1.09it/s, training_loss=1.4454]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 48/148 [00:45<01:32,  1.09it/s, training_loss=1.6518]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=1.6518]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 49/148 [00:46<01:30,  1.09it/s, training_loss=1.7912]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=1.7912]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 50/148 [00:47<01:29,  1.09it/s, training_loss=1.1866]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 51/148 [00:47<01:28,  1.09it/s, training_loss=1.1866]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 51/148 [00:47<01:28,  1.09it/s, training_loss=1.4350]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 52/148 [00:48<01:28,  1.08it/s, training_loss=1.4350]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 52/148 [00:48<01:28,  1.08it/s, training_loss=1.5632]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 53/148 [00:48<01:27,  1.09it/s, training_loss=1.5632]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 53/148 [00:49<01:27,  1.09it/s, training_loss=1.5927]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 54/148 [00:49<01:26,  1.09it/s, training_loss=1.5927]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 54/148 [00:50<01:26,  1.09it/s, training_loss=1.5042]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.5042]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.6792]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=1.6792]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.5024]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 57/148 [00:52<01:23,  1.08it/s, training_loss=1.5024]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 57/148 [00:53<01:23,  1.08it/s, training_loss=1.4067]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 58/148 [00:53<01:23,  1.08it/s, training_loss=1.4067]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 58/148 [00:54<01:23,  1.08it/s, training_loss=1.5858]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 59/148 [00:54<01:22,  1.08it/s, training_loss=1.5858]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 59/148 [00:55<01:22,  1.08it/s, training_loss=1.4455]\u001b[A\n",
      "Epoch 2:  41%|████      | 60/148 [00:55<01:21,  1.08it/s, training_loss=1.4455]\u001b[A\n",
      "Epoch 2:  41%|████      | 60/148 [00:56<01:21,  1.08it/s, training_loss=1.5490]\u001b[A\n",
      "Epoch 2:  41%|████      | 61/148 [00:56<01:20,  1.09it/s, training_loss=1.5490]\u001b[A\n",
      "Epoch 2:  41%|████      | 61/148 [00:57<01:20,  1.09it/s, training_loss=1.3151]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 62/148 [00:57<01:19,  1.09it/s, training_loss=1.3151]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 62/148 [00:58<01:19,  1.09it/s, training_loss=1.4724]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 63/148 [00:58<01:18,  1.08it/s, training_loss=1.4724]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 63/148 [00:59<01:18,  1.08it/s, training_loss=1.4882]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 64/148 [00:59<01:17,  1.08it/s, training_loss=1.4882]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 64/148 [00:59<01:17,  1.08it/s, training_loss=1.5704]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 65/148 [00:59<01:16,  1.08it/s, training_loss=1.5704]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 65/148 [01:00<01:16,  1.08it/s, training_loss=1.5824]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 66/148 [01:00<01:15,  1.08it/s, training_loss=1.5824]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 66/148 [01:01<01:15,  1.08it/s, training_loss=1.3251]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 67/148 [01:01<01:14,  1.08it/s, training_loss=1.3251]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 67/148 [01:02<01:14,  1.08it/s, training_loss=1.2810]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=1.2810]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=1.5288]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=1.5288]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=1.4375]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=1.4375]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=1.5230]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=1.5230]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.2852]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=1.2852]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 72/148 [01:07<01:09,  1.09it/s, training_loss=1.3937]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 73/148 [01:07<01:09,  1.09it/s, training_loss=1.3937]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 73/148 [01:08<01:09,  1.09it/s, training_loss=1.6559]\u001b[A\n",
      "Epoch 2:  50%|█████     | 74/148 [01:08<01:08,  1.09it/s, training_loss=1.6559]\u001b[A\n",
      "Epoch 2:  50%|█████     | 74/148 [01:09<01:08,  1.09it/s, training_loss=1.5604]\u001b[A\n",
      "Epoch 2:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.5604]\u001b[A\n",
      "Epoch 2:  51%|█████     | 75/148 [01:10<01:06,  1.09it/s, training_loss=1.6513]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=1.6513]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=1.3603]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 77/148 [01:10<01:05,  1.09it/s, training_loss=1.3603]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 77/148 [01:11<01:05,  1.09it/s, training_loss=1.5770]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 78/148 [01:11<01:04,  1.09it/s, training_loss=1.5770]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 78/148 [01:12<01:04,  1.09it/s, training_loss=1.4521]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 79/148 [01:12<01:03,  1.09it/s, training_loss=1.4521]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 79/148 [01:13<01:03,  1.09it/s, training_loss=1.4123]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.4123]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.4382]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=1.4382]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=1.5748]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.5748]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.3198]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 83/148 [01:16<00:59,  1.10it/s, training_loss=1.3198]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 83/148 [01:17<00:59,  1.10it/s, training_loss=1.6043]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 84/148 [01:17<00:58,  1.10it/s, training_loss=1.6043]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 84/148 [01:18<00:58,  1.10it/s, training_loss=1.7415]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.7415]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 85/148 [01:19<00:57,  1.09it/s, training_loss=1.4777]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.4777]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 86/148 [01:20<00:56,  1.09it/s, training_loss=1.6623]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 87/148 [01:20<00:55,  1.09it/s, training_loss=1.6623]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 87/148 [01:21<00:55,  1.09it/s, training_loss=1.6325]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.6325]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.5757]\u001b[A\n",
      "Epoch 2:  60%|██████    | 89/148 [01:21<00:54,  1.09it/s, training_loss=1.5757]\u001b[A\n",
      "Epoch 2:  60%|██████    | 89/148 [01:22<00:54,  1.09it/s, training_loss=1.5468]\u001b[A\n",
      "Epoch 2:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=1.5468]\u001b[A\n",
      "Epoch 2:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=1.4857]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=1.4857]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.3829]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.3829]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=1.6785]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.6785]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.6095]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=1.6095]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.6098]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.6098]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=1.2484]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 96/148 [01:28<00:47,  1.08it/s, training_loss=1.2484]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 96/148 [01:29<00:47,  1.08it/s, training_loss=1.4477]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 97/148 [01:29<00:47,  1.08it/s, training_loss=1.4477]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 97/148 [01:30<00:47,  1.08it/s, training_loss=1.3147]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 98/148 [01:30<00:46,  1.09it/s, training_loss=1.3147]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 98/148 [01:31<00:46,  1.09it/s, training_loss=1.5562]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 99/148 [01:31<00:45,  1.09it/s, training_loss=1.5562]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 99/148 [01:32<00:45,  1.09it/s, training_loss=1.3053]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 100/148 [01:32<00:44,  1.09it/s, training_loss=1.3053]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 100/148 [01:33<00:44,  1.09it/s, training_loss=1.2792]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 101/148 [01:33<00:43,  1.08it/s, training_loss=1.2792]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 101/148 [01:33<00:43,  1.08it/s, training_loss=1.6456]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.6456]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=1.6134]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 103/148 [01:34<00:41,  1.08it/s, training_loss=1.6134]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 103/148 [01:35<00:41,  1.08it/s, training_loss=1.3470]\u001b[A\n",
      "Epoch 2:  70%|███████   | 104/148 [01:35<00:40,  1.08it/s, training_loss=1.3470]\u001b[A\n",
      "Epoch 2:  70%|███████   | 104/148 [01:36<00:40,  1.08it/s, training_loss=1.6637]\u001b[A\n",
      "Epoch 2:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=1.6637]\u001b[A\n",
      "Epoch 2:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.3050]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.3050]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=1.2933]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=1.2933]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 107/148 [01:39<00:37,  1.09it/s, training_loss=1.5517]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=1.5517]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 108/148 [01:40<00:36,  1.09it/s, training_loss=1.3332]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.3332]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 109/148 [01:41<00:35,  1.09it/s, training_loss=1.1892]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.1892]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 110/148 [01:42<00:34,  1.09it/s, training_loss=1.1882]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 111/148 [01:42<00:34,  1.08it/s, training_loss=1.1882]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 111/148 [01:43<00:34,  1.08it/s, training_loss=1.1233]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 112/148 [01:43<00:33,  1.08it/s, training_loss=1.1233]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 112/148 [01:44<00:33,  1.08it/s, training_loss=1.6987]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.6987]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 113/148 [01:45<00:32,  1.09it/s, training_loss=1.5535]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.5535]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.3558]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 115/148 [01:45<00:30,  1.08it/s, training_loss=1.3558]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 115/148 [01:46<00:30,  1.08it/s, training_loss=1.3051]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 116/148 [01:46<00:29,  1.08it/s, training_loss=1.3051]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 116/148 [01:47<00:29,  1.08it/s, training_loss=1.2602]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 117/148 [01:47<00:28,  1.08it/s, training_loss=1.2602]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 117/148 [01:48<00:28,  1.08it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 118/148 [01:48<00:27,  1.08it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 118/148 [01:49<00:27,  1.08it/s, training_loss=1.1622]\u001b[A\n",
      "Epoch 2:  80%|████████  | 119/148 [01:49<00:26,  1.08it/s, training_loss=1.1622]\u001b[A\n",
      "Epoch 2:  80%|████████  | 119/148 [01:50<00:26,  1.08it/s, training_loss=1.2245]\u001b[A\n",
      "Epoch 2:  81%|████████  | 120/148 [01:50<00:25,  1.08it/s, training_loss=1.2245]\u001b[A\n",
      "Epoch 2:  81%|████████  | 120/148 [01:51<00:25,  1.08it/s, training_loss=1.5115]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 121/148 [01:51<00:24,  1.08it/s, training_loss=1.5115]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 121/148 [01:52<00:24,  1.08it/s, training_loss=1.6076]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 122/148 [01:52<00:24,  1.08it/s, training_loss=1.6076]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 122/148 [01:53<00:24,  1.08it/s, training_loss=1.5548]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 123/148 [01:53<00:23,  1.08it/s, training_loss=1.5548]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 123/148 [01:54<00:23,  1.08it/s, training_loss=1.4954]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 124/148 [01:54<00:22,  1.09it/s, training_loss=1.4954]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 124/148 [01:55<00:22,  1.09it/s, training_loss=1.4742]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=1.4742]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 125/148 [01:56<00:21,  1.09it/s, training_loss=1.4944]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=1.4944]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 126/148 [01:57<00:20,  1.09it/s, training_loss=1.4285]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.4285]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.2727]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.2727]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.2132]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 129/148 [01:58<00:17,  1.08it/s, training_loss=1.2132]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 129/148 [01:59<00:17,  1.08it/s, training_loss=1.2452]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 130/148 [01:59<00:16,  1.08it/s, training_loss=1.2452]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 130/148 [02:00<00:16,  1.08it/s, training_loss=1.2583]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 131/148 [02:00<00:15,  1.08it/s, training_loss=1.2583]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 131/148 [02:01<00:15,  1.08it/s, training_loss=1.6078]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.6078]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 132/148 [02:02<00:14,  1.09it/s, training_loss=1.3343]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 133/148 [02:02<00:13,  1.08it/s, training_loss=1.3343]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 133/148 [02:03<00:13,  1.08it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 134/148 [02:03<00:12,  1.08it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 134/148 [02:04<00:12,  1.08it/s, training_loss=1.3266]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 135/148 [02:04<00:12,  1.08it/s, training_loss=1.3266]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 135/148 [02:05<00:12,  1.08it/s, training_loss=1.5101]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 136/148 [02:05<00:11,  1.08it/s, training_loss=1.5101]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 136/148 [02:06<00:11,  1.08it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 137/148 [02:06<00:10,  1.08it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 137/148 [02:07<00:10,  1.08it/s, training_loss=1.5325]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.5325]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 138/148 [02:08<00:09,  1.09it/s, training_loss=1.4959]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.4959]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 139/148 [02:09<00:08,  1.09it/s, training_loss=1.6472]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 140/148 [02:09<00:07,  1.08it/s, training_loss=1.6472]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 140/148 [02:09<00:07,  1.08it/s, training_loss=1.3048]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 141/148 [02:09<00:06,  1.08it/s, training_loss=1.3048]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 141/148 [02:10<00:06,  1.08it/s, training_loss=1.6091]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 142/148 [02:10<00:05,  1.08it/s, training_loss=1.6091]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 142/148 [02:11<00:05,  1.08it/s, training_loss=1.5088]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.5088]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=1.5148]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=1.5148]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 144/148 [02:13<00:03,  1.09it/s, training_loss=1.3371]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 145/148 [02:13<00:02,  1.08it/s, training_loss=1.3371]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 145/148 [02:14<00:02,  1.08it/s, training_loss=1.0625]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 146/148 [02:14<00:01,  1.08it/s, training_loss=1.0625]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 146/148 [02:15<00:01,  1.08it/s, training_loss=1.2645]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 147/148 [02:15<00:00,  1.08it/s, training_loss=1.2645]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 147/148 [02:16<00:00,  1.08it/s, training_loss=1.4176]\u001b[A\n",
      "Epoch 2: 100%|██████████| 148/148 [02:16<00:00,  1.18it/s, training_loss=1.4176]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:52:14,074 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:52:14,076 - INFO - Memory usage after evaluation start: 3981.03 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=66.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.61it/s, Accuracy=66.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.61it/s, Accuracy=66.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.58it/s, Accuracy=66.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.58it/s, Accuracy=65.33%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.58it/s, Accuracy=65.33%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.58it/s, Accuracy=64.50%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.56it/s, Accuracy=64.50%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.56it/s, Accuracy=65.20%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.56it/s, Accuracy=65.20%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.56it/s, Accuracy=64.33%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.55it/s, Accuracy=64.33%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.55it/s, Accuracy=63.14%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.54it/s, Accuracy=63.14%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.54it/s, Accuracy=62.25%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.54it/s, Accuracy=62.25%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.54it/s, Accuracy=62.44%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.53it/s, Accuracy=62.44%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.53it/s, Accuracy=62.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.53it/s, Accuracy=62.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.53it/s, Accuracy=61.82%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.53it/s, Accuracy=61.82%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.53it/s, Accuracy=61.67%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.53it/s, Accuracy=61.67%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.53it/s, Accuracy=61.38%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.54it/s, Accuracy=61.38%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.54it/s, Accuracy=61.43%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.54it/s, Accuracy=61.43%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.54it/s, Accuracy=62.00%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.53it/s, Accuracy=62.00%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.53it/s, Accuracy=61.50%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.53it/s, Accuracy=61.50%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.53it/s, Accuracy=61.65%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.53it/s, Accuracy=61.65%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:02,  3.53it/s, Accuracy=62.00%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.53it/s, Accuracy=62.00%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.53it/s, Accuracy=62.32%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.53it/s, Accuracy=62.32%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.53it/s, Accuracy=62.50%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.53it/s, Accuracy=62.50%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.53it/s, Accuracy=62.95%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.54it/s, Accuracy=62.95%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.54it/s, Accuracy=62.82%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.53it/s, Accuracy=62.82%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.53it/s, Accuracy=62.78%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.52it/s, Accuracy=62.78%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.52it/s, Accuracy=62.67%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.53it/s, Accuracy=62.67%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:07<00:00,  3.53it/s, Accuracy=62.72%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.52it/s, Accuracy=62.72%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.52it/s, Accuracy=62.92%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.53it/s, Accuracy=62.92%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.65it/s, Accuracy=62.91%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:52:21,471 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:52:21,477 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:52:21,477 - INFO - Accuracy: 0.5057\n",
      "2025-02-19 10:52:21,478 - INFO - F1_score: 0.5019\n",
      "2025-02-19 10:52:21,479 - INFO - Precision: 0.3514\n",
      "2025-02-19 10:52:21,480 - INFO - Recall: 0.8784\n",
      "2025-02-19 10:52:21,486 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:52:21,487 - INFO - Accuracy: 0.8199\n",
      "2025-02-19 10:52:21,488 - INFO - F1_score: 0.6887\n",
      "2025-02-19 10:52:21,488 - INFO - Precision: 0.5532\n",
      "2025-02-19 10:52:21,489 - INFO - Recall: 0.9123\n",
      "2025-02-19 10:52:21,495 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:52:21,496 - INFO - Accuracy: 0.4023\n",
      "2025-02-19 10:52:21,497 - INFO - F1_score: 0.4135\n",
      "2025-02-19 10:52:21,498 - INFO - Precision: 0.2644\n",
      "2025-02-19 10:52:21,499 - INFO - Recall: 0.9483\n",
      "2025-02-19 10:52:21,505 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:52:21,505 - INFO - Accuracy: 0.7165\n",
      "2025-02-19 10:52:21,506 - INFO - F1_score: 0.4127\n",
      "2025-02-19 10:52:21,507 - INFO - Precision: 0.2955\n",
      "2025-02-19 10:52:21,508 - INFO - Recall: 0.6842\n",
      "2025-02-19 10:52:21,514 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:52:21,515 - INFO - Accuracy: 0.7011\n",
      "2025-02-19 10:52:21,515 - INFO - F1_score: 0.4000\n",
      "2025-02-19 10:52:21,516 - INFO - Precision: 0.2708\n",
      "2025-02-19 10:52:21,518 - INFO - Recall: 0.7647\n",
      "2025-02-19 10:52:21,519 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:52:25,333 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:52:25,334 - INFO - Memory usage after evaluation end: 3986.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 1/100 [05:10<4:17:08, 155.84s/it, Train Loss=1.4713, Val Loss=0.0483, Accuracy=0.6291]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:52:32,607 - INFO - New best accuracy: 0.6291\n",
      "2025-02-19 10:52:33,544 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 2/100 [05:11<4:14:20, 155.72s/it, Train Loss=1.4713, Val Loss=0.0483, Accuracy=0.6291]\n",
      "Epoch 3:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.4680]\u001b[A\n",
      "Epoch 3:   1%|          | 1/148 [00:00<02:13,  1.10it/s, training_loss=1.4680]\u001b[A\n",
      "Epoch 3:   1%|          | 1/148 [00:01<02:13,  1.10it/s, training_loss=1.2389]\u001b[A\n",
      "Epoch 3:   1%|▏         | 2/148 [00:01<02:13,  1.09it/s, training_loss=1.2389]\u001b[A\n",
      "Epoch 3:   1%|▏         | 2/148 [00:02<02:13,  1.09it/s, training_loss=1.6273]\u001b[A\n",
      "Epoch 3:   2%|▏         | 3/148 [00:02<02:12,  1.09it/s, training_loss=1.6273]\u001b[A\n",
      "Epoch 3:   2%|▏         | 3/148 [00:03<02:12,  1.09it/s, training_loss=1.7014]\u001b[A\n",
      "Epoch 3:   3%|▎         | 4/148 [00:03<02:11,  1.10it/s, training_loss=1.7014]\u001b[A\n",
      "Epoch 3:   3%|▎         | 4/148 [00:04<02:11,  1.10it/s, training_loss=1.3102]\u001b[A\n",
      "Epoch 3:   3%|▎         | 5/148 [00:04<02:11,  1.09it/s, training_loss=1.3102]\u001b[A\n",
      "Epoch 3:   3%|▎         | 5/148 [00:05<02:11,  1.09it/s, training_loss=1.2826]\u001b[A\n",
      "Epoch 3:   4%|▍         | 6/148 [00:05<02:10,  1.09it/s, training_loss=1.2826]\u001b[A\n",
      "Epoch 3:   4%|▍         | 6/148 [00:06<02:10,  1.09it/s, training_loss=1.5797]\u001b[A\n",
      "Epoch 3:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=1.5797]\u001b[A\n",
      "Epoch 3:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=1.5303]\u001b[A\n",
      "Epoch 3:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=1.5303]\u001b[A\n",
      "Epoch 3:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=1.3281]\u001b[A\n",
      "Epoch 3:   6%|▌         | 9/148 [00:08<02:07,  1.09it/s, training_loss=1.3281]\u001b[A\n",
      "Epoch 3:   6%|▌         | 9/148 [00:09<02:07,  1.09it/s, training_loss=1.5345]\u001b[A\n",
      "Epoch 3:   7%|▋         | 10/148 [00:09<02:07,  1.09it/s, training_loss=1.5345]\u001b[A\n",
      "Epoch 3:   7%|▋         | 10/148 [00:10<02:07,  1.09it/s, training_loss=1.5924]\u001b[A\n",
      "Epoch 3:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.5924]\u001b[A\n",
      "Epoch 3:   7%|▋         | 11/148 [00:11<02:05,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 3:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 3:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.4662]\u001b[A\n",
      "Epoch 3:   9%|▉         | 13/148 [00:11<02:03,  1.09it/s, training_loss=1.4662]\u001b[A\n",
      "Epoch 3:   9%|▉         | 13/148 [00:12<02:03,  1.09it/s, training_loss=1.7048]\u001b[A\n",
      "Epoch 3:   9%|▉         | 14/148 [00:12<02:03,  1.09it/s, training_loss=1.7048]\u001b[A\n",
      "Epoch 3:   9%|▉         | 14/148 [00:13<02:03,  1.09it/s, training_loss=1.5951]\u001b[A\n",
      "Epoch 3:  10%|█         | 15/148 [00:13<02:02,  1.09it/s, training_loss=1.5951]\u001b[A\n",
      "Epoch 3:  10%|█         | 15/148 [00:14<02:02,  1.09it/s, training_loss=1.6181]\u001b[A\n",
      "Epoch 3:  11%|█         | 16/148 [00:14<02:01,  1.09it/s, training_loss=1.6181]\u001b[A\n",
      "Epoch 3:  11%|█         | 16/148 [00:15<02:01,  1.09it/s, training_loss=1.3813]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 17/148 [00:15<02:00,  1.08it/s, training_loss=1.3813]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 17/148 [00:16<02:00,  1.08it/s, training_loss=1.5989]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 18/148 [00:16<01:59,  1.08it/s, training_loss=1.5989]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 18/148 [00:17<01:59,  1.08it/s, training_loss=1.6118]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 19/148 [00:17<01:58,  1.09it/s, training_loss=1.6118]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 19/148 [00:18<01:58,  1.09it/s, training_loss=1.3894]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 20/148 [00:18<01:58,  1.08it/s, training_loss=1.3894]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 20/148 [00:19<01:58,  1.08it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 21/148 [00:19<01:57,  1.08it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 21/148 [00:20<01:57,  1.08it/s, training_loss=1.3560]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 22/148 [00:20<01:56,  1.08it/s, training_loss=1.3560]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 22/148 [00:21<01:56,  1.08it/s, training_loss=1.2113]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 23/148 [00:21<01:55,  1.08it/s, training_loss=1.2113]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 23/148 [00:22<01:55,  1.08it/s, training_loss=1.2281]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 24/148 [00:22<01:55,  1.08it/s, training_loss=1.2281]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 24/148 [00:23<01:55,  1.08it/s, training_loss=1.2531]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 25/148 [00:23<01:54,  1.08it/s, training_loss=1.2531]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 25/148 [00:23<01:54,  1.08it/s, training_loss=1.7012]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 26/148 [00:23<01:52,  1.08it/s, training_loss=1.7012]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 26/148 [00:24<01:52,  1.08it/s, training_loss=1.2469]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 27/148 [00:24<01:51,  1.08it/s, training_loss=1.2469]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 27/148 [00:25<01:51,  1.08it/s, training_loss=1.4950]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 28/148 [00:25<01:50,  1.08it/s, training_loss=1.4950]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 28/148 [00:26<01:50,  1.08it/s, training_loss=1.7209]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 29/148 [00:26<01:50,  1.08it/s, training_loss=1.7209]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 29/148 [00:27<01:50,  1.08it/s, training_loss=1.2031]\u001b[A\n",
      "Epoch 3:  20%|██        | 30/148 [00:27<01:49,  1.08it/s, training_loss=1.2031]\u001b[A\n",
      "Epoch 3:  20%|██        | 30/148 [00:28<01:49,  1.08it/s, training_loss=1.0322]\u001b[A\n",
      "Epoch 3:  21%|██        | 31/148 [00:28<01:48,  1.08it/s, training_loss=1.0322]\u001b[A\n",
      "Epoch 3:  21%|██        | 31/148 [00:29<01:48,  1.08it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 32/148 [00:29<01:47,  1.08it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 32/148 [00:30<01:47,  1.08it/s, training_loss=1.4933]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 33/148 [00:30<01:46,  1.08it/s, training_loss=1.4933]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 33/148 [00:31<01:46,  1.08it/s, training_loss=1.4100]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 34/148 [00:31<01:45,  1.08it/s, training_loss=1.4100]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 34/148 [00:32<01:45,  1.08it/s, training_loss=1.6052]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 35/148 [00:32<01:44,  1.08it/s, training_loss=1.6052]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 35/148 [00:33<01:44,  1.08it/s, training_loss=1.5551]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 36/148 [00:33<01:43,  1.08it/s, training_loss=1.5551]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 36/148 [00:34<01:43,  1.08it/s, training_loss=1.4854]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=1.4854]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 37/148 [00:35<01:42,  1.08it/s, training_loss=1.4268]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 38/148 [00:35<01:41,  1.08it/s, training_loss=1.4268]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 38/148 [00:35<01:41,  1.08it/s, training_loss=1.3269]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 39/148 [00:35<01:41,  1.08it/s, training_loss=1.3269]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 39/148 [00:36<01:41,  1.08it/s, training_loss=1.6385]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 40/148 [00:36<01:39,  1.08it/s, training_loss=1.6385]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 40/148 [00:37<01:39,  1.08it/s, training_loss=1.4076]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 41/148 [00:37<01:38,  1.08it/s, training_loss=1.4076]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 41/148 [00:38<01:38,  1.08it/s, training_loss=1.6265]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 42/148 [00:38<01:37,  1.08it/s, training_loss=1.6265]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 42/148 [00:39<01:37,  1.08it/s, training_loss=1.5298]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 43/148 [00:39<01:36,  1.08it/s, training_loss=1.5298]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 43/148 [00:40<01:36,  1.08it/s, training_loss=1.1416]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 44/148 [00:40<01:36,  1.08it/s, training_loss=1.1416]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 44/148 [00:41<01:36,  1.08it/s, training_loss=1.6413]\u001b[A\n",
      "Epoch 3:  30%|███       | 45/148 [00:41<01:35,  1.08it/s, training_loss=1.6413]\u001b[A\n",
      "Epoch 3:  30%|███       | 45/148 [00:42<01:35,  1.08it/s, training_loss=1.2459]\u001b[A\n",
      "Epoch 3:  31%|███       | 46/148 [00:42<01:34,  1.08it/s, training_loss=1.2459]\u001b[A\n",
      "Epoch 3:  31%|███       | 46/148 [00:43<01:34,  1.08it/s, training_loss=1.4687]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.4687]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.3341]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 48/148 [00:44<01:32,  1.09it/s, training_loss=1.3341]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 48/148 [00:45<01:32,  1.09it/s, training_loss=1.5624]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 49/148 [00:45<01:31,  1.09it/s, training_loss=1.5624]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 49/148 [00:46<01:31,  1.09it/s, training_loss=1.5351]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=1.5351]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 50/148 [00:47<01:29,  1.09it/s, training_loss=1.6626]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 51/148 [00:47<01:28,  1.09it/s, training_loss=1.6626]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 51/148 [00:47<01:28,  1.09it/s, training_loss=1.4434]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 52/148 [00:47<01:28,  1.09it/s, training_loss=1.4434]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 52/148 [00:48<01:28,  1.09it/s, training_loss=1.5226]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 53/148 [00:48<01:27,  1.09it/s, training_loss=1.5226]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 53/148 [00:49<01:27,  1.09it/s, training_loss=1.4467]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 54/148 [00:49<01:26,  1.09it/s, training_loss=1.4467]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 54/148 [00:50<01:26,  1.09it/s, training_loss=1.5193]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.5193]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.6054]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=1.6054]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.5883]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.5883]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=1.4863]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 58/148 [00:53<01:22,  1.09it/s, training_loss=1.4863]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 58/148 [00:54<01:22,  1.09it/s, training_loss=1.3934]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 59/148 [00:54<01:21,  1.09it/s, training_loss=1.3934]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 59/148 [00:55<01:21,  1.09it/s, training_loss=1.3937]\u001b[A\n",
      "Epoch 3:  41%|████      | 60/148 [00:55<01:20,  1.09it/s, training_loss=1.3937]\u001b[A\n",
      "Epoch 3:  41%|████      | 60/148 [00:56<01:20,  1.09it/s, training_loss=1.5856]\u001b[A\n",
      "Epoch 3:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=1.5856]\u001b[A\n",
      "Epoch 3:  41%|████      | 61/148 [00:57<01:19,  1.09it/s, training_loss=1.1679]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 62/148 [00:57<01:18,  1.09it/s, training_loss=1.1679]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 62/148 [00:58<01:18,  1.09it/s, training_loss=1.6112]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 63/148 [00:58<01:17,  1.09it/s, training_loss=1.6112]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 63/148 [00:58<01:17,  1.09it/s, training_loss=1.5654]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 64/148 [00:58<01:17,  1.09it/s, training_loss=1.5654]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 64/148 [00:59<01:17,  1.09it/s, training_loss=1.1696]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 65/148 [00:59<01:16,  1.09it/s, training_loss=1.1696]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 65/148 [01:00<01:16,  1.09it/s, training_loss=1.5911]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 66/148 [01:00<01:15,  1.09it/s, training_loss=1.5911]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=1.4254]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 67/148 [01:01<01:14,  1.09it/s, training_loss=1.4254]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=1.1819]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=1.1819]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=1.6346]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=1.6346]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=1.4890]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=1.4890]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=1.4669]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=1.4669]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.2906]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=1.2906]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 72/148 [01:07<01:09,  1.09it/s, training_loss=1.0723]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 73/148 [01:07<01:08,  1.09it/s, training_loss=1.0723]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 73/148 [01:08<01:08,  1.09it/s, training_loss=1.0824]\u001b[A\n",
      "Epoch 3:  50%|█████     | 74/148 [01:08<01:07,  1.09it/s, training_loss=1.0824]\u001b[A\n",
      "Epoch 3:  50%|█████     | 74/148 [01:09<01:07,  1.09it/s, training_loss=1.5573]\u001b[A\n",
      "Epoch 3:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.5573]\u001b[A\n",
      "Epoch 3:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.5462]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 76/148 [01:09<01:05,  1.09it/s, training_loss=1.5462]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=1.5626]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 77/148 [01:10<01:05,  1.09it/s, training_loss=1.5626]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 77/148 [01:11<01:05,  1.09it/s, training_loss=1.1773]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 78/148 [01:11<01:04,  1.09it/s, training_loss=1.1773]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 78/148 [01:12<01:04,  1.09it/s, training_loss=1.4929]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 79/148 [01:12<01:03,  1.09it/s, training_loss=1.4929]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 79/148 [01:13<01:03,  1.09it/s, training_loss=1.4240]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.4240]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.5231]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=1.5231]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=1.5297]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.5297]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.4035]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=1.4035]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 83/148 [01:17<00:59,  1.09it/s, training_loss=1.6995]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=1.6995]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 84/148 [01:18<00:58,  1.09it/s, training_loss=1.1624]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.1624]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 85/148 [01:19<00:57,  1.09it/s, training_loss=1.4226]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.4226]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 86/148 [01:20<00:56,  1.09it/s, training_loss=1.7933]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 87/148 [01:20<00:55,  1.10it/s, training_loss=1.7933]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 87/148 [01:20<00:55,  1.10it/s, training_loss=1.6084]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 88/148 [01:20<00:54,  1.09it/s, training_loss=1.6084]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 88/148 [01:21<00:54,  1.09it/s, training_loss=1.5741]\u001b[A\n",
      "Epoch 3:  60%|██████    | 89/148 [01:21<00:53,  1.10it/s, training_loss=1.5741]\u001b[A\n",
      "Epoch 3:  60%|██████    | 89/148 [01:22<00:53,  1.10it/s, training_loss=1.1358]\u001b[A\n",
      "Epoch 3:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=1.1358]\u001b[A\n",
      "Epoch 3:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=1.4337]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=1.4337]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.5750]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.5750]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=1.2803]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.2803]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.6783]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=1.6783]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.5839]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.5839]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=1.1040]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.1040]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 96/148 [01:29<00:47,  1.09it/s, training_loss=1.6233]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.6233]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 97/148 [01:30<00:46,  1.09it/s, training_loss=1.5920]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=1.5920]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 98/148 [01:31<00:45,  1.09it/s, training_loss=1.4415]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=1.4415]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=1.1044]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 100/148 [01:31<00:44,  1.09it/s, training_loss=1.1044]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 100/148 [01:32<00:44,  1.09it/s, training_loss=1.0207]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 101/148 [01:32<00:43,  1.09it/s, training_loss=1.0207]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.5390]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.5390]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=1.5886]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 103/148 [01:34<00:41,  1.09it/s, training_loss=1.5886]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 103/148 [01:35<00:41,  1.09it/s, training_loss=1.5648]\u001b[A\n",
      "Epoch 3:  70%|███████   | 104/148 [01:35<00:40,  1.09it/s, training_loss=1.5648]\u001b[A\n",
      "Epoch 3:  70%|███████   | 104/148 [01:36<00:40,  1.09it/s, training_loss=1.5117]\u001b[A\n",
      "Epoch 3:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=1.5117]\u001b[A\n",
      "Epoch 3:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.2468]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.2468]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=1.6313]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=1.6313]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 107/148 [01:39<00:37,  1.09it/s, training_loss=1.5490]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=1.5490]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 108/148 [01:40<00:36,  1.09it/s, training_loss=1.2954]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.2954]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 109/148 [01:41<00:35,  1.09it/s, training_loss=1.6346]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.6346]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 110/148 [01:42<00:34,  1.09it/s, training_loss=1.6088]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=1.6088]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=1.0881]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 112/148 [01:42<00:33,  1.09it/s, training_loss=1.0881]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.4880]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 113/148 [01:43<00:32,  1.09it/s, training_loss=1.4880]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.4588]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 114/148 [01:44<00:31,  1.08it/s, training_loss=1.4588]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 114/148 [01:45<00:31,  1.08it/s, training_loss=1.5800]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.5800]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=1.5094]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 116/148 [01:46<00:29,  1.08it/s, training_loss=1.5094]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 116/148 [01:47<00:29,  1.08it/s, training_loss=1.5871]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.5871]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=1.3961]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 118/148 [01:48<00:27,  1.08it/s, training_loss=1.3961]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 118/148 [01:49<00:27,  1.08it/s, training_loss=1.1752]\u001b[A\n",
      "Epoch 3:  80%|████████  | 119/148 [01:49<00:26,  1.08it/s, training_loss=1.1752]\u001b[A\n",
      "Epoch 3:  80%|████████  | 119/148 [01:50<00:26,  1.08it/s, training_loss=1.4867]\u001b[A\n",
      "Epoch 3:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.4867]\u001b[A\n",
      "Epoch 3:  81%|████████  | 120/148 [01:51<00:25,  1.09it/s, training_loss=1.5174]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.5174]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 121/148 [01:52<00:24,  1.09it/s, training_loss=1.3538]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 122/148 [01:52<00:24,  1.08it/s, training_loss=1.3538]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 122/148 [01:53<00:24,  1.08it/s, training_loss=1.5441]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 123/148 [01:53<00:23,  1.08it/s, training_loss=1.5441]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 123/148 [01:54<00:23,  1.08it/s, training_loss=1.3295]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 124/148 [01:54<00:22,  1.08it/s, training_loss=1.3295]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 124/148 [01:54<00:22,  1.08it/s, training_loss=1.5070]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 125/148 [01:54<00:21,  1.09it/s, training_loss=1.5070]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=1.2609]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 126/148 [01:55<00:20,  1.09it/s, training_loss=1.2609]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=1.0871]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=1.0871]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.4432]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.4432]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.1316]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.1316]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=1.5664]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.5664]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=1.0881]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.0881]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=1.4781]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.4781]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 132/148 [02:02<00:14,  1.09it/s, training_loss=1.2545]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.2545]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 133/148 [02:03<00:13,  1.09it/s, training_loss=1.4118]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.4118]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 134/148 [02:04<00:12,  1.09it/s, training_loss=1.6471]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 135/148 [02:04<00:12,  1.08it/s, training_loss=1.6471]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 135/148 [02:05<00:12,  1.08it/s, training_loss=1.4495]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 136/148 [02:05<00:11,  1.08it/s, training_loss=1.4495]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 136/148 [02:06<00:11,  1.08it/s, training_loss=0.9917]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 137/148 [02:06<00:10,  1.08it/s, training_loss=0.9917]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 137/148 [02:06<00:10,  1.08it/s, training_loss=1.4542]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 138/148 [02:06<00:09,  1.08it/s, training_loss=1.4542]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 138/148 [02:07<00:09,  1.08it/s, training_loss=0.8777]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 139/148 [02:07<00:08,  1.08it/s, training_loss=0.8777]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 139/148 [02:08<00:08,  1.08it/s, training_loss=1.1002]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 140/148 [02:08<00:07,  1.08it/s, training_loss=1.1002]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 140/148 [02:09<00:07,  1.08it/s, training_loss=1.5843]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 141/148 [02:09<00:06,  1.08it/s, training_loss=1.5843]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 141/148 [02:10<00:06,  1.08it/s, training_loss=1.5474]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 142/148 [02:10<00:05,  1.08it/s, training_loss=1.5474]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 142/148 [02:11<00:05,  1.08it/s, training_loss=1.5146]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.5146]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=1.6291]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=1.6291]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 144/148 [02:13<00:03,  1.09it/s, training_loss=1.2494]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=1.2494]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 145/148 [02:14<00:02,  1.09it/s, training_loss=1.4677]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 146/148 [02:14<00:01,  1.08it/s, training_loss=1.4677]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 146/148 [02:15<00:01,  1.08it/s, training_loss=1.6004]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.6004]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.5352]\u001b[A\n",
      "Epoch 3: 100%|██████████| 148/148 [02:15<00:00,  1.18it/s, training_loss=1.5352]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:54:49,473 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:54:49,474 - INFO - Memory usage after evaluation start: 3986.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=64.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.66it/s, Accuracy=64.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.66it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.60it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.60it/s, Accuracy=71.33%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.59it/s, Accuracy=71.33%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.59it/s, Accuracy=70.50%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.57it/s, Accuracy=70.50%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.57it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.58it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.58it/s, Accuracy=71.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.57it/s, Accuracy=71.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.57it/s, Accuracy=69.71%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.56it/s, Accuracy=69.71%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.56it/s, Accuracy=68.75%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.56it/s, Accuracy=68.75%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.56it/s, Accuracy=68.89%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.56it/s, Accuracy=68.89%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.56it/s, Accuracy=69.60%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.55it/s, Accuracy=69.60%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.55it/s, Accuracy=68.91%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.54it/s, Accuracy=68.91%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.54it/s, Accuracy=69.33%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.54it/s, Accuracy=69.33%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.54it/s, Accuracy=68.31%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.55it/s, Accuracy=68.31%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.55it/s, Accuracy=67.86%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.55it/s, Accuracy=67.86%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.55it/s, Accuracy=68.13%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.55it/s, Accuracy=68.13%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.55it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.54it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.54it/s, Accuracy=67.53%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.54it/s, Accuracy=67.53%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:02,  3.54it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.53it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.53it/s, Accuracy=67.79%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.53it/s, Accuracy=67.79%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.53it/s, Accuracy=68.10%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.54it/s, Accuracy=68.10%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.54it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.54it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.54it/s, Accuracy=67.73%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.54it/s, Accuracy=67.73%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.54it/s, Accuracy=67.91%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.53it/s, Accuracy=67.91%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.53it/s, Accuracy=67.50%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.53it/s, Accuracy=67.50%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:07<00:00,  3.53it/s, Accuracy=67.60%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.53it/s, Accuracy=67.60%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.53it/s, Accuracy=67.85%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.53it/s, Accuracy=67.85%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.67it/s, Accuracy=67.89%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:54:56,845 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:54:56,852 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:54:56,852 - INFO - Accuracy: 0.6475\n",
      "2025-02-19 10:54:56,853 - INFO - F1_score: 0.5400\n",
      "2025-02-19 10:54:56,854 - INFO - Precision: 0.4286\n",
      "2025-02-19 10:54:56,854 - INFO - Recall: 0.7297\n",
      "2025-02-19 10:54:56,861 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:54:56,862 - INFO - Accuracy: 0.6820\n",
      "2025-02-19 10:54:56,862 - INFO - F1_score: 0.5699\n",
      "2025-02-19 10:54:56,863 - INFO - Precision: 0.4044\n",
      "2025-02-19 10:54:56,864 - INFO - Recall: 0.9649\n",
      "2025-02-19 10:54:56,871 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:54:56,871 - INFO - Accuracy: 0.5785\n",
      "2025-02-19 10:54:56,872 - INFO - F1_score: 0.4500\n",
      "2025-02-19 10:54:56,872 - INFO - Precision: 0.3169\n",
      "2025-02-19 10:54:56,873 - INFO - Recall: 0.7759\n",
      "2025-02-19 10:54:56,880 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:54:56,880 - INFO - Accuracy: 0.7203\n",
      "2025-02-19 10:54:56,881 - INFO - F1_score: 0.4065\n",
      "2025-02-19 10:54:56,882 - INFO - Precision: 0.2941\n",
      "2025-02-19 10:54:56,882 - INFO - Recall: 0.6579\n",
      "2025-02-19 10:54:56,889 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:54:56,889 - INFO - Accuracy: 0.7663\n",
      "2025-02-19 10:54:56,890 - INFO - F1_score: 0.4190\n",
      "2025-02-19 10:54:56,891 - INFO - Precision: 0.3099\n",
      "2025-02-19 10:54:56,891 - INFO - Recall: 0.6471\n",
      "2025-02-19 10:54:56,894 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:55:00,716 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:55:00,718 - INFO - Memory usage after evaluation end: 3992.41 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 2/100 [07:45<4:14:20, 155.72s/it, Train Loss=1.4407, Val Loss=0.0481, Accuracy=0.6789]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:55:07,989 - INFO - New best accuracy: 0.6789\n",
      "2025-02-19 10:55:09,061 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [07:46<4:11:35, 155.63s/it, Train Loss=1.4407, Val Loss=0.0481, Accuracy=0.6789]\n",
      "Epoch 4:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.3065]\u001b[A\n",
      "Epoch 4:   1%|          | 1/148 [00:00<02:13,  1.10it/s, training_loss=1.3065]\u001b[A\n",
      "Epoch 4:   1%|          | 1/148 [00:01<02:13,  1.10it/s, training_loss=1.0766]\u001b[A\n",
      "Epoch 4:   1%|▏         | 2/148 [00:01<02:13,  1.09it/s, training_loss=1.0766]\u001b[A\n",
      "Epoch 4:   1%|▏         | 2/148 [00:02<02:13,  1.09it/s, training_loss=1.7053]\u001b[A\n",
      "Epoch 4:   2%|▏         | 3/148 [00:02<02:12,  1.09it/s, training_loss=1.7053]\u001b[A\n",
      "Epoch 4:   2%|▏         | 3/148 [00:03<02:12,  1.09it/s, training_loss=1.3649]\u001b[A\n",
      "Epoch 4:   3%|▎         | 4/148 [00:03<02:12,  1.09it/s, training_loss=1.3649]\u001b[A\n",
      "Epoch 4:   3%|▎         | 4/148 [00:04<02:12,  1.09it/s, training_loss=1.3751]\u001b[A\n",
      "Epoch 4:   3%|▎         | 5/148 [00:04<02:12,  1.08it/s, training_loss=1.3751]\u001b[A\n",
      "Epoch 4:   3%|▎         | 5/148 [00:05<02:12,  1.08it/s, training_loss=1.0628]\u001b[A\n",
      "Epoch 4:   4%|▍         | 6/148 [00:05<02:11,  1.08it/s, training_loss=1.0628]\u001b[A\n",
      "Epoch 4:   4%|▍         | 6/148 [00:06<02:11,  1.08it/s, training_loss=1.5440]\u001b[A\n",
      "Epoch 4:   5%|▍         | 7/148 [00:06<02:10,  1.08it/s, training_loss=1.5440]\u001b[A\n",
      "Epoch 4:   5%|▍         | 7/148 [00:07<02:10,  1.08it/s, training_loss=1.6416]\u001b[A\n",
      "Epoch 4:   5%|▌         | 8/148 [00:07<02:09,  1.08it/s, training_loss=1.6416]\u001b[A\n",
      "Epoch 4:   5%|▌         | 8/148 [00:08<02:09,  1.08it/s, training_loss=1.5518]\u001b[A\n",
      "Epoch 4:   6%|▌         | 9/148 [00:08<02:07,  1.09it/s, training_loss=1.5518]\u001b[A\n",
      "Epoch 4:   6%|▌         | 9/148 [00:09<02:07,  1.09it/s, training_loss=1.3792]\u001b[A\n",
      "Epoch 4:   7%|▋         | 10/148 [00:09<02:07,  1.08it/s, training_loss=1.3792]\u001b[A\n",
      "Epoch 4:   7%|▋         | 10/148 [00:10<02:07,  1.08it/s, training_loss=1.6392]\u001b[A\n",
      "Epoch 4:   7%|▋         | 11/148 [00:10<02:06,  1.09it/s, training_loss=1.6392]\u001b[A\n",
      "Epoch 4:   7%|▋         | 11/148 [00:11<02:06,  1.09it/s, training_loss=1.2779]\u001b[A\n",
      "Epoch 4:   8%|▊         | 12/148 [00:11<02:05,  1.08it/s, training_loss=1.2779]\u001b[A\n",
      "Epoch 4:   8%|▊         | 12/148 [00:11<02:05,  1.08it/s, training_loss=1.5931]\u001b[A\n",
      "Epoch 4:   9%|▉         | 13/148 [00:11<02:04,  1.09it/s, training_loss=1.5931]\u001b[A\n",
      "Epoch 4:   9%|▉         | 13/148 [00:12<02:04,  1.09it/s, training_loss=1.5418]\u001b[A\n",
      "Epoch 4:   9%|▉         | 14/148 [00:12<02:03,  1.09it/s, training_loss=1.5418]\u001b[A\n",
      "Epoch 4:   9%|▉         | 14/148 [00:13<02:03,  1.09it/s, training_loss=1.1443]\u001b[A\n",
      "Epoch 4:  10%|█         | 15/148 [00:13<02:02,  1.09it/s, training_loss=1.1443]\u001b[A\n",
      "Epoch 4:  10%|█         | 15/148 [00:14<02:02,  1.09it/s, training_loss=1.7030]\u001b[A\n",
      "Epoch 4:  11%|█         | 16/148 [00:14<02:01,  1.09it/s, training_loss=1.7030]\u001b[A\n",
      "Epoch 4:  11%|█         | 16/148 [00:15<02:01,  1.09it/s, training_loss=1.6252]\u001b[A\n",
      "Epoch 4:  11%|█▏        | 17/148 [00:15<02:00,  1.09it/s, training_loss=1.6252]\u001b[A\n",
      "Epoch 4:  11%|█▏        | 17/148 [00:16<02:00,  1.09it/s, training_loss=1.5937]\u001b[A\n",
      "Epoch 4:  12%|█▏        | 18/148 [00:16<01:59,  1.09it/s, training_loss=1.5937]\u001b[A\n",
      "Epoch 4:  12%|█▏        | 18/148 [00:17<01:59,  1.09it/s, training_loss=1.2069]\u001b[A\n",
      "Epoch 4:  13%|█▎        | 19/148 [00:17<01:58,  1.08it/s, training_loss=1.2069]\u001b[A\n",
      "Epoch 4:  13%|█▎        | 19/148 [00:18<01:58,  1.08it/s, training_loss=1.6415]\u001b[A\n",
      "Epoch 4:  14%|█▎        | 20/148 [00:18<01:57,  1.09it/s, training_loss=1.6415]\u001b[A\n",
      "Epoch 4:  14%|█▎        | 20/148 [00:19<01:57,  1.09it/s, training_loss=1.2577]\u001b[A\n",
      "Epoch 4:  14%|█▍        | 21/148 [00:19<01:57,  1.08it/s, training_loss=1.2577]\u001b[A\n",
      "Epoch 4:  14%|█▍        | 21/148 [00:20<01:57,  1.08it/s, training_loss=1.2009]\u001b[A\n",
      "Epoch 4:  15%|█▍        | 22/148 [00:20<01:57,  1.07it/s, training_loss=1.2009]\u001b[A\n",
      "Epoch 4:  15%|█▍        | 22/148 [00:21<01:57,  1.07it/s, training_loss=1.6390]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 23/148 [00:21<01:55,  1.08it/s, training_loss=1.6390]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 23/148 [00:22<01:55,  1.08it/s, training_loss=1.2281]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=1.2281]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 24/148 [00:23<01:54,  1.08it/s, training_loss=1.5243]\u001b[A\n",
      "Epoch 4:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.5243]\u001b[A\n",
      "Epoch 4:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.1784]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 26/148 [00:23<01:52,  1.08it/s, training_loss=1.1784]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 26/148 [00:24<01:52,  1.08it/s, training_loss=1.1282]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 27/148 [00:24<01:52,  1.08it/s, training_loss=1.1282]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 27/148 [00:25<01:52,  1.08it/s, training_loss=1.0911]\u001b[A\n",
      "Epoch 4:  19%|█▉        | 28/148 [00:25<01:51,  1.08it/s, training_loss=1.0911]\u001b[A\n",
      "Epoch 4:  19%|█▉        | 28/148 [00:26<01:51,  1.08it/s, training_loss=1.1044]\u001b[A\n",
      "Epoch 4:  20%|█▉        | 29/148 [00:26<01:50,  1.08it/s, training_loss=1.1044]\u001b[A\n",
      "Epoch 4:  20%|█▉        | 29/148 [00:27<01:50,  1.08it/s, training_loss=1.2508]\u001b[A\n",
      "Epoch 4:  20%|██        | 30/148 [00:27<01:49,  1.08it/s, training_loss=1.2508]\u001b[A\n",
      "Epoch 4:  20%|██        | 30/148 [00:28<01:49,  1.08it/s, training_loss=1.2468]\u001b[A\n",
      "Epoch 4:  21%|██        | 31/148 [00:28<01:48,  1.08it/s, training_loss=1.2468]\u001b[A\n",
      "Epoch 4:  21%|██        | 31/148 [00:29<01:48,  1.08it/s, training_loss=1.5139]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 32/148 [00:29<01:47,  1.08it/s, training_loss=1.5139]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 32/148 [00:30<01:47,  1.08it/s, training_loss=1.2858]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 33/148 [00:30<01:46,  1.08it/s, training_loss=1.2858]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 33/148 [00:31<01:46,  1.08it/s, training_loss=1.5378]\u001b[A\n",
      "Epoch 4:  23%|██▎       | 34/148 [00:31<01:45,  1.08it/s, training_loss=1.5378]\u001b[A\n",
      "Epoch 4:  23%|██▎       | 34/148 [00:32<01:45,  1.08it/s, training_loss=1.5912]\u001b[A\n",
      "Epoch 4:  24%|██▎       | 35/148 [00:32<01:44,  1.08it/s, training_loss=1.5912]\u001b[A\n",
      "Epoch 4:  24%|██▎       | 35/148 [00:33<01:44,  1.08it/s, training_loss=1.3753]\u001b[A\n",
      "Epoch 4:  24%|██▍       | 36/148 [00:33<01:43,  1.08it/s, training_loss=1.3753]\u001b[A\n",
      "Epoch 4:  24%|██▍       | 36/148 [00:34<01:43,  1.08it/s, training_loss=1.2279]\u001b[A\n",
      "Epoch 4:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=1.2279]\u001b[A\n",
      "Epoch 4:  25%|██▌       | 37/148 [00:35<01:42,  1.08it/s, training_loss=1.5992]\u001b[A\n",
      "Epoch 4:  26%|██▌       | 38/148 [00:35<01:41,  1.08it/s, training_loss=1.5992]\u001b[A\n",
      "Epoch 4:  26%|██▌       | 38/148 [00:36<01:41,  1.08it/s, training_loss=1.1752]\u001b[A\n",
      "Epoch 4:  26%|██▋       | 39/148 [00:36<01:40,  1.09it/s, training_loss=1.1752]\u001b[A\n",
      "Epoch 4:  26%|██▋       | 39/148 [00:36<01:40,  1.09it/s, training_loss=1.5009]\u001b[A\n",
      "Epoch 4:  27%|██▋       | 40/148 [00:36<01:39,  1.09it/s, training_loss=1.5009]\u001b[A\n",
      "Epoch 4:  27%|██▋       | 40/148 [00:37<01:39,  1.09it/s, training_loss=1.1261]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=1.1261]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=1.5861]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 42/148 [00:38<01:37,  1.08it/s, training_loss=1.5861]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 42/148 [00:39<01:37,  1.08it/s, training_loss=1.5291]\u001b[A\n",
      "Epoch 4:  29%|██▉       | 43/148 [00:39<01:37,  1.08it/s, training_loss=1.5291]\u001b[A\n",
      "Epoch 4:  29%|██▉       | 43/148 [00:40<01:37,  1.08it/s, training_loss=1.4251]\u001b[A\n",
      "Epoch 4:  30%|██▉       | 44/148 [00:40<01:36,  1.08it/s, training_loss=1.4251]\u001b[A\n",
      "Epoch 4:  30%|██▉       | 44/148 [00:41<01:36,  1.08it/s, training_loss=1.4878]\u001b[A\n",
      "Epoch 4:  30%|███       | 45/148 [00:41<01:35,  1.08it/s, training_loss=1.4878]\u001b[A\n",
      "Epoch 4:  30%|███       | 45/148 [00:42<01:35,  1.08it/s, training_loss=1.6063]\u001b[A\n",
      "Epoch 4:  31%|███       | 46/148 [00:42<01:33,  1.09it/s, training_loss=1.6063]\u001b[A\n",
      "Epoch 4:  31%|███       | 46/148 [00:43<01:33,  1.09it/s, training_loss=1.6038]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.6038]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.6897]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 48/148 [00:44<01:31,  1.09it/s, training_loss=1.6897]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 48/148 [00:45<01:31,  1.09it/s, training_loss=1.5487]\u001b[A\n",
      "Epoch 4:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=1.5487]\u001b[A\n",
      "Epoch 4:  33%|███▎      | 49/148 [00:46<01:30,  1.09it/s, training_loss=1.1634]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=1.1634]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 50/148 [00:47<01:29,  1.09it/s, training_loss=1.5389]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 51/148 [00:47<01:29,  1.09it/s, training_loss=1.5389]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 51/148 [00:47<01:29,  1.09it/s, training_loss=1.5865]\u001b[A\n",
      "Epoch 4:  35%|███▌      | 52/148 [00:47<01:28,  1.09it/s, training_loss=1.5865]\u001b[A\n",
      "Epoch 4:  35%|███▌      | 52/148 [00:48<01:28,  1.09it/s, training_loss=1.2062]\u001b[A\n",
      "Epoch 4:  36%|███▌      | 53/148 [00:48<01:27,  1.09it/s, training_loss=1.2062]\u001b[A\n",
      "Epoch 4:  36%|███▌      | 53/148 [00:49<01:27,  1.09it/s, training_loss=1.0252]\u001b[A\n",
      "Epoch 4:  36%|███▋      | 54/148 [00:49<01:26,  1.09it/s, training_loss=1.0252]\u001b[A\n",
      "Epoch 4:  36%|███▋      | 54/148 [00:50<01:26,  1.09it/s, training_loss=1.5593]\u001b[A\n",
      "Epoch 4:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.5593]\u001b[A\n",
      "Epoch 4:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.5518]\u001b[A\n",
      "Epoch 4:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=1.5518]\u001b[A\n",
      "Epoch 4:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.0249]\u001b[A\n",
      "Epoch 4:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.0249]\u001b[A\n",
      "Epoch 4:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=1.1143]\u001b[A\n",
      "Epoch 4:  39%|███▉      | 58/148 [00:53<01:22,  1.09it/s, training_loss=1.1143]\u001b[A\n",
      "Epoch 4:  39%|███▉      | 58/148 [00:54<01:22,  1.09it/s, training_loss=1.1340]\u001b[A\n",
      "Epoch 4:  40%|███▉      | 59/148 [00:54<01:21,  1.09it/s, training_loss=1.1340]\u001b[A\n",
      "Epoch 4:  40%|███▉      | 59/148 [00:55<01:21,  1.09it/s, training_loss=1.1529]\u001b[A\n",
      "Epoch 4:  41%|████      | 60/148 [00:55<01:20,  1.09it/s, training_loss=1.1529]\u001b[A\n",
      "Epoch 4:  41%|████      | 60/148 [00:56<01:20,  1.09it/s, training_loss=0.9788]\u001b[A\n",
      "Epoch 4:  41%|████      | 61/148 [00:56<01:20,  1.09it/s, training_loss=0.9788]\u001b[A\n",
      "Epoch 4:  41%|████      | 61/148 [00:57<01:20,  1.09it/s, training_loss=1.2183]\u001b[A\n",
      "Epoch 4:  42%|████▏     | 62/148 [00:57<01:19,  1.09it/s, training_loss=1.2183]\u001b[A\n",
      "Epoch 4:  42%|████▏     | 62/148 [00:58<01:19,  1.09it/s, training_loss=1.2078]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 63/148 [00:58<01:18,  1.08it/s, training_loss=1.2078]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 63/148 [00:59<01:18,  1.08it/s, training_loss=1.6679]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 64/148 [00:59<01:17,  1.09it/s, training_loss=1.6679]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 64/148 [00:59<01:17,  1.09it/s, training_loss=1.0462]\u001b[A\n",
      "Epoch 4:  44%|████▍     | 65/148 [00:59<01:16,  1.09it/s, training_loss=1.0462]\u001b[A\n",
      "Epoch 4:  44%|████▍     | 65/148 [01:00<01:16,  1.09it/s, training_loss=1.4857]\u001b[A\n",
      "Epoch 4:  45%|████▍     | 66/148 [01:00<01:15,  1.09it/s, training_loss=1.4857]\u001b[A\n",
      "Epoch 4:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=1.1404]\u001b[A\n",
      "Epoch 4:  45%|████▌     | 67/148 [01:01<01:14,  1.08it/s, training_loss=1.1404]\u001b[A\n",
      "Epoch 4:  45%|████▌     | 67/148 [01:02<01:14,  1.08it/s, training_loss=1.5144]\u001b[A\n",
      "Epoch 4:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=1.5144]\u001b[A\n",
      "Epoch 4:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=1.2095]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=1.2095]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=1.5273]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=1.5273]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=1.3145]\u001b[A\n",
      "Epoch 4:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=1.3145]\u001b[A\n",
      "Epoch 4:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.3001]\u001b[A\n",
      "Epoch 4:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=1.3001]\u001b[A\n",
      "Epoch 4:  49%|████▊     | 72/148 [01:07<01:09,  1.09it/s, training_loss=1.5940]\u001b[A\n",
      "Epoch 4:  49%|████▉     | 73/148 [01:07<01:08,  1.09it/s, training_loss=1.5940]\u001b[A\n",
      "Epoch 4:  49%|████▉     | 73/148 [01:08<01:08,  1.09it/s, training_loss=1.5610]\u001b[A\n",
      "Epoch 4:  50%|█████     | 74/148 [01:08<01:07,  1.09it/s, training_loss=1.5610]\u001b[A\n",
      "Epoch 4:  50%|█████     | 74/148 [01:09<01:07,  1.09it/s, training_loss=1.6627]\u001b[A\n",
      "Epoch 4:  51%|█████     | 75/148 [01:09<01:06,  1.10it/s, training_loss=1.6627]\u001b[A\n",
      "Epoch 4:  51%|█████     | 75/148 [01:10<01:06,  1.10it/s, training_loss=1.3851]\u001b[A\n",
      "Epoch 4:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=1.3851]\u001b[A\n",
      "Epoch 4:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=1.5487]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 77/148 [01:10<01:04,  1.09it/s, training_loss=1.5487]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 77/148 [01:11<01:04,  1.09it/s, training_loss=1.5154]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 78/148 [01:11<01:03,  1.09it/s, training_loss=1.5154]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 78/148 [01:12<01:03,  1.09it/s, training_loss=1.3746]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 79/148 [01:12<01:03,  1.09it/s, training_loss=1.3746]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 79/148 [01:13<01:03,  1.09it/s, training_loss=1.0976]\u001b[A\n",
      "Epoch 4:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.0976]\u001b[A\n",
      "Epoch 4:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.3431]\u001b[A\n",
      "Epoch 4:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=1.3431]\u001b[A\n",
      "Epoch 4:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=1.2887]\u001b[A\n",
      "Epoch 4:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.2887]\u001b[A\n",
      "Epoch 4:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.6759]\u001b[A\n",
      "Epoch 4:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=1.6759]\u001b[A\n",
      "Epoch 4:  56%|█████▌    | 83/148 [01:17<00:59,  1.09it/s, training_loss=1.0865]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=1.0865]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 84/148 [01:18<00:58,  1.09it/s, training_loss=1.1278]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 85/148 [01:18<00:58,  1.09it/s, training_loss=1.1278]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 85/148 [01:19<00:58,  1.09it/s, training_loss=1.5749]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.5749]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 86/148 [01:20<00:56,  1.09it/s, training_loss=1.5698]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 87/148 [01:20<00:56,  1.09it/s, training_loss=1.5698]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 87/148 [01:21<00:56,  1.09it/s, training_loss=1.1374]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.1374]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.0575]\u001b[A\n",
      "Epoch 4:  60%|██████    | 89/148 [01:21<00:54,  1.08it/s, training_loss=1.0575]\u001b[A\n",
      "Epoch 4:  60%|██████    | 89/148 [01:22<00:54,  1.08it/s, training_loss=1.2403]\u001b[A\n",
      "Epoch 4:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=1.2403]\u001b[A\n",
      "Epoch 4:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=1.2812]\u001b[A\n",
      "Epoch 4:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=1.2812]\u001b[A\n",
      "Epoch 4:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.2742]\u001b[A\n",
      "Epoch 4:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.2742]\u001b[A\n",
      "Epoch 4:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=1.5547]\u001b[A\n",
      "Epoch 4:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.5547]\u001b[A\n",
      "Epoch 4:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.1586]\u001b[A\n",
      "Epoch 4:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=1.1586]\u001b[A\n",
      "Epoch 4:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.0911]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.0911]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=1.0878]\u001b[A\n",
      "Epoch 4:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.0878]\u001b[A\n",
      "Epoch 4:  65%|██████▍   | 96/148 [01:29<00:47,  1.09it/s, training_loss=1.0986]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.0986]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 97/148 [01:30<00:46,  1.09it/s, training_loss=1.4941]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=1.4941]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 98/148 [01:31<00:45,  1.09it/s, training_loss=1.1012]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=1.1012]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 99/148 [01:32<00:44,  1.09it/s, training_loss=1.1418]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 100/148 [01:32<00:44,  1.09it/s, training_loss=1.1418]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 100/148 [01:32<00:44,  1.09it/s, training_loss=1.1813]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 101/148 [01:32<00:43,  1.09it/s, training_loss=1.1813]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.6505]\u001b[A\n",
      "Epoch 4:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.6505]\u001b[A\n",
      "Epoch 4:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=1.3615]\u001b[A\n",
      "Epoch 4:  70%|██████▉   | 103/148 [01:34<00:41,  1.09it/s, training_loss=1.3615]\u001b[A\n",
      "Epoch 4:  70%|██████▉   | 103/148 [01:35<00:41,  1.09it/s, training_loss=1.5871]\u001b[A\n",
      "Epoch 4:  70%|███████   | 104/148 [01:35<00:40,  1.09it/s, training_loss=1.5871]\u001b[A\n",
      "Epoch 4:  70%|███████   | 104/148 [01:36<00:40,  1.09it/s, training_loss=1.6319]\u001b[A\n",
      "Epoch 4:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=1.6319]\u001b[A\n",
      "Epoch 4:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.4693]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.4693]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=1.5459]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=1.5459]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 107/148 [01:39<00:37,  1.09it/s, training_loss=1.3328]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=1.3328]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 108/148 [01:40<00:36,  1.09it/s, training_loss=1.3105]\u001b[A\n",
      "Epoch 4:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.3105]\u001b[A\n",
      "Epoch 4:  74%|███████▎  | 109/148 [01:41<00:35,  1.09it/s, training_loss=1.1699]\u001b[A\n",
      "Epoch 4:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.1699]\u001b[A\n",
      "Epoch 4:  74%|███████▍  | 110/148 [01:42<00:34,  1.09it/s, training_loss=1.1078]\u001b[A\n",
      "Epoch 4:  75%|███████▌  | 111/148 [01:42<00:34,  1.09it/s, training_loss=1.1078]\u001b[A\n",
      "Epoch 4:  75%|███████▌  | 111/148 [01:43<00:34,  1.09it/s, training_loss=1.1715]\u001b[A\n",
      "Epoch 4:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.1715]\u001b[A\n",
      "Epoch 4:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.4942]\u001b[A\n",
      "Epoch 4:  76%|███████▋  | 113/148 [01:43<00:32,  1.09it/s, training_loss=1.4942]\u001b[A\n",
      "Epoch 4:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.6125]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.6125]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.5520]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 115/148 [01:45<00:30,  1.10it/s, training_loss=1.5520]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 115/148 [01:46<00:30,  1.10it/s, training_loss=1.3749]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.3749]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=0.9958]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=0.9958]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=0.9849]\u001b[A\n",
      "Epoch 4:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=0.9849]\u001b[A\n",
      "Epoch 4:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.0857]\u001b[A\n",
      "Epoch 4:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.0857]\u001b[A\n",
      "Epoch 4:  80%|████████  | 119/148 [01:50<00:26,  1.09it/s, training_loss=1.5768]\u001b[A\n",
      "Epoch 4:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.5768]\u001b[A\n",
      "Epoch 4:  81%|████████  | 120/148 [01:51<00:25,  1.09it/s, training_loss=1.1315]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 121/148 [01:51<00:24,  1.08it/s, training_loss=1.1315]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 121/148 [01:52<00:24,  1.08it/s, training_loss=1.5274]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.5274]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 122/148 [01:53<00:23,  1.09it/s, training_loss=0.9827]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 123/148 [01:53<00:23,  1.09it/s, training_loss=0.9827]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 123/148 [01:54<00:23,  1.09it/s, training_loss=1.2077]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 124/148 [01:54<00:22,  1.09it/s, training_loss=1.2077]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 124/148 [01:55<00:22,  1.09it/s, training_loss=1.6018]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=1.6018]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=1.3383]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 126/148 [01:55<00:20,  1.08it/s, training_loss=1.3383]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 126/148 [01:56<00:20,  1.08it/s, training_loss=1.5940]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=1.5940]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.3149]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.3149]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.5160]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.5160]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=1.3460]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.3460]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=1.4173]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.4173]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=1.2798]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 132/148 [02:01<00:14,  1.08it/s, training_loss=1.2798]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 132/148 [02:02<00:14,  1.08it/s, training_loss=1.0823]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.0823]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 133/148 [02:03<00:13,  1.09it/s, training_loss=1.1725]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.1725]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 134/148 [02:04<00:12,  1.09it/s, training_loss=1.5879]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=1.5879]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 135/148 [02:05<00:11,  1.09it/s, training_loss=1.2938]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.2938]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 136/148 [02:06<00:11,  1.09it/s, training_loss=1.1679]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.1679]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.2178]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.2178]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.3479]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.3479]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.3995]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=1.3995]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=1.1150]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=1.1150]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 141/148 [02:10<00:06,  1.09it/s, training_loss=1.5686]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=1.5686]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 142/148 [02:11<00:05,  1.09it/s, training_loss=1.0783]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.0783]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 144/148 [02:13<00:03,  1.09it/s, training_loss=1.6959]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=1.6959]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 145/148 [02:14<00:02,  1.09it/s, training_loss=1.0309]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 146/148 [02:14<00:01,  1.08it/s, training_loss=1.0309]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 146/148 [02:15<00:01,  1.08it/s, training_loss=1.6300]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.6300]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.1027]\u001b[A\n",
      "Epoch 4: 100%|██████████| 148/148 [02:15<00:00,  1.18it/s, training_loss=1.1027]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:57:25,000 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:57:25,002 - INFO - Memory usage after evaluation start: 4001.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.63it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.63it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.60it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.60it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.58it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.58it/s, Accuracy=68.50%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.57it/s, Accuracy=68.50%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.57it/s, Accuracy=69.20%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.57it/s, Accuracy=69.20%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.57it/s, Accuracy=69.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.56it/s, Accuracy=69.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.56it/s, Accuracy=69.14%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.55it/s, Accuracy=69.14%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.55it/s, Accuracy=67.50%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.55it/s, Accuracy=67.50%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.55it/s, Accuracy=67.56%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.54it/s, Accuracy=67.56%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.54it/s, Accuracy=67.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.54it/s, Accuracy=67.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.54it/s, Accuracy=67.09%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.53it/s, Accuracy=67.09%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.53it/s, Accuracy=67.50%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.54it/s, Accuracy=67.50%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.54it/s, Accuracy=66.77%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.55it/s, Accuracy=66.77%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.55it/s, Accuracy=66.71%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.55it/s, Accuracy=66.71%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.55it/s, Accuracy=66.93%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.54it/s, Accuracy=66.93%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.54it/s, Accuracy=66.62%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.54it/s, Accuracy=66.62%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.54it/s, Accuracy=66.24%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.53it/s, Accuracy=66.24%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:02,  3.53it/s, Accuracy=66.78%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.54it/s, Accuracy=66.78%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.54it/s, Accuracy=66.63%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.53it/s, Accuracy=66.63%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.53it/s, Accuracy=67.10%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.53it/s, Accuracy=67.10%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.53it/s, Accuracy=67.05%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.53it/s, Accuracy=67.05%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.53it/s, Accuracy=66.82%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.54it/s, Accuracy=66.82%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.54it/s, Accuracy=67.22%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.54it/s, Accuracy=67.22%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.54it/s, Accuracy=66.92%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.54it/s, Accuracy=66.92%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:07<00:00,  3.54it/s, Accuracy=67.04%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.54it/s, Accuracy=67.04%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.54it/s, Accuracy=67.08%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.54it/s, Accuracy=67.08%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.66it/s, Accuracy=67.05%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:57:32,381 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 10:57:32,387 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 10:57:32,387 - INFO - Accuracy: 0.4368\n",
      "2025-02-19 10:57:32,388 - INFO - F1_score: 0.4731\n",
      "2025-02-19 10:57:32,389 - INFO - Precision: 0.3220\n",
      "2025-02-19 10:57:32,390 - INFO - Recall: 0.8919\n",
      "2025-02-19 10:57:32,396 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 10:57:32,396 - INFO - Accuracy: 0.8544\n",
      "2025-02-19 10:57:32,397 - INFO - F1_score: 0.7286\n",
      "2025-02-19 10:57:32,398 - INFO - Precision: 0.6145\n",
      "2025-02-19 10:57:32,399 - INFO - Recall: 0.8947\n",
      "2025-02-19 10:57:32,405 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 10:57:32,406 - INFO - Accuracy: 0.6475\n",
      "2025-02-19 10:57:32,406 - INFO - F1_score: 0.4945\n",
      "2025-02-19 10:57:32,407 - INFO - Precision: 0.3629\n",
      "2025-02-19 10:57:32,408 - INFO - Recall: 0.7759\n",
      "2025-02-19 10:57:32,414 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 10:57:32,415 - INFO - Accuracy: 0.6245\n",
      "2025-02-19 10:57:32,415 - INFO - F1_score: 0.3553\n",
      "2025-02-19 10:57:32,416 - INFO - Precision: 0.2368\n",
      "2025-02-19 10:57:32,416 - INFO - Recall: 0.7105\n",
      "2025-02-19 10:57:32,423 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 10:57:32,424 - INFO - Accuracy: 0.7893\n",
      "2025-02-19 10:57:32,424 - INFO - F1_score: 0.4330\n",
      "2025-02-19 10:57:32,425 - INFO - Precision: 0.3333\n",
      "2025-02-19 10:57:32,425 - INFO - Recall: 0.6176\n",
      "2025-02-19 10:57:32,428 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:57:36,234 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 10:57:36,236 - INFO - Memory usage after evaluation end: 4007.16 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [10:21<4:11:35, 155.63s/it, Train Loss=1.3552, Val Loss=0.0469, Accuracy=0.6705]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:57:43,530 - INFO - Learning rate: 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 4/100 [10:21<4:08:16, 155.17s/it, Train Loss=1.3552, Val Loss=0.0469, Accuracy=0.6705]\n",
      "Epoch 5:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.2095]\u001b[A\n",
      "Epoch 5:   1%|          | 1/148 [00:00<02:16,  1.07it/s, training_loss=1.2095]\u001b[A\n",
      "Epoch 5:   1%|          | 1/148 [00:01<02:16,  1.07it/s, training_loss=1.5343]\u001b[A\n",
      "Epoch 5:   1%|▏         | 2/148 [00:01<02:14,  1.09it/s, training_loss=1.5343]\u001b[A\n",
      "Epoch 5:   1%|▏         | 2/148 [00:02<02:14,  1.09it/s, training_loss=1.6707]\u001b[A\n",
      "Epoch 5:   2%|▏         | 3/148 [00:02<02:14,  1.08it/s, training_loss=1.6707]\u001b[A\n",
      "Epoch 5:   2%|▏         | 3/148 [00:03<02:14,  1.08it/s, training_loss=0.9994]\u001b[A\n",
      "Epoch 5:   3%|▎         | 4/148 [00:03<02:12,  1.09it/s, training_loss=0.9994]\u001b[A\n",
      "Epoch 5:   3%|▎         | 4/148 [00:04<02:12,  1.09it/s, training_loss=0.9855]\u001b[A\n",
      "Epoch 5:   3%|▎         | 5/148 [00:04<02:11,  1.09it/s, training_loss=0.9855]\u001b[A\n",
      "Epoch 5:   3%|▎         | 5/148 [00:05<02:11,  1.09it/s, training_loss=1.1893]\u001b[A\n",
      "Epoch 5:   4%|▍         | 6/148 [00:05<02:10,  1.08it/s, training_loss=1.1893]\u001b[A\n",
      "Epoch 5:   4%|▍         | 6/148 [00:06<02:10,  1.08it/s, training_loss=1.5973]\u001b[A\n",
      "Epoch 5:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=1.5973]\u001b[A\n",
      "Epoch 5:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=1.5634]\u001b[A\n",
      "Epoch 5:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=1.5634]\u001b[A\n",
      "Epoch 5:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=1.6199]\u001b[A\n",
      "Epoch 5:   6%|▌         | 9/148 [00:08<02:07,  1.09it/s, training_loss=1.6199]\u001b[A\n",
      "Epoch 5:   6%|▌         | 9/148 [00:09<02:07,  1.09it/s, training_loss=1.5869]\u001b[A\n",
      "Epoch 5:   7%|▋         | 10/148 [00:09<02:07,  1.09it/s, training_loss=1.5869]\u001b[A\n",
      "Epoch 5:   7%|▋         | 10/148 [00:10<02:07,  1.09it/s, training_loss=1.1435]\u001b[A\n",
      "Epoch 5:   7%|▋         | 11/148 [00:10<02:06,  1.09it/s, training_loss=1.1435]\u001b[A\n",
      "Epoch 5:   7%|▋         | 11/148 [00:11<02:06,  1.09it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 5:   8%|▊         | 12/148 [00:11<02:05,  1.09it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 5:   8%|▊         | 12/148 [00:11<02:05,  1.09it/s, training_loss=1.5792]\u001b[A\n",
      "Epoch 5:   9%|▉         | 13/148 [00:11<02:04,  1.09it/s, training_loss=1.5792]\u001b[A\n",
      "Epoch 5:   9%|▉         | 13/148 [00:12<02:04,  1.09it/s, training_loss=1.6105]\u001b[A\n",
      "Epoch 5:   9%|▉         | 14/148 [00:12<02:03,  1.08it/s, training_loss=1.6105]\u001b[A\n",
      "Epoch 5:   9%|▉         | 14/148 [00:13<02:03,  1.08it/s, training_loss=1.5149]\u001b[A\n",
      "Epoch 5:  10%|█         | 15/148 [00:13<02:02,  1.08it/s, training_loss=1.5149]\u001b[A\n",
      "Epoch 5:  10%|█         | 15/148 [00:14<02:02,  1.08it/s, training_loss=1.5268]\u001b[A\n",
      "Epoch 5:  11%|█         | 16/148 [00:14<02:02,  1.08it/s, training_loss=1.5268]\u001b[A\n",
      "Epoch 5:  11%|█         | 16/148 [00:15<02:02,  1.08it/s, training_loss=0.9260]\u001b[A\n",
      "Epoch 5:  11%|█▏        | 17/148 [00:15<02:01,  1.08it/s, training_loss=0.9260]\u001b[A\n",
      "Epoch 5:  11%|█▏        | 17/148 [00:16<02:01,  1.08it/s, training_loss=1.1643]\u001b[A\n",
      "Epoch 5:  12%|█▏        | 18/148 [00:16<02:00,  1.08it/s, training_loss=1.1643]\u001b[A\n",
      "Epoch 5:  12%|█▏        | 18/148 [00:17<02:00,  1.08it/s, training_loss=1.5519]\u001b[A\n",
      "Epoch 5:  13%|█▎        | 19/148 [00:17<01:59,  1.08it/s, training_loss=1.5519]\u001b[A\n",
      "Epoch 5:  13%|█▎        | 19/148 [00:18<01:59,  1.08it/s, training_loss=1.2228]\u001b[A\n",
      "Epoch 5:  14%|█▎        | 20/148 [00:18<01:58,  1.08it/s, training_loss=1.2228]\u001b[A\n",
      "Epoch 5:  14%|█▎        | 20/148 [00:19<01:58,  1.08it/s, training_loss=1.5430]\u001b[A\n",
      "Epoch 5:  14%|█▍        | 21/148 [00:19<01:57,  1.08it/s, training_loss=1.5430]\u001b[A\n",
      "Epoch 5:  14%|█▍        | 21/148 [00:20<01:57,  1.08it/s, training_loss=1.5742]\u001b[A\n",
      "Epoch 5:  15%|█▍        | 22/148 [00:20<01:56,  1.09it/s, training_loss=1.5742]\u001b[A\n",
      "Epoch 5:  15%|█▍        | 22/148 [00:21<01:56,  1.09it/s, training_loss=1.0325]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 23/148 [00:21<01:55,  1.08it/s, training_loss=1.0325]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 23/148 [00:22<01:55,  1.08it/s, training_loss=1.0752]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=1.0752]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 24/148 [00:23<01:54,  1.08it/s, training_loss=1.0078]\u001b[A\n",
      "Epoch 5:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.0078]\u001b[A\n",
      "Epoch 5:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.4747]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 26/148 [00:23<01:52,  1.08it/s, training_loss=1.4747]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 26/148 [00:24<01:52,  1.08it/s, training_loss=1.6296]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 27/148 [00:24<01:51,  1.08it/s, training_loss=1.6296]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 27/148 [00:25<01:51,  1.08it/s, training_loss=1.1122]\u001b[A\n",
      "Epoch 5:  19%|█▉        | 28/148 [00:25<01:51,  1.08it/s, training_loss=1.1122]\u001b[A\n",
      "Epoch 5:  19%|█▉        | 28/148 [00:26<01:51,  1.08it/s, training_loss=1.1782]\u001b[A\n",
      "Epoch 5:  20%|█▉        | 29/148 [00:26<01:50,  1.08it/s, training_loss=1.1782]\u001b[A\n",
      "Epoch 5:  20%|█▉        | 29/148 [00:27<01:50,  1.08it/s, training_loss=1.5830]\u001b[A\n",
      "Epoch 5:  20%|██        | 30/148 [00:27<01:48,  1.08it/s, training_loss=1.5830]\u001b[A\n",
      "Epoch 5:  20%|██        | 30/148 [00:28<01:48,  1.08it/s, training_loss=1.2058]\u001b[A\n",
      "Epoch 5:  21%|██        | 31/148 [00:28<01:48,  1.08it/s, training_loss=1.2058]\u001b[A\n",
      "Epoch 5:  21%|██        | 31/148 [00:29<01:48,  1.08it/s, training_loss=1.2552]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 32/148 [00:29<01:47,  1.08it/s, training_loss=1.2552]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 32/148 [00:30<01:47,  1.08it/s, training_loss=1.5031]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 33/148 [00:30<01:45,  1.09it/s, training_loss=1.5031]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 33/148 [00:31<01:45,  1.09it/s, training_loss=1.6425]\u001b[A\n",
      "Epoch 5:  23%|██▎       | 34/148 [00:31<01:44,  1.09it/s, training_loss=1.6425]\u001b[A\n",
      "Epoch 5:  23%|██▎       | 34/148 [00:32<01:44,  1.09it/s, training_loss=1.1038]\u001b[A\n",
      "Epoch 5:  24%|██▎       | 35/148 [00:32<01:44,  1.08it/s, training_loss=1.1038]\u001b[A\n",
      "Epoch 5:  24%|██▎       | 35/148 [00:33<01:44,  1.08it/s, training_loss=1.2250]\u001b[A\n",
      "Epoch 5:  24%|██▍       | 36/148 [00:33<01:43,  1.08it/s, training_loss=1.2250]\u001b[A\n",
      "Epoch 5:  24%|██▍       | 36/148 [00:34<01:43,  1.08it/s, training_loss=1.1018]\u001b[A\n",
      "Epoch 5:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=1.1018]\u001b[A\n",
      "Epoch 5:  25%|██▌       | 37/148 [00:35<01:42,  1.08it/s, training_loss=1.4319]\u001b[A\n",
      "Epoch 5:  26%|██▌       | 38/148 [00:35<01:41,  1.09it/s, training_loss=1.4319]\u001b[A\n",
      "Epoch 5:  26%|██▌       | 38/148 [00:35<01:41,  1.09it/s, training_loss=1.0830]\u001b[A\n",
      "Epoch 5:  26%|██▋       | 39/148 [00:35<01:40,  1.09it/s, training_loss=1.0830]\u001b[A\n",
      "Epoch 5:  26%|██▋       | 39/148 [00:36<01:40,  1.09it/s, training_loss=1.6420]\u001b[A\n",
      "Epoch 5:  27%|██▋       | 40/148 [00:36<01:39,  1.09it/s, training_loss=1.6420]\u001b[A\n",
      "Epoch 5:  27%|██▋       | 40/148 [00:37<01:39,  1.09it/s, training_loss=1.6871]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=1.6871]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=1.3998]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=1.3998]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=1.6191]\u001b[A\n",
      "Epoch 5:  29%|██▉       | 43/148 [00:39<01:36,  1.09it/s, training_loss=1.6191]\u001b[A\n",
      "Epoch 5:  29%|██▉       | 43/148 [00:40<01:36,  1.09it/s, training_loss=1.5536]\u001b[A\n",
      "Epoch 5:  30%|██▉       | 44/148 [00:40<01:35,  1.09it/s, training_loss=1.5536]\u001b[A\n",
      "Epoch 5:  30%|██▉       | 44/148 [00:41<01:35,  1.09it/s, training_loss=1.5082]\u001b[A\n",
      "Epoch 5:  30%|███       | 45/148 [00:41<01:34,  1.09it/s, training_loss=1.5082]\u001b[A\n",
      "Epoch 5:  30%|███       | 45/148 [00:42<01:34,  1.09it/s, training_loss=1.0815]\u001b[A\n",
      "Epoch 5:  31%|███       | 46/148 [00:42<01:33,  1.09it/s, training_loss=1.0815]\u001b[A\n",
      "Epoch 5:  31%|███       | 46/148 [00:43<01:33,  1.09it/s, training_loss=0.9842]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=0.9842]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.3384]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 48/148 [00:44<01:31,  1.09it/s, training_loss=1.3384]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 48/148 [00:45<01:31,  1.09it/s, training_loss=1.5877]\u001b[A\n",
      "Epoch 5:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=1.5877]\u001b[A\n",
      "Epoch 5:  33%|███▎      | 49/148 [00:46<01:30,  1.09it/s, training_loss=0.9437]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=0.9437]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=1.6563]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 51/148 [00:46<01:28,  1.09it/s, training_loss=1.6563]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 51/148 [00:47<01:28,  1.09it/s, training_loss=1.6150]\u001b[A\n",
      "Epoch 5:  35%|███▌      | 52/148 [00:47<01:27,  1.09it/s, training_loss=1.6150]\u001b[A\n",
      "Epoch 5:  35%|███▌      | 52/148 [00:48<01:27,  1.09it/s, training_loss=1.4793]\u001b[A\n",
      "Epoch 5:  36%|███▌      | 53/148 [00:48<01:26,  1.10it/s, training_loss=1.4793]\u001b[A\n",
      "Epoch 5:  36%|███▌      | 53/148 [00:49<01:26,  1.10it/s, training_loss=1.5210]\u001b[A\n",
      "Epoch 5:  36%|███▋      | 54/148 [00:49<01:25,  1.09it/s, training_loss=1.5210]\u001b[A\n",
      "Epoch 5:  36%|███▋      | 54/148 [00:50<01:25,  1.09it/s, training_loss=1.6233]\u001b[A\n",
      "Epoch 5:  37%|███▋      | 55/148 [00:50<01:24,  1.10it/s, training_loss=1.6233]\u001b[A\n",
      "Epoch 5:  37%|███▋      | 55/148 [00:51<01:24,  1.10it/s, training_loss=0.9566]\u001b[A\n",
      "Epoch 5:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=0.9566]\u001b[A\n",
      "Epoch 5:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.5676]\u001b[A\n",
      "Epoch 5:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.5676]\u001b[A\n",
      "Epoch 5:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=0.9203]\u001b[A\n",
      "Epoch 5:  39%|███▉      | 58/148 [00:53<01:22,  1.09it/s, training_loss=0.9203]\u001b[A\n",
      "Epoch 5:  39%|███▉      | 58/148 [00:54<01:22,  1.09it/s, training_loss=0.9351]\u001b[A\n",
      "Epoch 5:  40%|███▉      | 59/148 [00:54<01:21,  1.09it/s, training_loss=0.9351]\u001b[A\n",
      "Epoch 5:  40%|███▉      | 59/148 [00:55<01:21,  1.09it/s, training_loss=0.9477]\u001b[A\n",
      "Epoch 5:  41%|████      | 60/148 [00:55<01:21,  1.08it/s, training_loss=0.9477]\u001b[A\n",
      "Epoch 5:  41%|████      | 60/148 [00:56<01:21,  1.08it/s, training_loss=1.6210]\u001b[A\n",
      "Epoch 5:  41%|████      | 61/148 [00:56<01:20,  1.09it/s, training_loss=1.6210]\u001b[A\n",
      "Epoch 5:  41%|████      | 61/148 [00:57<01:20,  1.09it/s, training_loss=1.5506]\u001b[A\n",
      "Epoch 5:  42%|████▏     | 62/148 [00:57<01:18,  1.09it/s, training_loss=1.5506]\u001b[A\n",
      "Epoch 5:  42%|████▏     | 62/148 [00:58<01:18,  1.09it/s, training_loss=1.1823]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 63/148 [00:58<01:18,  1.08it/s, training_loss=1.1823]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 63/148 [00:58<01:18,  1.08it/s, training_loss=1.1369]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 64/148 [00:58<01:17,  1.08it/s, training_loss=1.1369]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 64/148 [00:59<01:17,  1.08it/s, training_loss=1.5610]\u001b[A\n",
      "Epoch 5:  44%|████▍     | 65/148 [00:59<01:16,  1.09it/s, training_loss=1.5610]\u001b[A\n",
      "Epoch 5:  44%|████▍     | 65/148 [01:00<01:16,  1.09it/s, training_loss=1.6224]\u001b[A\n",
      "Epoch 5:  45%|████▍     | 66/148 [01:00<01:15,  1.09it/s, training_loss=1.6224]\u001b[A\n",
      "Epoch 5:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=1.6825]\u001b[A\n",
      "Epoch 5:  45%|████▌     | 67/148 [01:01<01:14,  1.09it/s, training_loss=1.6825]\u001b[A\n",
      "Epoch 5:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=1.0839]\u001b[A\n",
      "Epoch 5:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=1.0839]\u001b[A\n",
      "Epoch 5:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=0.9769]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=0.9769]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=1.5887]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=1.5887]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=1.6310]\u001b[A\n",
      "Epoch 5:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=1.6310]\u001b[A\n",
      "Epoch 5:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.6782]\u001b[A\n",
      "Epoch 5:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=1.6782]\u001b[A\n",
      "Epoch 5:  49%|████▊     | 72/148 [01:07<01:09,  1.09it/s, training_loss=1.5764]\u001b[A\n",
      "Epoch 5:  49%|████▉     | 73/148 [01:07<01:08,  1.09it/s, training_loss=1.5764]\u001b[A\n",
      "Epoch 5:  49%|████▉     | 73/148 [01:08<01:08,  1.09it/s, training_loss=1.4893]\u001b[A\n",
      "Epoch 5:  50%|█████     | 74/148 [01:08<01:07,  1.09it/s, training_loss=1.4893]\u001b[A\n",
      "Epoch 5:  50%|█████     | 74/148 [01:09<01:07,  1.09it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 5:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 5:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.0812]\u001b[A\n",
      "Epoch 5:  51%|█████▏    | 76/148 [01:09<01:06,  1.09it/s, training_loss=1.0812]\u001b[A\n",
      "Epoch 5:  51%|█████▏    | 76/148 [01:10<01:06,  1.09it/s, training_loss=1.0923]\u001b[A\n",
      "Epoch 5:  52%|█████▏    | 77/148 [01:10<01:05,  1.09it/s, training_loss=1.0923]\u001b[A\n",
      "Epoch 5:  52%|█████▏    | 77/148 [01:11<01:05,  1.09it/s, training_loss=1.0679]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 78/148 [01:11<01:04,  1.09it/s, training_loss=1.0679]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 78/148 [01:12<01:04,  1.09it/s, training_loss=1.3245]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 79/148 [01:12<01:03,  1.09it/s, training_loss=1.3245]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 79/148 [01:13<01:03,  1.09it/s, training_loss=1.1141]\u001b[A\n",
      "Epoch 5:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.1141]\u001b[A\n",
      "Epoch 5:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.2440]\u001b[A\n",
      "Epoch 5:  55%|█████▍    | 81/148 [01:14<01:01,  1.08it/s, training_loss=1.2440]\u001b[A\n",
      "Epoch 5:  55%|█████▍    | 81/148 [01:15<01:01,  1.08it/s, training_loss=1.0571]\u001b[A\n",
      "Epoch 5:  55%|█████▌    | 82/148 [01:15<01:00,  1.08it/s, training_loss=1.0571]\u001b[A\n",
      "Epoch 5:  55%|█████▌    | 82/148 [01:16<01:00,  1.08it/s, training_loss=1.5564]\u001b[A\n",
      "Epoch 5:  56%|█████▌    | 83/148 [01:16<00:59,  1.08it/s, training_loss=1.5564]\u001b[A\n",
      "Epoch 5:  56%|█████▌    | 83/148 [01:17<00:59,  1.08it/s, training_loss=0.9423]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=0.9423]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 84/148 [01:18<00:58,  1.09it/s, training_loss=1.1360]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.1360]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 85/148 [01:19<00:57,  1.09it/s, training_loss=1.1550]\u001b[A\n",
      "Epoch 5:  58%|█████▊    | 86/148 [01:19<00:57,  1.09it/s, training_loss=1.1550]\u001b[A\n",
      "Epoch 5:  58%|█████▊    | 86/148 [01:20<00:57,  1.09it/s, training_loss=0.9858]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 87/148 [01:20<00:56,  1.09it/s, training_loss=0.9858]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 87/148 [01:20<00:56,  1.09it/s, training_loss=1.6741]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 88/148 [01:20<00:55,  1.09it/s, training_loss=1.6741]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.5875]\u001b[A\n",
      "Epoch 5:  60%|██████    | 89/148 [01:21<00:54,  1.09it/s, training_loss=1.5875]\u001b[A\n",
      "Epoch 5:  60%|██████    | 89/148 [01:22<00:54,  1.09it/s, training_loss=1.2857]\u001b[A\n",
      "Epoch 5:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=1.2857]\u001b[A\n",
      "Epoch 5:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=1.6537]\u001b[A\n",
      "Epoch 5:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=1.6537]\u001b[A\n",
      "Epoch 5:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.1057]\u001b[A\n",
      "Epoch 5:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.1057]\u001b[A\n",
      "Epoch 5:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=1.6368]\u001b[A\n",
      "Epoch 5:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.6368]\u001b[A\n",
      "Epoch 5:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.5451]\u001b[A\n",
      "Epoch 5:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=1.5451]\u001b[A\n",
      "Epoch 5:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.0516]\u001b[A\n",
      "Epoch 5:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.0516]\u001b[A\n",
      "Epoch 5:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=1.1466]\u001b[A\n",
      "Epoch 5:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.1466]\u001b[A\n",
      "Epoch 5:  65%|██████▍   | 96/148 [01:29<00:47,  1.09it/s, training_loss=1.0378]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 97/148 [01:29<00:47,  1.08it/s, training_loss=1.0378]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 97/148 [01:30<00:47,  1.08it/s, training_loss=1.0091]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 98/148 [01:30<00:46,  1.08it/s, training_loss=1.0091]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 98/148 [01:31<00:46,  1.08it/s, training_loss=1.5134]\u001b[A\n",
      "Epoch 5:  67%|██████▋   | 99/148 [01:31<00:45,  1.09it/s, training_loss=1.5134]\u001b[A\n",
      "Epoch 5:  67%|██████▋   | 99/148 [01:31<00:45,  1.09it/s, training_loss=1.5096]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 100/148 [01:31<00:43,  1.09it/s, training_loss=1.5096]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 100/148 [01:32<00:43,  1.09it/s, training_loss=1.4910]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 101/148 [01:32<00:43,  1.09it/s, training_loss=1.4910]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.5532]\u001b[A\n",
      "Epoch 5:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.5532]\u001b[A\n",
      "Epoch 5:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=1.6483]\u001b[A\n",
      "Epoch 5:  70%|██████▉   | 103/148 [01:34<00:41,  1.09it/s, training_loss=1.6483]\u001b[A\n",
      "Epoch 5:  70%|██████▉   | 103/148 [01:35<00:41,  1.09it/s, training_loss=1.5578]\u001b[A\n",
      "Epoch 5:  70%|███████   | 104/148 [01:35<00:40,  1.09it/s, training_loss=1.5578]\u001b[A\n",
      "Epoch 5:  70%|███████   | 104/148 [01:36<00:40,  1.09it/s, training_loss=1.1094]\u001b[A\n",
      "Epoch 5:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=1.1094]\u001b[A\n",
      "Epoch 5:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.0999]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.0999]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=1.5445]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=1.5445]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 107/148 [01:39<00:37,  1.09it/s, training_loss=0.8866]\u001b[A\n",
      "Epoch 5:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=0.8866]\u001b[A\n",
      "Epoch 5:  73%|███████▎  | 108/148 [01:40<00:36,  1.09it/s, training_loss=1.6854]\u001b[A\n",
      "Epoch 5:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.6854]\u001b[A\n",
      "Epoch 5:  74%|███████▎  | 109/148 [01:41<00:35,  1.09it/s, training_loss=1.5506]\u001b[A\n",
      "Epoch 5:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.5506]\u001b[A\n",
      "Epoch 5:  74%|███████▍  | 110/148 [01:42<00:34,  1.09it/s, training_loss=1.0877]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=1.0877]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 111/148 [01:43<00:33,  1.09it/s, training_loss=1.5843]\u001b[A\n",
      "Epoch 5:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.5843]\u001b[A\n",
      "Epoch 5:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.1563]\u001b[A\n",
      "Epoch 5:  76%|███████▋  | 113/148 [01:43<00:32,  1.08it/s, training_loss=1.1563]\u001b[A\n",
      "Epoch 5:  76%|███████▋  | 113/148 [01:44<00:32,  1.08it/s, training_loss=1.5875]\u001b[A\n",
      "Epoch 5:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.5875]\u001b[A\n",
      "Epoch 5:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.3363]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.3363]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=1.5430]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.5430]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=1.4755]\u001b[A\n",
      "Epoch 5:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.4755]\u001b[A\n",
      "Epoch 5:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=1.5132]\u001b[A\n",
      "Epoch 5:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=1.5132]\u001b[A\n",
      "Epoch 5:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.1038]\u001b[A\n",
      "Epoch 5:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.1038]\u001b[A\n",
      "Epoch 5:  80%|████████  | 119/148 [01:50<00:26,  1.09it/s, training_loss=1.5231]\u001b[A\n",
      "Epoch 5:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.5231]\u001b[A\n",
      "Epoch 5:  81%|████████  | 120/148 [01:51<00:25,  1.09it/s, training_loss=1.7638]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.7638]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 121/148 [01:52<00:24,  1.09it/s, training_loss=1.2219]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.2219]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 122/148 [01:53<00:23,  1.09it/s, training_loss=1.1243]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=1.1243]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 123/148 [01:54<00:22,  1.09it/s, training_loss=1.6937]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 124/148 [01:54<00:22,  1.09it/s, training_loss=1.6937]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 124/148 [01:54<00:22,  1.09it/s, training_loss=1.6255]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 125/148 [01:54<00:21,  1.09it/s, training_loss=1.6255]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=0.9721]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 126/148 [01:55<00:20,  1.09it/s, training_loss=0.9721]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=0.9540]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=0.9540]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.2414]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.2414]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.5488]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.5488]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=1.6172]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.6172]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=1.0276]\u001b[A\n",
      "Epoch 5:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.0276]\u001b[A\n",
      "Epoch 5:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=1.5965]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.5965]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 132/148 [02:02<00:14,  1.09it/s, training_loss=1.2019]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.2019]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 133/148 [02:03<00:13,  1.09it/s, training_loss=1.5230]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.5230]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 134/148 [02:04<00:12,  1.09it/s, training_loss=0.9750]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=0.9750]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 135/148 [02:05<00:11,  1.09it/s, training_loss=1.1995]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.1995]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.5439]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=1.5439]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.2425]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 138/148 [02:06<00:09,  1.08it/s, training_loss=1.2425]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 138/148 [02:07<00:09,  1.08it/s, training_loss=1.0351]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 139/148 [02:07<00:08,  1.08it/s, training_loss=1.0351]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 139/148 [02:08<00:08,  1.08it/s, training_loss=1.5749]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 140/148 [02:08<00:07,  1.08it/s, training_loss=1.5749]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 140/148 [02:09<00:07,  1.08it/s, training_loss=1.5197]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=1.5197]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 141/148 [02:10<00:06,  1.09it/s, training_loss=1.5446]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=1.5446]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 142/148 [02:11<00:05,  1.09it/s, training_loss=1.0227]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.0227]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=1.3996]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=1.3996]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 144/148 [02:13<00:03,  1.09it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 145/148 [02:14<00:02,  1.09it/s, training_loss=1.0732]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 146/148 [02:14<00:01,  1.09it/s, training_loss=1.0732]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 146/148 [02:15<00:01,  1.09it/s, training_loss=0.8760]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=0.8760]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.0354]\u001b[A\n",
      "Epoch 5: 100%|██████████| 148/148 [02:15<00:00,  1.18it/s, training_loss=1.0354]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 10:59:59,380 - INFO - Starting model evaluation...\n",
      "2025-02-19 10:59:59,381 - INFO - Memory usage after evaluation start: 4007.41 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.66it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.66it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.61it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.61it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.59it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.59it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.57it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.57it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.56it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.56it/s, Accuracy=72.33%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.56it/s, Accuracy=72.33%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.56it/s, Accuracy=70.86%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.55it/s, Accuracy=70.86%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.55it/s, Accuracy=68.75%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.55it/s, Accuracy=68.75%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.55it/s, Accuracy=68.44%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.54it/s, Accuracy=68.44%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.54it/s, Accuracy=69.60%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.54it/s, Accuracy=69.60%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.54it/s, Accuracy=68.91%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.53it/s, Accuracy=68.91%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.53it/s, Accuracy=69.00%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.53it/s, Accuracy=69.00%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.53it/s, Accuracy=68.77%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.54it/s, Accuracy=68.77%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.54it/s, Accuracy=68.71%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.54it/s, Accuracy=68.71%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.54it/s, Accuracy=68.80%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.55it/s, Accuracy=68.80%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.55it/s, Accuracy=68.25%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.54it/s, Accuracy=68.25%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.54it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.53it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:02,  3.53it/s, Accuracy=68.33%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.54it/s, Accuracy=68.33%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.54it/s, Accuracy=68.21%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.54it/s, Accuracy=68.21%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.54it/s, Accuracy=68.60%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.55it/s, Accuracy=68.60%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.55it/s, Accuracy=68.48%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.53it/s, Accuracy=68.48%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.53it/s, Accuracy=68.27%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.53it/s, Accuracy=68.27%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.53it/s, Accuracy=68.43%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.54it/s, Accuracy=68.43%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.54it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.53it/s, Accuracy=68.00%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:07<00:00,  3.53it/s, Accuracy=67.84%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.53it/s, Accuracy=67.84%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.53it/s, Accuracy=68.08%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.53it/s, Accuracy=68.08%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.66it/s, Accuracy=68.05%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:00:06,763 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 11:00:06,768 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 11:00:06,769 - INFO - Accuracy: 0.5287\n",
      "2025-02-19 11:00:06,770 - INFO - F1_score: 0.4938\n",
      "2025-02-19 11:00:06,771 - INFO - Precision: 0.3550\n",
      "2025-02-19 11:00:06,772 - INFO - Recall: 0.8108\n",
      "2025-02-19 11:00:06,777 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 11:00:06,778 - INFO - Accuracy: 0.8429\n",
      "2025-02-19 11:00:06,778 - INFO - F1_score: 0.7172\n",
      "2025-02-19 11:00:06,779 - INFO - Precision: 0.5909\n",
      "2025-02-19 11:00:06,780 - INFO - Recall: 0.9123\n",
      "2025-02-19 11:00:06,786 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 11:00:06,786 - INFO - Accuracy: 0.5824\n",
      "2025-02-19 11:00:06,787 - INFO - F1_score: 0.4734\n",
      "2025-02-19 11:00:06,787 - INFO - Precision: 0.3289\n",
      "2025-02-19 11:00:06,788 - INFO - Recall: 0.8448\n",
      "2025-02-19 11:00:06,794 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 11:00:06,794 - INFO - Accuracy: 0.7433\n",
      "2025-02-19 11:00:06,795 - INFO - F1_score: 0.3853\n",
      "2025-02-19 11:00:06,795 - INFO - Precision: 0.2958\n",
      "2025-02-19 11:00:06,796 - INFO - Recall: 0.5526\n",
      "2025-02-19 11:00:06,802 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 11:00:06,803 - INFO - Accuracy: 0.7050\n",
      "2025-02-19 11:00:06,803 - INFO - F1_score: 0.4211\n",
      "2025-02-19 11:00:06,804 - INFO - Precision: 0.2828\n",
      "2025-02-19 11:00:06,805 - INFO - Recall: 0.8235\n",
      "2025-02-19 11:00:06,807 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:00:10,594 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 11:00:10,596 - INFO - Memory usage after evaluation end: 4012.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 4/100 [12:55<4:08:16, 155.17s/it, Train Loss=1.3408, Val Loss=0.0482, Accuracy=0.6805]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:00:17,867 - INFO - New best accuracy: 0.6805\n",
      "2025-02-19 11:00:18,824 - INFO - Learning rate: 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   5%|▌         | 5/100 [12:58<4:06:29, 155.68s/it, Train Loss=1.3408, Val Loss=0.0482, Accuracy=0.6805]\n",
      "Epoch 6:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.1523]\u001b[A\n",
      "Epoch 6:   1%|          | 1/148 [00:00<02:18,  1.06it/s, training_loss=1.1523]\u001b[A\n",
      "Epoch 6:   1%|          | 1/148 [00:01<02:18,  1.06it/s, training_loss=1.5845]\u001b[A\n",
      "Epoch 6:   1%|▏         | 2/148 [00:01<02:14,  1.08it/s, training_loss=1.5845]\u001b[A\n",
      "Epoch 6:   1%|▏         | 2/148 [00:02<02:14,  1.08it/s, training_loss=1.0609]\u001b[A\n",
      "Epoch 6:   2%|▏         | 3/148 [00:02<02:13,  1.09it/s, training_loss=1.0609]\u001b[A\n",
      "Epoch 6:   2%|▏         | 3/148 [00:03<02:13,  1.09it/s, training_loss=0.9931]\u001b[A\n",
      "Epoch 6:   3%|▎         | 4/148 [00:03<02:12,  1.09it/s, training_loss=0.9931]\u001b[A\n",
      "Epoch 6:   3%|▎         | 4/148 [00:04<02:12,  1.09it/s, training_loss=1.1156]\u001b[A\n",
      "Epoch 6:   3%|▎         | 5/148 [00:04<02:11,  1.09it/s, training_loss=1.1156]\u001b[A\n",
      "Epoch 6:   3%|▎         | 5/148 [00:05<02:11,  1.09it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 6:   4%|▍         | 6/148 [00:05<02:10,  1.09it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 6:   4%|▍         | 6/148 [00:06<02:10,  1.09it/s, training_loss=1.5895]\u001b[A\n",
      "Epoch 6:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=1.5895]\u001b[A\n",
      "Epoch 6:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=1.5660]\u001b[A\n",
      "Epoch 6:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=1.5660]\u001b[A\n",
      "Epoch 6:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=1.5288]\u001b[A\n",
      "Epoch 6:   6%|▌         | 9/148 [00:08<02:07,  1.09it/s, training_loss=1.5288]\u001b[A\n",
      "Epoch 6:   6%|▌         | 9/148 [00:09<02:07,  1.09it/s, training_loss=1.5817]\u001b[A\n",
      "Epoch 6:   7%|▋         | 10/148 [00:09<02:06,  1.09it/s, training_loss=1.5817]\u001b[A\n",
      "Epoch 6:   7%|▋         | 10/148 [00:10<02:06,  1.09it/s, training_loss=1.6083]\u001b[A\n",
      "Epoch 6:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.6083]\u001b[A\n",
      "Epoch 6:   7%|▋         | 11/148 [00:11<02:05,  1.09it/s, training_loss=1.5651]\u001b[A\n",
      "Epoch 6:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.5651]\u001b[A\n",
      "Epoch 6:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.1098]\u001b[A\n",
      "Epoch 6:   9%|▉         | 13/148 [00:11<02:04,  1.08it/s, training_loss=1.1098]\u001b[A\n",
      "Epoch 6:   9%|▉         | 13/148 [00:12<02:04,  1.08it/s, training_loss=1.1738]\u001b[A\n",
      "Epoch 6:   9%|▉         | 14/148 [00:12<02:03,  1.08it/s, training_loss=1.1738]\u001b[A\n",
      "Epoch 6:   9%|▉         | 14/148 [00:13<02:03,  1.08it/s, training_loss=0.9531]\u001b[A\n",
      "Epoch 6:  10%|█         | 15/148 [00:13<02:03,  1.08it/s, training_loss=0.9531]\u001b[A\n",
      "Epoch 6:  10%|█         | 15/148 [00:14<02:03,  1.08it/s, training_loss=1.3693]\u001b[A\n",
      "Epoch 6:  11%|█         | 16/148 [00:14<02:02,  1.08it/s, training_loss=1.3693]\u001b[A\n",
      "Epoch 6:  11%|█         | 16/148 [00:15<02:02,  1.08it/s, training_loss=1.2956]\u001b[A\n",
      "Epoch 6:  11%|█▏        | 17/148 [00:15<02:01,  1.08it/s, training_loss=1.2956]\u001b[A\n",
      "Epoch 6:  11%|█▏        | 17/148 [00:16<02:01,  1.08it/s, training_loss=1.5699]\u001b[A\n",
      "Epoch 6:  12%|█▏        | 18/148 [00:16<02:00,  1.08it/s, training_loss=1.5699]\u001b[A\n",
      "Epoch 6:  12%|█▏        | 18/148 [00:17<02:00,  1.08it/s, training_loss=0.9599]\u001b[A\n",
      "Epoch 6:  13%|█▎        | 19/148 [00:17<01:59,  1.08it/s, training_loss=0.9599]\u001b[A\n",
      "Epoch 6:  13%|█▎        | 19/148 [00:18<01:59,  1.08it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 6:  14%|█▎        | 20/148 [00:18<01:58,  1.08it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 6:  14%|█▎        | 20/148 [00:19<01:58,  1.08it/s, training_loss=1.6175]\u001b[A\n",
      "Epoch 6:  14%|█▍        | 21/148 [00:19<01:58,  1.08it/s, training_loss=1.6175]\u001b[A\n",
      "Epoch 6:  14%|█▍        | 21/148 [00:20<01:58,  1.08it/s, training_loss=1.5763]\u001b[A\n",
      "Epoch 6:  15%|█▍        | 22/148 [00:20<01:56,  1.08it/s, training_loss=1.5763]\u001b[A\n",
      "Epoch 6:  15%|█▍        | 22/148 [00:21<01:56,  1.08it/s, training_loss=1.3036]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 23/148 [00:21<01:55,  1.08it/s, training_loss=1.3036]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 23/148 [00:22<01:55,  1.08it/s, training_loss=1.0521]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 24/148 [00:22<01:55,  1.07it/s, training_loss=1.0521]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 24/148 [00:23<01:55,  1.07it/s, training_loss=1.6054]\u001b[A\n",
      "Epoch 6:  17%|█▋        | 25/148 [00:23<01:54,  1.07it/s, training_loss=1.6054]\u001b[A\n",
      "Epoch 6:  17%|█▋        | 25/148 [00:24<01:54,  1.07it/s, training_loss=1.0822]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 26/148 [00:24<01:53,  1.08it/s, training_loss=1.0822]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 26/148 [00:24<01:53,  1.08it/s, training_loss=1.6670]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 27/148 [00:24<01:52,  1.07it/s, training_loss=1.6670]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 27/148 [00:25<01:52,  1.07it/s, training_loss=1.1300]\u001b[A\n",
      "Epoch 6:  19%|█▉        | 28/148 [00:25<01:51,  1.07it/s, training_loss=1.1300]\u001b[A\n",
      "Epoch 6:  19%|█▉        | 28/148 [00:26<01:51,  1.07it/s, training_loss=1.0662]\u001b[A\n",
      "Epoch 6:  20%|█▉        | 29/148 [00:26<01:50,  1.07it/s, training_loss=1.0662]\u001b[A\n",
      "Epoch 6:  20%|█▉        | 29/148 [00:27<01:50,  1.07it/s, training_loss=1.5649]\u001b[A\n",
      "Epoch 6:  20%|██        | 30/148 [00:27<01:49,  1.08it/s, training_loss=1.5649]\u001b[A\n",
      "Epoch 6:  20%|██        | 30/148 [00:28<01:49,  1.08it/s, training_loss=0.9191]\u001b[A\n",
      "Epoch 6:  21%|██        | 31/148 [00:28<01:48,  1.08it/s, training_loss=0.9191]\u001b[A\n",
      "Epoch 6:  21%|██        | 31/148 [00:29<01:48,  1.08it/s, training_loss=1.6053]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 32/148 [00:29<01:47,  1.08it/s, training_loss=1.6053]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 32/148 [00:30<01:47,  1.08it/s, training_loss=1.5904]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 33/148 [00:30<01:46,  1.08it/s, training_loss=1.5904]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 33/148 [00:31<01:46,  1.08it/s, training_loss=1.1217]\u001b[A\n",
      "Epoch 6:  23%|██▎       | 34/148 [00:31<01:45,  1.08it/s, training_loss=1.1217]\u001b[A\n",
      "Epoch 6:  23%|██▎       | 34/148 [00:32<01:45,  1.08it/s, training_loss=1.5244]\u001b[A\n",
      "Epoch 6:  24%|██▎       | 35/148 [00:32<01:44,  1.08it/s, training_loss=1.5244]\u001b[A\n",
      "Epoch 6:  24%|██▎       | 35/148 [00:33<01:44,  1.08it/s, training_loss=1.4236]\u001b[A\n",
      "Epoch 6:  24%|██▍       | 36/148 [00:33<01:43,  1.08it/s, training_loss=1.4236]\u001b[A\n",
      "Epoch 6:  24%|██▍       | 36/148 [00:34<01:43,  1.08it/s, training_loss=1.6812]\u001b[A\n",
      "Epoch 6:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=1.6812]\u001b[A\n",
      "Epoch 6:  25%|██▌       | 37/148 [00:35<01:42,  1.08it/s, training_loss=1.0767]\u001b[A\n",
      "Epoch 6:  26%|██▌       | 38/148 [00:35<01:41,  1.08it/s, training_loss=1.0767]\u001b[A\n",
      "Epoch 6:  26%|██▌       | 38/148 [00:36<01:41,  1.08it/s, training_loss=1.5368]\u001b[A\n",
      "Epoch 6:  26%|██▋       | 39/148 [00:36<01:40,  1.08it/s, training_loss=1.5368]\u001b[A\n",
      "Epoch 6:  26%|██▋       | 39/148 [00:37<01:40,  1.08it/s, training_loss=1.6654]\u001b[A\n",
      "Epoch 6:  27%|██▋       | 40/148 [00:37<01:39,  1.08it/s, training_loss=1.6654]\u001b[A\n",
      "Epoch 6:  27%|██▋       | 40/148 [00:37<01:39,  1.08it/s, training_loss=1.0987]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 41/148 [00:37<01:38,  1.08it/s, training_loss=1.0987]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 41/148 [00:38<01:38,  1.08it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 42/148 [00:38<01:37,  1.08it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 42/148 [00:39<01:37,  1.08it/s, training_loss=1.5502]\u001b[A\n",
      "Epoch 6:  29%|██▉       | 43/148 [00:39<01:37,  1.08it/s, training_loss=1.5502]\u001b[A\n",
      "Epoch 6:  29%|██▉       | 43/148 [00:40<01:37,  1.08it/s, training_loss=1.5073]\u001b[A\n",
      "Epoch 6:  30%|██▉       | 44/148 [00:40<01:36,  1.08it/s, training_loss=1.5073]\u001b[A\n",
      "Epoch 6:  30%|██▉       | 44/148 [00:41<01:36,  1.08it/s, training_loss=0.9349]\u001b[A\n",
      "Epoch 6:  30%|███       | 45/148 [00:41<01:35,  1.08it/s, training_loss=0.9349]\u001b[A\n",
      "Epoch 6:  30%|███       | 45/148 [00:42<01:35,  1.08it/s, training_loss=1.5004]\u001b[A\n",
      "Epoch 6:  31%|███       | 46/148 [00:42<01:34,  1.08it/s, training_loss=1.5004]\u001b[A\n",
      "Epoch 6:  31%|███       | 46/148 [00:43<01:34,  1.08it/s, training_loss=1.0193]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 47/148 [00:43<01:33,  1.08it/s, training_loss=1.0193]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 47/148 [00:44<01:33,  1.08it/s, training_loss=1.5759]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 48/148 [00:44<01:32,  1.09it/s, training_loss=1.5759]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 48/148 [00:45<01:32,  1.09it/s, training_loss=0.9688]\u001b[A\n",
      "Epoch 6:  33%|███▎      | 49/148 [00:45<01:31,  1.09it/s, training_loss=0.9688]\u001b[A\n",
      "Epoch 6:  33%|███▎      | 49/148 [00:46<01:31,  1.09it/s, training_loss=1.6150]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 50/148 [00:46<01:30,  1.09it/s, training_loss=1.6150]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 50/148 [00:47<01:30,  1.09it/s, training_loss=1.6637]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 51/148 [00:47<01:29,  1.09it/s, training_loss=1.6637]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 51/148 [00:48<01:29,  1.09it/s, training_loss=1.5736]\u001b[A\n",
      "Epoch 6:  35%|███▌      | 52/148 [00:48<01:27,  1.09it/s, training_loss=1.5736]\u001b[A\n",
      "Epoch 6:  35%|███▌      | 52/148 [00:48<01:27,  1.09it/s, training_loss=1.5365]\u001b[A\n",
      "Epoch 6:  36%|███▌      | 53/148 [00:48<01:26,  1.09it/s, training_loss=1.5365]\u001b[A\n",
      "Epoch 6:  36%|███▌      | 53/148 [00:49<01:26,  1.09it/s, training_loss=1.5714]\u001b[A\n",
      "Epoch 6:  36%|███▋      | 54/148 [00:49<01:25,  1.10it/s, training_loss=1.5714]\u001b[A\n",
      "Epoch 6:  36%|███▋      | 54/148 [00:50<01:25,  1.10it/s, training_loss=1.1800]\u001b[A\n",
      "Epoch 6:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.1800]\u001b[A\n",
      "Epoch 6:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.5408]\u001b[A\n",
      "Epoch 6:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=1.5408]\u001b[A\n",
      "Epoch 6:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.0586]\u001b[A\n",
      "Epoch 6:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.0586]\u001b[A\n",
      "Epoch 6:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=0.9373]\u001b[A\n",
      "Epoch 6:  39%|███▉      | 58/148 [00:53<01:22,  1.08it/s, training_loss=0.9373]\u001b[A\n",
      "Epoch 6:  39%|███▉      | 58/148 [00:54<01:22,  1.08it/s, training_loss=1.0228]\u001b[A\n",
      "Epoch 6:  40%|███▉      | 59/148 [00:54<01:22,  1.08it/s, training_loss=1.0228]\u001b[A\n",
      "Epoch 6:  40%|███▉      | 59/148 [00:55<01:22,  1.08it/s, training_loss=1.5442]\u001b[A\n",
      "Epoch 6:  41%|████      | 60/148 [00:55<01:20,  1.09it/s, training_loss=1.5442]\u001b[A\n",
      "Epoch 6:  41%|████      | 60/148 [00:56<01:20,  1.09it/s, training_loss=0.8946]\u001b[A\n",
      "Epoch 6:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=0.8946]\u001b[A\n",
      "Epoch 6:  41%|████      | 61/148 [00:57<01:19,  1.09it/s, training_loss=1.5667]\u001b[A\n",
      "Epoch 6:  42%|████▏     | 62/148 [00:57<01:18,  1.09it/s, training_loss=1.5667]\u001b[A\n",
      "Epoch 6:  42%|████▏     | 62/148 [00:58<01:18,  1.09it/s, training_loss=0.8924]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 63/148 [00:58<01:17,  1.09it/s, training_loss=0.8924]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 63/148 [00:59<01:17,  1.09it/s, training_loss=1.5069]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 64/148 [00:59<01:16,  1.09it/s, training_loss=1.5069]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 64/148 [00:59<01:16,  1.09it/s, training_loss=1.6010]\u001b[A\n",
      "Epoch 6:  44%|████▍     | 65/148 [00:59<01:15,  1.10it/s, training_loss=1.6010]\u001b[A\n",
      "Epoch 6:  44%|████▍     | 65/148 [01:00<01:15,  1.10it/s, training_loss=0.8607]\u001b[A\n",
      "Epoch 6:  45%|████▍     | 66/148 [01:00<01:15,  1.09it/s, training_loss=0.8607]\u001b[A\n",
      "Epoch 6:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=1.6462]\u001b[A\n",
      "Epoch 6:  45%|████▌     | 67/148 [01:01<01:14,  1.09it/s, training_loss=1.6462]\u001b[A\n",
      "Epoch 6:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=1.4228]\u001b[A\n",
      "Epoch 6:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=1.4228]\u001b[A\n",
      "Epoch 6:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=0.8620]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=0.8620]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=0.9797]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 70/148 [01:04<01:12,  1.08it/s, training_loss=0.9797]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 70/148 [01:05<01:12,  1.08it/s, training_loss=0.8367]\u001b[A\n",
      "Epoch 6:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=0.8367]\u001b[A\n",
      "Epoch 6:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.5885]\u001b[A\n",
      "Epoch 6:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=1.5885]\u001b[A\n",
      "Epoch 6:  49%|████▊     | 72/148 [01:07<01:09,  1.09it/s, training_loss=1.0348]\u001b[A\n",
      "Epoch 6:  49%|████▉     | 73/148 [01:07<01:08,  1.09it/s, training_loss=1.0348]\u001b[A\n",
      "Epoch 6:  49%|████▉     | 73/148 [01:08<01:08,  1.09it/s, training_loss=1.2474]\u001b[A\n",
      "Epoch 6:  50%|█████     | 74/148 [01:08<01:07,  1.09it/s, training_loss=1.2474]\u001b[A\n",
      "Epoch 6:  50%|█████     | 74/148 [01:09<01:07,  1.09it/s, training_loss=0.9773]\u001b[A\n",
      "Epoch 6:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=0.9773]\u001b[A\n",
      "Epoch 6:  51%|█████     | 75/148 [01:10<01:06,  1.09it/s, training_loss=1.5538]\u001b[A\n",
      "Epoch 6:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=1.5538]\u001b[A\n",
      "Epoch 6:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=0.8868]\u001b[A\n",
      "Epoch 6:  52%|█████▏    | 77/148 [01:10<01:04,  1.09it/s, training_loss=0.8868]\u001b[A\n",
      "Epoch 6:  52%|█████▏    | 77/148 [01:11<01:04,  1.09it/s, training_loss=1.2688]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 78/148 [01:11<01:03,  1.09it/s, training_loss=1.2688]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 78/148 [01:12<01:03,  1.09it/s, training_loss=1.5261]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 79/148 [01:12<01:03,  1.09it/s, training_loss=1.5261]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 79/148 [01:13<01:03,  1.09it/s, training_loss=1.1565]\u001b[A\n",
      "Epoch 6:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.1565]\u001b[A\n",
      "Epoch 6:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.4952]\u001b[A\n",
      "Epoch 6:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=1.4952]\u001b[A\n",
      "Epoch 6:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=0.9135]\u001b[A\n",
      "Epoch 6:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=0.9135]\u001b[A\n",
      "Epoch 6:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.6151]\u001b[A\n",
      "Epoch 6:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=1.6151]\u001b[A\n",
      "Epoch 6:  56%|█████▌    | 83/148 [01:17<00:59,  1.09it/s, training_loss=1.3246]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=1.3246]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 84/148 [01:18<00:58,  1.09it/s, training_loss=1.5527]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.5527]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 85/148 [01:19<00:57,  1.09it/s, training_loss=1.0300]\u001b[A\n",
      "Epoch 6:  58%|█████▊    | 86/148 [01:19<00:57,  1.08it/s, training_loss=1.0300]\u001b[A\n",
      "Epoch 6:  58%|█████▊    | 86/148 [01:20<00:57,  1.08it/s, training_loss=1.3374]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 87/148 [01:20<00:56,  1.08it/s, training_loss=1.3374]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 87/148 [01:21<00:56,  1.08it/s, training_loss=0.9156]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=0.9156]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 88/148 [01:22<00:55,  1.09it/s, training_loss=1.6013]\u001b[A\n",
      "Epoch 6:  60%|██████    | 89/148 [01:22<00:54,  1.09it/s, training_loss=1.6013]\u001b[A\n",
      "Epoch 6:  60%|██████    | 89/148 [01:22<00:54,  1.09it/s, training_loss=0.9165]\u001b[A\n",
      "Epoch 6:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=0.9165]\u001b[A\n",
      "Epoch 6:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=0.9258]\u001b[A\n",
      "Epoch 6:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=0.9258]\u001b[A\n",
      "Epoch 6:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.0339]\u001b[A\n",
      "Epoch 6:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.0339]\u001b[A\n",
      "Epoch 6:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=0.9550]\u001b[A\n",
      "Epoch 6:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=0.9550]\u001b[A\n",
      "Epoch 6:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=0.9655]\u001b[A\n",
      "Epoch 6:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=0.9655]\u001b[A\n",
      "Epoch 6:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.1270]\u001b[A\n",
      "Epoch 6:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.1270]\u001b[A\n",
      "Epoch 6:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=0.8966]\u001b[A\n",
      "Epoch 6:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=0.8966]\u001b[A\n",
      "Epoch 6:  65%|██████▍   | 96/148 [01:29<00:47,  1.09it/s, training_loss=1.4264]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.4264]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 97/148 [01:30<00:46,  1.09it/s, training_loss=0.8812]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 98/148 [01:30<00:46,  1.09it/s, training_loss=0.8812]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 98/148 [01:31<00:46,  1.09it/s, training_loss=1.5548]\u001b[A\n",
      "Epoch 6:  67%|██████▋   | 99/148 [01:31<00:45,  1.09it/s, training_loss=1.5548]\u001b[A\n",
      "Epoch 6:  67%|██████▋   | 99/148 [01:32<00:45,  1.09it/s, training_loss=0.9808]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 100/148 [01:32<00:44,  1.09it/s, training_loss=0.9808]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 100/148 [01:33<00:44,  1.09it/s, training_loss=1.5375]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.5375]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.6201]\u001b[A\n",
      "Epoch 6:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.6201]\u001b[A\n",
      "Epoch 6:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=0.9469]\u001b[A\n",
      "Epoch 6:  70%|██████▉   | 103/148 [01:34<00:41,  1.09it/s, training_loss=0.9469]\u001b[A\n",
      "Epoch 6:  70%|██████▉   | 103/148 [01:35<00:41,  1.09it/s, training_loss=0.9819]\u001b[A\n",
      "Epoch 6:  70%|███████   | 104/148 [01:35<00:40,  1.09it/s, training_loss=0.9819]\u001b[A\n",
      "Epoch 6:  70%|███████   | 104/148 [01:36<00:40,  1.09it/s, training_loss=1.6037]\u001b[A\n",
      "Epoch 6:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=1.6037]\u001b[A\n",
      "Epoch 6:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.6168]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.6168]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=0.9275]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=0.9275]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 107/148 [01:39<00:37,  1.09it/s, training_loss=0.9396]\u001b[A\n",
      "Epoch 6:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=0.9396]\u001b[A\n",
      "Epoch 6:  73%|███████▎  | 108/148 [01:40<00:36,  1.09it/s, training_loss=1.5633]\u001b[A\n",
      "Epoch 6:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.5633]\u001b[A\n",
      "Epoch 6:  74%|███████▎  | 109/148 [01:41<00:35,  1.09it/s, training_loss=1.3483]\u001b[A\n",
      "Epoch 6:  74%|███████▍  | 110/148 [01:41<00:35,  1.09it/s, training_loss=1.3483]\u001b[A\n",
      "Epoch 6:  74%|███████▍  | 110/148 [01:42<00:35,  1.09it/s, training_loss=1.2347]\u001b[A\n",
      "Epoch 6:  75%|███████▌  | 111/148 [01:42<00:34,  1.08it/s, training_loss=1.2347]\u001b[A\n",
      "Epoch 6:  75%|███████▌  | 111/148 [01:43<00:34,  1.08it/s, training_loss=1.5537]\u001b[A\n",
      "Epoch 6:  76%|███████▌  | 112/148 [01:43<00:33,  1.08it/s, training_loss=1.5537]\u001b[A\n",
      "Epoch 6:  76%|███████▌  | 112/148 [01:44<00:33,  1.08it/s, training_loss=1.6182]\u001b[A\n",
      "Epoch 6:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.6182]\u001b[A\n",
      "Epoch 6:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.2272]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 114/148 [01:44<00:31,  1.08it/s, training_loss=1.2272]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 114/148 [01:45<00:31,  1.08it/s, training_loss=1.1183]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 115/148 [01:45<00:30,  1.08it/s, training_loss=1.1183]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 115/148 [01:46<00:30,  1.08it/s, training_loss=0.8732]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 116/148 [01:46<00:29,  1.08it/s, training_loss=0.8732]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 116/148 [01:47<00:29,  1.08it/s, training_loss=0.9297]\u001b[A\n",
      "Epoch 6:  79%|███████▉  | 117/148 [01:47<00:28,  1.08it/s, training_loss=0.9297]\u001b[A\n",
      "Epoch 6:  79%|███████▉  | 117/148 [01:48<00:28,  1.08it/s, training_loss=1.1424]\u001b[A\n",
      "Epoch 6:  80%|███████▉  | 118/148 [01:48<00:27,  1.08it/s, training_loss=1.1424]\u001b[A\n",
      "Epoch 6:  80%|███████▉  | 118/148 [01:49<00:27,  1.08it/s, training_loss=1.5896]\u001b[A\n",
      "Epoch 6:  80%|████████  | 119/148 [01:49<00:26,  1.08it/s, training_loss=1.5896]\u001b[A\n",
      "Epoch 6:  80%|████████  | 119/148 [01:50<00:26,  1.08it/s, training_loss=1.4596]\u001b[A\n",
      "Epoch 6:  81%|████████  | 120/148 [01:50<00:25,  1.08it/s, training_loss=1.4596]\u001b[A\n",
      "Epoch 6:  81%|████████  | 120/148 [01:51<00:25,  1.08it/s, training_loss=1.0439]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 121/148 [01:51<00:25,  1.08it/s, training_loss=1.0439]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 121/148 [01:52<00:25,  1.08it/s, training_loss=1.4978]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 122/148 [01:52<00:24,  1.08it/s, training_loss=1.4978]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 122/148 [01:53<00:24,  1.08it/s, training_loss=1.5530]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 123/148 [01:53<00:23,  1.08it/s, training_loss=1.5530]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 123/148 [01:54<00:23,  1.08it/s, training_loss=1.0249]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 124/148 [01:54<00:22,  1.08it/s, training_loss=1.0249]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 124/148 [01:55<00:22,  1.08it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 125/148 [01:55<00:21,  1.08it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 125/148 [01:56<00:21,  1.08it/s, training_loss=1.1360]\u001b[A\n",
      "Epoch 6:  85%|████████▌ | 126/148 [01:56<00:20,  1.08it/s, training_loss=1.1360]\u001b[A\n",
      "Epoch 6:  85%|████████▌ | 126/148 [01:57<00:20,  1.08it/s, training_loss=0.8915]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 127/148 [01:57<00:19,  1.08it/s, training_loss=0.8915]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 127/148 [01:57<00:19,  1.08it/s, training_loss=1.5801]\u001b[A\n",
      "Epoch 6:  86%|████████▋ | 128/148 [01:57<00:18,  1.08it/s, training_loss=1.5801]\u001b[A\n",
      "Epoch 6:  86%|████████▋ | 128/148 [01:58<00:18,  1.08it/s, training_loss=1.0266]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 129/148 [01:58<00:17,  1.08it/s, training_loss=1.0266]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 129/148 [01:59<00:17,  1.08it/s, training_loss=1.1383]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 130/148 [01:59<00:16,  1.08it/s, training_loss=1.1383]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 130/148 [02:00<00:16,  1.08it/s, training_loss=1.1571]\u001b[A\n",
      "Epoch 6:  89%|████████▊ | 131/148 [02:00<00:15,  1.08it/s, training_loss=1.1571]\u001b[A\n",
      "Epoch 6:  89%|████████▊ | 131/148 [02:01<00:15,  1.08it/s, training_loss=0.8373]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 132/148 [02:01<00:14,  1.08it/s, training_loss=0.8373]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 132/148 [02:02<00:14,  1.08it/s, training_loss=0.9590]\u001b[A\n",
      "Epoch 6:  90%|████████▉ | 133/148 [02:02<00:13,  1.08it/s, training_loss=0.9590]\u001b[A\n",
      "Epoch 6:  90%|████████▉ | 133/148 [02:03<00:13,  1.08it/s, training_loss=1.5680]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 134/148 [02:03<00:12,  1.08it/s, training_loss=1.5680]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 134/148 [02:04<00:12,  1.08it/s, training_loss=1.5338]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 135/148 [02:04<00:12,  1.08it/s, training_loss=1.5338]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 135/148 [02:05<00:12,  1.08it/s, training_loss=1.4829]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 136/148 [02:05<00:11,  1.08it/s, training_loss=1.4829]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 136/148 [02:06<00:11,  1.08it/s, training_loss=1.0821]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 137/148 [02:06<00:10,  1.08it/s, training_loss=1.0821]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 137/148 [02:07<00:10,  1.08it/s, training_loss=1.5934]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 138/148 [02:07<00:09,  1.08it/s, training_loss=1.5934]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 138/148 [02:08<00:09,  1.08it/s, training_loss=1.5796]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.5796]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 139/148 [02:09<00:08,  1.09it/s, training_loss=0.8321]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 140/148 [02:09<00:07,  1.08it/s, training_loss=0.8321]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 140/148 [02:09<00:07,  1.08it/s, training_loss=1.1170]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 141/148 [02:09<00:06,  1.08it/s, training_loss=1.1170]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 141/148 [02:10<00:06,  1.08it/s, training_loss=0.9340]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 142/148 [02:10<00:05,  1.08it/s, training_loss=0.9340]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 142/148 [02:11<00:05,  1.08it/s, training_loss=0.9998]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 143/148 [02:11<00:04,  1.08it/s, training_loss=0.9998]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 143/148 [02:12<00:04,  1.08it/s, training_loss=1.6109]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 144/148 [02:12<00:03,  1.08it/s, training_loss=1.6109]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 144/148 [02:13<00:03,  1.08it/s, training_loss=1.5734]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 145/148 [02:13<00:02,  1.08it/s, training_loss=1.5734]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 145/148 [02:14<00:02,  1.08it/s, training_loss=1.5889]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 146/148 [02:14<00:01,  1.08it/s, training_loss=1.5889]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 146/148 [02:15<00:01,  1.08it/s, training_loss=1.1391]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 147/148 [02:15<00:00,  1.08it/s, training_loss=1.1391]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 147/148 [02:16<00:00,  1.08it/s, training_loss=0.9290]\u001b[A\n",
      "Epoch 6: 100%|██████████| 148/148 [02:16<00:00,  1.17it/s, training_loss=0.9290]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:02:36,326 - INFO - Starting model evaluation...\n",
      "2025-02-19 11:02:36,327 - INFO - Memory usage after evaluation start: 4013.16 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=66.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.61it/s, Accuracy=66.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.61it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.59it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.59it/s, Accuracy=72.67%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.57it/s, Accuracy=72.67%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.57it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.55it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.55it/s, Accuracy=72.40%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.56it/s, Accuracy=72.40%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.56it/s, Accuracy=73.33%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.57it/s, Accuracy=73.33%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.57it/s, Accuracy=71.14%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.57it/s, Accuracy=71.14%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.57it/s, Accuracy=69.50%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.57it/s, Accuracy=69.50%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.57it/s, Accuracy=69.11%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.55it/s, Accuracy=69.11%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.55it/s, Accuracy=69.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.55it/s, Accuracy=69.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.55it/s, Accuracy=69.64%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.54it/s, Accuracy=69.64%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.54it/s, Accuracy=70.17%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.54it/s, Accuracy=70.17%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.54it/s, Accuracy=69.38%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.54it/s, Accuracy=69.38%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.54it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.54it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.54it/s, Accuracy=69.73%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.54it/s, Accuracy=69.73%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.54it/s, Accuracy=68.88%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.54it/s, Accuracy=68.88%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.54it/s, Accuracy=68.47%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.54it/s, Accuracy=68.47%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:02,  3.54it/s, Accuracy=69.11%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.54it/s, Accuracy=69.11%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.54it/s, Accuracy=69.26%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.53it/s, Accuracy=69.26%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.53it/s, Accuracy=69.50%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.54it/s, Accuracy=69.50%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.54it/s, Accuracy=69.71%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.54it/s, Accuracy=69.71%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.54it/s, Accuracy=69.64%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.54it/s, Accuracy=69.64%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.54it/s, Accuracy=70.09%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.54it/s, Accuracy=70.09%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.54it/s, Accuracy=69.50%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.55it/s, Accuracy=69.50%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:07<00:00,  3.55it/s, Accuracy=69.60%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.53it/s, Accuracy=69.60%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.53it/s, Accuracy=69.69%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.53it/s, Accuracy=69.69%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.66it/s, Accuracy=69.73%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:02:43,705 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 11:02:43,710 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 11:02:43,711 - INFO - Accuracy: 0.6398\n",
      "2025-02-19 11:02:43,712 - INFO - F1_score: 0.5392\n",
      "2025-02-19 11:02:43,712 - INFO - Precision: 0.4231\n",
      "2025-02-19 11:02:43,713 - INFO - Recall: 0.7432\n",
      "2025-02-19 11:02:43,719 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 11:02:43,720 - INFO - Accuracy: 0.8008\n",
      "2025-02-19 11:02:43,721 - INFO - F1_score: 0.6709\n",
      "2025-02-19 11:02:43,722 - INFO - Precision: 0.5248\n",
      "2025-02-19 11:02:43,722 - INFO - Recall: 0.9298\n",
      "2025-02-19 11:02:43,729 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 11:02:43,729 - INFO - Accuracy: 0.6667\n",
      "2025-02-19 11:02:43,730 - INFO - F1_score: 0.5029\n",
      "2025-02-19 11:02:43,732 - INFO - Precision: 0.3761\n",
      "2025-02-19 11:02:43,732 - INFO - Recall: 0.7586\n",
      "2025-02-19 11:02:43,738 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 11:02:43,739 - INFO - Accuracy: 0.5824\n",
      "2025-02-19 11:02:43,739 - INFO - F1_score: 0.3145\n",
      "2025-02-19 11:02:43,741 - INFO - Precision: 0.2066\n",
      "2025-02-19 11:02:43,742 - INFO - Recall: 0.6579\n",
      "2025-02-19 11:02:43,747 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 11:02:43,748 - INFO - Accuracy: 0.7969\n",
      "2025-02-19 11:02:43,749 - INFO - F1_score: 0.4536\n",
      "2025-02-19 11:02:43,749 - INFO - Precision: 0.3492\n",
      "2025-02-19 11:02:43,751 - INFO - Recall: 0.6471\n",
      "2025-02-19 11:02:43,753 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:02:47,629 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 11:02:47,630 - INFO - Memory usage after evaluation end: 4018.41 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   5%|▌         | 5/100 [15:32<4:06:29, 155.68s/it, Train Loss=1.2832, Val Loss=0.0506, Accuracy=0.6973]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:02:54,905 - INFO - New best accuracy: 0.6973\n",
      "2025-02-19 11:02:55,960 - INFO - Learning rate: 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 6/100 [15:33<4:03:59, 155.74s/it, Train Loss=1.2832, Val Loss=0.0506, Accuracy=0.6973]\n",
      "Epoch 7:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=0.8773]\u001b[A\n",
      "Epoch 7:   1%|          | 1/148 [00:00<02:13,  1.10it/s, training_loss=0.8773]\u001b[A\n",
      "Epoch 7:   1%|          | 1/148 [00:01<02:13,  1.10it/s, training_loss=1.5267]\u001b[A\n",
      "Epoch 7:   1%|▏         | 2/148 [00:01<02:13,  1.10it/s, training_loss=1.5267]\u001b[A\n",
      "Epoch 7:   1%|▏         | 2/148 [00:02<02:13,  1.10it/s, training_loss=1.0047]\u001b[A\n",
      "Epoch 7:   2%|▏         | 3/148 [00:02<02:12,  1.09it/s, training_loss=1.0047]\u001b[A\n",
      "Epoch 7:   2%|▏         | 3/148 [00:03<02:12,  1.09it/s, training_loss=1.0603]\u001b[A\n",
      "Epoch 7:   3%|▎         | 4/148 [00:03<02:11,  1.09it/s, training_loss=1.0603]\u001b[A\n",
      "Epoch 7:   3%|▎         | 4/148 [00:04<02:11,  1.09it/s, training_loss=0.9727]\u001b[A\n",
      "Epoch 7:   3%|▎         | 5/148 [00:04<02:11,  1.09it/s, training_loss=0.9727]\u001b[A\n",
      "Epoch 7:   3%|▎         | 5/148 [00:05<02:11,  1.09it/s, training_loss=1.3344]\u001b[A\n",
      "Epoch 7:   4%|▍         | 6/148 [00:05<02:10,  1.09it/s, training_loss=1.3344]\u001b[A\n",
      "Epoch 7:   4%|▍         | 6/148 [00:06<02:10,  1.09it/s, training_loss=0.8589]\u001b[A\n",
      "Epoch 7:   5%|▍         | 7/148 [00:06<02:10,  1.08it/s, training_loss=0.8589]\u001b[A\n",
      "Epoch 7:   5%|▍         | 7/148 [00:07<02:10,  1.08it/s, training_loss=1.6061]\u001b[A\n",
      "Epoch 7:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=1.6061]\u001b[A\n",
      "Epoch 7:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=1.4834]\u001b[A\n",
      "Epoch 7:   6%|▌         | 9/148 [00:08<02:07,  1.09it/s, training_loss=1.4834]\u001b[A\n",
      "Epoch 7:   6%|▌         | 9/148 [00:09<02:07,  1.09it/s, training_loss=0.9584]\u001b[A\n",
      "Epoch 7:   7%|▋         | 10/148 [00:09<02:07,  1.09it/s, training_loss=0.9584]\u001b[A\n",
      "Epoch 7:   7%|▋         | 10/148 [00:10<02:07,  1.09it/s, training_loss=1.0408]\u001b[A\n",
      "Epoch 7:   7%|▋         | 11/148 [00:10<02:06,  1.08it/s, training_loss=1.0408]\u001b[A\n",
      "Epoch 7:   7%|▋         | 11/148 [00:11<02:06,  1.08it/s, training_loss=1.5943]\u001b[A\n",
      "Epoch 7:   8%|▊         | 12/148 [00:11<02:05,  1.09it/s, training_loss=1.5943]\u001b[A\n",
      "Epoch 7:   8%|▊         | 12/148 [00:11<02:05,  1.09it/s, training_loss=1.1189]\u001b[A\n",
      "Epoch 7:   9%|▉         | 13/148 [00:11<02:04,  1.08it/s, training_loss=1.1189]\u001b[A\n",
      "Epoch 7:   9%|▉         | 13/148 [00:12<02:04,  1.08it/s, training_loss=0.9566]\u001b[A\n",
      "Epoch 7:   9%|▉         | 14/148 [00:12<02:04,  1.08it/s, training_loss=0.9566]\u001b[A\n",
      "Epoch 7:   9%|▉         | 14/148 [00:13<02:04,  1.08it/s, training_loss=1.1192]\u001b[A\n",
      "Epoch 7:  10%|█         | 15/148 [00:13<02:03,  1.08it/s, training_loss=1.1192]\u001b[A\n",
      "Epoch 7:  10%|█         | 15/148 [00:14<02:03,  1.08it/s, training_loss=1.1482]\u001b[A\n",
      "Epoch 7:  11%|█         | 16/148 [00:14<02:02,  1.08it/s, training_loss=1.1482]\u001b[A\n",
      "Epoch 7:  11%|█         | 16/148 [00:15<02:02,  1.08it/s, training_loss=1.5717]\u001b[A\n",
      "Epoch 7:  11%|█▏        | 17/148 [00:15<02:01,  1.08it/s, training_loss=1.5717]\u001b[A\n",
      "Epoch 7:  11%|█▏        | 17/148 [00:16<02:01,  1.08it/s, training_loss=1.1889]\u001b[A\n",
      "Epoch 7:  12%|█▏        | 18/148 [00:16<02:01,  1.07it/s, training_loss=1.1889]\u001b[A\n",
      "Epoch 7:  12%|█▏        | 18/148 [00:17<02:01,  1.07it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 7:  13%|█▎        | 19/148 [00:17<02:00,  1.07it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 7:  13%|█▎        | 19/148 [00:18<02:00,  1.07it/s, training_loss=1.5098]\u001b[A\n",
      "Epoch 7:  14%|█▎        | 20/148 [00:18<01:58,  1.08it/s, training_loss=1.5098]\u001b[A\n",
      "Epoch 7:  14%|█▎        | 20/148 [00:19<01:58,  1.08it/s, training_loss=1.0860]\u001b[A\n",
      "Epoch 7:  14%|█▍        | 21/148 [00:19<01:58,  1.07it/s, training_loss=1.0860]\u001b[A\n",
      "Epoch 7:  14%|█▍        | 21/148 [00:20<01:58,  1.07it/s, training_loss=0.9247]\u001b[A\n",
      "Epoch 7:  15%|█▍        | 22/148 [00:20<01:57,  1.07it/s, training_loss=0.9247]\u001b[A\n",
      "Epoch 7:  15%|█▍        | 22/148 [00:21<01:57,  1.07it/s, training_loss=1.5797]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 23/148 [00:21<01:56,  1.07it/s, training_loss=1.5797]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 23/148 [00:22<01:56,  1.07it/s, training_loss=0.9980]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 24/148 [00:22<01:55,  1.07it/s, training_loss=0.9980]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 24/148 [00:23<01:55,  1.07it/s, training_loss=1.0278]\u001b[A\n",
      "Epoch 7:  17%|█▋        | 25/148 [00:23<01:54,  1.07it/s, training_loss=1.0278]\u001b[A\n",
      "Epoch 7:  17%|█▋        | 25/148 [00:24<01:54,  1.07it/s, training_loss=0.9161]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 26/148 [00:24<01:53,  1.08it/s, training_loss=0.9161]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 26/148 [00:25<01:53,  1.08it/s, training_loss=1.3678]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 27/148 [00:25<01:52,  1.08it/s, training_loss=1.3678]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 27/148 [00:25<01:52,  1.08it/s, training_loss=0.9466]\u001b[A\n",
      "Epoch 7:  19%|█▉        | 28/148 [00:25<01:51,  1.08it/s, training_loss=0.9466]\u001b[A\n",
      "Epoch 7:  19%|█▉        | 28/148 [00:26<01:51,  1.08it/s, training_loss=1.6683]\u001b[A\n",
      "Epoch 7:  20%|█▉        | 29/148 [00:26<01:50,  1.08it/s, training_loss=1.6683]\u001b[A\n",
      "Epoch 7:  20%|█▉        | 29/148 [00:27<01:50,  1.08it/s, training_loss=1.5849]\u001b[A\n",
      "Epoch 7:  20%|██        | 30/148 [00:27<01:48,  1.08it/s, training_loss=1.5849]\u001b[A\n",
      "Epoch 7:  20%|██        | 30/148 [00:28<01:48,  1.08it/s, training_loss=0.9321]\u001b[A\n",
      "Epoch 7:  21%|██        | 31/148 [00:28<01:47,  1.08it/s, training_loss=0.9321]\u001b[A\n",
      "Epoch 7:  21%|██        | 31/148 [00:29<01:47,  1.08it/s, training_loss=1.5952]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 32/148 [00:29<01:46,  1.09it/s, training_loss=1.5952]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 32/148 [00:30<01:46,  1.09it/s, training_loss=1.5276]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 33/148 [00:30<01:45,  1.09it/s, training_loss=1.5276]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 33/148 [00:31<01:45,  1.09it/s, training_loss=1.1531]\u001b[A\n",
      "Epoch 7:  23%|██▎       | 34/148 [00:31<01:44,  1.09it/s, training_loss=1.1531]\u001b[A\n",
      "Epoch 7:  23%|██▎       | 34/148 [00:32<01:44,  1.09it/s, training_loss=1.5882]\u001b[A\n",
      "Epoch 7:  24%|██▎       | 35/148 [00:32<01:43,  1.09it/s, training_loss=1.5882]\u001b[A\n",
      "Epoch 7:  24%|██▎       | 35/148 [00:33<01:43,  1.09it/s, training_loss=1.0191]\u001b[A\n",
      "Epoch 7:  24%|██▍       | 36/148 [00:33<01:43,  1.08it/s, training_loss=1.0191]\u001b[A\n",
      "Epoch 7:  24%|██▍       | 36/148 [00:34<01:43,  1.08it/s, training_loss=0.8541]\u001b[A\n",
      "Epoch 7:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=0.8541]\u001b[A\n",
      "Epoch 7:  25%|██▌       | 37/148 [00:35<01:42,  1.08it/s, training_loss=0.8592]\u001b[A\n",
      "Epoch 7:  26%|██▌       | 38/148 [00:35<01:41,  1.08it/s, training_loss=0.8592]\u001b[A\n",
      "Epoch 7:  26%|██▌       | 38/148 [00:36<01:41,  1.08it/s, training_loss=1.5973]\u001b[A\n",
      "Epoch 7:  26%|██▋       | 39/148 [00:36<01:40,  1.08it/s, training_loss=1.5973]\u001b[A\n",
      "Epoch 7:  26%|██▋       | 39/148 [00:36<01:40,  1.08it/s, training_loss=0.9887]\u001b[A\n",
      "Epoch 7:  27%|██▋       | 40/148 [00:36<01:39,  1.09it/s, training_loss=0.9887]\u001b[A\n",
      "Epoch 7:  27%|██▋       | 40/148 [00:37<01:39,  1.09it/s, training_loss=1.5327]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=1.5327]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=0.9690]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=0.9690]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=1.3970]\u001b[A\n",
      "Epoch 7:  29%|██▉       | 43/148 [00:39<01:36,  1.09it/s, training_loss=1.3970]\u001b[A\n",
      "Epoch 7:  29%|██▉       | 43/148 [00:40<01:36,  1.09it/s, training_loss=1.1550]\u001b[A\n",
      "Epoch 7:  30%|██▉       | 44/148 [00:40<01:35,  1.09it/s, training_loss=1.1550]\u001b[A\n",
      "Epoch 7:  30%|██▉       | 44/148 [00:41<01:35,  1.09it/s, training_loss=1.5335]\u001b[A\n",
      "Epoch 7:  30%|███       | 45/148 [00:41<01:33,  1.10it/s, training_loss=1.5335]\u001b[A\n",
      "Epoch 7:  30%|███       | 45/148 [00:42<01:33,  1.10it/s, training_loss=1.1798]\u001b[A\n",
      "Epoch 7:  31%|███       | 46/148 [00:42<01:33,  1.10it/s, training_loss=1.1798]\u001b[A\n",
      "Epoch 7:  31%|███       | 46/148 [00:43<01:33,  1.10it/s, training_loss=1.3664]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.3664]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.6461]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 48/148 [00:44<01:31,  1.09it/s, training_loss=1.6461]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 48/148 [00:45<01:31,  1.09it/s, training_loss=0.9527]\u001b[A\n",
      "Epoch 7:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=0.9527]\u001b[A\n",
      "Epoch 7:  33%|███▎      | 49/148 [00:46<01:30,  1.09it/s, training_loss=1.0886]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 50/148 [00:46<01:30,  1.09it/s, training_loss=1.0886]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 50/148 [00:47<01:30,  1.09it/s, training_loss=1.0647]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 51/148 [00:47<01:29,  1.08it/s, training_loss=1.0647]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 51/148 [00:47<01:29,  1.08it/s, training_loss=1.5606]\u001b[A\n",
      "Epoch 7:  35%|███▌      | 52/148 [00:47<01:28,  1.09it/s, training_loss=1.5606]\u001b[A\n",
      "Epoch 7:  35%|███▌      | 52/148 [00:48<01:28,  1.09it/s, training_loss=0.9430]\u001b[A\n",
      "Epoch 7:  36%|███▌      | 53/148 [00:48<01:27,  1.08it/s, training_loss=0.9430]\u001b[A\n",
      "Epoch 7:  36%|███▌      | 53/148 [00:49<01:27,  1.08it/s, training_loss=1.5826]\u001b[A\n",
      "Epoch 7:  36%|███▋      | 54/148 [00:49<01:26,  1.08it/s, training_loss=1.5826]\u001b[A\n",
      "Epoch 7:  36%|███▋      | 54/148 [00:50<01:26,  1.08it/s, training_loss=1.5034]\u001b[A\n",
      "Epoch 7:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.5034]\u001b[A\n",
      "Epoch 7:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.6240]\u001b[A\n",
      "Epoch 7:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=1.6240]\u001b[A\n",
      "Epoch 7:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.6042]\u001b[A\n",
      "Epoch 7:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.6042]\u001b[A\n",
      "Epoch 7:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=1.0539]\u001b[A\n",
      "Epoch 7:  39%|███▉      | 58/148 [00:53<01:22,  1.10it/s, training_loss=1.0539]\u001b[A\n",
      "Epoch 7:  39%|███▉      | 58/148 [00:54<01:22,  1.10it/s, training_loss=0.9437]\u001b[A\n",
      "Epoch 7:  40%|███▉      | 59/148 [00:54<01:21,  1.10it/s, training_loss=0.9437]\u001b[A\n",
      "Epoch 7:  40%|███▉      | 59/148 [00:55<01:21,  1.10it/s, training_loss=1.6684]\u001b[A\n",
      "Epoch 7:  41%|████      | 60/148 [00:55<01:20,  1.10it/s, training_loss=1.6684]\u001b[A\n",
      "Epoch 7:  41%|████      | 60/148 [00:56<01:20,  1.10it/s, training_loss=0.8606]\u001b[A\n",
      "Epoch 7:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=0.8606]\u001b[A\n",
      "Epoch 7:  41%|████      | 61/148 [00:57<01:19,  1.09it/s, training_loss=1.7176]\u001b[A\n",
      "Epoch 7:  42%|████▏     | 62/148 [00:57<01:18,  1.09it/s, training_loss=1.7176]\u001b[A\n",
      "Epoch 7:  42%|████▏     | 62/148 [00:58<01:18,  1.09it/s, training_loss=0.9770]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 63/148 [00:58<01:17,  1.09it/s, training_loss=0.9770]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 63/148 [00:58<01:17,  1.09it/s, training_loss=0.9196]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 64/148 [00:58<01:17,  1.09it/s, training_loss=0.9196]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 64/148 [00:59<01:17,  1.09it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 7:  44%|████▍     | 65/148 [00:59<01:16,  1.09it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 7:  44%|████▍     | 65/148 [01:00<01:16,  1.09it/s, training_loss=0.8594]\u001b[A\n",
      "Epoch 7:  45%|████▍     | 66/148 [01:00<01:15,  1.09it/s, training_loss=0.8594]\u001b[A\n",
      "Epoch 7:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=0.9938]\u001b[A\n",
      "Epoch 7:  45%|████▌     | 67/148 [01:01<01:14,  1.09it/s, training_loss=0.9938]\u001b[A\n",
      "Epoch 7:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=0.9982]\u001b[A\n",
      "Epoch 7:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=0.9982]\u001b[A\n",
      "Epoch 7:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=0.9497]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=0.9497]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=0.8999]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=0.8999]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=1.2472]\u001b[A\n",
      "Epoch 7:  48%|████▊     | 71/148 [01:05<01:11,  1.08it/s, training_loss=1.2472]\u001b[A\n",
      "Epoch 7:  48%|████▊     | 71/148 [01:06<01:11,  1.08it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 7:  49%|████▊     | 72/148 [01:06<01:10,  1.08it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 7:  49%|████▊     | 72/148 [01:07<01:10,  1.08it/s, training_loss=1.6127]\u001b[A\n",
      "Epoch 7:  49%|████▉     | 73/148 [01:07<01:09,  1.08it/s, training_loss=1.6127]\u001b[A\n",
      "Epoch 7:  49%|████▉     | 73/148 [01:08<01:09,  1.08it/s, training_loss=1.0021]\u001b[A\n",
      "Epoch 7:  50%|█████     | 74/148 [01:08<01:08,  1.09it/s, training_loss=1.0021]\u001b[A\n",
      "Epoch 7:  50%|█████     | 74/148 [01:09<01:08,  1.09it/s, training_loss=1.4949]\u001b[A\n",
      "Epoch 7:  51%|█████     | 75/148 [01:09<01:07,  1.09it/s, training_loss=1.4949]\u001b[A\n",
      "Epoch 7:  51%|█████     | 75/148 [01:10<01:07,  1.09it/s, training_loss=1.5017]\u001b[A\n",
      "Epoch 7:  51%|█████▏    | 76/148 [01:10<01:06,  1.08it/s, training_loss=1.5017]\u001b[A\n",
      "Epoch 7:  51%|█████▏    | 76/148 [01:10<01:06,  1.08it/s, training_loss=1.5732]\u001b[A\n",
      "Epoch 7:  52%|█████▏    | 77/148 [01:10<01:05,  1.09it/s, training_loss=1.5732]\u001b[A\n",
      "Epoch 7:  52%|█████▏    | 77/148 [01:11<01:05,  1.09it/s, training_loss=1.5831]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 78/148 [01:11<01:04,  1.09it/s, training_loss=1.5831]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 78/148 [01:12<01:04,  1.09it/s, training_loss=1.5855]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 79/148 [01:12<01:03,  1.09it/s, training_loss=1.5855]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 79/148 [01:13<01:03,  1.09it/s, training_loss=1.3250]\u001b[A\n",
      "Epoch 7:  54%|█████▍    | 80/148 [01:13<01:02,  1.08it/s, training_loss=1.3250]\u001b[A\n",
      "Epoch 7:  54%|█████▍    | 80/148 [01:14<01:02,  1.08it/s, training_loss=1.4751]\u001b[A\n",
      "Epoch 7:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=1.4751]\u001b[A\n",
      "Epoch 7:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=1.4830]\u001b[A\n",
      "Epoch 7:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.4830]\u001b[A\n",
      "Epoch 7:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=0.9344]\u001b[A\n",
      "Epoch 7:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=0.9344]\u001b[A\n",
      "Epoch 7:  56%|█████▌    | 83/148 [01:17<00:59,  1.09it/s, training_loss=1.5416]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=1.5416]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 84/148 [01:18<00:58,  1.09it/s, training_loss=1.6608]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.6608]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 85/148 [01:19<00:57,  1.09it/s, training_loss=1.6476]\u001b[A\n",
      "Epoch 7:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.6476]\u001b[A\n",
      "Epoch 7:  58%|█████▊    | 86/148 [01:20<00:56,  1.09it/s, training_loss=0.9750]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 87/148 [01:20<00:56,  1.09it/s, training_loss=0.9750]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 87/148 [01:21<00:56,  1.09it/s, training_loss=1.6199]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.6199]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.5833]\u001b[A\n",
      "Epoch 7:  60%|██████    | 89/148 [01:21<00:54,  1.09it/s, training_loss=1.5833]\u001b[A\n",
      "Epoch 7:  60%|██████    | 89/148 [01:22<00:54,  1.09it/s, training_loss=0.9963]\u001b[A\n",
      "Epoch 7:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=0.9963]\u001b[A\n",
      "Epoch 7:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=0.9751]\u001b[A\n",
      "Epoch 7:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=0.9751]\u001b[A\n",
      "Epoch 7:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.0772]\u001b[A\n",
      "Epoch 7:  62%|██████▏   | 92/148 [01:24<00:51,  1.08it/s, training_loss=1.0772]\u001b[A\n",
      "Epoch 7:  62%|██████▏   | 92/148 [01:25<00:51,  1.08it/s, training_loss=1.1932]\u001b[A\n",
      "Epoch 7:  63%|██████▎   | 93/148 [01:25<00:50,  1.08it/s, training_loss=1.1932]\u001b[A\n",
      "Epoch 7:  63%|██████▎   | 93/148 [01:26<00:50,  1.08it/s, training_loss=1.5837]\u001b[A\n",
      "Epoch 7:  64%|██████▎   | 94/148 [01:26<00:49,  1.08it/s, training_loss=1.5837]\u001b[A\n",
      "Epoch 7:  64%|██████▎   | 94/148 [01:27<00:49,  1.08it/s, training_loss=1.2050]\u001b[A\n",
      "Epoch 7:  64%|██████▍   | 95/148 [01:27<00:48,  1.08it/s, training_loss=1.2050]\u001b[A\n",
      "Epoch 7:  64%|██████▍   | 95/148 [01:28<00:48,  1.08it/s, training_loss=0.8723]\u001b[A\n",
      "Epoch 7:  65%|██████▍   | 96/148 [01:28<00:48,  1.08it/s, training_loss=0.8723]\u001b[A\n",
      "Epoch 7:  65%|██████▍   | 96/148 [01:29<00:48,  1.08it/s, training_loss=1.5410]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 97/148 [01:29<00:47,  1.08it/s, training_loss=1.5410]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 97/148 [01:30<00:47,  1.08it/s, training_loss=1.2188]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 98/148 [01:30<00:46,  1.08it/s, training_loss=1.2188]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 98/148 [01:31<00:46,  1.08it/s, training_loss=1.5901]\u001b[A\n",
      "Epoch 7:  67%|██████▋   | 99/148 [01:31<00:45,  1.09it/s, training_loss=1.5901]\u001b[A\n",
      "Epoch 7:  67%|██████▋   | 99/148 [01:32<00:45,  1.09it/s, training_loss=0.8713]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 100/148 [01:32<00:44,  1.08it/s, training_loss=0.8713]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 100/148 [01:33<00:44,  1.08it/s, training_loss=1.5509]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.5509]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.5716]\u001b[A\n",
      "Epoch 7:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.5716]\u001b[A\n",
      "Epoch 7:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=1.0216]\u001b[A\n",
      "Epoch 7:  70%|██████▉   | 103/148 [01:34<00:41,  1.10it/s, training_loss=1.0216]\u001b[A\n",
      "Epoch 7:  70%|██████▉   | 103/148 [01:35<00:41,  1.10it/s, training_loss=1.4861]\u001b[A\n",
      "Epoch 7:  70%|███████   | 104/148 [01:35<00:40,  1.10it/s, training_loss=1.4861]\u001b[A\n",
      "Epoch 7:  70%|███████   | 104/148 [01:36<00:40,  1.10it/s, training_loss=1.1561]\u001b[A\n",
      "Epoch 7:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=1.1561]\u001b[A\n",
      "Epoch 7:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.6041]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.6041]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=0.9624]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=0.9624]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 107/148 [01:39<00:37,  1.09it/s, training_loss=1.5663]\u001b[A\n",
      "Epoch 7:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=1.5663]\u001b[A\n",
      "Epoch 7:  73%|███████▎  | 108/148 [01:40<00:36,  1.09it/s, training_loss=1.0266]\u001b[A\n",
      "Epoch 7:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.0266]\u001b[A\n",
      "Epoch 7:  74%|███████▎  | 109/148 [01:41<00:35,  1.09it/s, training_loss=1.6108]\u001b[A\n",
      "Epoch 7:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.6108]\u001b[A\n",
      "Epoch 7:  74%|███████▍  | 110/148 [01:42<00:34,  1.09it/s, training_loss=1.0566]\u001b[A\n",
      "Epoch 7:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=1.0566]\u001b[A\n",
      "Epoch 7:  75%|███████▌  | 111/148 [01:43<00:33,  1.09it/s, training_loss=1.1169]\u001b[A\n",
      "Epoch 7:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.1169]\u001b[A\n",
      "Epoch 7:  76%|███████▌  | 112/148 [01:44<00:33,  1.09it/s, training_loss=1.5771]\u001b[A\n",
      "Epoch 7:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.5771]\u001b[A\n",
      "Epoch 7:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.4605]\u001b[A\n",
      "Epoch 7:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.4605]\u001b[A\n",
      "Epoch 7:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.0345]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.0345]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=1.0397]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.0397]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=1.5529]\u001b[A\n",
      "Epoch 7:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.5529]\u001b[A\n",
      "Epoch 7:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=0.9779]\u001b[A\n",
      "Epoch 7:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=0.9779]\u001b[A\n",
      "Epoch 7:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.5582]\u001b[A\n",
      "Epoch 7:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.5582]\u001b[A\n",
      "Epoch 7:  80%|████████  | 119/148 [01:50<00:26,  1.09it/s, training_loss=0.9640]\u001b[A\n",
      "Epoch 7:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=0.9640]\u001b[A\n",
      "Epoch 7:  81%|████████  | 120/148 [01:51<00:25,  1.09it/s, training_loss=1.4580]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.4580]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 121/148 [01:52<00:24,  1.09it/s, training_loss=1.6077]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.6077]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 122/148 [01:53<00:23,  1.09it/s, training_loss=0.9092]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=0.9092]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 123/148 [01:54<00:22,  1.09it/s, training_loss=1.5357]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 124/148 [01:54<00:21,  1.10it/s, training_loss=1.5357]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 124/148 [01:54<00:21,  1.10it/s, training_loss=1.5583]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 125/148 [01:54<00:20,  1.10it/s, training_loss=1.5583]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 125/148 [01:55<00:20,  1.10it/s, training_loss=1.3519]\u001b[A\n",
      "Epoch 7:  85%|████████▌ | 126/148 [01:55<00:20,  1.10it/s, training_loss=1.3519]\u001b[A\n",
      "Epoch 7:  85%|████████▌ | 126/148 [01:56<00:20,  1.10it/s, training_loss=0.8912]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=0.8912]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.1023]\u001b[A\n",
      "Epoch 7:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.1023]\u001b[A\n",
      "Epoch 7:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.0944]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.0944]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=0.8961]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=0.8961]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=1.6342]\u001b[A\n",
      "Epoch 7:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.6342]\u001b[A\n",
      "Epoch 7:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=1.5831]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.5831]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 132/148 [02:02<00:14,  1.09it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 133/148 [02:03<00:13,  1.09it/s, training_loss=0.8946]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=0.8946]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 134/148 [02:04<00:12,  1.09it/s, training_loss=1.1904]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=1.1904]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 135/148 [02:05<00:11,  1.09it/s, training_loss=0.8817]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=0.8817]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.6489]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=1.6489]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.3519]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.3519]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.5606]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.5606]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.6021]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=1.6021]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=1.5287]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 141/148 [02:09<00:06,  1.10it/s, training_loss=1.5287]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 141/148 [02:10<00:06,  1.10it/s, training_loss=0.9043]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=0.9043]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 142/148 [02:11<00:05,  1.09it/s, training_loss=1.5880]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.5880]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=1.5993]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 144/148 [02:12<00:03,  1.10it/s, training_loss=1.5993]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 144/148 [02:13<00:03,  1.10it/s, training_loss=1.5333]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 145/148 [02:13<00:02,  1.10it/s, training_loss=1.5333]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 145/148 [02:14<00:02,  1.10it/s, training_loss=0.9291]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 146/148 [02:14<00:01,  1.10it/s, training_loss=0.9291]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 146/148 [02:15<00:01,  1.10it/s, training_loss=1.5201]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 147/148 [02:15<00:00,  1.10it/s, training_loss=1.5201]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 147/148 [02:15<00:00,  1.10it/s, training_loss=1.4656]\u001b[A\n",
      "Epoch 7: 100%|██████████| 148/148 [02:15<00:00,  1.19it/s, training_loss=1.4656]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:05:11,743 - INFO - Starting model evaluation...\n",
      "2025-02-19 11:05:11,744 - INFO - Memory usage after evaluation start: 4023.28 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.67it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.67it/s, Accuracy=74.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.62it/s, Accuracy=74.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.62it/s, Accuracy=72.67%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.61it/s, Accuracy=72.67%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.61it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.61it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.61it/s, Accuracy=72.80%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.61it/s, Accuracy=72.80%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.61it/s, Accuracy=73.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.61it/s, Accuracy=73.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.61it/s, Accuracy=72.29%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.61it/s, Accuracy=72.29%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.61it/s, Accuracy=71.50%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.61it/s, Accuracy=71.50%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.61it/s, Accuracy=71.11%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.60it/s, Accuracy=71.11%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.60it/s, Accuracy=71.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.59it/s, Accuracy=71.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.59it/s, Accuracy=70.91%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.59it/s, Accuracy=70.91%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.59it/s, Accuracy=70.83%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.60it/s, Accuracy=70.83%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.60it/s, Accuracy=70.62%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.61it/s, Accuracy=70.62%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.61it/s, Accuracy=70.86%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.60it/s, Accuracy=70.86%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.60it/s, Accuracy=70.67%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.60it/s, Accuracy=70.67%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.60it/s, Accuracy=70.12%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.60it/s, Accuracy=70.12%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.60it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.61it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.61it/s, Accuracy=70.78%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.60it/s, Accuracy=70.78%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.60it/s, Accuracy=70.84%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.60it/s, Accuracy=70.84%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.60it/s, Accuracy=71.30%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.60it/s, Accuracy=71.30%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.60it/s, Accuracy=71.33%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.60it/s, Accuracy=71.33%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.60it/s, Accuracy=71.27%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.59it/s, Accuracy=71.27%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.59it/s, Accuracy=71.39%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.59it/s, Accuracy=71.39%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.59it/s, Accuracy=70.92%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.59it/s, Accuracy=70.92%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.59it/s, Accuracy=70.88%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.59it/s, Accuracy=70.88%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.59it/s, Accuracy=71.08%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.60it/s, Accuracy=71.08%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.72it/s, Accuracy=71.11%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:05:19,010 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 11:05:19,016 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 11:05:19,016 - INFO - Accuracy: 0.5824\n",
      "2025-02-19 11:05:19,017 - INFO - F1_score: 0.5362\n",
      "2025-02-19 11:05:19,018 - INFO - Precision: 0.3913\n",
      "2025-02-19 11:05:19,018 - INFO - Recall: 0.8514\n",
      "2025-02-19 11:05:19,024 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 11:05:19,025 - INFO - Accuracy: 0.8621\n",
      "2025-02-19 11:05:19,026 - INFO - F1_score: 0.7429\n",
      "2025-02-19 11:05:19,026 - INFO - Precision: 0.6265\n",
      "2025-02-19 11:05:19,027 - INFO - Recall: 0.9123\n",
      "2025-02-19 11:05:19,033 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 11:05:19,034 - INFO - Accuracy: 0.6820\n",
      "2025-02-19 11:05:19,035 - INFO - F1_score: 0.5257\n",
      "2025-02-19 11:05:19,035 - INFO - Precision: 0.3932\n",
      "2025-02-19 11:05:19,036 - INFO - Recall: 0.7931\n",
      "2025-02-19 11:05:19,042 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 11:05:19,043 - INFO - Accuracy: 0.6782\n",
      "2025-02-19 11:05:19,044 - INFO - F1_score: 0.3438\n",
      "2025-02-19 11:05:19,045 - INFO - Precision: 0.2444\n",
      "2025-02-19 11:05:19,045 - INFO - Recall: 0.5789\n",
      "2025-02-19 11:05:19,051 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 11:05:19,052 - INFO - Accuracy: 0.7510\n",
      "2025-02-19 11:05:19,053 - INFO - F1_score: 0.4538\n",
      "2025-02-19 11:05:19,054 - INFO - Precision: 0.3176\n",
      "2025-02-19 11:05:19,055 - INFO - Recall: 0.7941\n",
      "2025-02-19 11:05:19,057 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:05:22,965 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 11:05:22,966 - INFO - Memory usage after evaluation end: 4028.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 6/100 [18:08<4:03:59, 155.74s/it, Train Loss=1.2782, Val Loss=0.0509, Accuracy=0.7111]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:05:30,178 - INFO - New best accuracy: 0.7111\n",
      "2025-02-19 11:05:31,133 - INFO - Learning rate: 2.5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   7%|▋         | 7/100 [18:09<4:01:06, 155.55s/it, Train Loss=1.2782, Val Loss=0.0509, Accuracy=0.7111]\n",
      "Epoch 8:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.3324]\u001b[A\n",
      "Epoch 8:   1%|          | 1/148 [00:00<02:12,  1.11it/s, training_loss=1.3324]\u001b[A\n",
      "Epoch 8:   1%|          | 1/148 [00:01<02:12,  1.11it/s, training_loss=0.9637]\u001b[A\n",
      "Epoch 8:   1%|▏         | 2/148 [00:01<02:11,  1.11it/s, training_loss=0.9637]\u001b[A\n",
      "Epoch 8:   1%|▏         | 2/148 [00:02<02:11,  1.11it/s, training_loss=1.5575]\u001b[A\n",
      "Epoch 8:   2%|▏         | 3/148 [00:02<02:10,  1.11it/s, training_loss=1.5575]\u001b[A\n",
      "Epoch 8:   2%|▏         | 3/148 [00:03<02:10,  1.11it/s, training_loss=0.9150]\u001b[A\n",
      "Epoch 8:   3%|▎         | 4/148 [00:03<02:10,  1.10it/s, training_loss=0.9150]\u001b[A\n",
      "Epoch 8:   3%|▎         | 4/148 [00:04<02:10,  1.10it/s, training_loss=1.1439]\u001b[A\n",
      "Epoch 8:   3%|▎         | 5/148 [00:04<02:10,  1.10it/s, training_loss=1.1439]\u001b[A\n",
      "Epoch 8:   3%|▎         | 5/148 [00:05<02:10,  1.10it/s, training_loss=0.9624]\u001b[A\n",
      "Epoch 8:   4%|▍         | 6/148 [00:05<02:09,  1.10it/s, training_loss=0.9624]\u001b[A\n",
      "Epoch 8:   4%|▍         | 6/148 [00:06<02:09,  1.10it/s, training_loss=1.0549]\u001b[A\n",
      "Epoch 8:   5%|▍         | 7/148 [00:06<02:07,  1.10it/s, training_loss=1.0549]\u001b[A\n",
      "Epoch 8:   5%|▍         | 7/148 [00:07<02:07,  1.10it/s, training_loss=1.4379]\u001b[A\n",
      "Epoch 8:   5%|▌         | 8/148 [00:07<02:06,  1.11it/s, training_loss=1.4379]\u001b[A\n",
      "Epoch 8:   5%|▌         | 8/148 [00:08<02:06,  1.11it/s, training_loss=1.6170]\u001b[A\n",
      "Epoch 8:   6%|▌         | 9/148 [00:08<02:05,  1.11it/s, training_loss=1.6170]\u001b[A\n",
      "Epoch 8:   6%|▌         | 9/148 [00:09<02:05,  1.11it/s, training_loss=1.5309]\u001b[A\n",
      "Epoch 8:   7%|▋         | 10/148 [00:09<02:04,  1.11it/s, training_loss=1.5309]\u001b[A\n",
      "Epoch 8:   7%|▋         | 10/148 [00:09<02:04,  1.11it/s, training_loss=0.8261]\u001b[A\n",
      "Epoch 8:   7%|▋         | 11/148 [00:09<02:03,  1.11it/s, training_loss=0.8261]\u001b[A\n",
      "Epoch 8:   7%|▋         | 11/148 [00:10<02:03,  1.11it/s, training_loss=1.6309]\u001b[A\n",
      "Epoch 8:   8%|▊         | 12/148 [00:10<02:02,  1.11it/s, training_loss=1.6309]\u001b[A\n",
      "Epoch 8:   8%|▊         | 12/148 [00:11<02:02,  1.11it/s, training_loss=0.9680]\u001b[A\n",
      "Epoch 8:   9%|▉         | 13/148 [00:11<02:02,  1.11it/s, training_loss=0.9680]\u001b[A\n",
      "Epoch 8:   9%|▉         | 13/148 [00:12<02:02,  1.11it/s, training_loss=0.8134]\u001b[A\n",
      "Epoch 8:   9%|▉         | 14/148 [00:12<02:00,  1.11it/s, training_loss=0.8134]\u001b[A\n",
      "Epoch 8:   9%|▉         | 14/148 [00:13<02:00,  1.11it/s, training_loss=0.8917]\u001b[A\n",
      "Epoch 8:  10%|█         | 15/148 [00:13<02:00,  1.10it/s, training_loss=0.8917]\u001b[A\n",
      "Epoch 8:  10%|█         | 15/148 [00:14<02:00,  1.10it/s, training_loss=1.6051]\u001b[A\n",
      "Epoch 8:  11%|█         | 16/148 [00:14<01:59,  1.11it/s, training_loss=1.6051]\u001b[A\n",
      "Epoch 8:  11%|█         | 16/148 [00:15<01:59,  1.11it/s, training_loss=1.5750]\u001b[A\n",
      "Epoch 8:  11%|█▏        | 17/148 [00:15<01:58,  1.11it/s, training_loss=1.5750]\u001b[A\n",
      "Epoch 8:  11%|█▏        | 17/148 [00:16<01:58,  1.11it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 8:  12%|█▏        | 18/148 [00:16<01:57,  1.11it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 8:  12%|█▏        | 18/148 [00:17<01:57,  1.11it/s, training_loss=1.5417]\u001b[A\n",
      "Epoch 8:  13%|█▎        | 19/148 [00:17<01:56,  1.11it/s, training_loss=1.5417]\u001b[A\n",
      "Epoch 8:  13%|█▎        | 19/148 [00:18<01:56,  1.11it/s, training_loss=1.0080]\u001b[A\n",
      "Epoch 8:  14%|█▎        | 20/148 [00:18<01:55,  1.11it/s, training_loss=1.0080]\u001b[A\n",
      "Epoch 8:  14%|█▎        | 20/148 [00:18<01:55,  1.11it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 8:  14%|█▍        | 21/148 [00:18<01:54,  1.11it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 8:  14%|█▍        | 21/148 [00:19<01:54,  1.11it/s, training_loss=0.9357]\u001b[A\n",
      "Epoch 8:  15%|█▍        | 22/148 [00:19<01:53,  1.11it/s, training_loss=0.9357]\u001b[A\n",
      "Epoch 8:  15%|█▍        | 22/148 [00:20<01:53,  1.11it/s, training_loss=1.5544]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 23/148 [00:20<01:52,  1.11it/s, training_loss=1.5544]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 23/148 [00:21<01:52,  1.11it/s, training_loss=1.5257]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 24/148 [00:21<01:51,  1.11it/s, training_loss=1.5257]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 24/148 [00:22<01:51,  1.11it/s, training_loss=1.5093]\u001b[A\n",
      "Epoch 8:  17%|█▋        | 25/148 [00:22<01:50,  1.11it/s, training_loss=1.5093]\u001b[A\n",
      "Epoch 8:  17%|█▋        | 25/148 [00:23<01:50,  1.11it/s, training_loss=1.4697]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 26/148 [00:23<01:49,  1.11it/s, training_loss=1.4697]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 26/148 [00:24<01:49,  1.11it/s, training_loss=0.8980]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 27/148 [00:24<01:49,  1.11it/s, training_loss=0.8980]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 27/148 [00:25<01:49,  1.11it/s, training_loss=1.5724]\u001b[A\n",
      "Epoch 8:  19%|█▉        | 28/148 [00:25<01:48,  1.11it/s, training_loss=1.5724]\u001b[A\n",
      "Epoch 8:  19%|█▉        | 28/148 [00:26<01:48,  1.11it/s, training_loss=0.8937]\u001b[A\n",
      "Epoch 8:  20%|█▉        | 29/148 [00:26<01:47,  1.11it/s, training_loss=0.8937]\u001b[A\n",
      "Epoch 8:  20%|█▉        | 29/148 [00:27<01:47,  1.11it/s, training_loss=1.5993]\u001b[A\n",
      "Epoch 8:  20%|██        | 30/148 [00:27<01:46,  1.11it/s, training_loss=1.5993]\u001b[A\n",
      "Epoch 8:  20%|██        | 30/148 [00:27<01:46,  1.11it/s, training_loss=1.6562]\u001b[A\n",
      "Epoch 8:  21%|██        | 31/148 [00:27<01:45,  1.11it/s, training_loss=1.6562]\u001b[A\n",
      "Epoch 8:  21%|██        | 31/148 [00:28<01:45,  1.11it/s, training_loss=0.9967]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 32/148 [00:28<01:44,  1.11it/s, training_loss=0.9967]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 32/148 [00:29<01:44,  1.11it/s, training_loss=1.5756]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 33/148 [00:29<01:43,  1.11it/s, training_loss=1.5756]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 33/148 [00:30<01:43,  1.11it/s, training_loss=1.4877]\u001b[A\n",
      "Epoch 8:  23%|██▎       | 34/148 [00:30<01:42,  1.11it/s, training_loss=1.4877]\u001b[A\n",
      "Epoch 8:  23%|██▎       | 34/148 [00:31<01:42,  1.11it/s, training_loss=0.9465]\u001b[A\n",
      "Epoch 8:  24%|██▎       | 35/148 [00:31<01:42,  1.11it/s, training_loss=0.9465]\u001b[A\n",
      "Epoch 8:  24%|██▎       | 35/148 [00:32<01:42,  1.11it/s, training_loss=1.5396]\u001b[A\n",
      "Epoch 8:  24%|██▍       | 36/148 [00:32<01:41,  1.10it/s, training_loss=1.5396]\u001b[A\n",
      "Epoch 8:  24%|██▍       | 36/148 [00:33<01:41,  1.10it/s, training_loss=1.0247]\u001b[A\n",
      "Epoch 8:  25%|██▌       | 37/148 [00:33<01:40,  1.10it/s, training_loss=1.0247]\u001b[A\n",
      "Epoch 8:  25%|██▌       | 37/148 [00:34<01:40,  1.10it/s, training_loss=1.0869]\u001b[A\n",
      "Epoch 8:  26%|██▌       | 38/148 [00:34<01:40,  1.10it/s, training_loss=1.0869]\u001b[A\n",
      "Epoch 8:  26%|██▌       | 38/148 [00:35<01:40,  1.10it/s, training_loss=0.8681]\u001b[A\n",
      "Epoch 8:  26%|██▋       | 39/148 [00:35<01:39,  1.10it/s, training_loss=0.8681]\u001b[A\n",
      "Epoch 8:  26%|██▋       | 39/148 [00:36<01:39,  1.10it/s, training_loss=1.5571]\u001b[A\n",
      "Epoch 8:  27%|██▋       | 40/148 [00:36<01:37,  1.10it/s, training_loss=1.5571]\u001b[A\n",
      "Epoch 8:  27%|██▋       | 40/148 [00:37<01:37,  1.10it/s, training_loss=1.5485]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 41/148 [00:37<01:36,  1.11it/s, training_loss=1.5485]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 41/148 [00:37<01:36,  1.11it/s, training_loss=1.0470]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 42/148 [00:37<01:35,  1.11it/s, training_loss=1.0470]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 42/148 [00:38<01:35,  1.11it/s, training_loss=1.4663]\u001b[A\n",
      "Epoch 8:  29%|██▉       | 43/148 [00:38<01:34,  1.11it/s, training_loss=1.4663]\u001b[A\n",
      "Epoch 8:  29%|██▉       | 43/148 [00:39<01:34,  1.11it/s, training_loss=0.9702]\u001b[A\n",
      "Epoch 8:  30%|██▉       | 44/148 [00:39<01:34,  1.10it/s, training_loss=0.9702]\u001b[A\n",
      "Epoch 8:  30%|██▉       | 44/148 [00:40<01:34,  1.10it/s, training_loss=0.8179]\u001b[A\n",
      "Epoch 8:  30%|███       | 45/148 [00:40<01:33,  1.10it/s, training_loss=0.8179]\u001b[A\n",
      "Epoch 8:  30%|███       | 45/148 [00:41<01:33,  1.10it/s, training_loss=1.5907]\u001b[A\n",
      "Epoch 8:  31%|███       | 46/148 [00:41<01:32,  1.10it/s, training_loss=1.5907]\u001b[A\n",
      "Epoch 8:  31%|███       | 46/148 [00:42<01:32,  1.10it/s, training_loss=1.3705]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 47/148 [00:42<01:31,  1.11it/s, training_loss=1.3705]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 47/148 [00:43<01:31,  1.11it/s, training_loss=1.0233]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 48/148 [00:43<01:30,  1.10it/s, training_loss=1.0233]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 48/148 [00:44<01:30,  1.10it/s, training_loss=1.6106]\u001b[A\n",
      "Epoch 8:  33%|███▎      | 49/148 [00:44<01:29,  1.10it/s, training_loss=1.6106]\u001b[A\n",
      "Epoch 8:  33%|███▎      | 49/148 [00:45<01:29,  1.10it/s, training_loss=0.9569]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 50/148 [00:45<01:28,  1.11it/s, training_loss=0.9569]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 50/148 [00:46<01:28,  1.11it/s, training_loss=1.5024]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 51/148 [00:46<01:27,  1.11it/s, training_loss=1.5024]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 51/148 [00:46<01:27,  1.11it/s, training_loss=0.9496]\u001b[A\n",
      "Epoch 8:  35%|███▌      | 52/148 [00:46<01:26,  1.11it/s, training_loss=0.9496]\u001b[A\n",
      "Epoch 8:  35%|███▌      | 52/148 [00:47<01:26,  1.11it/s, training_loss=1.6034]\u001b[A\n",
      "Epoch 8:  36%|███▌      | 53/148 [00:47<01:25,  1.11it/s, training_loss=1.6034]\u001b[A\n",
      "Epoch 8:  36%|███▌      | 53/148 [00:48<01:25,  1.11it/s, training_loss=1.3307]\u001b[A\n",
      "Epoch 8:  36%|███▋      | 54/148 [00:48<01:25,  1.11it/s, training_loss=1.3307]\u001b[A\n",
      "Epoch 8:  36%|███▋      | 54/148 [00:49<01:25,  1.11it/s, training_loss=0.8478]\u001b[A\n",
      "Epoch 8:  37%|███▋      | 55/148 [00:49<01:24,  1.10it/s, training_loss=0.8478]\u001b[A\n",
      "Epoch 8:  37%|███▋      | 55/148 [00:50<01:24,  1.10it/s, training_loss=1.0332]\u001b[A\n",
      "Epoch 8:  38%|███▊      | 56/148 [00:50<01:23,  1.10it/s, training_loss=1.0332]\u001b[A\n",
      "Epoch 8:  38%|███▊      | 56/148 [00:51<01:23,  1.10it/s, training_loss=1.6583]\u001b[A\n",
      "Epoch 8:  39%|███▊      | 57/148 [00:51<01:22,  1.11it/s, training_loss=1.6583]\u001b[A\n",
      "Epoch 8:  39%|███▊      | 57/148 [00:52<01:22,  1.11it/s, training_loss=1.4649]\u001b[A\n",
      "Epoch 8:  39%|███▉      | 58/148 [00:52<01:21,  1.11it/s, training_loss=1.4649]\u001b[A\n",
      "Epoch 8:  39%|███▉      | 58/148 [00:53<01:21,  1.11it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 8:  40%|███▉      | 59/148 [00:53<01:20,  1.11it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 8:  40%|███▉      | 59/148 [00:54<01:20,  1.11it/s, training_loss=1.5887]\u001b[A\n",
      "Epoch 8:  41%|████      | 60/148 [00:54<01:19,  1.11it/s, training_loss=1.5887]\u001b[A\n",
      "Epoch 8:  41%|████      | 60/148 [00:55<01:19,  1.11it/s, training_loss=0.8450]\u001b[A\n",
      "Epoch 8:  41%|████      | 61/148 [00:55<01:18,  1.10it/s, training_loss=0.8450]\u001b[A\n",
      "Epoch 8:  41%|████      | 61/148 [00:56<01:18,  1.10it/s, training_loss=0.8712]\u001b[A\n",
      "Epoch 8:  42%|████▏     | 62/148 [00:56<01:18,  1.10it/s, training_loss=0.8712]\u001b[A\n",
      "Epoch 8:  42%|████▏     | 62/148 [00:56<01:18,  1.10it/s, training_loss=0.8474]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 63/148 [00:56<01:17,  1.10it/s, training_loss=0.8474]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 63/148 [00:57<01:17,  1.10it/s, training_loss=1.0156]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 64/148 [00:57<01:16,  1.10it/s, training_loss=1.0156]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 64/148 [00:58<01:16,  1.10it/s, training_loss=1.0083]\u001b[A\n",
      "Epoch 8:  44%|████▍     | 65/148 [00:58<01:15,  1.10it/s, training_loss=1.0083]\u001b[A\n",
      "Epoch 8:  44%|████▍     | 65/148 [00:59<01:15,  1.10it/s, training_loss=0.8045]\u001b[A\n",
      "Epoch 8:  45%|████▍     | 66/148 [00:59<01:14,  1.10it/s, training_loss=0.8045]\u001b[A\n",
      "Epoch 8:  45%|████▍     | 66/148 [01:00<01:14,  1.10it/s, training_loss=1.5301]\u001b[A\n",
      "Epoch 8:  45%|████▌     | 67/148 [01:00<01:13,  1.11it/s, training_loss=1.5301]\u001b[A\n",
      "Epoch 8:  45%|████▌     | 67/148 [01:01<01:13,  1.11it/s, training_loss=1.2708]\u001b[A\n",
      "Epoch 8:  46%|████▌     | 68/148 [01:01<01:12,  1.11it/s, training_loss=1.2708]\u001b[A\n",
      "Epoch 8:  46%|████▌     | 68/148 [01:02<01:12,  1.11it/s, training_loss=1.6226]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 69/148 [01:02<01:11,  1.11it/s, training_loss=1.6226]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 69/148 [01:03<01:11,  1.11it/s, training_loss=1.5926]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 70/148 [01:03<01:10,  1.11it/s, training_loss=1.5926]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 70/148 [01:04<01:10,  1.11it/s, training_loss=0.9614]\u001b[A\n",
      "Epoch 8:  48%|████▊     | 71/148 [01:04<01:09,  1.10it/s, training_loss=0.9614]\u001b[A\n",
      "Epoch 8:  48%|████▊     | 71/148 [01:05<01:09,  1.10it/s, training_loss=0.9497]\u001b[A\n",
      "Epoch 8:  49%|████▊     | 72/148 [01:05<01:08,  1.11it/s, training_loss=0.9497]\u001b[A\n",
      "Epoch 8:  49%|████▊     | 72/148 [01:05<01:08,  1.11it/s, training_loss=1.6757]\u001b[A\n",
      "Epoch 8:  49%|████▉     | 73/148 [01:05<01:07,  1.11it/s, training_loss=1.6757]\u001b[A\n",
      "Epoch 8:  49%|████▉     | 73/148 [01:06<01:07,  1.11it/s, training_loss=1.5397]\u001b[A\n",
      "Epoch 8:  50%|█████     | 74/148 [01:06<01:07,  1.10it/s, training_loss=1.5397]\u001b[A\n",
      "Epoch 8:  50%|█████     | 74/148 [01:07<01:07,  1.10it/s, training_loss=1.6013]\u001b[A\n",
      "Epoch 8:  51%|█████     | 75/148 [01:07<01:06,  1.10it/s, training_loss=1.6013]\u001b[A\n",
      "Epoch 8:  51%|█████     | 75/148 [01:08<01:06,  1.10it/s, training_loss=1.5562]\u001b[A\n",
      "Epoch 8:  51%|█████▏    | 76/148 [01:08<01:05,  1.11it/s, training_loss=1.5562]\u001b[A\n",
      "Epoch 8:  51%|█████▏    | 76/148 [01:09<01:05,  1.11it/s, training_loss=1.4963]\u001b[A\n",
      "Epoch 8:  52%|█████▏    | 77/148 [01:09<01:03,  1.11it/s, training_loss=1.4963]\u001b[A\n",
      "Epoch 8:  52%|█████▏    | 77/148 [01:10<01:03,  1.11it/s, training_loss=1.1059]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 78/148 [01:10<01:03,  1.11it/s, training_loss=1.1059]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 78/148 [01:11<01:03,  1.11it/s, training_loss=1.6222]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 79/148 [01:11<01:02,  1.11it/s, training_loss=1.6222]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 79/148 [01:12<01:02,  1.11it/s, training_loss=0.8825]\u001b[A\n",
      "Epoch 8:  54%|█████▍    | 80/148 [01:12<01:01,  1.11it/s, training_loss=0.8825]\u001b[A\n",
      "Epoch 8:  54%|█████▍    | 80/148 [01:13<01:01,  1.11it/s, training_loss=0.9840]\u001b[A\n",
      "Epoch 8:  55%|█████▍    | 81/148 [01:13<01:00,  1.10it/s, training_loss=0.9840]\u001b[A\n",
      "Epoch 8:  55%|█████▍    | 81/148 [01:14<01:00,  1.10it/s, training_loss=1.5992]\u001b[A\n",
      "Epoch 8:  55%|█████▌    | 82/148 [01:14<00:59,  1.11it/s, training_loss=1.5992]\u001b[A\n",
      "Epoch 8:  55%|█████▌    | 82/148 [01:15<00:59,  1.11it/s, training_loss=1.5482]\u001b[A\n",
      "Epoch 8:  56%|█████▌    | 83/148 [01:15<00:58,  1.11it/s, training_loss=1.5482]\u001b[A\n",
      "Epoch 8:  56%|█████▌    | 83/148 [01:15<00:58,  1.11it/s, training_loss=0.8835]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 84/148 [01:15<00:57,  1.11it/s, training_loss=0.8835]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 84/148 [01:16<00:57,  1.11it/s, training_loss=1.0686]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 85/148 [01:16<00:56,  1.11it/s, training_loss=1.0686]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 85/148 [01:17<00:56,  1.11it/s, training_loss=1.0756]\u001b[A\n",
      "Epoch 8:  58%|█████▊    | 86/148 [01:17<00:56,  1.10it/s, training_loss=1.0756]\u001b[A\n",
      "Epoch 8:  58%|█████▊    | 86/148 [01:18<00:56,  1.10it/s, training_loss=1.5423]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 87/148 [01:18<00:55,  1.10it/s, training_loss=1.5423]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 87/148 [01:19<00:55,  1.10it/s, training_loss=0.8611]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 88/148 [01:19<00:54,  1.10it/s, training_loss=0.8611]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 88/148 [01:20<00:54,  1.10it/s, training_loss=1.6524]\u001b[A\n",
      "Epoch 8:  60%|██████    | 89/148 [01:20<00:53,  1.11it/s, training_loss=1.6524]\u001b[A\n",
      "Epoch 8:  60%|██████    | 89/148 [01:21<00:53,  1.11it/s, training_loss=1.5544]\u001b[A\n",
      "Epoch 8:  61%|██████    | 90/148 [01:21<00:52,  1.11it/s, training_loss=1.5544]\u001b[A\n",
      "Epoch 8:  61%|██████    | 90/148 [01:22<00:52,  1.11it/s, training_loss=1.4510]\u001b[A\n",
      "Epoch 8:  61%|██████▏   | 91/148 [01:22<00:51,  1.11it/s, training_loss=1.4510]\u001b[A\n",
      "Epoch 8:  61%|██████▏   | 91/148 [01:23<00:51,  1.11it/s, training_loss=0.9644]\u001b[A\n",
      "Epoch 8:  62%|██████▏   | 92/148 [01:23<00:50,  1.11it/s, training_loss=0.9644]\u001b[A\n",
      "Epoch 8:  62%|██████▏   | 92/148 [01:24<00:50,  1.11it/s, training_loss=0.8950]\u001b[A\n",
      "Epoch 8:  63%|██████▎   | 93/148 [01:24<00:49,  1.11it/s, training_loss=0.8950]\u001b[A\n",
      "Epoch 8:  63%|██████▎   | 93/148 [01:24<00:49,  1.11it/s, training_loss=1.5481]\u001b[A\n",
      "Epoch 8:  64%|██████▎   | 94/148 [01:24<00:48,  1.11it/s, training_loss=1.5481]\u001b[A\n",
      "Epoch 8:  64%|██████▎   | 94/148 [01:25<00:48,  1.11it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 8:  64%|██████▍   | 95/148 [01:25<00:47,  1.11it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 8:  64%|██████▍   | 95/148 [01:26<00:47,  1.11it/s, training_loss=1.2349]\u001b[A\n",
      "Epoch 8:  65%|██████▍   | 96/148 [01:26<00:46,  1.11it/s, training_loss=1.2349]\u001b[A\n",
      "Epoch 8:  65%|██████▍   | 96/148 [01:27<00:46,  1.11it/s, training_loss=1.4045]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 97/148 [01:27<00:46,  1.10it/s, training_loss=1.4045]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 97/148 [01:28<00:46,  1.10it/s, training_loss=1.5922]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 98/148 [01:28<00:45,  1.10it/s, training_loss=1.5922]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 98/148 [01:29<00:45,  1.10it/s, training_loss=0.8624]\u001b[A\n",
      "Epoch 8:  67%|██████▋   | 99/148 [01:29<00:44,  1.11it/s, training_loss=0.8624]\u001b[A\n",
      "Epoch 8:  67%|██████▋   | 99/148 [01:30<00:44,  1.11it/s, training_loss=1.0060]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 100/148 [01:30<00:43,  1.10it/s, training_loss=1.0060]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 100/148 [01:31<00:43,  1.10it/s, training_loss=1.3959]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 101/148 [01:31<00:42,  1.11it/s, training_loss=1.3959]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 101/148 [01:32<00:42,  1.11it/s, training_loss=1.2596]\u001b[A\n",
      "Epoch 8:  69%|██████▉   | 102/148 [01:32<00:41,  1.11it/s, training_loss=1.2596]\u001b[A\n",
      "Epoch 8:  69%|██████▉   | 102/148 [01:33<00:41,  1.11it/s, training_loss=1.0183]\u001b[A\n",
      "Epoch 8:  70%|██████▉   | 103/148 [01:33<00:40,  1.11it/s, training_loss=1.0183]\u001b[A\n",
      "Epoch 8:  70%|██████▉   | 103/148 [01:33<00:40,  1.11it/s, training_loss=1.5602]\u001b[A\n",
      "Epoch 8:  70%|███████   | 104/148 [01:33<00:39,  1.11it/s, training_loss=1.5602]\u001b[A\n",
      "Epoch 8:  70%|███████   | 104/148 [01:34<00:39,  1.11it/s, training_loss=0.9156]\u001b[A\n",
      "Epoch 8:  71%|███████   | 105/148 [01:34<00:38,  1.11it/s, training_loss=0.9156]\u001b[A\n",
      "Epoch 8:  71%|███████   | 105/148 [01:35<00:38,  1.11it/s, training_loss=1.6352]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 106/148 [01:35<00:37,  1.11it/s, training_loss=1.6352]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 106/148 [01:36<00:37,  1.11it/s, training_loss=1.1187]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 107/148 [01:36<00:36,  1.11it/s, training_loss=1.1187]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 107/148 [01:37<00:36,  1.11it/s, training_loss=0.8932]\u001b[A\n",
      "Epoch 8:  73%|███████▎  | 108/148 [01:37<00:36,  1.10it/s, training_loss=0.8932]\u001b[A\n",
      "Epoch 8:  73%|███████▎  | 108/148 [01:38<00:36,  1.10it/s, training_loss=0.9409]\u001b[A\n",
      "Epoch 8:  74%|███████▎  | 109/148 [01:38<00:35,  1.10it/s, training_loss=0.9409]\u001b[A\n",
      "Epoch 8:  74%|███████▎  | 109/148 [01:39<00:35,  1.10it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 8:  74%|███████▍  | 110/148 [01:39<00:34,  1.11it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 8:  74%|███████▍  | 110/148 [01:40<00:34,  1.11it/s, training_loss=1.4037]\u001b[A\n",
      "Epoch 8:  75%|███████▌  | 111/148 [01:40<00:33,  1.11it/s, training_loss=1.4037]\u001b[A\n",
      "Epoch 8:  75%|███████▌  | 111/148 [01:41<00:33,  1.11it/s, training_loss=0.9708]\u001b[A\n",
      "Epoch 8:  76%|███████▌  | 112/148 [01:41<00:32,  1.11it/s, training_loss=0.9708]\u001b[A\n",
      "Epoch 8:  76%|███████▌  | 112/148 [01:42<00:32,  1.11it/s, training_loss=1.0590]\u001b[A\n",
      "Epoch 8:  76%|███████▋  | 113/148 [01:42<00:31,  1.10it/s, training_loss=1.0590]\u001b[A\n",
      "Epoch 8:  76%|███████▋  | 113/148 [01:43<00:31,  1.10it/s, training_loss=1.0836]\u001b[A\n",
      "Epoch 8:  77%|███████▋  | 114/148 [01:43<00:30,  1.10it/s, training_loss=1.0836]\u001b[A\n",
      "Epoch 8:  77%|███████▋  | 114/148 [01:43<00:30,  1.10it/s, training_loss=0.8922]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 115/148 [01:43<00:29,  1.10it/s, training_loss=0.8922]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 115/148 [01:44<00:29,  1.10it/s, training_loss=1.5895]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 116/148 [01:44<00:28,  1.11it/s, training_loss=1.5895]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 116/148 [01:45<00:28,  1.11it/s, training_loss=1.4972]\u001b[A\n",
      "Epoch 8:  79%|███████▉  | 117/148 [01:45<00:27,  1.11it/s, training_loss=1.4972]\u001b[A\n",
      "Epoch 8:  79%|███████▉  | 117/148 [01:46<00:27,  1.11it/s, training_loss=1.4845]\u001b[A\n",
      "Epoch 8:  80%|███████▉  | 118/148 [01:46<00:27,  1.11it/s, training_loss=1.4845]\u001b[A\n",
      "Epoch 8:  80%|███████▉  | 118/148 [01:47<00:27,  1.11it/s, training_loss=1.6200]\u001b[A\n",
      "Epoch 8:  80%|████████  | 119/148 [01:47<00:26,  1.11it/s, training_loss=1.6200]\u001b[A\n",
      "Epoch 8:  80%|████████  | 119/148 [01:48<00:26,  1.11it/s, training_loss=1.5638]\u001b[A\n",
      "Epoch 8:  81%|████████  | 120/148 [01:48<00:25,  1.11it/s, training_loss=1.5638]\u001b[A\n",
      "Epoch 8:  81%|████████  | 120/148 [01:49<00:25,  1.11it/s, training_loss=0.8846]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 121/148 [01:49<00:24,  1.11it/s, training_loss=0.8846]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 121/148 [01:50<00:24,  1.11it/s, training_loss=0.9377]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 122/148 [01:50<00:23,  1.11it/s, training_loss=0.9377]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 122/148 [01:51<00:23,  1.11it/s, training_loss=1.6469]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 123/148 [01:51<00:22,  1.11it/s, training_loss=1.6469]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 123/148 [01:52<00:22,  1.11it/s, training_loss=1.0004]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 124/148 [01:52<00:21,  1.11it/s, training_loss=1.0004]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 124/148 [01:52<00:21,  1.11it/s, training_loss=1.5854]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 125/148 [01:52<00:20,  1.11it/s, training_loss=1.5854]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 125/148 [01:53<00:20,  1.11it/s, training_loss=0.9754]\u001b[A\n",
      "Epoch 8:  85%|████████▌ | 126/148 [01:53<00:19,  1.11it/s, training_loss=0.9754]\u001b[A\n",
      "Epoch 8:  85%|████████▌ | 126/148 [01:54<00:19,  1.11it/s, training_loss=1.6035]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 127/148 [01:54<00:18,  1.11it/s, training_loss=1.6035]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 127/148 [01:55<00:18,  1.11it/s, training_loss=0.9207]\u001b[A\n",
      "Epoch 8:  86%|████████▋ | 128/148 [01:55<00:17,  1.11it/s, training_loss=0.9207]\u001b[A\n",
      "Epoch 8:  86%|████████▋ | 128/148 [01:56<00:17,  1.11it/s, training_loss=0.8628]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 129/148 [01:56<00:17,  1.11it/s, training_loss=0.8628]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 129/148 [01:57<00:17,  1.11it/s, training_loss=0.9330]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 130/148 [01:57<00:16,  1.11it/s, training_loss=0.9330]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 130/148 [01:58<00:16,  1.11it/s, training_loss=0.8955]\u001b[A\n",
      "Epoch 8:  89%|████████▊ | 131/148 [01:58<00:15,  1.10it/s, training_loss=0.8955]\u001b[A\n",
      "Epoch 8:  89%|████████▊ | 131/148 [01:59<00:15,  1.10it/s, training_loss=1.6372]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 132/148 [01:59<00:14,  1.11it/s, training_loss=1.6372]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 132/148 [02:00<00:14,  1.11it/s, training_loss=0.8199]\u001b[A\n",
      "Epoch 8:  90%|████████▉ | 133/148 [02:00<00:13,  1.10it/s, training_loss=0.8199]\u001b[A\n",
      "Epoch 8:  90%|████████▉ | 133/148 [02:01<00:13,  1.10it/s, training_loss=1.4598]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 134/148 [02:01<00:12,  1.11it/s, training_loss=1.4598]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 134/148 [02:01<00:12,  1.11it/s, training_loss=1.4814]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 135/148 [02:01<00:11,  1.11it/s, training_loss=1.4814]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 135/148 [02:02<00:11,  1.11it/s, training_loss=1.4868]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 136/148 [02:02<00:10,  1.11it/s, training_loss=1.4868]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 136/148 [02:03<00:10,  1.11it/s, training_loss=0.9816]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 137/148 [02:03<00:09,  1.11it/s, training_loss=0.9816]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 137/148 [02:04<00:09,  1.11it/s, training_loss=1.0185]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 138/148 [02:04<00:08,  1.11it/s, training_loss=1.0185]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 138/148 [02:05<00:08,  1.11it/s, training_loss=1.5574]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 139/148 [02:05<00:08,  1.11it/s, training_loss=1.5574]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 139/148 [02:06<00:08,  1.11it/s, training_loss=0.8998]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 140/148 [02:06<00:07,  1.11it/s, training_loss=0.8998]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 140/148 [02:07<00:07,  1.11it/s, training_loss=0.9772]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 141/148 [02:07<00:06,  1.11it/s, training_loss=0.9772]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 141/148 [02:08<00:06,  1.11it/s, training_loss=0.9065]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 142/148 [02:08<00:05,  1.11it/s, training_loss=0.9065]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 142/148 [02:09<00:05,  1.11it/s, training_loss=0.9195]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 143/148 [02:09<00:04,  1.11it/s, training_loss=0.9195]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 143/148 [02:10<00:04,  1.11it/s, training_loss=0.9464]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 144/148 [02:10<00:03,  1.11it/s, training_loss=0.9464]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 144/148 [02:10<00:03,  1.11it/s, training_loss=0.9631]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 145/148 [02:10<00:02,  1.11it/s, training_loss=0.9631]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 145/148 [02:11<00:02,  1.11it/s, training_loss=1.5326]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 146/148 [02:11<00:01,  1.11it/s, training_loss=1.5326]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 146/148 [02:12<00:01,  1.11it/s, training_loss=1.5406]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 147/148 [02:12<00:00,  1.11it/s, training_loss=1.5406]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 147/148 [02:13<00:00,  1.11it/s, training_loss=1.5986]\u001b[A\n",
      "Epoch 8: 100%|██████████| 148/148 [02:13<00:00,  1.21it/s, training_loss=1.5986]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:07:44,572 - INFO - Starting model evaluation...\n",
      "2025-02-19 11:07:44,573 - INFO - Memory usage after evaluation start: 4029.16 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=76.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:06,  3.73it/s, Accuracy=76.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:06,  3.73it/s, Accuracy=77.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.66it/s, Accuracy=77.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.66it/s, Accuracy=76.67%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.66it/s, Accuracy=76.67%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.66it/s, Accuracy=74.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.64it/s, Accuracy=74.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.64it/s, Accuracy=74.40%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.65it/s, Accuracy=74.40%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.65it/s, Accuracy=74.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.64it/s, Accuracy=74.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.64it/s, Accuracy=72.86%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.63it/s, Accuracy=72.86%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.63it/s, Accuracy=71.25%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.64it/s, Accuracy=71.25%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.64it/s, Accuracy=70.67%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.62it/s, Accuracy=70.67%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.62it/s, Accuracy=71.20%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.63it/s, Accuracy=71.20%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.63it/s, Accuracy=70.55%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.63it/s, Accuracy=70.55%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.63it/s, Accuracy=70.67%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.63it/s, Accuracy=70.67%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.63it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.63it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.63it/s, Accuracy=70.14%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.63it/s, Accuracy=70.14%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.63it/s, Accuracy=70.13%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.63it/s, Accuracy=70.13%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.63it/s, Accuracy=69.38%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.62it/s, Accuracy=69.38%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.62it/s, Accuracy=68.94%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.63it/s, Accuracy=68.94%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.63it/s, Accuracy=69.56%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.62it/s, Accuracy=69.56%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.62it/s, Accuracy=69.58%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.61it/s, Accuracy=69.58%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.61it/s, Accuracy=69.90%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.62it/s, Accuracy=69.90%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.62it/s, Accuracy=70.10%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.62it/s, Accuracy=70.10%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.62it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.62it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.62it/s, Accuracy=70.26%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.62it/s, Accuracy=70.26%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.62it/s, Accuracy=69.92%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.62it/s, Accuracy=69.92%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.62it/s, Accuracy=69.84%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.62it/s, Accuracy=69.84%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.62it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.62it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.75it/s, Accuracy=70.04%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:07:51,780 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 11:07:51,786 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 11:07:51,787 - INFO - Accuracy: 0.6245\n",
      "2025-02-19 11:07:51,787 - INFO - F1_score: 0.5333\n",
      "2025-02-19 11:07:51,788 - INFO - Precision: 0.4118\n",
      "2025-02-19 11:07:51,789 - INFO - Recall: 0.7568\n",
      "2025-02-19 11:07:51,795 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 11:07:51,796 - INFO - Accuracy: 0.7931\n",
      "2025-02-19 11:07:51,796 - INFO - F1_score: 0.6625\n",
      "2025-02-19 11:07:51,797 - INFO - Precision: 0.5146\n",
      "2025-02-19 11:07:51,799 - INFO - Recall: 0.9298\n",
      "2025-02-19 11:07:51,805 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 11:07:51,805 - INFO - Accuracy: 0.5939\n",
      "2025-02-19 11:07:51,806 - INFO - F1_score: 0.4804\n",
      "2025-02-19 11:07:51,806 - INFO - Precision: 0.3356\n",
      "2025-02-19 11:07:51,807 - INFO - Recall: 0.8448\n",
      "2025-02-19 11:07:51,814 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 11:07:51,815 - INFO - Accuracy: 0.7011\n",
      "2025-02-19 11:07:51,815 - INFO - F1_score: 0.3390\n",
      "2025-02-19 11:07:51,816 - INFO - Precision: 0.2500\n",
      "2025-02-19 11:07:51,818 - INFO - Recall: 0.5263\n",
      "2025-02-19 11:07:51,824 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 11:07:51,825 - INFO - Accuracy: 0.7893\n",
      "2025-02-19 11:07:51,825 - INFO - F1_score: 0.4554\n",
      "2025-02-19 11:07:51,826 - INFO - Precision: 0.3433\n",
      "2025-02-19 11:07:51,827 - INFO - Recall: 0.6765\n",
      "2025-02-19 11:07:51,829 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:07:55,773 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 11:07:55,775 - INFO - Memory usage after evaluation end: 4034.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   7%|▋         | 7/100 [20:40<4:01:06, 155.55s/it, Train Loss=1.2512, Val Loss=0.0519, Accuracy=0.7004]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:08:02,887 - INFO - Learning rate: 2.5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 8/100 [20:40<3:56:39, 154.34s/it, Train Loss=1.2512, Val Loss=0.0519, Accuracy=0.7004]\n",
      "Epoch 9:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=0.9016]\u001b[A\n",
      "Epoch 9:   1%|          | 1/148 [00:00<02:11,  1.11it/s, training_loss=0.9016]\u001b[A\n",
      "Epoch 9:   1%|          | 1/148 [00:01<02:11,  1.11it/s, training_loss=0.9711]\u001b[A\n",
      "Epoch 9:   1%|▏         | 2/148 [00:01<02:11,  1.11it/s, training_loss=0.9711]\u001b[A\n",
      "Epoch 9:   1%|▏         | 2/148 [00:02<02:11,  1.11it/s, training_loss=0.8829]\u001b[A\n",
      "Epoch 9:   2%|▏         | 3/148 [00:02<02:10,  1.11it/s, training_loss=0.8829]\u001b[A\n",
      "Epoch 9:   2%|▏         | 3/148 [00:03<02:10,  1.11it/s, training_loss=1.6129]\u001b[A\n",
      "Epoch 9:   3%|▎         | 4/148 [00:03<02:08,  1.12it/s, training_loss=1.6129]\u001b[A\n",
      "Epoch 9:   3%|▎         | 4/148 [00:04<02:08,  1.12it/s, training_loss=1.6124]\u001b[A\n",
      "Epoch 9:   3%|▎         | 5/148 [00:04<02:07,  1.12it/s, training_loss=1.6124]\u001b[A\n",
      "Epoch 9:   3%|▎         | 5/148 [00:05<02:07,  1.12it/s, training_loss=0.8404]\u001b[A\n",
      "Epoch 9:   4%|▍         | 6/148 [00:05<02:07,  1.12it/s, training_loss=0.8404]\u001b[A\n",
      "Epoch 9:   4%|▍         | 6/148 [00:06<02:07,  1.12it/s, training_loss=1.1394]\u001b[A\n",
      "Epoch 9:   5%|▍         | 7/148 [00:06<02:06,  1.11it/s, training_loss=1.1394]\u001b[A\n",
      "Epoch 9:   5%|▍         | 7/148 [00:07<02:06,  1.11it/s, training_loss=0.9589]\u001b[A\n",
      "Epoch 9:   5%|▌         | 8/148 [00:07<02:05,  1.11it/s, training_loss=0.9589]\u001b[A\n",
      "Epoch 9:   5%|▌         | 8/148 [00:08<02:05,  1.11it/s, training_loss=1.5274]\u001b[A\n",
      "Epoch 9:   6%|▌         | 9/148 [00:08<02:04,  1.12it/s, training_loss=1.5274]\u001b[A\n",
      "Epoch 9:   6%|▌         | 9/148 [00:08<02:04,  1.12it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 9:   7%|▋         | 10/148 [00:08<02:03,  1.11it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 9:   7%|▋         | 10/148 [00:09<02:03,  1.11it/s, training_loss=1.4978]\u001b[A\n",
      "Epoch 9:   7%|▋         | 11/148 [00:09<02:03,  1.11it/s, training_loss=1.4978]\u001b[A\n",
      "Epoch 9:   7%|▋         | 11/148 [00:10<02:03,  1.11it/s, training_loss=0.8272]\u001b[A\n",
      "Epoch 9:   8%|▊         | 12/148 [00:10<02:02,  1.11it/s, training_loss=0.8272]\u001b[A\n",
      "Epoch 9:   8%|▊         | 12/148 [00:11<02:02,  1.11it/s, training_loss=1.0140]\u001b[A\n",
      "Epoch 9:   9%|▉         | 13/148 [00:11<02:01,  1.11it/s, training_loss=1.0140]\u001b[A\n",
      "Epoch 9:   9%|▉         | 13/148 [00:12<02:01,  1.11it/s, training_loss=1.6436]\u001b[A\n",
      "Epoch 9:   9%|▉         | 14/148 [00:12<02:00,  1.11it/s, training_loss=1.6436]\u001b[A\n",
      "Epoch 9:   9%|▉         | 14/148 [00:13<02:00,  1.11it/s, training_loss=1.6699]\u001b[A\n",
      "Epoch 9:  10%|█         | 15/148 [00:13<01:59,  1.11it/s, training_loss=1.6699]\u001b[A\n",
      "Epoch 9:  10%|█         | 15/148 [00:14<01:59,  1.11it/s, training_loss=0.8874]\u001b[A\n",
      "Epoch 9:  11%|█         | 16/148 [00:14<01:58,  1.11it/s, training_loss=0.8874]\u001b[A\n",
      "Epoch 9:  11%|█         | 16/148 [00:15<01:58,  1.11it/s, training_loss=1.0019]\u001b[A\n",
      "Epoch 9:  11%|█▏        | 17/148 [00:15<01:57,  1.11it/s, training_loss=1.0019]\u001b[A\n",
      "Epoch 9:  11%|█▏        | 17/148 [00:16<01:57,  1.11it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 9:  12%|█▏        | 18/148 [00:16<01:57,  1.11it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 9:  12%|█▏        | 18/148 [00:17<01:57,  1.11it/s, training_loss=1.0505]\u001b[A\n",
      "Epoch 9:  13%|█▎        | 19/148 [00:17<01:56,  1.11it/s, training_loss=1.0505]\u001b[A\n",
      "Epoch 9:  13%|█▎        | 19/148 [00:17<01:56,  1.11it/s, training_loss=0.9536]\u001b[A\n",
      "Epoch 9:  14%|█▎        | 20/148 [00:17<01:55,  1.10it/s, training_loss=0.9536]\u001b[A\n",
      "Epoch 9:  14%|█▎        | 20/148 [00:18<01:55,  1.10it/s, training_loss=0.9349]\u001b[A\n",
      "Epoch 9:  14%|█▍        | 21/148 [00:18<01:54,  1.11it/s, training_loss=0.9349]\u001b[A\n",
      "Epoch 9:  14%|█▍        | 21/148 [00:19<01:54,  1.11it/s, training_loss=0.8443]\u001b[A\n",
      "Epoch 9:  15%|█▍        | 22/148 [00:19<01:53,  1.11it/s, training_loss=0.8443]\u001b[A\n",
      "Epoch 9:  15%|█▍        | 22/148 [00:20<01:53,  1.11it/s, training_loss=1.5379]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 23/148 [00:20<01:52,  1.11it/s, training_loss=1.5379]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 23/148 [00:21<01:52,  1.11it/s, training_loss=1.0387]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 24/148 [00:21<01:52,  1.10it/s, training_loss=1.0387]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 24/148 [00:22<01:52,  1.10it/s, training_loss=1.5903]\u001b[A\n",
      "Epoch 9:  17%|█▋        | 25/148 [00:22<01:51,  1.11it/s, training_loss=1.5903]\u001b[A\n",
      "Epoch 9:  17%|█▋        | 25/148 [00:23<01:51,  1.11it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 26/148 [00:23<01:50,  1.11it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 26/148 [00:24<01:50,  1.11it/s, training_loss=1.6138]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 27/148 [00:24<01:49,  1.11it/s, training_loss=1.6138]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 27/148 [00:25<01:49,  1.11it/s, training_loss=1.5431]\u001b[A\n",
      "Epoch 9:  19%|█▉        | 28/148 [00:25<01:48,  1.11it/s, training_loss=1.5431]\u001b[A\n",
      "Epoch 9:  19%|█▉        | 28/148 [00:26<01:48,  1.11it/s, training_loss=1.6264]\u001b[A\n",
      "Epoch 9:  20%|█▉        | 29/148 [00:26<01:47,  1.11it/s, training_loss=1.6264]\u001b[A\n",
      "Epoch 9:  20%|█▉        | 29/148 [00:26<01:47,  1.11it/s, training_loss=1.5627]\u001b[A\n",
      "Epoch 9:  20%|██        | 30/148 [00:27<01:45,  1.11it/s, training_loss=1.5627]\u001b[A\n",
      "Epoch 9:  20%|██        | 30/148 [00:27<01:45,  1.11it/s, training_loss=1.0858]\u001b[A\n",
      "Epoch 9:  21%|██        | 31/148 [00:27<01:44,  1.12it/s, training_loss=1.0858]\u001b[A\n",
      "Epoch 9:  21%|██        | 31/148 [00:28<01:44,  1.12it/s, training_loss=1.1235]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 32/148 [00:28<01:44,  1.11it/s, training_loss=1.1235]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 32/148 [00:29<01:44,  1.11it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 33/148 [00:29<01:43,  1.11it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 33/148 [00:30<01:43,  1.11it/s, training_loss=1.6101]\u001b[A\n",
      "Epoch 9:  23%|██▎       | 34/148 [00:30<01:42,  1.11it/s, training_loss=1.6101]\u001b[A\n",
      "Epoch 9:  23%|██▎       | 34/148 [00:31<01:42,  1.11it/s, training_loss=0.9180]\u001b[A\n",
      "Epoch 9:  24%|██▎       | 35/148 [00:31<01:41,  1.11it/s, training_loss=0.9180]\u001b[A\n",
      "Epoch 9:  24%|██▎       | 35/148 [00:32<01:41,  1.11it/s, training_loss=1.5618]\u001b[A\n",
      "Epoch 9:  24%|██▍       | 36/148 [00:32<01:40,  1.11it/s, training_loss=1.5618]\u001b[A\n",
      "Epoch 9:  24%|██▍       | 36/148 [00:33<01:40,  1.11it/s, training_loss=0.8761]\u001b[A\n",
      "Epoch 9:  25%|██▌       | 37/148 [00:33<01:39,  1.11it/s, training_loss=0.8761]\u001b[A\n",
      "Epoch 9:  25%|██▌       | 37/148 [00:34<01:39,  1.11it/s, training_loss=1.5095]\u001b[A\n",
      "Epoch 9:  26%|██▌       | 38/148 [00:34<01:38,  1.11it/s, training_loss=1.5095]\u001b[A\n",
      "Epoch 9:  26%|██▌       | 38/148 [00:35<01:38,  1.11it/s, training_loss=1.5683]\u001b[A\n",
      "Epoch 9:  26%|██▋       | 39/148 [00:35<01:37,  1.11it/s, training_loss=1.5683]\u001b[A\n",
      "Epoch 9:  26%|██▋       | 39/148 [00:35<01:37,  1.11it/s, training_loss=1.0591]\u001b[A\n",
      "Epoch 9:  27%|██▋       | 40/148 [00:35<01:37,  1.11it/s, training_loss=1.0591]\u001b[A\n",
      "Epoch 9:  27%|██▋       | 40/148 [00:36<01:37,  1.11it/s, training_loss=0.9660]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 41/148 [00:36<01:36,  1.11it/s, training_loss=0.9660]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 41/148 [00:37<01:36,  1.11it/s, training_loss=0.8580]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 42/148 [00:37<01:35,  1.11it/s, training_loss=0.8580]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 42/148 [00:38<01:35,  1.11it/s, training_loss=0.9110]\u001b[A\n",
      "Epoch 9:  29%|██▉       | 43/148 [00:38<01:34,  1.11it/s, training_loss=0.9110]\u001b[A\n",
      "Epoch 9:  29%|██▉       | 43/148 [00:39<01:34,  1.11it/s, training_loss=1.6203]\u001b[A\n",
      "Epoch 9:  30%|██▉       | 44/148 [00:39<01:33,  1.11it/s, training_loss=1.6203]\u001b[A\n",
      "Epoch 9:  30%|██▉       | 44/148 [00:40<01:33,  1.11it/s, training_loss=1.0522]\u001b[A\n",
      "Epoch 9:  30%|███       | 45/148 [00:40<01:32,  1.12it/s, training_loss=1.0522]\u001b[A\n",
      "Epoch 9:  30%|███       | 45/148 [00:41<01:32,  1.12it/s, training_loss=0.8490]\u001b[A\n",
      "Epoch 9:  31%|███       | 46/148 [00:41<01:31,  1.11it/s, training_loss=0.8490]\u001b[A\n",
      "Epoch 9:  31%|███       | 46/148 [00:42<01:31,  1.11it/s, training_loss=1.5537]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 47/148 [00:42<01:30,  1.11it/s, training_loss=1.5537]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 47/148 [00:43<01:30,  1.11it/s, training_loss=1.5431]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 48/148 [00:43<01:29,  1.11it/s, training_loss=1.5431]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 48/148 [00:44<01:29,  1.11it/s, training_loss=0.9509]\u001b[A\n",
      "Epoch 9:  33%|███▎      | 49/148 [00:44<01:29,  1.11it/s, training_loss=0.9509]\u001b[A\n",
      "Epoch 9:  33%|███▎      | 49/148 [00:44<01:29,  1.11it/s, training_loss=0.8753]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 50/148 [00:45<01:28,  1.10it/s, training_loss=0.8753]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 50/148 [00:45<01:28,  1.10it/s, training_loss=1.1006]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 51/148 [00:45<01:27,  1.10it/s, training_loss=1.1006]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 51/148 [00:46<01:27,  1.10it/s, training_loss=1.0192]\u001b[A\n",
      "Epoch 9:  35%|███▌      | 52/148 [00:46<01:26,  1.11it/s, training_loss=1.0192]\u001b[A\n",
      "Epoch 9:  35%|███▌      | 52/148 [00:47<01:26,  1.11it/s, training_loss=1.6688]\u001b[A\n",
      "Epoch 9:  36%|███▌      | 53/148 [00:47<01:25,  1.11it/s, training_loss=1.6688]\u001b[A\n",
      "Epoch 9:  36%|███▌      | 53/148 [00:48<01:25,  1.11it/s, training_loss=0.8304]\u001b[A\n",
      "Epoch 9:  36%|███▋      | 54/148 [00:48<01:24,  1.11it/s, training_loss=0.8304]\u001b[A\n",
      "Epoch 9:  36%|███▋      | 54/148 [00:49<01:24,  1.11it/s, training_loss=1.4451]\u001b[A\n",
      "Epoch 9:  37%|███▋      | 55/148 [00:49<01:23,  1.11it/s, training_loss=1.4451]\u001b[A\n",
      "Epoch 9:  37%|███▋      | 55/148 [00:50<01:23,  1.11it/s, training_loss=1.5698]\u001b[A\n",
      "Epoch 9:  38%|███▊      | 56/148 [00:50<01:22,  1.11it/s, training_loss=1.5698]\u001b[A\n",
      "Epoch 9:  38%|███▊      | 56/148 [00:51<01:22,  1.11it/s, training_loss=0.8747]\u001b[A\n",
      "Epoch 9:  39%|███▊      | 57/148 [00:51<01:21,  1.11it/s, training_loss=0.8747]\u001b[A\n",
      "Epoch 9:  39%|███▊      | 57/148 [00:52<01:21,  1.11it/s, training_loss=1.5035]\u001b[A\n",
      "Epoch 9:  39%|███▉      | 58/148 [00:52<01:20,  1.11it/s, training_loss=1.5035]\u001b[A\n",
      "Epoch 9:  39%|███▉      | 58/148 [00:53<01:20,  1.11it/s, training_loss=0.8778]\u001b[A\n",
      "Epoch 9:  40%|███▉      | 59/148 [00:53<01:20,  1.11it/s, training_loss=0.8778]\u001b[A\n",
      "Epoch 9:  40%|███▉      | 59/148 [00:53<01:20,  1.11it/s, training_loss=0.9364]\u001b[A\n",
      "Epoch 9:  41%|████      | 60/148 [00:54<01:19,  1.11it/s, training_loss=0.9364]\u001b[A\n",
      "Epoch 9:  41%|████      | 60/148 [00:54<01:19,  1.11it/s, training_loss=1.6910]\u001b[A\n",
      "Epoch 9:  41%|████      | 61/148 [00:54<01:18,  1.11it/s, training_loss=1.6910]\u001b[A\n",
      "Epoch 9:  41%|████      | 61/148 [00:55<01:18,  1.11it/s, training_loss=0.8126]\u001b[A\n",
      "Epoch 9:  42%|████▏     | 62/148 [00:55<01:17,  1.11it/s, training_loss=0.8126]\u001b[A\n",
      "Epoch 9:  42%|████▏     | 62/148 [00:56<01:17,  1.11it/s, training_loss=1.0545]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 63/148 [00:56<01:16,  1.11it/s, training_loss=1.0545]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 63/148 [00:57<01:16,  1.11it/s, training_loss=0.8750]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 64/148 [00:57<01:15,  1.11it/s, training_loss=0.8750]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 64/148 [00:58<01:15,  1.11it/s, training_loss=1.4522]\u001b[A\n",
      "Epoch 9:  44%|████▍     | 65/148 [00:58<01:14,  1.11it/s, training_loss=1.4522]\u001b[A\n",
      "Epoch 9:  44%|████▍     | 65/148 [00:59<01:14,  1.11it/s, training_loss=0.8742]\u001b[A\n",
      "Epoch 9:  45%|████▍     | 66/148 [00:59<01:13,  1.11it/s, training_loss=0.8742]\u001b[A\n",
      "Epoch 9:  45%|████▍     | 66/148 [01:00<01:13,  1.11it/s, training_loss=1.5267]\u001b[A\n",
      "Epoch 9:  45%|████▌     | 67/148 [01:00<01:12,  1.11it/s, training_loss=1.5267]\u001b[A\n",
      "Epoch 9:  45%|████▌     | 67/148 [01:01<01:12,  1.11it/s, training_loss=1.0890]\u001b[A\n",
      "Epoch 9:  46%|████▌     | 68/148 [01:01<01:12,  1.11it/s, training_loss=1.0890]\u001b[A\n",
      "Epoch 9:  46%|████▌     | 68/148 [01:02<01:12,  1.11it/s, training_loss=1.5284]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 69/148 [01:02<01:11,  1.11it/s, training_loss=1.5284]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 69/148 [01:03<01:11,  1.11it/s, training_loss=1.0193]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 70/148 [01:03<01:10,  1.11it/s, training_loss=1.0193]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 70/148 [01:03<01:10,  1.11it/s, training_loss=1.0271]\u001b[A\n",
      "Epoch 9:  48%|████▊     | 71/148 [01:03<01:09,  1.11it/s, training_loss=1.0271]\u001b[A\n",
      "Epoch 9:  48%|████▊     | 71/148 [01:04<01:09,  1.11it/s, training_loss=1.0440]\u001b[A\n",
      "Epoch 9:  49%|████▊     | 72/148 [01:04<01:08,  1.11it/s, training_loss=1.0440]\u001b[A\n",
      "Epoch 9:  49%|████▊     | 72/148 [01:05<01:08,  1.11it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 9:  49%|████▉     | 73/148 [01:05<01:07,  1.12it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 9:  49%|████▉     | 73/148 [01:06<01:07,  1.12it/s, training_loss=0.8402]\u001b[A\n",
      "Epoch 9:  50%|█████     | 74/148 [01:06<01:06,  1.11it/s, training_loss=0.8402]\u001b[A\n",
      "Epoch 9:  50%|█████     | 74/148 [01:07<01:06,  1.11it/s, training_loss=1.4224]\u001b[A\n",
      "Epoch 9:  51%|█████     | 75/148 [01:07<01:05,  1.11it/s, training_loss=1.4224]\u001b[A\n",
      "Epoch 9:  51%|█████     | 75/148 [01:08<01:05,  1.11it/s, training_loss=1.5635]\u001b[A\n",
      "Epoch 9:  51%|█████▏    | 76/148 [01:08<01:04,  1.11it/s, training_loss=1.5635]\u001b[A\n",
      "Epoch 9:  51%|█████▏    | 76/148 [01:09<01:04,  1.11it/s, training_loss=0.9123]\u001b[A\n",
      "Epoch 9:  52%|█████▏    | 77/148 [01:09<01:03,  1.11it/s, training_loss=0.9123]\u001b[A\n",
      "Epoch 9:  52%|█████▏    | 77/148 [01:10<01:03,  1.11it/s, training_loss=1.6182]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 78/148 [01:10<01:03,  1.11it/s, training_loss=1.6182]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 78/148 [01:11<01:03,  1.11it/s, training_loss=1.6577]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 79/148 [01:11<01:01,  1.11it/s, training_loss=1.6577]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 79/148 [01:11<01:01,  1.11it/s, training_loss=1.5078]\u001b[A\n",
      "Epoch 9:  54%|█████▍    | 80/148 [01:11<01:00,  1.11it/s, training_loss=1.5078]\u001b[A\n",
      "Epoch 9:  54%|█████▍    | 80/148 [01:12<01:00,  1.11it/s, training_loss=0.9022]\u001b[A\n",
      "Epoch 9:  55%|█████▍    | 81/148 [01:12<01:00,  1.11it/s, training_loss=0.9022]\u001b[A\n",
      "Epoch 9:  55%|█████▍    | 81/148 [01:13<01:00,  1.11it/s, training_loss=0.8737]\u001b[A\n",
      "Epoch 9:  55%|█████▌    | 82/148 [01:13<00:59,  1.11it/s, training_loss=0.8737]\u001b[A\n",
      "Epoch 9:  55%|█████▌    | 82/148 [01:14<00:59,  1.11it/s, training_loss=1.5618]\u001b[A\n",
      "Epoch 9:  56%|█████▌    | 83/148 [01:14<00:58,  1.11it/s, training_loss=1.5618]\u001b[A\n",
      "Epoch 9:  56%|█████▌    | 83/148 [01:15<00:58,  1.11it/s, training_loss=1.6300]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 84/148 [01:15<00:57,  1.12it/s, training_loss=1.6300]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 84/148 [01:16<00:57,  1.12it/s, training_loss=0.9116]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 85/148 [01:16<00:56,  1.11it/s, training_loss=0.9116]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 85/148 [01:17<00:56,  1.11it/s, training_loss=0.9518]\u001b[A\n",
      "Epoch 9:  58%|█████▊    | 86/148 [01:17<00:56,  1.11it/s, training_loss=0.9518]\u001b[A\n",
      "Epoch 9:  58%|█████▊    | 86/148 [01:18<00:56,  1.11it/s, training_loss=1.5321]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 87/148 [01:18<00:54,  1.11it/s, training_loss=1.5321]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 87/148 [01:19<00:54,  1.11it/s, training_loss=0.8746]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 88/148 [01:19<00:54,  1.11it/s, training_loss=0.8746]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 88/148 [01:20<00:54,  1.11it/s, training_loss=1.5907]\u001b[A\n",
      "Epoch 9:  60%|██████    | 89/148 [01:20<00:53,  1.11it/s, training_loss=1.5907]\u001b[A\n",
      "Epoch 9:  60%|██████    | 89/148 [01:21<00:53,  1.11it/s, training_loss=1.0143]\u001b[A\n",
      "Epoch 9:  61%|██████    | 90/148 [01:21<00:52,  1.11it/s, training_loss=1.0143]\u001b[A\n",
      "Epoch 9:  61%|██████    | 90/148 [01:21<00:52,  1.11it/s, training_loss=0.8515]\u001b[A\n",
      "Epoch 9:  61%|██████▏   | 91/148 [01:21<00:51,  1.11it/s, training_loss=0.8515]\u001b[A\n",
      "Epoch 9:  61%|██████▏   | 91/148 [01:22<00:51,  1.11it/s, training_loss=1.0643]\u001b[A\n",
      "Epoch 9:  62%|██████▏   | 92/148 [01:22<00:50,  1.11it/s, training_loss=1.0643]\u001b[A\n",
      "Epoch 9:  62%|██████▏   | 92/148 [01:23<00:50,  1.11it/s, training_loss=0.9526]\u001b[A\n",
      "Epoch 9:  63%|██████▎   | 93/148 [01:23<00:49,  1.11it/s, training_loss=0.9526]\u001b[A\n",
      "Epoch 9:  63%|██████▎   | 93/148 [01:24<00:49,  1.11it/s, training_loss=1.5196]\u001b[A\n",
      "Epoch 9:  64%|██████▎   | 94/148 [01:24<00:48,  1.11it/s, training_loss=1.5196]\u001b[A\n",
      "Epoch 9:  64%|██████▎   | 94/148 [01:25<00:48,  1.11it/s, training_loss=1.0312]\u001b[A\n",
      "Epoch 9:  64%|██████▍   | 95/148 [01:25<00:47,  1.11it/s, training_loss=1.0312]\u001b[A\n",
      "Epoch 9:  64%|██████▍   | 95/148 [01:26<00:47,  1.11it/s, training_loss=1.5458]\u001b[A\n",
      "Epoch 9:  65%|██████▍   | 96/148 [01:26<00:46,  1.11it/s, training_loss=1.5458]\u001b[A\n",
      "Epoch 9:  65%|██████▍   | 96/148 [01:27<00:46,  1.11it/s, training_loss=1.0658]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 97/148 [01:27<00:46,  1.11it/s, training_loss=1.0658]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 97/148 [01:28<00:46,  1.11it/s, training_loss=1.0063]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 98/148 [01:28<00:45,  1.11it/s, training_loss=1.0063]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 98/148 [01:29<00:45,  1.11it/s, training_loss=0.9178]\u001b[A\n",
      "Epoch 9:  67%|██████▋   | 99/148 [01:29<00:44,  1.11it/s, training_loss=0.9178]\u001b[A\n",
      "Epoch 9:  67%|██████▋   | 99/148 [01:30<00:44,  1.11it/s, training_loss=1.5301]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 100/148 [01:30<00:43,  1.11it/s, training_loss=1.5301]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 100/148 [01:30<00:43,  1.11it/s, training_loss=1.5789]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 101/148 [01:30<00:42,  1.11it/s, training_loss=1.5789]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 101/148 [01:31<00:42,  1.11it/s, training_loss=1.6470]\u001b[A\n",
      "Epoch 9:  69%|██████▉   | 102/148 [01:31<00:41,  1.11it/s, training_loss=1.6470]\u001b[A\n",
      "Epoch 9:  69%|██████▉   | 102/148 [01:32<00:41,  1.11it/s, training_loss=0.8577]\u001b[A\n",
      "Epoch 9:  70%|██████▉   | 103/148 [01:32<00:40,  1.11it/s, training_loss=0.8577]\u001b[A\n",
      "Epoch 9:  70%|██████▉   | 103/148 [01:33<00:40,  1.11it/s, training_loss=1.0843]\u001b[A\n",
      "Epoch 9:  70%|███████   | 104/148 [01:33<00:39,  1.11it/s, training_loss=1.0843]\u001b[A\n",
      "Epoch 9:  70%|███████   | 104/148 [01:34<00:39,  1.11it/s, training_loss=1.5671]\u001b[A\n",
      "Epoch 9:  71%|███████   | 105/148 [01:34<00:38,  1.11it/s, training_loss=1.5671]\u001b[A\n",
      "Epoch 9:  71%|███████   | 105/148 [01:35<00:38,  1.11it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 106/148 [01:35<00:37,  1.11it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 106/148 [01:36<00:37,  1.11it/s, training_loss=1.0371]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 107/148 [01:36<00:36,  1.11it/s, training_loss=1.0371]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 107/148 [01:37<00:36,  1.11it/s, training_loss=0.8075]\u001b[A\n",
      "Epoch 9:  73%|███████▎  | 108/148 [01:37<00:35,  1.11it/s, training_loss=0.8075]\u001b[A\n",
      "Epoch 9:  73%|███████▎  | 108/148 [01:38<00:35,  1.11it/s, training_loss=1.0037]\u001b[A\n",
      "Epoch 9:  74%|███████▎  | 109/148 [01:38<00:35,  1.11it/s, training_loss=1.0037]\u001b[A\n",
      "Epoch 9:  74%|███████▎  | 109/148 [01:39<00:35,  1.11it/s, training_loss=1.0127]\u001b[A\n",
      "Epoch 9:  74%|███████▍  | 110/148 [01:39<00:34,  1.11it/s, training_loss=1.0127]\u001b[A\n",
      "Epoch 9:  74%|███████▍  | 110/148 [01:39<00:34,  1.11it/s, training_loss=1.4271]\u001b[A\n",
      "Epoch 9:  75%|███████▌  | 111/148 [01:39<00:33,  1.11it/s, training_loss=1.4271]\u001b[A\n",
      "Epoch 9:  75%|███████▌  | 111/148 [01:40<00:33,  1.11it/s, training_loss=1.0020]\u001b[A\n",
      "Epoch 9:  76%|███████▌  | 112/148 [01:40<00:32,  1.11it/s, training_loss=1.0020]\u001b[A\n",
      "Epoch 9:  76%|███████▌  | 112/148 [01:41<00:32,  1.11it/s, training_loss=0.8658]\u001b[A\n",
      "Epoch 9:  76%|███████▋  | 113/148 [01:41<00:31,  1.11it/s, training_loss=0.8658]\u001b[A\n",
      "Epoch 9:  76%|███████▋  | 113/148 [01:42<00:31,  1.11it/s, training_loss=0.8590]\u001b[A\n",
      "Epoch 9:  77%|███████▋  | 114/148 [01:42<00:30,  1.11it/s, training_loss=0.8590]\u001b[A\n",
      "Epoch 9:  77%|███████▋  | 114/148 [01:43<00:30,  1.11it/s, training_loss=1.5922]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 115/148 [01:43<00:29,  1.11it/s, training_loss=1.5922]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 115/148 [01:44<00:29,  1.11it/s, training_loss=0.8412]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 116/148 [01:44<00:28,  1.11it/s, training_loss=0.8412]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 116/148 [01:45<00:28,  1.11it/s, training_loss=1.4920]\u001b[A\n",
      "Epoch 9:  79%|███████▉  | 117/148 [01:45<00:27,  1.11it/s, training_loss=1.4920]\u001b[A\n",
      "Epoch 9:  79%|███████▉  | 117/148 [01:46<00:27,  1.11it/s, training_loss=0.9697]\u001b[A\n",
      "Epoch 9:  80%|███████▉  | 118/148 [01:46<00:27,  1.11it/s, training_loss=0.9697]\u001b[A\n",
      "Epoch 9:  80%|███████▉  | 118/148 [01:47<00:27,  1.11it/s, training_loss=1.5837]\u001b[A\n",
      "Epoch 9:  80%|████████  | 119/148 [01:47<00:26,  1.11it/s, training_loss=1.5837]\u001b[A\n",
      "Epoch 9:  80%|████████  | 119/148 [01:48<00:26,  1.11it/s, training_loss=0.9730]\u001b[A\n",
      "Epoch 9:  81%|████████  | 120/148 [01:48<00:25,  1.11it/s, training_loss=0.9730]\u001b[A\n",
      "Epoch 9:  81%|████████  | 120/148 [01:48<00:25,  1.11it/s, training_loss=1.1091]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 121/148 [01:48<00:24,  1.10it/s, training_loss=1.1091]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 121/148 [01:49<00:24,  1.10it/s, training_loss=1.5238]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 122/148 [01:49<00:23,  1.11it/s, training_loss=1.5238]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 122/148 [01:50<00:23,  1.11it/s, training_loss=1.5057]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 123/148 [01:50<00:22,  1.11it/s, training_loss=1.5057]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 123/148 [01:51<00:22,  1.11it/s, training_loss=0.9767]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 124/148 [01:51<00:21,  1.10it/s, training_loss=0.9767]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 124/148 [01:52<00:21,  1.10it/s, training_loss=1.5480]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 125/148 [01:52<00:20,  1.11it/s, training_loss=1.5480]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 125/148 [01:53<00:20,  1.11it/s, training_loss=0.9144]\u001b[A\n",
      "Epoch 9:  85%|████████▌ | 126/148 [01:53<00:19,  1.11it/s, training_loss=0.9144]\u001b[A\n",
      "Epoch 9:  85%|████████▌ | 126/148 [01:54<00:19,  1.11it/s, training_loss=1.5292]\u001b[A\n",
      "Epoch 9:  86%|████████▌ | 127/148 [01:54<00:18,  1.11it/s, training_loss=1.5292]\u001b[A\n",
      "Epoch 9:  86%|████████▌ | 127/148 [01:55<00:18,  1.11it/s, training_loss=1.5198]\u001b[A\n",
      "Epoch 9:  86%|████████▋ | 128/148 [01:55<00:18,  1.11it/s, training_loss=1.5198]\u001b[A\n",
      "Epoch 9:  86%|████████▋ | 128/148 [01:56<00:18,  1.11it/s, training_loss=1.3160]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 129/148 [01:56<00:17,  1.11it/s, training_loss=1.3160]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 129/148 [01:57<00:17,  1.11it/s, training_loss=1.6112]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 130/148 [01:57<00:16,  1.11it/s, training_loss=1.6112]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 130/148 [01:57<00:16,  1.11it/s, training_loss=1.5165]\u001b[A\n",
      "Epoch 9:  89%|████████▊ | 131/148 [01:57<00:15,  1.11it/s, training_loss=1.5165]\u001b[A\n",
      "Epoch 9:  89%|████████▊ | 131/148 [01:58<00:15,  1.11it/s, training_loss=0.9440]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 132/148 [01:58<00:14,  1.11it/s, training_loss=0.9440]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 132/148 [01:59<00:14,  1.11it/s, training_loss=1.4971]\u001b[A\n",
      "Epoch 9:  90%|████████▉ | 133/148 [01:59<00:13,  1.11it/s, training_loss=1.4971]\u001b[A\n",
      "Epoch 9:  90%|████████▉ | 133/148 [02:00<00:13,  1.11it/s, training_loss=0.9536]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 134/148 [02:00<00:12,  1.11it/s, training_loss=0.9536]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 134/148 [02:01<00:12,  1.11it/s, training_loss=0.8425]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 135/148 [02:01<00:11,  1.11it/s, training_loss=0.8425]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 135/148 [02:02<00:11,  1.11it/s, training_loss=1.4885]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 136/148 [02:02<00:10,  1.11it/s, training_loss=1.4885]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 136/148 [02:03<00:10,  1.11it/s, training_loss=1.6490]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 137/148 [02:03<00:09,  1.11it/s, training_loss=1.6490]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 137/148 [02:04<00:09,  1.11it/s, training_loss=1.4948]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 138/148 [02:04<00:09,  1.11it/s, training_loss=1.4948]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 138/148 [02:05<00:09,  1.11it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 139/148 [02:05<00:08,  1.11it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 139/148 [02:06<00:08,  1.11it/s, training_loss=0.9472]\u001b[A\n",
      "Epoch 9:  95%|█████████▍| 140/148 [02:06<00:07,  1.11it/s, training_loss=0.9472]\u001b[A\n",
      "Epoch 9:  95%|█████████▍| 140/148 [02:06<00:07,  1.11it/s, training_loss=1.5333]\u001b[A\n",
      "Epoch 9:  95%|█████████▌| 141/148 [02:06<00:06,  1.11it/s, training_loss=1.5333]\u001b[A\n",
      "Epoch 9:  95%|█████████▌| 141/148 [02:07<00:06,  1.11it/s, training_loss=1.5179]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 142/148 [02:07<00:05,  1.11it/s, training_loss=1.5179]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 142/148 [02:08<00:05,  1.11it/s, training_loss=1.5171]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 143/148 [02:08<00:04,  1.12it/s, training_loss=1.5171]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 143/148 [02:09<00:04,  1.12it/s, training_loss=1.5128]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 144/148 [02:09<00:03,  1.12it/s, training_loss=1.5128]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 144/148 [02:10<00:03,  1.12it/s, training_loss=1.5384]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 145/148 [02:10<00:02,  1.12it/s, training_loss=1.5384]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 145/148 [02:11<00:02,  1.12it/s, training_loss=0.8874]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 146/148 [02:11<00:01,  1.12it/s, training_loss=0.8874]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 146/148 [02:12<00:01,  1.12it/s, training_loss=1.5812]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 147/148 [02:12<00:00,  1.11it/s, training_loss=1.5812]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 147/148 [02:13<00:00,  1.11it/s, training_loss=0.8492]\u001b[A\n",
      "Epoch 9: 100%|██████████| 148/148 [02:13<00:00,  1.21it/s, training_loss=0.8492]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:10:15,910 - INFO - Starting model evaluation...\n",
      "2025-02-19 11:10:15,911 - INFO - Memory usage after evaluation start: 4034.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.71it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.71it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.66it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.66it/s, Accuracy=71.33%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.65it/s, Accuracy=71.33%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.65it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.62it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.62it/s, Accuracy=71.60%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.61it/s, Accuracy=71.60%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.61it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.61it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.61it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.59it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.59it/s, Accuracy=68.50%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.59it/s, Accuracy=68.50%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.59it/s, Accuracy=68.22%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.58it/s, Accuracy=68.22%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.58it/s, Accuracy=68.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.60it/s, Accuracy=68.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.60it/s, Accuracy=68.18%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.61it/s, Accuracy=68.18%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.61it/s, Accuracy=68.83%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.62it/s, Accuracy=68.83%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.62it/s, Accuracy=68.62%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.63it/s, Accuracy=68.62%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.63it/s, Accuracy=68.86%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.62it/s, Accuracy=68.86%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.62it/s, Accuracy=68.80%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.63it/s, Accuracy=68.80%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.63it/s, Accuracy=68.25%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.63it/s, Accuracy=68.25%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.63it/s, Accuracy=68.12%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.62it/s, Accuracy=68.12%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.62it/s, Accuracy=68.89%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.63it/s, Accuracy=68.89%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.63it/s, Accuracy=69.16%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.63it/s, Accuracy=69.16%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.63it/s, Accuracy=69.60%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.63it/s, Accuracy=69.60%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.63it/s, Accuracy=69.81%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.63it/s, Accuracy=69.81%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.63it/s, Accuracy=69.82%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.63it/s, Accuracy=69.82%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.63it/s, Accuracy=70.26%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.63it/s, Accuracy=70.26%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.63it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.62it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.62it/s, Accuracy=70.08%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.62it/s, Accuracy=70.08%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.62it/s, Accuracy=70.23%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.62it/s, Accuracy=70.23%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.74it/s, Accuracy=70.27%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:10:23,136 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 11:10:23,141 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 11:10:23,142 - INFO - Accuracy: 0.6513\n",
      "2025-02-19 11:10:23,143 - INFO - F1_score: 0.5604\n",
      "2025-02-19 11:10:23,143 - INFO - Precision: 0.4361\n",
      "2025-02-19 11:10:23,144 - INFO - Recall: 0.7838\n",
      "2025-02-19 11:10:23,151 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 11:10:23,151 - INFO - Accuracy: 0.8506\n",
      "2025-02-19 11:10:23,152 - INFO - F1_score: 0.7234\n",
      "2025-02-19 11:10:23,153 - INFO - Precision: 0.6071\n",
      "2025-02-19 11:10:23,154 - INFO - Recall: 0.8947\n",
      "2025-02-19 11:10:23,160 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 11:10:23,160 - INFO - Accuracy: 0.5785\n",
      "2025-02-19 11:10:23,161 - INFO - F1_score: 0.4660\n",
      "2025-02-19 11:10:23,162 - INFO - Precision: 0.3243\n",
      "2025-02-19 11:10:23,163 - INFO - Recall: 0.8276\n",
      "2025-02-19 11:10:23,170 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 11:10:23,170 - INFO - Accuracy: 0.6667\n",
      "2025-02-19 11:10:23,171 - INFO - F1_score: 0.3459\n",
      "2025-02-19 11:10:23,171 - INFO - Precision: 0.2421\n",
      "2025-02-19 11:10:23,172 - INFO - Recall: 0.6053\n",
      "2025-02-19 11:10:23,178 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 11:10:23,179 - INFO - Accuracy: 0.7663\n",
      "2025-02-19 11:10:23,179 - INFO - F1_score: 0.4190\n",
      "2025-02-19 11:10:23,180 - INFO - Precision: 0.3099\n",
      "2025-02-19 11:10:23,181 - INFO - Recall: 0.6471\n",
      "2025-02-19 11:10:23,183 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:10:27,063 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 11:10:27,064 - INFO - Memory usage after evaluation end: 4040.53 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 8/100 [23:12<3:56:39, 154.34s/it, Train Loss=1.2364, Val Loss=0.0523, Accuracy=0.7027]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:10:34,166 - INFO - Learning rate: 2.5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [23:12<3:52:38, 153.38s/it, Train Loss=1.2364, Val Loss=0.0523, Accuracy=0.7027]\n",
      "Epoch 10:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.1094]\u001b[A\n",
      "Epoch 10:   1%|          | 1/148 [00:00<02:11,  1.12it/s, training_loss=1.1094]\u001b[A\n",
      "Epoch 10:   1%|          | 1/148 [00:01<02:11,  1.12it/s, training_loss=1.0440]\u001b[A\n",
      "Epoch 10:   1%|▏         | 2/148 [00:01<02:10,  1.12it/s, training_loss=1.0440]\u001b[A\n",
      "Epoch 10:   1%|▏         | 2/148 [00:02<02:10,  1.12it/s, training_loss=0.9161]\u001b[A\n",
      "Epoch 10:   2%|▏         | 3/148 [00:02<02:09,  1.12it/s, training_loss=0.9161]\u001b[A\n",
      "Epoch 10:   2%|▏         | 3/148 [00:03<02:09,  1.12it/s, training_loss=1.6043]\u001b[A\n",
      "Epoch 10:   3%|▎         | 4/148 [00:03<02:08,  1.12it/s, training_loss=1.6043]\u001b[A\n",
      "Epoch 10:   3%|▎         | 4/148 [00:04<02:08,  1.12it/s, training_loss=0.9361]\u001b[A\n",
      "Epoch 10:   3%|▎         | 5/148 [00:04<02:08,  1.11it/s, training_loss=0.9361]\u001b[A\n",
      "Epoch 10:   3%|▎         | 5/148 [00:05<02:08,  1.11it/s, training_loss=1.0480]\u001b[A\n",
      "Epoch 10:   4%|▍         | 6/148 [00:05<02:07,  1.11it/s, training_loss=1.0480]\u001b[A\n",
      "Epoch 10:   4%|▍         | 6/148 [00:06<02:07,  1.11it/s, training_loss=0.9936]\u001b[A\n",
      "Epoch 10:   5%|▍         | 7/148 [00:06<02:06,  1.11it/s, training_loss=0.9936]\u001b[A\n",
      "Epoch 10:   5%|▍         | 7/148 [00:07<02:06,  1.11it/s, training_loss=0.8380]\u001b[A\n",
      "Epoch 10:   5%|▌         | 8/148 [00:07<02:05,  1.11it/s, training_loss=0.8380]\u001b[A\n",
      "Epoch 10:   5%|▌         | 8/148 [00:08<02:05,  1.11it/s, training_loss=0.9258]\u001b[A\n",
      "Epoch 10:   6%|▌         | 9/148 [00:08<02:05,  1.11it/s, training_loss=0.9258]\u001b[A\n",
      "Epoch 10:   6%|▌         | 9/148 [00:08<02:05,  1.11it/s, training_loss=0.9014]\u001b[A\n",
      "Epoch 10:   7%|▋         | 10/148 [00:08<02:04,  1.11it/s, training_loss=0.9014]\u001b[A\n",
      "Epoch 10:   7%|▋         | 10/148 [00:09<02:04,  1.11it/s, training_loss=1.5374]\u001b[A\n",
      "Epoch 10:   7%|▋         | 11/148 [00:09<02:03,  1.11it/s, training_loss=1.5374]\u001b[A\n",
      "Epoch 10:   7%|▋         | 11/148 [00:10<02:03,  1.11it/s, training_loss=1.6747]\u001b[A\n",
      "Epoch 10:   8%|▊         | 12/148 [00:10<02:01,  1.12it/s, training_loss=1.6747]\u001b[A\n",
      "Epoch 10:   8%|▊         | 12/148 [00:11<02:01,  1.12it/s, training_loss=1.3172]\u001b[A\n",
      "Epoch 10:   9%|▉         | 13/148 [00:11<02:00,  1.12it/s, training_loss=1.3172]\u001b[A\n",
      "Epoch 10:   9%|▉         | 13/148 [00:12<02:00,  1.12it/s, training_loss=1.6100]\u001b[A\n",
      "Epoch 10:   9%|▉         | 14/148 [00:12<01:59,  1.12it/s, training_loss=1.6100]\u001b[A\n",
      "Epoch 10:   9%|▉         | 14/148 [00:13<01:59,  1.12it/s, training_loss=0.9942]\u001b[A\n",
      "Epoch 10:  10%|█         | 15/148 [00:13<01:59,  1.12it/s, training_loss=0.9942]\u001b[A\n",
      "Epoch 10:  10%|█         | 15/148 [00:14<01:59,  1.12it/s, training_loss=0.9781]\u001b[A\n",
      "Epoch 10:  11%|█         | 16/148 [00:14<01:58,  1.11it/s, training_loss=0.9781]\u001b[A\n",
      "Epoch 10:  11%|█         | 16/148 [00:15<01:58,  1.11it/s, training_loss=1.6843]\u001b[A\n",
      "Epoch 10:  11%|█▏        | 17/148 [00:15<01:57,  1.11it/s, training_loss=1.6843]\u001b[A\n",
      "Epoch 10:  11%|█▏        | 17/148 [00:16<01:57,  1.11it/s, training_loss=1.4234]\u001b[A\n",
      "Epoch 10:  12%|█▏        | 18/148 [00:16<01:56,  1.11it/s, training_loss=1.4234]\u001b[A\n",
      "Epoch 10:  12%|█▏        | 18/148 [00:17<01:56,  1.11it/s, training_loss=1.6188]\u001b[A\n",
      "Epoch 10:  13%|█▎        | 19/148 [00:17<01:56,  1.11it/s, training_loss=1.6188]\u001b[A\n",
      "Epoch 10:  13%|█▎        | 19/148 [00:17<01:56,  1.11it/s, training_loss=0.8436]\u001b[A\n",
      "Epoch 10:  14%|█▎        | 20/148 [00:17<01:55,  1.11it/s, training_loss=0.8436]\u001b[A\n",
      "Epoch 10:  14%|█▎        | 20/148 [00:18<01:55,  1.11it/s, training_loss=1.5615]\u001b[A\n",
      "Epoch 10:  14%|█▍        | 21/148 [00:18<01:54,  1.11it/s, training_loss=1.5615]\u001b[A\n",
      "Epoch 10:  14%|█▍        | 21/148 [00:19<01:54,  1.11it/s, training_loss=0.8831]\u001b[A\n",
      "Epoch 10:  15%|█▍        | 22/148 [00:19<01:53,  1.11it/s, training_loss=0.8831]\u001b[A\n",
      "Epoch 10:  15%|█▍        | 22/148 [00:20<01:53,  1.11it/s, training_loss=0.8249]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 23/148 [00:20<01:52,  1.11it/s, training_loss=0.8249]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 23/148 [00:21<01:52,  1.11it/s, training_loss=0.8888]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 24/148 [00:21<01:51,  1.11it/s, training_loss=0.8888]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 24/148 [00:22<01:51,  1.11it/s, training_loss=0.8602]\u001b[A\n",
      "Epoch 10:  17%|█▋        | 25/148 [00:22<01:50,  1.11it/s, training_loss=0.8602]\u001b[A\n",
      "Epoch 10:  17%|█▋        | 25/148 [00:23<01:50,  1.11it/s, training_loss=1.6116]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 26/148 [00:23<01:49,  1.11it/s, training_loss=1.6116]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 26/148 [00:24<01:49,  1.11it/s, training_loss=0.8596]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 27/148 [00:24<01:48,  1.11it/s, training_loss=0.8596]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 27/148 [00:25<01:48,  1.11it/s, training_loss=0.8794]\u001b[A\n",
      "Epoch 10:  19%|█▉        | 28/148 [00:25<01:48,  1.11it/s, training_loss=0.8794]\u001b[A\n",
      "Epoch 10:  19%|█▉        | 28/148 [00:26<01:48,  1.11it/s, training_loss=0.9425]\u001b[A\n",
      "Epoch 10:  20%|█▉        | 29/148 [00:26<01:47,  1.11it/s, training_loss=0.9425]\u001b[A\n",
      "Epoch 10:  20%|█▉        | 29/148 [00:26<01:47,  1.11it/s, training_loss=1.4881]\u001b[A\n",
      "Epoch 10:  20%|██        | 30/148 [00:26<01:46,  1.11it/s, training_loss=1.4881]\u001b[A\n",
      "Epoch 10:  20%|██        | 30/148 [00:27<01:46,  1.11it/s, training_loss=0.9591]\u001b[A\n",
      "Epoch 10:  21%|██        | 31/148 [00:27<01:45,  1.11it/s, training_loss=0.9591]\u001b[A\n",
      "Epoch 10:  21%|██        | 31/148 [00:28<01:45,  1.11it/s, training_loss=0.8906]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 32/148 [00:28<01:44,  1.11it/s, training_loss=0.8906]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 32/148 [00:29<01:44,  1.11it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 33/148 [00:29<01:43,  1.11it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 33/148 [00:30<01:43,  1.11it/s, training_loss=1.5386]\u001b[A\n",
      "Epoch 10:  23%|██▎       | 34/148 [00:30<01:42,  1.12it/s, training_loss=1.5386]\u001b[A\n",
      "Epoch 10:  23%|██▎       | 34/148 [00:31<01:42,  1.12it/s, training_loss=0.8352]\u001b[A\n",
      "Epoch 10:  24%|██▎       | 35/148 [00:31<01:41,  1.11it/s, training_loss=0.8352]\u001b[A\n",
      "Epoch 10:  24%|██▎       | 35/148 [00:32<01:41,  1.11it/s, training_loss=0.9555]\u001b[A\n",
      "Epoch 10:  24%|██▍       | 36/148 [00:32<01:40,  1.11it/s, training_loss=0.9555]\u001b[A\n",
      "Epoch 10:  24%|██▍       | 36/148 [00:33<01:40,  1.11it/s, training_loss=0.9107]\u001b[A\n",
      "Epoch 10:  25%|██▌       | 37/148 [00:33<01:40,  1.11it/s, training_loss=0.9107]\u001b[A\n",
      "Epoch 10:  25%|██▌       | 37/148 [00:34<01:40,  1.11it/s, training_loss=1.0151]\u001b[A\n",
      "Epoch 10:  26%|██▌       | 38/148 [00:34<01:39,  1.11it/s, training_loss=1.0151]\u001b[A\n",
      "Epoch 10:  26%|██▌       | 38/148 [00:35<01:39,  1.11it/s, training_loss=1.0740]\u001b[A\n",
      "Epoch 10:  26%|██▋       | 39/148 [00:35<01:38,  1.11it/s, training_loss=1.0740]\u001b[A\n",
      "Epoch 10:  26%|██▋       | 39/148 [00:35<01:38,  1.11it/s, training_loss=1.5245]\u001b[A\n",
      "Epoch 10:  27%|██▋       | 40/148 [00:35<01:37,  1.11it/s, training_loss=1.5245]\u001b[A\n",
      "Epoch 10:  27%|██▋       | 40/148 [00:36<01:37,  1.11it/s, training_loss=1.0037]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 41/148 [00:36<01:36,  1.11it/s, training_loss=1.0037]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 41/148 [00:37<01:36,  1.11it/s, training_loss=1.0572]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 42/148 [00:37<01:35,  1.11it/s, training_loss=1.0572]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 42/148 [00:38<01:35,  1.11it/s, training_loss=0.9936]\u001b[A\n",
      "Epoch 10:  29%|██▉       | 43/148 [00:38<01:34,  1.11it/s, training_loss=0.9936]\u001b[A\n",
      "Epoch 10:  29%|██▉       | 43/148 [00:39<01:34,  1.11it/s, training_loss=0.8675]\u001b[A\n",
      "Epoch 10:  30%|██▉       | 44/148 [00:39<01:33,  1.11it/s, training_loss=0.8675]\u001b[A\n",
      "Epoch 10:  30%|██▉       | 44/148 [00:40<01:33,  1.11it/s, training_loss=1.1698]\u001b[A\n",
      "Epoch 10:  30%|███       | 45/148 [00:40<01:32,  1.11it/s, training_loss=1.1698]\u001b[A\n",
      "Epoch 10:  30%|███       | 45/148 [00:41<01:32,  1.11it/s, training_loss=0.8851]\u001b[A\n",
      "Epoch 10:  31%|███       | 46/148 [00:41<01:32,  1.10it/s, training_loss=0.8851]\u001b[A\n",
      "Epoch 10:  31%|███       | 46/148 [00:42<01:32,  1.10it/s, training_loss=1.5108]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 47/148 [00:42<01:31,  1.11it/s, training_loss=1.5108]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 47/148 [00:43<01:31,  1.11it/s, training_loss=1.0444]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 48/148 [00:43<01:30,  1.11it/s, training_loss=1.0444]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 48/148 [00:44<01:30,  1.11it/s, training_loss=1.6322]\u001b[A\n",
      "Epoch 10:  33%|███▎      | 49/148 [00:44<01:29,  1.11it/s, training_loss=1.6322]\u001b[A\n",
      "Epoch 10:  33%|███▎      | 49/148 [00:44<01:29,  1.11it/s, training_loss=1.0621]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 50/148 [00:44<01:28,  1.11it/s, training_loss=1.0621]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 50/148 [00:45<01:28,  1.11it/s, training_loss=0.8560]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 51/148 [00:45<01:27,  1.11it/s, training_loss=0.8560]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 51/148 [00:46<01:27,  1.11it/s, training_loss=1.5551]\u001b[A\n",
      "Epoch 10:  35%|███▌      | 52/148 [00:46<01:26,  1.11it/s, training_loss=1.5551]\u001b[A\n",
      "Epoch 10:  35%|███▌      | 52/148 [00:47<01:26,  1.11it/s, training_loss=1.1520]\u001b[A\n",
      "Epoch 10:  36%|███▌      | 53/148 [00:47<01:25,  1.11it/s, training_loss=1.1520]\u001b[A\n",
      "Epoch 10:  36%|███▌      | 53/148 [00:48<01:25,  1.11it/s, training_loss=1.0186]\u001b[A\n",
      "Epoch 10:  36%|███▋      | 54/148 [00:48<01:24,  1.11it/s, training_loss=1.0186]\u001b[A\n",
      "Epoch 10:  36%|███▋      | 54/148 [00:49<01:24,  1.11it/s, training_loss=0.9215]\u001b[A\n",
      "Epoch 10:  37%|███▋      | 55/148 [00:49<01:23,  1.11it/s, training_loss=0.9215]\u001b[A\n",
      "Epoch 10:  37%|███▋      | 55/148 [00:50<01:23,  1.11it/s, training_loss=1.0907]\u001b[A\n",
      "Epoch 10:  38%|███▊      | 56/148 [00:50<01:22,  1.11it/s, training_loss=1.0907]\u001b[A\n",
      "Epoch 10:  38%|███▊      | 56/148 [00:51<01:22,  1.11it/s, training_loss=1.5959]\u001b[A\n",
      "Epoch 10:  39%|███▊      | 57/148 [00:51<01:21,  1.11it/s, training_loss=1.5959]\u001b[A\n",
      "Epoch 10:  39%|███▊      | 57/148 [00:52<01:21,  1.11it/s, training_loss=1.0172]\u001b[A\n",
      "Epoch 10:  39%|███▉      | 58/148 [00:52<01:20,  1.11it/s, training_loss=1.0172]\u001b[A\n",
      "Epoch 10:  39%|███▉      | 58/148 [00:53<01:20,  1.11it/s, training_loss=1.5177]\u001b[A\n",
      "Epoch 10:  40%|███▉      | 59/148 [00:53<01:19,  1.12it/s, training_loss=1.5177]\u001b[A\n",
      "Epoch 10:  40%|███▉      | 59/148 [00:53<01:19,  1.12it/s, training_loss=0.9388]\u001b[A\n",
      "Epoch 10:  41%|████      | 60/148 [00:53<01:19,  1.11it/s, training_loss=0.9388]\u001b[A\n",
      "Epoch 10:  41%|████      | 60/148 [00:54<01:19,  1.11it/s, training_loss=1.5948]\u001b[A\n",
      "Epoch 10:  41%|████      | 61/148 [00:54<01:18,  1.11it/s, training_loss=1.5948]\u001b[A\n",
      "Epoch 10:  41%|████      | 61/148 [00:55<01:18,  1.11it/s, training_loss=1.5546]\u001b[A\n",
      "Epoch 10:  42%|████▏     | 62/148 [00:55<01:17,  1.12it/s, training_loss=1.5546]\u001b[A\n",
      "Epoch 10:  42%|████▏     | 62/148 [00:56<01:17,  1.12it/s, training_loss=1.0332]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 63/148 [00:56<01:15,  1.12it/s, training_loss=1.0332]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 63/148 [00:57<01:15,  1.12it/s, training_loss=1.5857]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 64/148 [00:57<01:15,  1.12it/s, training_loss=1.5857]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 64/148 [00:58<01:15,  1.12it/s, training_loss=1.4981]\u001b[A\n",
      "Epoch 10:  44%|████▍     | 65/148 [00:58<01:14,  1.12it/s, training_loss=1.4981]\u001b[A\n",
      "Epoch 10:  44%|████▍     | 65/148 [00:59<01:14,  1.12it/s, training_loss=1.5476]\u001b[A\n",
      "Epoch 10:  45%|████▍     | 66/148 [00:59<01:13,  1.12it/s, training_loss=1.5476]\u001b[A\n",
      "Epoch 10:  45%|████▍     | 66/148 [01:00<01:13,  1.12it/s, training_loss=1.5525]\u001b[A\n",
      "Epoch 10:  45%|████▌     | 67/148 [01:00<01:12,  1.12it/s, training_loss=1.5525]\u001b[A\n",
      "Epoch 10:  45%|████▌     | 67/148 [01:01<01:12,  1.12it/s, training_loss=1.6503]\u001b[A\n",
      "Epoch 10:  46%|████▌     | 68/148 [01:01<01:11,  1.12it/s, training_loss=1.6503]\u001b[A\n",
      "Epoch 10:  46%|████▌     | 68/148 [01:02<01:11,  1.12it/s, training_loss=1.5609]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 69/148 [01:02<01:10,  1.12it/s, training_loss=1.5609]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 69/148 [01:02<01:10,  1.12it/s, training_loss=1.5414]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 70/148 [01:02<01:09,  1.12it/s, training_loss=1.5414]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 70/148 [01:03<01:09,  1.12it/s, training_loss=1.6505]\u001b[A\n",
      "Epoch 10:  48%|████▊     | 71/148 [01:03<01:08,  1.12it/s, training_loss=1.6505]\u001b[A\n",
      "Epoch 10:  48%|████▊     | 71/148 [01:04<01:08,  1.12it/s, training_loss=0.8483]\u001b[A\n",
      "Epoch 10:  49%|████▊     | 72/148 [01:04<01:08,  1.11it/s, training_loss=0.8483]\u001b[A\n",
      "Epoch 10:  49%|████▊     | 72/148 [01:05<01:08,  1.11it/s, training_loss=0.8498]\u001b[A\n",
      "Epoch 10:  49%|████▉     | 73/148 [01:05<01:07,  1.11it/s, training_loss=0.8498]\u001b[A\n",
      "Epoch 10:  49%|████▉     | 73/148 [01:06<01:07,  1.11it/s, training_loss=0.9848]\u001b[A\n",
      "Epoch 10:  50%|█████     | 74/148 [01:06<01:06,  1.11it/s, training_loss=0.9848]\u001b[A\n",
      "Epoch 10:  50%|█████     | 74/148 [01:07<01:06,  1.11it/s, training_loss=1.5253]\u001b[A\n",
      "Epoch 10:  51%|█████     | 75/148 [01:07<01:05,  1.11it/s, training_loss=1.5253]\u001b[A\n",
      "Epoch 10:  51%|█████     | 75/148 [01:08<01:05,  1.11it/s, training_loss=1.7000]\u001b[A\n",
      "Epoch 10:  51%|█████▏    | 76/148 [01:08<01:04,  1.11it/s, training_loss=1.7000]\u001b[A\n",
      "Epoch 10:  51%|█████▏    | 76/148 [01:09<01:04,  1.11it/s, training_loss=0.8405]\u001b[A\n",
      "Epoch 10:  52%|█████▏    | 77/148 [01:09<01:03,  1.11it/s, training_loss=0.8405]\u001b[A\n",
      "Epoch 10:  52%|█████▏    | 77/148 [01:10<01:03,  1.11it/s, training_loss=0.8128]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 78/148 [01:10<01:03,  1.11it/s, training_loss=0.8128]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 78/148 [01:11<01:03,  1.11it/s, training_loss=1.5782]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 79/148 [01:11<01:02,  1.11it/s, training_loss=1.5782]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 79/148 [01:11<01:02,  1.11it/s, training_loss=1.5161]\u001b[A\n",
      "Epoch 10:  54%|█████▍    | 80/148 [01:11<01:01,  1.11it/s, training_loss=1.5161]\u001b[A\n",
      "Epoch 10:  54%|█████▍    | 80/148 [01:12<01:01,  1.11it/s, training_loss=0.9968]\u001b[A\n",
      "Epoch 10:  55%|█████▍    | 81/148 [01:12<01:00,  1.11it/s, training_loss=0.9968]\u001b[A\n",
      "Epoch 10:  55%|█████▍    | 81/148 [01:13<01:00,  1.11it/s, training_loss=1.0240]\u001b[A\n",
      "Epoch 10:  55%|█████▌    | 82/148 [01:13<00:59,  1.11it/s, training_loss=1.0240]\u001b[A\n",
      "Epoch 10:  55%|█████▌    | 82/148 [01:14<00:59,  1.11it/s, training_loss=1.6221]\u001b[A\n",
      "Epoch 10:  56%|█████▌    | 83/148 [01:14<00:58,  1.11it/s, training_loss=1.6221]\u001b[A\n",
      "Epoch 10:  56%|█████▌    | 83/148 [01:15<00:58,  1.11it/s, training_loss=0.8767]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 84/148 [01:15<00:57,  1.11it/s, training_loss=0.8767]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 84/148 [01:16<00:57,  1.11it/s, training_loss=1.6557]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 85/148 [01:16<00:56,  1.11it/s, training_loss=1.6557]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 85/148 [01:17<00:56,  1.11it/s, training_loss=1.6223]\u001b[A\n",
      "Epoch 10:  58%|█████▊    | 86/148 [01:17<00:55,  1.11it/s, training_loss=1.6223]\u001b[A\n",
      "Epoch 10:  58%|█████▊    | 86/148 [01:18<00:55,  1.11it/s, training_loss=1.2427]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 87/148 [01:18<00:54,  1.11it/s, training_loss=1.2427]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 87/148 [01:19<00:54,  1.11it/s, training_loss=0.8585]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 88/148 [01:19<00:53,  1.11it/s, training_loss=0.8585]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 88/148 [01:20<00:53,  1.11it/s, training_loss=1.6102]\u001b[A\n",
      "Epoch 10:  60%|██████    | 89/148 [01:20<00:52,  1.12it/s, training_loss=1.6102]\u001b[A\n",
      "Epoch 10:  60%|██████    | 89/148 [01:20<00:52,  1.12it/s, training_loss=1.5856]\u001b[A\n",
      "Epoch 10:  61%|██████    | 90/148 [01:20<00:52,  1.11it/s, training_loss=1.5856]\u001b[A\n",
      "Epoch 10:  61%|██████    | 90/148 [01:21<00:52,  1.11it/s, training_loss=1.5437]\u001b[A\n",
      "Epoch 10:  61%|██████▏   | 91/148 [01:21<00:51,  1.11it/s, training_loss=1.5437]\u001b[A\n",
      "Epoch 10:  61%|██████▏   | 91/148 [01:22<00:51,  1.11it/s, training_loss=0.8751]\u001b[A\n",
      "Epoch 10:  62%|██████▏   | 92/148 [01:22<00:50,  1.11it/s, training_loss=0.8751]\u001b[A\n",
      "Epoch 10:  62%|██████▏   | 92/148 [01:23<00:50,  1.11it/s, training_loss=0.9666]\u001b[A\n",
      "Epoch 10:  63%|██████▎   | 93/148 [01:23<00:49,  1.11it/s, training_loss=0.9666]\u001b[A\n",
      "Epoch 10:  63%|██████▎   | 93/148 [01:24<00:49,  1.11it/s, training_loss=1.5517]\u001b[A\n",
      "Epoch 10:  64%|██████▎   | 94/148 [01:24<00:48,  1.11it/s, training_loss=1.5517]\u001b[A\n",
      "Epoch 10:  64%|██████▎   | 94/148 [01:25<00:48,  1.11it/s, training_loss=1.6238]\u001b[A\n",
      "Epoch 10:  64%|██████▍   | 95/148 [01:25<00:47,  1.11it/s, training_loss=1.6238]\u001b[A\n",
      "Epoch 10:  64%|██████▍   | 95/148 [01:26<00:47,  1.11it/s, training_loss=1.6109]\u001b[A\n",
      "Epoch 10:  65%|██████▍   | 96/148 [01:26<00:46,  1.11it/s, training_loss=1.6109]\u001b[A\n",
      "Epoch 10:  65%|██████▍   | 96/148 [01:27<00:46,  1.11it/s, training_loss=1.5941]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 97/148 [01:27<00:45,  1.11it/s, training_loss=1.5941]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 97/148 [01:28<00:45,  1.11it/s, training_loss=0.8923]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 98/148 [01:28<00:44,  1.11it/s, training_loss=0.8923]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 98/148 [01:29<00:44,  1.11it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 10:  67%|██████▋   | 99/148 [01:29<00:44,  1.11it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 10:  67%|██████▋   | 99/148 [01:29<00:44,  1.11it/s, training_loss=1.5249]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 100/148 [01:29<00:43,  1.11it/s, training_loss=1.5249]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 100/148 [01:30<00:43,  1.11it/s, training_loss=0.8305]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 101/148 [01:30<00:42,  1.11it/s, training_loss=0.8305]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 101/148 [01:31<00:42,  1.11it/s, training_loss=1.6075]\u001b[A\n",
      "Epoch 10:  69%|██████▉   | 102/148 [01:31<00:41,  1.11it/s, training_loss=1.6075]\u001b[A\n",
      "Epoch 10:  69%|██████▉   | 102/148 [01:32<00:41,  1.11it/s, training_loss=1.5221]\u001b[A\n",
      "Epoch 10:  70%|██████▉   | 103/148 [01:32<00:40,  1.11it/s, training_loss=1.5221]\u001b[A\n",
      "Epoch 10:  70%|██████▉   | 103/148 [01:33<00:40,  1.11it/s, training_loss=1.5434]\u001b[A\n",
      "Epoch 10:  70%|███████   | 104/148 [01:33<00:39,  1.11it/s, training_loss=1.5434]\u001b[A\n",
      "Epoch 10:  70%|███████   | 104/148 [01:34<00:39,  1.11it/s, training_loss=0.8453]\u001b[A\n",
      "Epoch 10:  71%|███████   | 105/148 [01:34<00:38,  1.11it/s, training_loss=0.8453]\u001b[A\n",
      "Epoch 10:  71%|███████   | 105/148 [01:35<00:38,  1.11it/s, training_loss=1.6662]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 106/148 [01:35<00:37,  1.12it/s, training_loss=1.6662]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 106/148 [01:36<00:37,  1.12it/s, training_loss=0.8621]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 107/148 [01:36<00:36,  1.11it/s, training_loss=0.8621]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 107/148 [01:37<00:36,  1.11it/s, training_loss=1.5928]\u001b[A\n",
      "Epoch 10:  73%|███████▎  | 108/148 [01:37<00:35,  1.11it/s, training_loss=1.5928]\u001b[A\n",
      "Epoch 10:  73%|███████▎  | 108/148 [01:37<00:35,  1.11it/s, training_loss=0.9846]\u001b[A\n",
      "Epoch 10:  74%|███████▎  | 109/148 [01:37<00:35,  1.11it/s, training_loss=0.9846]\u001b[A\n",
      "Epoch 10:  74%|███████▎  | 109/148 [01:38<00:35,  1.11it/s, training_loss=0.9652]\u001b[A\n",
      "Epoch 10:  74%|███████▍  | 110/148 [01:38<00:34,  1.11it/s, training_loss=0.9652]\u001b[A\n",
      "Epoch 10:  74%|███████▍  | 110/148 [01:39<00:34,  1.11it/s, training_loss=1.5709]\u001b[A\n",
      "Epoch 10:  75%|███████▌  | 111/148 [01:39<00:33,  1.11it/s, training_loss=1.5709]\u001b[A\n",
      "Epoch 10:  75%|███████▌  | 111/148 [01:40<00:33,  1.11it/s, training_loss=0.9238]\u001b[A\n",
      "Epoch 10:  76%|███████▌  | 112/148 [01:40<00:32,  1.11it/s, training_loss=0.9238]\u001b[A\n",
      "Epoch 10:  76%|███████▌  | 112/148 [01:41<00:32,  1.11it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 10:  76%|███████▋  | 113/148 [01:41<00:31,  1.12it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 10:  76%|███████▋  | 113/148 [01:42<00:31,  1.12it/s, training_loss=1.6594]\u001b[A\n",
      "Epoch 10:  77%|███████▋  | 114/148 [01:42<00:30,  1.11it/s, training_loss=1.6594]\u001b[A\n",
      "Epoch 10:  77%|███████▋  | 114/148 [01:43<00:30,  1.11it/s, training_loss=1.5313]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 115/148 [01:43<00:29,  1.11it/s, training_loss=1.5313]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 115/148 [01:44<00:29,  1.11it/s, training_loss=0.9118]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 116/148 [01:44<00:28,  1.11it/s, training_loss=0.9118]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 116/148 [01:45<00:28,  1.11it/s, training_loss=1.5025]\u001b[A\n",
      "Epoch 10:  79%|███████▉  | 117/148 [01:45<00:27,  1.11it/s, training_loss=1.5025]\u001b[A\n",
      "Epoch 10:  79%|███████▉  | 117/148 [01:46<00:27,  1.11it/s, training_loss=1.5227]\u001b[A\n",
      "Epoch 10:  80%|███████▉  | 118/148 [01:46<00:26,  1.11it/s, training_loss=1.5227]\u001b[A\n",
      "Epoch 10:  80%|███████▉  | 118/148 [01:46<00:26,  1.11it/s, training_loss=1.3553]\u001b[A\n",
      "Epoch 10:  80%|████████  | 119/148 [01:46<00:26,  1.11it/s, training_loss=1.3553]\u001b[A\n",
      "Epoch 10:  80%|████████  | 119/148 [01:47<00:26,  1.11it/s, training_loss=1.6614]\u001b[A\n",
      "Epoch 10:  81%|████████  | 120/148 [01:47<00:25,  1.12it/s, training_loss=1.6614]\u001b[A\n",
      "Epoch 10:  81%|████████  | 120/148 [01:48<00:25,  1.12it/s, training_loss=1.0078]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 121/148 [01:48<00:24,  1.11it/s, training_loss=1.0078]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 121/148 [01:49<00:24,  1.11it/s, training_loss=1.5726]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 122/148 [01:49<00:23,  1.11it/s, training_loss=1.5726]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 122/148 [01:50<00:23,  1.11it/s, training_loss=1.6009]\u001b[A\n",
      "Epoch 10:  83%|████████▎ | 123/148 [01:50<00:22,  1.11it/s, training_loss=1.6009]\u001b[A\n",
      "Epoch 10:  83%|████████▎ | 123/148 [01:51<00:22,  1.11it/s, training_loss=1.2286]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 124/148 [01:51<00:21,  1.11it/s, training_loss=1.2286]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 124/148 [01:52<00:21,  1.11it/s, training_loss=0.8746]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 125/148 [01:52<00:20,  1.11it/s, training_loss=0.8746]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 125/148 [01:53<00:20,  1.11it/s, training_loss=0.8518]\u001b[A\n",
      "Epoch 10:  85%|████████▌ | 126/148 [01:53<00:19,  1.11it/s, training_loss=0.8518]\u001b[A\n",
      "Epoch 10:  85%|████████▌ | 126/148 [01:54<00:19,  1.11it/s, training_loss=0.8272]\u001b[A\n",
      "Epoch 10:  86%|████████▌ | 127/148 [01:54<00:18,  1.11it/s, training_loss=0.8272]\u001b[A\n",
      "Epoch 10:  86%|████████▌ | 127/148 [01:55<00:18,  1.11it/s, training_loss=1.5966]\u001b[A\n",
      "Epoch 10:  86%|████████▋ | 128/148 [01:55<00:18,  1.11it/s, training_loss=1.5966]\u001b[A\n",
      "Epoch 10:  86%|████████▋ | 128/148 [01:55<00:18,  1.11it/s, training_loss=1.4852]\u001b[A\n",
      "Epoch 10:  87%|████████▋ | 129/148 [01:55<00:17,  1.11it/s, training_loss=1.4852]\u001b[A\n",
      "Epoch 10:  87%|████████▋ | 129/148 [01:56<00:17,  1.11it/s, training_loss=1.4837]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 130/148 [01:56<00:16,  1.11it/s, training_loss=1.4837]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 130/148 [01:57<00:16,  1.11it/s, training_loss=0.8752]\u001b[A\n",
      "Epoch 10:  89%|████████▊ | 131/148 [01:57<00:15,  1.11it/s, training_loss=0.8752]\u001b[A\n",
      "Epoch 10:  89%|████████▊ | 131/148 [01:58<00:15,  1.11it/s, training_loss=1.4944]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 132/148 [01:58<00:14,  1.11it/s, training_loss=1.4944]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 132/148 [01:59<00:14,  1.11it/s, training_loss=0.8265]\u001b[A\n",
      "Epoch 10:  90%|████████▉ | 133/148 [01:59<00:13,  1.11it/s, training_loss=0.8265]\u001b[A\n",
      "Epoch 10:  90%|████████▉ | 133/148 [02:00<00:13,  1.11it/s, training_loss=0.9713]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 134/148 [02:00<00:12,  1.11it/s, training_loss=0.9713]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 134/148 [02:01<00:12,  1.11it/s, training_loss=1.5696]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 135/148 [02:01<00:11,  1.11it/s, training_loss=1.5696]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 135/148 [02:02<00:11,  1.11it/s, training_loss=0.8707]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 136/148 [02:02<00:10,  1.11it/s, training_loss=0.8707]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 136/148 [02:03<00:10,  1.11it/s, training_loss=1.5295]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 137/148 [02:03<00:09,  1.11it/s, training_loss=1.5295]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 137/148 [02:04<00:09,  1.11it/s, training_loss=1.6349]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 138/148 [02:04<00:09,  1.11it/s, training_loss=1.6349]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 138/148 [02:04<00:09,  1.11it/s, training_loss=1.5920]\u001b[A\n",
      "Epoch 10:  94%|█████████▍| 139/148 [02:04<00:08,  1.11it/s, training_loss=1.5920]\u001b[A\n",
      "Epoch 10:  94%|█████████▍| 139/148 [02:05<00:08,  1.11it/s, training_loss=1.5950]\u001b[A\n",
      "Epoch 10:  95%|█████████▍| 140/148 [02:05<00:07,  1.11it/s, training_loss=1.5950]\u001b[A\n",
      "Epoch 10:  95%|█████████▍| 140/148 [02:06<00:07,  1.11it/s, training_loss=0.9501]\u001b[A\n",
      "Epoch 10:  95%|█████████▌| 141/148 [02:06<00:06,  1.11it/s, training_loss=0.9501]\u001b[A\n",
      "Epoch 10:  95%|█████████▌| 141/148 [02:07<00:06,  1.11it/s, training_loss=0.9257]\u001b[A\n",
      "Epoch 10:  96%|█████████▌| 142/148 [02:07<00:05,  1.11it/s, training_loss=0.9257]\u001b[A\n",
      "Epoch 10:  96%|█████████▌| 142/148 [02:08<00:05,  1.11it/s, training_loss=1.5409]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 143/148 [02:08<00:04,  1.11it/s, training_loss=1.5409]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 143/148 [02:09<00:04,  1.11it/s, training_loss=0.8892]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 144/148 [02:09<00:03,  1.10it/s, training_loss=0.8892]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 144/148 [02:10<00:03,  1.10it/s, training_loss=1.6571]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 145/148 [02:10<00:02,  1.10it/s, training_loss=1.6571]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 145/148 [02:11<00:02,  1.10it/s, training_loss=0.8986]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 146/148 [02:11<00:01,  1.10it/s, training_loss=0.8986]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 146/148 [02:12<00:01,  1.10it/s, training_loss=0.8206]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 147/148 [02:12<00:00,  1.11it/s, training_loss=0.8206]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 147/148 [02:12<00:00,  1.11it/s, training_loss=1.4657]\u001b[A\n",
      "Epoch 10: 100%|██████████| 148/148 [02:12<00:00,  1.20it/s, training_loss=1.4657]\u001b[A\n",
      "                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:12:47,068 - INFO - Starting model evaluation...\n",
      "2025-02-19 11:12:47,069 - INFO - Memory usage after evaluation start: 4040.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=66.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:06,  3.74it/s, Accuracy=66.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:06,  3.74it/s, Accuracy=69.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.67it/s, Accuracy=69.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.67it/s, Accuracy=68.67%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.64it/s, Accuracy=68.67%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.64it/s, Accuracy=67.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.64it/s, Accuracy=67.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.64it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.64it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.64it/s, Accuracy=70.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.65it/s, Accuracy=70.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.65it/s, Accuracy=69.71%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.63it/s, Accuracy=69.71%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.63it/s, Accuracy=68.50%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.64it/s, Accuracy=68.50%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.64it/s, Accuracy=68.22%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.64it/s, Accuracy=68.22%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.64it/s, Accuracy=69.20%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.63it/s, Accuracy=69.20%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.63it/s, Accuracy=69.09%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.63it/s, Accuracy=69.09%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.63it/s, Accuracy=69.50%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.64it/s, Accuracy=69.50%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.64it/s, Accuracy=68.77%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.63it/s, Accuracy=68.77%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.63it/s, Accuracy=68.71%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.64it/s, Accuracy=68.71%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.64it/s, Accuracy=68.93%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.63it/s, Accuracy=68.93%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.63it/s, Accuracy=68.50%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.63it/s, Accuracy=68.50%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.63it/s, Accuracy=68.24%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.64it/s, Accuracy=68.24%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.64it/s, Accuracy=69.11%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.64it/s, Accuracy=69.11%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.64it/s, Accuracy=69.58%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.63it/s, Accuracy=69.58%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.63it/s, Accuracy=69.90%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.64it/s, Accuracy=69.90%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.64it/s, Accuracy=69.71%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.62it/s, Accuracy=69.71%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.62it/s, Accuracy=69.73%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.63it/s, Accuracy=69.73%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.63it/s, Accuracy=69.83%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.63it/s, Accuracy=69.83%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.63it/s, Accuracy=69.50%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.62it/s, Accuracy=69.50%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.62it/s, Accuracy=69.52%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.62it/s, Accuracy=69.52%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.62it/s, Accuracy=69.85%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.63it/s, Accuracy=69.85%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.75it/s, Accuracy=69.96%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:12:54,265 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 11:12:54,272 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 11:12:54,273 - INFO - Accuracy: 0.5441\n",
      "2025-02-19 11:12:54,274 - INFO - F1_score: 0.5143\n",
      "2025-02-19 11:12:54,275 - INFO - Precision: 0.3684\n",
      "2025-02-19 11:12:54,275 - INFO - Recall: 0.8514\n",
      "2025-02-19 11:12:54,281 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 11:12:54,282 - INFO - Accuracy: 0.7356\n",
      "2025-02-19 11:12:54,283 - INFO - F1_score: 0.6057\n",
      "2025-02-19 11:12:54,284 - INFO - Precision: 0.4492\n",
      "2025-02-19 11:12:54,284 - INFO - Recall: 0.9298\n",
      "2025-02-19 11:12:54,291 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 11:12:54,292 - INFO - Accuracy: 0.6973\n",
      "2025-02-19 11:12:54,292 - INFO - F1_score: 0.5380\n",
      "2025-02-19 11:12:54,293 - INFO - Precision: 0.4071\n",
      "2025-02-19 11:12:54,294 - INFO - Recall: 0.7931\n",
      "2025-02-19 11:12:54,301 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 11:12:54,301 - INFO - Accuracy: 0.6858\n",
      "2025-02-19 11:12:54,302 - INFO - F1_score: 0.3279\n",
      "2025-02-19 11:12:54,303 - INFO - Precision: 0.2381\n",
      "2025-02-19 11:12:54,303 - INFO - Recall: 0.5263\n",
      "2025-02-19 11:12:54,310 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 11:12:54,311 - INFO - Accuracy: 0.8352\n",
      "2025-02-19 11:12:54,311 - INFO - F1_score: 0.4819\n",
      "2025-02-19 11:12:54,312 - INFO - Precision: 0.4082\n",
      "2025-02-19 11:12:54,313 - INFO - Recall: 0.5882\n",
      "2025-02-19 11:12:54,315 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:12:58,214 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 11:12:58,215 - INFO - Memory usage after evaluation end: 4046.28 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [25:43<3:52:38, 153.38s/it, Train Loss=1.2474, Val Loss=0.0517, Accuracy=0.6996]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:13:05,359 - INFO - Learning rate: 1.25e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 10/100 [25:44<3:49:40, 153.12s/it, Train Loss=1.2474, Val Loss=0.0517, Accuracy=0.6996]\n",
      "Epoch 11:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.0765]\u001b[A\n",
      "Epoch 11:   1%|          | 1/148 [00:00<02:10,  1.12it/s, training_loss=1.0765]\u001b[A\n",
      "Epoch 11:   1%|          | 1/148 [00:01<02:10,  1.12it/s, training_loss=1.2441]\u001b[A\n",
      "Epoch 11:   1%|▏         | 2/148 [00:01<02:10,  1.12it/s, training_loss=1.2441]\u001b[A\n",
      "Epoch 11:   1%|▏         | 2/148 [00:02<02:10,  1.12it/s, training_loss=0.8592]\u001b[A\n",
      "Epoch 11:   2%|▏         | 3/148 [00:02<02:10,  1.11it/s, training_loss=0.8592]\u001b[A\n",
      "Epoch 11:   2%|▏         | 3/148 [00:03<02:10,  1.11it/s, training_loss=0.9170]\u001b[A\n",
      "Epoch 11:   3%|▎         | 4/148 [00:03<02:09,  1.11it/s, training_loss=0.9170]\u001b[A\n",
      "Epoch 11:   3%|▎         | 4/148 [00:04<02:09,  1.11it/s, training_loss=1.5821]\u001b[A\n",
      "Epoch 11:   3%|▎         | 5/148 [00:04<02:07,  1.12it/s, training_loss=1.5821]\u001b[A\n",
      "Epoch 11:   3%|▎         | 5/148 [00:05<02:07,  1.12it/s, training_loss=0.9192]\u001b[A\n",
      "Epoch 11:   4%|▍         | 6/148 [00:05<02:07,  1.12it/s, training_loss=0.9192]\u001b[A\n",
      "Epoch 11:   4%|▍         | 6/148 [00:06<02:07,  1.12it/s, training_loss=0.8372]\u001b[A\n",
      "Epoch 11:   5%|▍         | 7/148 [00:06<02:06,  1.11it/s, training_loss=0.8372]\u001b[A\n",
      "Epoch 11:   5%|▍         | 7/148 [00:07<02:06,  1.11it/s, training_loss=1.6108]\u001b[A\n",
      "Epoch 11:   5%|▌         | 8/148 [00:07<02:05,  1.12it/s, training_loss=1.6108]\u001b[A\n",
      "Epoch 11:   5%|▌         | 8/148 [00:08<02:05,  1.12it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 11:   6%|▌         | 9/148 [00:08<02:04,  1.12it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 11:   6%|▌         | 9/148 [00:08<02:04,  1.12it/s, training_loss=0.9417]\u001b[A\n",
      "Epoch 11:   7%|▋         | 10/148 [00:08<02:03,  1.12it/s, training_loss=0.9417]\u001b[A\n",
      "Epoch 11:   7%|▋         | 10/148 [00:09<02:03,  1.12it/s, training_loss=0.8235]\u001b[A\n",
      "Epoch 11:   7%|▋         | 11/148 [00:09<02:02,  1.12it/s, training_loss=0.8235]\u001b[A\n",
      "Epoch 11:   7%|▋         | 11/148 [00:10<02:02,  1.12it/s, training_loss=1.7334]\u001b[A\n",
      "Epoch 11:   8%|▊         | 12/148 [00:10<02:01,  1.12it/s, training_loss=1.7334]\u001b[A\n",
      "Epoch 11:   8%|▊         | 12/148 [00:11<02:01,  1.12it/s, training_loss=1.6171]\u001b[A\n",
      "Epoch 11:   9%|▉         | 13/148 [00:11<02:00,  1.12it/s, training_loss=1.6171]\u001b[A\n",
      "Epoch 11:   9%|▉         | 13/148 [00:12<02:00,  1.12it/s, training_loss=0.9401]\u001b[A\n",
      "Epoch 11:   9%|▉         | 14/148 [00:12<01:59,  1.12it/s, training_loss=0.9401]\u001b[A\n",
      "Epoch 11:   9%|▉         | 14/148 [00:13<01:59,  1.12it/s, training_loss=1.6196]\u001b[A\n",
      "Epoch 11:  10%|█         | 15/148 [00:13<01:58,  1.12it/s, training_loss=1.6196]\u001b[A\n",
      "Epoch 11:  10%|█         | 15/148 [00:14<01:58,  1.12it/s, training_loss=1.5896]\u001b[A\n",
      "Epoch 11:  11%|█         | 16/148 [00:14<01:57,  1.12it/s, training_loss=1.5896]\u001b[A\n",
      "Epoch 11:  11%|█         | 16/148 [00:15<01:57,  1.12it/s, training_loss=0.8380]\u001b[A\n",
      "Epoch 11:  11%|█▏        | 17/148 [00:15<01:57,  1.12it/s, training_loss=0.8380]\u001b[A\n",
      "Epoch 11:  11%|█▏        | 17/148 [00:16<01:57,  1.12it/s, training_loss=1.6398]\u001b[A\n",
      "Epoch 11:  12%|█▏        | 18/148 [00:16<01:56,  1.12it/s, training_loss=1.6398]\u001b[A\n",
      "Epoch 11:  12%|█▏        | 18/148 [00:16<01:56,  1.12it/s, training_loss=1.3079]\u001b[A\n",
      "Epoch 11:  13%|█▎        | 19/148 [00:16<01:55,  1.12it/s, training_loss=1.3079]\u001b[A\n",
      "Epoch 11:  13%|█▎        | 19/148 [00:17<01:55,  1.12it/s, training_loss=1.5049]\u001b[A\n",
      "Epoch 11:  14%|█▎        | 20/148 [00:17<01:54,  1.12it/s, training_loss=1.5049]\u001b[A\n",
      "Epoch 11:  14%|█▎        | 20/148 [00:18<01:54,  1.12it/s, training_loss=1.6666]\u001b[A\n",
      "Epoch 11:  14%|█▍        | 21/148 [00:18<01:53,  1.12it/s, training_loss=1.6666]\u001b[A\n",
      "Epoch 11:  14%|█▍        | 21/148 [00:19<01:53,  1.12it/s, training_loss=1.5336]\u001b[A\n",
      "Epoch 11:  15%|█▍        | 22/148 [00:19<01:52,  1.12it/s, training_loss=1.5336]\u001b[A\n",
      "Epoch 11:  15%|█▍        | 22/148 [00:20<01:52,  1.12it/s, training_loss=1.0039]\u001b[A\n",
      "Epoch 11:  16%|█▌        | 23/148 [00:20<01:52,  1.11it/s, training_loss=1.0039]\u001b[A\n",
      "Epoch 11:  16%|█▌        | 23/148 [00:21<01:52,  1.11it/s, training_loss=1.5934]\u001b[A\n",
      "Epoch 11:  16%|█▌        | 24/148 [00:21<01:51,  1.12it/s, training_loss=1.5934]\u001b[A\n",
      "Epoch 11:  16%|█▌        | 24/148 [00:22<01:51,  1.12it/s, training_loss=0.9314]\u001b[A\n",
      "Epoch 11:  17%|█▋        | 25/148 [00:22<01:50,  1.11it/s, training_loss=0.9314]\u001b[A\n",
      "Epoch 11:  17%|█▋        | 25/148 [00:23<01:50,  1.11it/s, training_loss=1.0750]\u001b[A\n",
      "Epoch 11:  18%|█▊        | 26/148 [00:23<01:49,  1.11it/s, training_loss=1.0750]\u001b[A\n",
      "Epoch 11:  18%|█▊        | 26/148 [00:24<01:49,  1.11it/s, training_loss=1.1262]\u001b[A\n",
      "Epoch 11:  18%|█▊        | 27/148 [00:24<01:49,  1.11it/s, training_loss=1.1262]\u001b[A\n",
      "Epoch 11:  18%|█▊        | 27/148 [00:25<01:49,  1.11it/s, training_loss=0.8049]\u001b[A\n",
      "Epoch 11:  19%|█▉        | 28/148 [00:25<01:47,  1.11it/s, training_loss=0.8049]\u001b[A\n",
      "Epoch 11:  19%|█▉        | 28/148 [00:25<01:47,  1.11it/s, training_loss=1.6604]\u001b[A\n",
      "Epoch 11:  20%|█▉        | 29/148 [00:25<01:46,  1.12it/s, training_loss=1.6604]\u001b[A\n",
      "Epoch 11:  20%|█▉        | 29/148 [00:26<01:46,  1.12it/s, training_loss=0.9951]\u001b[A\n",
      "Epoch 11:  20%|██        | 30/148 [00:26<01:45,  1.12it/s, training_loss=0.9951]\u001b[A\n",
      "Epoch 11:  20%|██        | 30/148 [00:27<01:45,  1.12it/s, training_loss=0.8551]\u001b[A\n",
      "Epoch 11:  21%|██        | 31/148 [00:27<01:45,  1.11it/s, training_loss=0.8551]\u001b[A\n",
      "Epoch 11:  21%|██        | 31/148 [00:28<01:45,  1.11it/s, training_loss=1.3863]\u001b[A\n",
      "Epoch 11:  22%|██▏       | 32/148 [00:28<01:43,  1.12it/s, training_loss=1.3863]\u001b[A\n",
      "Epoch 11:  22%|██▏       | 32/148 [00:29<01:43,  1.12it/s, training_loss=0.9406]\u001b[A\n",
      "Epoch 11:  22%|██▏       | 33/148 [00:29<01:43,  1.11it/s, training_loss=0.9406]\u001b[A\n",
      "Epoch 11:  22%|██▏       | 33/148 [00:30<01:43,  1.11it/s, training_loss=0.8143]\u001b[A\n",
      "Epoch 11:  23%|██▎       | 34/148 [00:30<01:42,  1.11it/s, training_loss=0.8143]\u001b[A\n",
      "Epoch 11:  23%|██▎       | 34/148 [00:31<01:42,  1.11it/s, training_loss=1.5744]\u001b[A\n",
      "Epoch 11:  24%|██▎       | 35/148 [00:31<01:41,  1.11it/s, training_loss=1.5744]\u001b[A\n",
      "Epoch 11:  24%|██▎       | 35/148 [00:32<01:41,  1.11it/s, training_loss=1.4933]\u001b[A\n",
      "Epoch 11:  24%|██▍       | 36/148 [00:32<01:40,  1.11it/s, training_loss=1.4933]\u001b[A\n",
      "Epoch 11:  24%|██▍       | 36/148 [00:33<01:40,  1.11it/s, training_loss=1.6499]\u001b[A\n",
      "Epoch 11:  25%|██▌       | 37/148 [00:33<01:40,  1.11it/s, training_loss=1.6499]\u001b[A\n",
      "Epoch 11:  25%|██▌       | 37/148 [00:34<01:40,  1.11it/s, training_loss=0.9839]\u001b[A\n",
      "Epoch 11:  26%|██▌       | 38/148 [00:34<01:39,  1.11it/s, training_loss=0.9839]\u001b[A\n",
      "Epoch 11:  26%|██▌       | 38/148 [00:34<01:39,  1.11it/s, training_loss=1.4517]\u001b[A\n",
      "Epoch 11:  26%|██▋       | 39/148 [00:34<01:38,  1.11it/s, training_loss=1.4517]\u001b[A\n",
      "Epoch 11:  26%|██▋       | 39/148 [00:35<01:38,  1.11it/s, training_loss=0.8249]\u001b[A\n",
      "Epoch 11:  27%|██▋       | 40/148 [00:35<01:37,  1.11it/s, training_loss=0.8249]\u001b[A\n",
      "Epoch 11:  27%|██▋       | 40/148 [00:36<01:37,  1.11it/s, training_loss=0.8798]\u001b[A\n",
      "Epoch 11:  28%|██▊       | 41/148 [00:36<01:36,  1.11it/s, training_loss=0.8798]\u001b[A\n",
      "Epoch 11:  28%|██▊       | 41/148 [00:37<01:36,  1.11it/s, training_loss=0.9007]\u001b[A\n",
      "Epoch 11:  28%|██▊       | 42/148 [00:37<01:35,  1.11it/s, training_loss=0.9007]\u001b[A\n",
      "Epoch 11:  28%|██▊       | 42/148 [00:38<01:35,  1.11it/s, training_loss=1.2736]\u001b[A\n",
      "Epoch 11:  29%|██▉       | 43/148 [00:38<01:34,  1.11it/s, training_loss=1.2736]\u001b[A\n",
      "Epoch 11:  29%|██▉       | 43/148 [00:39<01:34,  1.11it/s, training_loss=0.9477]\u001b[A\n",
      "Epoch 11:  30%|██▉       | 44/148 [00:39<01:33,  1.11it/s, training_loss=0.9477]\u001b[A\n",
      "Epoch 11:  30%|██▉       | 44/148 [00:40<01:33,  1.11it/s, training_loss=1.5562]\u001b[A\n",
      "Epoch 11:  30%|███       | 45/148 [00:40<01:32,  1.11it/s, training_loss=1.5562]\u001b[A\n",
      "Epoch 11:  30%|███       | 45/148 [00:41<01:32,  1.11it/s, training_loss=0.9876]\u001b[A\n",
      "Epoch 11:  31%|███       | 46/148 [00:41<01:31,  1.11it/s, training_loss=0.9876]\u001b[A\n",
      "Epoch 11:  31%|███       | 46/148 [00:42<01:31,  1.11it/s, training_loss=1.5346]\u001b[A\n",
      "Epoch 11:  32%|███▏      | 47/148 [00:42<01:31,  1.11it/s, training_loss=1.5346]\u001b[A\n",
      "Epoch 11:  32%|███▏      | 47/148 [00:43<01:31,  1.11it/s, training_loss=1.6394]\u001b[A\n",
      "Epoch 11:  32%|███▏      | 48/148 [00:43<01:29,  1.11it/s, training_loss=1.6394]\u001b[A\n",
      "Epoch 11:  32%|███▏      | 48/148 [00:43<01:29,  1.11it/s, training_loss=1.5508]\u001b[A\n",
      "Epoch 11:  33%|███▎      | 49/148 [00:43<01:28,  1.11it/s, training_loss=1.5508]\u001b[A\n",
      "Epoch 11:  33%|███▎      | 49/148 [00:44<01:28,  1.11it/s, training_loss=1.2935]\u001b[A\n",
      "Epoch 11:  34%|███▍      | 50/148 [00:44<01:27,  1.11it/s, training_loss=1.2935]\u001b[A\n",
      "Epoch 11:  34%|███▍      | 50/148 [00:45<01:27,  1.11it/s, training_loss=1.1065]\u001b[A\n",
      "Epoch 11:  34%|███▍      | 51/148 [00:45<01:27,  1.11it/s, training_loss=1.1065]\u001b[A\n",
      "Epoch 11:  34%|███▍      | 51/148 [00:46<01:27,  1.11it/s, training_loss=1.4191]\u001b[A\n",
      "Epoch 11:  35%|███▌      | 52/148 [00:46<01:26,  1.11it/s, training_loss=1.4191]\u001b[A\n",
      "Epoch 11:  35%|███▌      | 52/148 [00:47<01:26,  1.11it/s, training_loss=1.5838]\u001b[A\n",
      "Epoch 11:  36%|███▌      | 53/148 [00:47<01:25,  1.11it/s, training_loss=1.5838]\u001b[A\n",
      "Epoch 11:  36%|███▌      | 53/148 [00:48<01:25,  1.11it/s, training_loss=1.4913]\u001b[A\n",
      "Epoch 11:  36%|███▋      | 54/148 [00:48<01:24,  1.11it/s, training_loss=1.4913]\u001b[A\n",
      "Epoch 11:  36%|███▋      | 54/148 [00:49<01:24,  1.11it/s, training_loss=0.9419]\u001b[A\n",
      "Epoch 11:  37%|███▋      | 55/148 [00:49<01:23,  1.11it/s, training_loss=0.9419]\u001b[A\n",
      "Epoch 11:  37%|███▋      | 55/148 [00:50<01:23,  1.11it/s, training_loss=1.5096]\u001b[A\n",
      "Epoch 11:  38%|███▊      | 56/148 [00:50<01:22,  1.11it/s, training_loss=1.5096]\u001b[A\n",
      "Epoch 11:  38%|███▊      | 56/148 [00:51<01:22,  1.11it/s, training_loss=0.8515]\u001b[A\n",
      "Epoch 11:  39%|███▊      | 57/148 [00:51<01:22,  1.11it/s, training_loss=0.8515]\u001b[A\n",
      "Epoch 11:  39%|███▊      | 57/148 [00:52<01:22,  1.11it/s, training_loss=1.5308]\u001b[A\n",
      "Epoch 11:  39%|███▉      | 58/148 [00:52<01:21,  1.11it/s, training_loss=1.5308]\u001b[A\n",
      "Epoch 11:  39%|███▉      | 58/148 [00:52<01:21,  1.11it/s, training_loss=0.9742]\u001b[A\n",
      "Epoch 11:  40%|███▉      | 59/148 [00:52<01:20,  1.11it/s, training_loss=0.9742]\u001b[A\n",
      "Epoch 11:  40%|███▉      | 59/148 [00:53<01:20,  1.11it/s, training_loss=0.9225]\u001b[A\n",
      "Epoch 11:  41%|████      | 60/148 [00:53<01:19,  1.11it/s, training_loss=0.9225]\u001b[A\n",
      "Epoch 11:  41%|████      | 60/148 [00:54<01:19,  1.11it/s, training_loss=0.8984]\u001b[A\n",
      "Epoch 11:  41%|████      | 61/148 [00:54<01:18,  1.11it/s, training_loss=0.8984]\u001b[A\n",
      "Epoch 11:  41%|████      | 61/148 [00:55<01:18,  1.11it/s, training_loss=1.6264]\u001b[A\n",
      "Epoch 11:  42%|████▏     | 62/148 [00:55<01:17,  1.11it/s, training_loss=1.6264]\u001b[A\n",
      "Epoch 11:  42%|████▏     | 62/148 [00:56<01:17,  1.11it/s, training_loss=1.5227]\u001b[A\n",
      "Epoch 11:  43%|████▎     | 63/148 [00:56<01:16,  1.11it/s, training_loss=1.5227]\u001b[A\n",
      "Epoch 11:  43%|████▎     | 63/148 [00:57<01:16,  1.11it/s, training_loss=1.5190]\u001b[A\n",
      "Epoch 11:  43%|████▎     | 64/148 [00:57<01:15,  1.11it/s, training_loss=1.5190]\u001b[A\n",
      "Epoch 11:  43%|████▎     | 64/148 [00:58<01:15,  1.11it/s, training_loss=0.8390]\u001b[A\n",
      "Epoch 11:  44%|████▍     | 65/148 [00:58<01:14,  1.11it/s, training_loss=0.8390]\u001b[A\n",
      "Epoch 11:  44%|████▍     | 65/148 [00:59<01:14,  1.11it/s, training_loss=0.9435]\u001b[A\n",
      "Epoch 11:  45%|████▍     | 66/148 [00:59<01:13,  1.11it/s, training_loss=0.9435]\u001b[A\n",
      "Epoch 11:  45%|████▍     | 66/148 [01:00<01:13,  1.11it/s, training_loss=1.0008]\u001b[A\n",
      "Epoch 11:  45%|████▌     | 67/148 [01:00<01:13,  1.11it/s, training_loss=1.0008]\u001b[A\n",
      "Epoch 11:  45%|████▌     | 67/148 [01:01<01:13,  1.11it/s, training_loss=1.6887]\u001b[A\n",
      "Epoch 11:  46%|████▌     | 68/148 [01:01<01:11,  1.11it/s, training_loss=1.6887]\u001b[A\n",
      "Epoch 11:  46%|████▌     | 68/148 [01:01<01:11,  1.11it/s, training_loss=0.8258]\u001b[A\n",
      "Epoch 11:  47%|████▋     | 69/148 [01:01<01:10,  1.11it/s, training_loss=0.8258]\u001b[A\n",
      "Epoch 11:  47%|████▋     | 69/148 [01:02<01:10,  1.11it/s, training_loss=0.8672]\u001b[A\n",
      "Epoch 11:  47%|████▋     | 70/148 [01:02<01:10,  1.11it/s, training_loss=0.8672]\u001b[A\n",
      "Epoch 11:  47%|████▋     | 70/148 [01:03<01:10,  1.11it/s, training_loss=1.6003]\u001b[A\n",
      "Epoch 11:  48%|████▊     | 71/148 [01:03<01:09,  1.11it/s, training_loss=1.6003]\u001b[A\n",
      "Epoch 11:  48%|████▊     | 71/148 [01:04<01:09,  1.11it/s, training_loss=1.5854]\u001b[A\n",
      "Epoch 11:  49%|████▊     | 72/148 [01:04<01:08,  1.11it/s, training_loss=1.5854]\u001b[A\n",
      "Epoch 11:  49%|████▊     | 72/148 [01:05<01:08,  1.11it/s, training_loss=1.4927]\u001b[A\n",
      "Epoch 11:  49%|████▉     | 73/148 [01:05<01:07,  1.11it/s, training_loss=1.4927]\u001b[A\n",
      "Epoch 11:  49%|████▉     | 73/148 [01:06<01:07,  1.11it/s, training_loss=0.9131]\u001b[A\n",
      "Epoch 11:  50%|█████     | 74/148 [01:06<01:06,  1.11it/s, training_loss=0.9131]\u001b[A\n",
      "Epoch 11:  50%|█████     | 74/148 [01:07<01:06,  1.11it/s, training_loss=0.8584]\u001b[A\n",
      "Epoch 11:  51%|█████     | 75/148 [01:07<01:05,  1.11it/s, training_loss=0.8584]\u001b[A\n",
      "Epoch 11:  51%|█████     | 75/148 [01:08<01:05,  1.11it/s, training_loss=1.6293]\u001b[A\n",
      "Epoch 11:  51%|█████▏    | 76/148 [01:08<01:04,  1.11it/s, training_loss=1.6293]\u001b[A\n",
      "Epoch 11:  51%|█████▏    | 76/148 [01:09<01:04,  1.11it/s, training_loss=0.8396]\u001b[A\n",
      "Epoch 11:  52%|█████▏    | 77/148 [01:09<01:03,  1.11it/s, training_loss=0.8396]\u001b[A\n",
      "Epoch 11:  52%|█████▏    | 77/148 [01:10<01:03,  1.11it/s, training_loss=1.0222]\u001b[A\n",
      "Epoch 11:  53%|█████▎    | 78/148 [01:10<01:02,  1.11it/s, training_loss=1.0222]\u001b[A\n",
      "Epoch 11:  53%|█████▎    | 78/148 [01:10<01:02,  1.11it/s, training_loss=0.9718]\u001b[A\n",
      "Epoch 11:  53%|█████▎    | 79/148 [01:10<01:02,  1.11it/s, training_loss=0.9718]\u001b[A\n",
      "Epoch 11:  53%|█████▎    | 79/148 [01:11<01:02,  1.11it/s, training_loss=0.9701]\u001b[A\n",
      "Epoch 11:  54%|█████▍    | 80/148 [01:11<01:01,  1.11it/s, training_loss=0.9701]\u001b[A\n",
      "Epoch 11:  54%|█████▍    | 80/148 [01:12<01:01,  1.11it/s, training_loss=0.8459]\u001b[A\n",
      "Epoch 11:  55%|█████▍    | 81/148 [01:12<01:00,  1.11it/s, training_loss=0.8459]\u001b[A\n",
      "Epoch 11:  55%|█████▍    | 81/148 [01:13<01:00,  1.11it/s, training_loss=1.6070]\u001b[A\n",
      "Epoch 11:  55%|█████▌    | 82/148 [01:13<00:59,  1.11it/s, training_loss=1.6070]\u001b[A\n",
      "Epoch 11:  55%|█████▌    | 82/148 [01:14<00:59,  1.11it/s, training_loss=1.5753]\u001b[A\n",
      "Epoch 11:  56%|█████▌    | 83/148 [01:14<00:58,  1.11it/s, training_loss=1.5753]\u001b[A\n",
      "Epoch 11:  56%|█████▌    | 83/148 [01:15<00:58,  1.11it/s, training_loss=1.4695]\u001b[A\n",
      "Epoch 11:  57%|█████▋    | 84/148 [01:15<00:57,  1.12it/s, training_loss=1.4695]\u001b[A\n",
      "Epoch 11:  57%|█████▋    | 84/148 [01:16<00:57,  1.12it/s, training_loss=0.9647]\u001b[A\n",
      "Epoch 11:  57%|█████▋    | 85/148 [01:16<00:56,  1.12it/s, training_loss=0.9647]\u001b[A\n",
      "Epoch 11:  57%|█████▋    | 85/148 [01:17<00:56,  1.12it/s, training_loss=1.0052]\u001b[A\n",
      "Epoch 11:  58%|█████▊    | 86/148 [01:17<00:55,  1.11it/s, training_loss=1.0052]\u001b[A\n",
      "Epoch 11:  58%|█████▊    | 86/148 [01:18<00:55,  1.11it/s, training_loss=1.5406]\u001b[A\n",
      "Epoch 11:  59%|█████▉    | 87/148 [01:18<00:54,  1.11it/s, training_loss=1.5406]\u001b[A\n",
      "Epoch 11:  59%|█████▉    | 87/148 [01:19<00:54,  1.11it/s, training_loss=1.1498]\u001b[A\n",
      "Epoch 11:  59%|█████▉    | 88/148 [01:19<00:53,  1.11it/s, training_loss=1.1498]\u001b[A\n",
      "Epoch 11:  59%|█████▉    | 88/148 [01:19<00:53,  1.11it/s, training_loss=1.5692]\u001b[A\n",
      "Epoch 11:  60%|██████    | 89/148 [01:19<00:53,  1.11it/s, training_loss=1.5692]\u001b[A\n",
      "Epoch 11:  60%|██████    | 89/148 [01:20<00:53,  1.11it/s, training_loss=0.9564]\u001b[A\n",
      "Epoch 11:  61%|██████    | 90/148 [01:20<00:52,  1.12it/s, training_loss=0.9564]\u001b[A\n",
      "Epoch 11:  61%|██████    | 90/148 [01:21<00:52,  1.12it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 11:  61%|██████▏   | 91/148 [01:21<00:51,  1.12it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 11:  61%|██████▏   | 91/148 [01:22<00:51,  1.12it/s, training_loss=0.9712]\u001b[A\n",
      "Epoch 11:  62%|██████▏   | 92/148 [01:22<00:50,  1.11it/s, training_loss=0.9712]\u001b[A\n",
      "Epoch 11:  62%|██████▏   | 92/148 [01:23<00:50,  1.11it/s, training_loss=0.8824]\u001b[A\n",
      "Epoch 11:  63%|██████▎   | 93/148 [01:23<00:49,  1.11it/s, training_loss=0.8824]\u001b[A\n",
      "Epoch 11:  63%|██████▎   | 93/148 [01:24<00:49,  1.11it/s, training_loss=1.5802]\u001b[A\n",
      "Epoch 11:  64%|██████▎   | 94/148 [01:24<00:48,  1.11it/s, training_loss=1.5802]\u001b[A\n",
      "Epoch 11:  64%|██████▎   | 94/148 [01:25<00:48,  1.11it/s, training_loss=1.5365]\u001b[A\n",
      "Epoch 11:  64%|██████▍   | 95/148 [01:25<00:47,  1.12it/s, training_loss=1.5365]\u001b[A\n",
      "Epoch 11:  64%|██████▍   | 95/148 [01:26<00:47,  1.12it/s, training_loss=0.8923]\u001b[A\n",
      "Epoch 11:  65%|██████▍   | 96/148 [01:26<00:46,  1.11it/s, training_loss=0.8923]\u001b[A\n",
      "Epoch 11:  65%|██████▍   | 96/148 [01:27<00:46,  1.11it/s, training_loss=1.5238]\u001b[A\n",
      "Epoch 11:  66%|██████▌   | 97/148 [01:27<00:45,  1.11it/s, training_loss=1.5238]\u001b[A\n",
      "Epoch 11:  66%|██████▌   | 97/148 [01:28<00:45,  1.11it/s, training_loss=1.5508]\u001b[A\n",
      "Epoch 11:  66%|██████▌   | 98/148 [01:28<00:44,  1.12it/s, training_loss=1.5508]\u001b[A\n",
      "Epoch 11:  66%|██████▌   | 98/148 [01:28<00:44,  1.12it/s, training_loss=1.5795]\u001b[A\n",
      "Epoch 11:  67%|██████▋   | 99/148 [01:28<00:43,  1.12it/s, training_loss=1.5795]\u001b[A\n",
      "Epoch 11:  67%|██████▋   | 99/148 [01:29<00:43,  1.12it/s, training_loss=0.8101]\u001b[A\n",
      "Epoch 11:  68%|██████▊   | 100/148 [01:29<00:43,  1.11it/s, training_loss=0.8101]\u001b[A\n",
      "Epoch 11:  68%|██████▊   | 100/148 [01:30<00:43,  1.11it/s, training_loss=1.5225]\u001b[A\n",
      "Epoch 11:  68%|██████▊   | 101/148 [01:30<00:42,  1.11it/s, training_loss=1.5225]\u001b[A\n",
      "Epoch 11:  68%|██████▊   | 101/148 [01:31<00:42,  1.11it/s, training_loss=1.5609]\u001b[A\n",
      "Epoch 11:  69%|██████▉   | 102/148 [01:31<00:41,  1.11it/s, training_loss=1.5609]\u001b[A\n",
      "Epoch 11:  69%|██████▉   | 102/148 [01:32<00:41,  1.11it/s, training_loss=1.6508]\u001b[A\n",
      "Epoch 11:  70%|██████▉   | 103/148 [01:32<00:40,  1.12it/s, training_loss=1.6508]\u001b[A\n",
      "Epoch 11:  70%|██████▉   | 103/148 [01:33<00:40,  1.12it/s, training_loss=0.8909]\u001b[A\n",
      "Epoch 11:  70%|███████   | 104/148 [01:33<00:39,  1.12it/s, training_loss=0.8909]\u001b[A\n",
      "Epoch 11:  70%|███████   | 104/148 [01:34<00:39,  1.12it/s, training_loss=1.5924]\u001b[A\n",
      "Epoch 11:  71%|███████   | 105/148 [01:34<00:38,  1.12it/s, training_loss=1.5924]\u001b[A\n",
      "Epoch 11:  71%|███████   | 105/148 [01:35<00:38,  1.12it/s, training_loss=1.5749]\u001b[A\n",
      "Epoch 11:  72%|███████▏  | 106/148 [01:35<00:37,  1.12it/s, training_loss=1.5749]\u001b[A\n",
      "Epoch 11:  72%|███████▏  | 106/148 [01:36<00:37,  1.12it/s, training_loss=0.8354]\u001b[A\n",
      "Epoch 11:  72%|███████▏  | 107/148 [01:36<00:36,  1.11it/s, training_loss=0.8354]\u001b[A\n",
      "Epoch 11:  72%|███████▏  | 107/148 [01:37<00:36,  1.11it/s, training_loss=1.6181]\u001b[A\n",
      "Epoch 11:  73%|███████▎  | 108/148 [01:37<00:35,  1.12it/s, training_loss=1.6181]\u001b[A\n",
      "Epoch 11:  73%|███████▎  | 108/148 [01:37<00:35,  1.12it/s, training_loss=1.6408]\u001b[A\n",
      "Epoch 11:  74%|███████▎  | 109/148 [01:37<00:34,  1.12it/s, training_loss=1.6408]\u001b[A\n",
      "Epoch 11:  74%|███████▎  | 109/148 [01:38<00:34,  1.12it/s, training_loss=0.9160]\u001b[A\n",
      "Epoch 11:  74%|███████▍  | 110/148 [01:38<00:34,  1.12it/s, training_loss=0.9160]\u001b[A\n",
      "Epoch 11:  74%|███████▍  | 110/148 [01:39<00:34,  1.12it/s, training_loss=1.6525]\u001b[A\n",
      "Epoch 11:  75%|███████▌  | 111/148 [01:39<00:33,  1.11it/s, training_loss=1.6525]\u001b[A\n",
      "Epoch 11:  75%|███████▌  | 111/148 [01:40<00:33,  1.11it/s, training_loss=0.9806]\u001b[A\n",
      "Epoch 11:  76%|███████▌  | 112/148 [01:40<00:32,  1.11it/s, training_loss=0.9806]\u001b[A\n",
      "Epoch 11:  76%|███████▌  | 112/148 [01:41<00:32,  1.11it/s, training_loss=0.8504]\u001b[A\n",
      "Epoch 11:  76%|███████▋  | 113/148 [01:41<00:31,  1.11it/s, training_loss=0.8504]\u001b[A\n",
      "Epoch 11:  76%|███████▋  | 113/148 [01:42<00:31,  1.11it/s, training_loss=0.8330]\u001b[A\n",
      "Epoch 11:  77%|███████▋  | 114/148 [01:42<00:30,  1.11it/s, training_loss=0.8330]\u001b[A\n",
      "Epoch 11:  77%|███████▋  | 114/148 [01:43<00:30,  1.11it/s, training_loss=1.1588]\u001b[A\n",
      "Epoch 11:  78%|███████▊  | 115/148 [01:43<00:29,  1.11it/s, training_loss=1.1588]\u001b[A\n",
      "Epoch 11:  78%|███████▊  | 115/148 [01:44<00:29,  1.11it/s, training_loss=1.5181]\u001b[A\n",
      "Epoch 11:  78%|███████▊  | 116/148 [01:44<00:28,  1.11it/s, training_loss=1.5181]\u001b[A\n",
      "Epoch 11:  78%|███████▊  | 116/148 [01:45<00:28,  1.11it/s, training_loss=0.9899]\u001b[A\n",
      "Epoch 11:  79%|███████▉  | 117/148 [01:45<00:27,  1.11it/s, training_loss=0.9899]\u001b[A\n",
      "Epoch 11:  79%|███████▉  | 117/148 [01:46<00:27,  1.11it/s, training_loss=1.6184]\u001b[A\n",
      "Epoch 11:  80%|███████▉  | 118/148 [01:46<00:26,  1.11it/s, training_loss=1.6184]\u001b[A\n",
      "Epoch 11:  80%|███████▉  | 118/148 [01:46<00:26,  1.11it/s, training_loss=1.5807]\u001b[A\n",
      "Epoch 11:  80%|████████  | 119/148 [01:46<00:25,  1.12it/s, training_loss=1.5807]\u001b[A\n",
      "Epoch 11:  80%|████████  | 119/148 [01:47<00:25,  1.12it/s, training_loss=0.9938]\u001b[A\n",
      "Epoch 11:  81%|████████  | 120/148 [01:47<00:25,  1.12it/s, training_loss=0.9938]\u001b[A\n",
      "Epoch 11:  81%|████████  | 120/148 [01:48<00:25,  1.12it/s, training_loss=0.8512]\u001b[A\n",
      "Epoch 11:  82%|████████▏ | 121/148 [01:48<00:24,  1.12it/s, training_loss=0.8512]\u001b[A\n",
      "Epoch 11:  82%|████████▏ | 121/148 [01:49<00:24,  1.12it/s, training_loss=1.5651]\u001b[A\n",
      "Epoch 11:  82%|████████▏ | 122/148 [01:49<00:23,  1.12it/s, training_loss=1.5651]\u001b[A\n",
      "Epoch 11:  82%|████████▏ | 122/148 [01:50<00:23,  1.12it/s, training_loss=1.0480]\u001b[A\n",
      "Epoch 11:  83%|████████▎ | 123/148 [01:50<00:22,  1.11it/s, training_loss=1.0480]\u001b[A\n",
      "Epoch 11:  83%|████████▎ | 123/148 [01:51<00:22,  1.11it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 11:  84%|████████▍ | 124/148 [01:51<00:21,  1.11it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 11:  84%|████████▍ | 124/148 [01:52<00:21,  1.11it/s, training_loss=1.0441]\u001b[A\n",
      "Epoch 11:  84%|████████▍ | 125/148 [01:52<00:20,  1.11it/s, training_loss=1.0441]\u001b[A\n",
      "Epoch 11:  84%|████████▍ | 125/148 [01:53<00:20,  1.11it/s, training_loss=1.0066]\u001b[A\n",
      "Epoch 11:  85%|████████▌ | 126/148 [01:53<00:19,  1.11it/s, training_loss=1.0066]\u001b[A\n",
      "Epoch 11:  85%|████████▌ | 126/148 [01:54<00:19,  1.11it/s, training_loss=1.3502]\u001b[A\n",
      "Epoch 11:  86%|████████▌ | 127/148 [01:54<00:18,  1.12it/s, training_loss=1.3502]\u001b[A\n",
      "Epoch 11:  86%|████████▌ | 127/148 [01:54<00:18,  1.12it/s, training_loss=1.5989]\u001b[A\n",
      "Epoch 11:  86%|████████▋ | 128/148 [01:54<00:17,  1.12it/s, training_loss=1.5989]\u001b[A\n",
      "Epoch 11:  86%|████████▋ | 128/148 [01:55<00:17,  1.12it/s, training_loss=1.6551]\u001b[A\n",
      "Epoch 11:  87%|████████▋ | 129/148 [01:55<00:17,  1.12it/s, training_loss=1.6551]\u001b[A\n",
      "Epoch 11:  87%|████████▋ | 129/148 [01:56<00:17,  1.12it/s, training_loss=1.1651]\u001b[A\n",
      "Epoch 11:  88%|████████▊ | 130/148 [01:56<00:16,  1.12it/s, training_loss=1.1651]\u001b[A\n",
      "Epoch 11:  88%|████████▊ | 130/148 [01:57<00:16,  1.12it/s, training_loss=1.5396]\u001b[A\n",
      "Epoch 11:  89%|████████▊ | 131/148 [01:57<00:15,  1.12it/s, training_loss=1.5396]\u001b[A\n",
      "Epoch 11:  89%|████████▊ | 131/148 [01:58<00:15,  1.12it/s, training_loss=0.8527]\u001b[A\n",
      "Epoch 11:  89%|████████▉ | 132/148 [01:58<00:14,  1.11it/s, training_loss=0.8527]\u001b[A\n",
      "Epoch 11:  89%|████████▉ | 132/148 [01:59<00:14,  1.11it/s, training_loss=1.5966]\u001b[A\n",
      "Epoch 11:  90%|████████▉ | 133/148 [01:59<00:13,  1.11it/s, training_loss=1.5966]\u001b[A\n",
      "Epoch 11:  90%|████████▉ | 133/148 [02:00<00:13,  1.11it/s, training_loss=0.9017]\u001b[A\n",
      "Epoch 11:  91%|█████████ | 134/148 [02:00<00:12,  1.11it/s, training_loss=0.9017]\u001b[A\n",
      "Epoch 11:  91%|█████████ | 134/148 [02:01<00:12,  1.11it/s, training_loss=1.4869]\u001b[A\n",
      "Epoch 11:  91%|█████████ | 135/148 [02:01<00:11,  1.11it/s, training_loss=1.4869]\u001b[A\n",
      "Epoch 11:  91%|█████████ | 135/148 [02:02<00:11,  1.11it/s, training_loss=1.6288]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 136/148 [02:02<00:10,  1.12it/s, training_loss=1.6288]\u001b[A\n",
      "Epoch 11:  92%|█████████▏| 136/148 [02:03<00:10,  1.12it/s, training_loss=0.8463]\u001b[A\n",
      "Epoch 11:  93%|█████████▎| 137/148 [02:03<00:09,  1.11it/s, training_loss=0.8463]\u001b[A\n",
      "Epoch 11:  93%|█████████▎| 137/148 [02:03<00:09,  1.11it/s, training_loss=1.7225]\u001b[A\n",
      "Epoch 11:  93%|█████████▎| 138/148 [02:03<00:08,  1.11it/s, training_loss=1.7225]\u001b[A\n",
      "Epoch 11:  93%|█████████▎| 138/148 [02:04<00:08,  1.11it/s, training_loss=0.8158]\u001b[A\n",
      "Epoch 11:  94%|█████████▍| 139/148 [02:04<00:08,  1.11it/s, training_loss=0.8158]\u001b[A\n",
      "Epoch 11:  94%|█████████▍| 139/148 [02:05<00:08,  1.11it/s, training_loss=1.5909]\u001b[A\n",
      "Epoch 11:  95%|█████████▍| 140/148 [02:05<00:07,  1.11it/s, training_loss=1.5909]\u001b[A\n",
      "Epoch 11:  95%|█████████▍| 140/148 [02:06<00:07,  1.11it/s, training_loss=1.5706]\u001b[A\n",
      "Epoch 11:  95%|█████████▌| 141/148 [02:06<00:06,  1.11it/s, training_loss=1.5706]\u001b[A\n",
      "Epoch 11:  95%|█████████▌| 141/148 [02:07<00:06,  1.11it/s, training_loss=0.9032]\u001b[A\n",
      "Epoch 11:  96%|█████████▌| 142/148 [02:07<00:05,  1.11it/s, training_loss=0.9032]\u001b[A\n",
      "Epoch 11:  96%|█████████▌| 142/148 [02:08<00:05,  1.11it/s, training_loss=0.8282]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 143/148 [02:08<00:04,  1.11it/s, training_loss=0.8282]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 143/148 [02:09<00:04,  1.11it/s, training_loss=0.8284]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 144/148 [02:09<00:03,  1.11it/s, training_loss=0.8284]\u001b[A\n",
      "Epoch 11:  97%|█████████▋| 144/148 [02:10<00:03,  1.11it/s, training_loss=1.5744]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 145/148 [02:10<00:02,  1.11it/s, training_loss=1.5744]\u001b[A\n",
      "Epoch 11:  98%|█████████▊| 145/148 [02:11<00:02,  1.11it/s, training_loss=0.8674]\u001b[A\n",
      "Epoch 11:  99%|█████████▊| 146/148 [02:11<00:01,  1.11it/s, training_loss=0.8674]\u001b[A\n",
      "Epoch 11:  99%|█████████▊| 146/148 [02:12<00:01,  1.11it/s, training_loss=1.0029]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 147/148 [02:12<00:00,  1.11it/s, training_loss=1.0029]\u001b[A\n",
      "Epoch 11:  99%|█████████▉| 147/148 [02:12<00:00,  1.11it/s, training_loss=1.4416]\u001b[A\n",
      "Epoch 11: 100%|██████████| 148/148 [02:12<00:00,  1.21it/s, training_loss=1.4416]\u001b[A\n",
      "                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:15:19,403 - INFO - Starting model evaluation...\n",
      "2025-02-19 11:15:19,404 - INFO - Memory usage after evaluation start: 4046.28 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.71it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.71it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.63it/s, Accuracy=72.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.63it/s, Accuracy=70.67%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.64it/s, Accuracy=70.67%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.64it/s, Accuracy=69.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.63it/s, Accuracy=69.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.63it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.63it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.63it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.65it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.65it/s, Accuracy=69.14%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.65it/s, Accuracy=69.14%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.65it/s, Accuracy=67.75%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.65it/s, Accuracy=67.75%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.65it/s, Accuracy=67.11%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.64it/s, Accuracy=67.11%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.64it/s, Accuracy=68.20%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.64it/s, Accuracy=68.20%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.64it/s, Accuracy=67.82%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.64it/s, Accuracy=67.82%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.64it/s, Accuracy=68.33%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.64it/s, Accuracy=68.33%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.64it/s, Accuracy=67.54%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.63it/s, Accuracy=67.54%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.63it/s, Accuracy=67.57%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.64it/s, Accuracy=67.57%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.64it/s, Accuracy=67.47%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.64it/s, Accuracy=67.47%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.64it/s, Accuracy=67.00%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.63it/s, Accuracy=67.00%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.63it/s, Accuracy=66.94%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.63it/s, Accuracy=66.94%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.63it/s, Accuracy=67.89%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.63it/s, Accuracy=67.89%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.63it/s, Accuracy=68.42%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.62it/s, Accuracy=68.42%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.62it/s, Accuracy=68.90%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.63it/s, Accuracy=68.90%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.63it/s, Accuracy=68.76%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.63it/s, Accuracy=68.76%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.63it/s, Accuracy=68.82%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.64it/s, Accuracy=68.82%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.64it/s, Accuracy=69.22%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.63it/s, Accuracy=69.22%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.63it/s, Accuracy=68.92%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.64it/s, Accuracy=68.92%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.64it/s, Accuracy=68.96%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.62it/s, Accuracy=68.96%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.62it/s, Accuracy=69.15%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.63it/s, Accuracy=69.15%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.75it/s, Accuracy=69.20%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:15:26,601 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 11:15:26,606 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 11:15:26,607 - INFO - Accuracy: 0.5057\n",
      "2025-02-19 11:15:26,608 - INFO - F1_score: 0.4901\n",
      "2025-02-19 11:15:26,609 - INFO - Precision: 0.3464\n",
      "2025-02-19 11:15:26,610 - INFO - Recall: 0.8378\n",
      "2025-02-19 11:15:26,616 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 11:15:26,616 - INFO - Accuracy: 0.8352\n",
      "2025-02-19 11:15:26,617 - INFO - F1_score: 0.7034\n",
      "2025-02-19 11:15:26,618 - INFO - Precision: 0.5795\n",
      "2025-02-19 11:15:26,618 - INFO - Recall: 0.8947\n",
      "2025-02-19 11:15:26,625 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 11:15:26,626 - INFO - Accuracy: 0.6513\n",
      "2025-02-19 11:15:26,627 - INFO - F1_score: 0.5081\n",
      "2025-02-19 11:15:26,627 - INFO - Precision: 0.3701\n",
      "2025-02-19 11:15:26,628 - INFO - Recall: 0.8103\n",
      "2025-02-19 11:15:26,635 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 11:15:26,635 - INFO - Accuracy: 0.6705\n",
      "2025-02-19 11:15:26,636 - INFO - F1_score: 0.3281\n",
      "2025-02-19 11:15:26,637 - INFO - Precision: 0.2333\n",
      "2025-02-19 11:15:26,638 - INFO - Recall: 0.5526\n",
      "2025-02-19 11:15:26,644 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 11:15:26,645 - INFO - Accuracy: 0.7969\n",
      "2025-02-19 11:15:26,645 - INFO - F1_score: 0.4536\n",
      "2025-02-19 11:15:26,646 - INFO - Precision: 0.3492\n",
      "2025-02-19 11:15:26,647 - INFO - Recall: 0.6471\n",
      "2025-02-19 11:15:26,649 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:15:30,594 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 11:15:30,595 - INFO - Memory usage after evaluation end: 4051.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  10%|█         | 10/100 [28:15<3:49:40, 153.12s/it, Train Loss=1.2469, Val Loss=0.0519, Accuracy=0.6920]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:15:37,682 - INFO - Learning rate: 1.25e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  11%|█         | 11/100 [28:15<3:46:09, 152.47s/it, Train Loss=1.2469, Val Loss=0.0519, Accuracy=0.6920]\n",
      "Epoch 12:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.6570]\u001b[A\n",
      "Epoch 12:   1%|          | 1/148 [00:00<02:10,  1.12it/s, training_loss=1.6570]\u001b[A\n",
      "Epoch 12:   1%|          | 1/148 [00:01<02:10,  1.12it/s, training_loss=0.8456]\u001b[A\n",
      "Epoch 12:   1%|▏         | 2/148 [00:01<02:10,  1.12it/s, training_loss=0.8456]\u001b[A\n",
      "Epoch 12:   1%|▏         | 2/148 [00:02<02:10,  1.12it/s, training_loss=1.5248]\u001b[A\n",
      "Epoch 12:   2%|▏         | 3/148 [00:02<02:09,  1.12it/s, training_loss=1.5248]\u001b[A\n",
      "Epoch 12:   2%|▏         | 3/148 [00:03<02:09,  1.12it/s, training_loss=1.5451]\u001b[A\n",
      "Epoch 12:   3%|▎         | 4/148 [00:03<02:08,  1.12it/s, training_loss=1.5451]\u001b[A\n",
      "Epoch 12:   3%|▎         | 4/148 [00:04<02:08,  1.12it/s, training_loss=0.8749]\u001b[A\n",
      "Epoch 12:   3%|▎         | 5/148 [00:04<02:08,  1.11it/s, training_loss=0.8749]\u001b[A\n",
      "Epoch 12:   3%|▎         | 5/148 [00:05<02:08,  1.11it/s, training_loss=1.4342]\u001b[A\n",
      "Epoch 12:   4%|▍         | 6/148 [00:05<02:07,  1.11it/s, training_loss=1.4342]\u001b[A\n",
      "Epoch 12:   4%|▍         | 6/148 [00:06<02:07,  1.11it/s, training_loss=1.5557]\u001b[A\n",
      "Epoch 12:   5%|▍         | 7/148 [00:06<02:06,  1.12it/s, training_loss=1.5557]\u001b[A\n",
      "Epoch 12:   5%|▍         | 7/148 [00:07<02:06,  1.12it/s, training_loss=0.9157]\u001b[A\n",
      "Epoch 12:   5%|▌         | 8/148 [00:07<02:06,  1.11it/s, training_loss=0.9157]\u001b[A\n",
      "Epoch 12:   5%|▌         | 8/148 [00:08<02:06,  1.11it/s, training_loss=1.5935]\u001b[A\n",
      "Epoch 12:   6%|▌         | 9/148 [00:08<02:04,  1.12it/s, training_loss=1.5935]\u001b[A\n",
      "Epoch 12:   6%|▌         | 9/148 [00:08<02:04,  1.12it/s, training_loss=1.5879]\u001b[A\n",
      "Epoch 12:   7%|▋         | 10/148 [00:08<02:03,  1.11it/s, training_loss=1.5879]\u001b[A\n",
      "Epoch 12:   7%|▋         | 10/148 [00:09<02:03,  1.11it/s, training_loss=1.1245]\u001b[A\n",
      "Epoch 12:   7%|▋         | 11/148 [00:09<02:02,  1.11it/s, training_loss=1.1245]\u001b[A\n",
      "Epoch 12:   7%|▋         | 11/148 [00:10<02:02,  1.11it/s, training_loss=0.9942]\u001b[A\n",
      "Epoch 12:   8%|▊         | 12/148 [00:10<02:02,  1.11it/s, training_loss=0.9942]\u001b[A\n",
      "Epoch 12:   8%|▊         | 12/148 [00:11<02:02,  1.11it/s, training_loss=1.5784]\u001b[A\n",
      "Epoch 12:   9%|▉         | 13/148 [00:11<02:00,  1.12it/s, training_loss=1.5784]\u001b[A\n",
      "Epoch 12:   9%|▉         | 13/148 [00:12<02:00,  1.12it/s, training_loss=0.8571]\u001b[A\n",
      "Epoch 12:   9%|▉         | 14/148 [00:12<02:00,  1.11it/s, training_loss=0.8571]\u001b[A\n",
      "Epoch 12:   9%|▉         | 14/148 [00:13<02:00,  1.11it/s, training_loss=1.5089]\u001b[A\n",
      "Epoch 12:  10%|█         | 15/148 [00:13<01:59,  1.12it/s, training_loss=1.5089]\u001b[A\n",
      "Epoch 12:  10%|█         | 15/148 [00:14<01:59,  1.12it/s, training_loss=0.8791]\u001b[A\n",
      "Epoch 12:  11%|█         | 16/148 [00:14<01:57,  1.12it/s, training_loss=0.8791]\u001b[A\n",
      "Epoch 12:  11%|█         | 16/148 [00:15<01:57,  1.12it/s, training_loss=1.5205]\u001b[A\n",
      "Epoch 12:  11%|█▏        | 17/148 [00:15<01:56,  1.12it/s, training_loss=1.5205]\u001b[A\n",
      "Epoch 12:  11%|█▏        | 17/148 [00:16<01:56,  1.12it/s, training_loss=1.4928]\u001b[A\n",
      "Epoch 12:  12%|█▏        | 18/148 [00:16<01:55,  1.12it/s, training_loss=1.4928]\u001b[A\n",
      "Epoch 12:  12%|█▏        | 18/148 [00:17<01:55,  1.12it/s, training_loss=0.9466]\u001b[A\n",
      "Epoch 12:  13%|█▎        | 19/148 [00:17<01:55,  1.12it/s, training_loss=0.9466]\u001b[A\n",
      "Epoch 12:  13%|█▎        | 19/148 [00:17<01:55,  1.12it/s, training_loss=1.6176]\u001b[A\n",
      "Epoch 12:  14%|█▎        | 20/148 [00:17<01:54,  1.12it/s, training_loss=1.6176]\u001b[A\n",
      "Epoch 12:  14%|█▎        | 20/148 [00:18<01:54,  1.12it/s, training_loss=0.8619]\u001b[A\n",
      "Epoch 12:  14%|█▍        | 21/148 [00:18<01:53,  1.12it/s, training_loss=0.8619]\u001b[A\n",
      "Epoch 12:  14%|█▍        | 21/148 [00:19<01:53,  1.12it/s, training_loss=0.9739]\u001b[A\n",
      "Epoch 12:  15%|█▍        | 22/148 [00:19<01:53,  1.11it/s, training_loss=0.9739]\u001b[A\n",
      "Epoch 12:  15%|█▍        | 22/148 [00:20<01:53,  1.11it/s, training_loss=0.9192]\u001b[A\n",
      "Epoch 12:  16%|█▌        | 23/148 [00:20<01:52,  1.11it/s, training_loss=0.9192]\u001b[A\n",
      "Epoch 12:  16%|█▌        | 23/148 [00:21<01:52,  1.11it/s, training_loss=0.9038]\u001b[A\n",
      "Epoch 12:  16%|█▌        | 24/148 [00:21<01:51,  1.11it/s, training_loss=0.9038]\u001b[A\n",
      "Epoch 12:  16%|█▌        | 24/148 [00:22<01:51,  1.11it/s, training_loss=0.9462]\u001b[A\n",
      "Epoch 12:  17%|█▋        | 25/148 [00:22<01:51,  1.11it/s, training_loss=0.9462]\u001b[A\n",
      "Epoch 12:  17%|█▋        | 25/148 [00:23<01:51,  1.11it/s, training_loss=0.8439]\u001b[A\n",
      "Epoch 12:  18%|█▊        | 26/148 [00:23<01:50,  1.11it/s, training_loss=0.8439]\u001b[A\n",
      "Epoch 12:  18%|█▊        | 26/148 [00:24<01:50,  1.11it/s, training_loss=1.0813]\u001b[A\n",
      "Epoch 12:  18%|█▊        | 27/148 [00:24<01:49,  1.11it/s, training_loss=1.0813]\u001b[A\n",
      "Epoch 12:  18%|█▊        | 27/148 [00:25<01:49,  1.11it/s, training_loss=1.5499]\u001b[A\n",
      "Epoch 12:  19%|█▉        | 28/148 [00:25<01:47,  1.11it/s, training_loss=1.5499]\u001b[A\n",
      "Epoch 12:  19%|█▉        | 28/148 [00:26<01:47,  1.11it/s, training_loss=1.4769]\u001b[A\n",
      "Epoch 12:  20%|█▉        | 29/148 [00:26<01:46,  1.11it/s, training_loss=1.4769]\u001b[A\n",
      "Epoch 12:  20%|█▉        | 29/148 [00:26<01:46,  1.11it/s, training_loss=1.4765]\u001b[A\n",
      "Epoch 12:  20%|██        | 30/148 [00:26<01:46,  1.11it/s, training_loss=1.4765]\u001b[A\n",
      "Epoch 12:  20%|██        | 30/148 [00:27<01:46,  1.11it/s, training_loss=1.6194]\u001b[A\n",
      "Epoch 12:  21%|██        | 31/148 [00:27<01:44,  1.11it/s, training_loss=1.6194]\u001b[A\n",
      "Epoch 12:  21%|██        | 31/148 [00:28<01:44,  1.11it/s, training_loss=1.6061]\u001b[A\n",
      "Epoch 12:  22%|██▏       | 32/148 [00:28<01:44,  1.11it/s, training_loss=1.6061]\u001b[A\n",
      "Epoch 12:  22%|██▏       | 32/148 [00:29<01:44,  1.11it/s, training_loss=1.4114]\u001b[A\n",
      "Epoch 12:  22%|██▏       | 33/148 [00:29<01:43,  1.12it/s, training_loss=1.4114]\u001b[A\n",
      "Epoch 12:  22%|██▏       | 33/148 [00:30<01:43,  1.12it/s, training_loss=1.6149]\u001b[A\n",
      "Epoch 12:  23%|██▎       | 34/148 [00:30<01:42,  1.12it/s, training_loss=1.6149]\u001b[A\n",
      "Epoch 12:  23%|██▎       | 34/148 [00:31<01:42,  1.12it/s, training_loss=1.0624]\u001b[A\n",
      "Epoch 12:  24%|██▎       | 35/148 [00:31<01:41,  1.12it/s, training_loss=1.0624]\u001b[A\n",
      "Epoch 12:  24%|██▎       | 35/148 [00:32<01:41,  1.12it/s, training_loss=1.5159]\u001b[A\n",
      "Epoch 12:  24%|██▍       | 36/148 [00:32<01:40,  1.12it/s, training_loss=1.5159]\u001b[A\n",
      "Epoch 12:  24%|██▍       | 36/148 [00:33<01:40,  1.12it/s, training_loss=0.8407]\u001b[A\n",
      "Epoch 12:  25%|██▌       | 37/148 [00:33<01:39,  1.12it/s, training_loss=0.8407]\u001b[A\n",
      "Epoch 12:  25%|██▌       | 37/148 [00:34<01:39,  1.12it/s, training_loss=0.9374]\u001b[A\n",
      "Epoch 12:  26%|██▌       | 38/148 [00:34<01:38,  1.12it/s, training_loss=0.9374]\u001b[A\n",
      "Epoch 12:  26%|██▌       | 38/148 [00:34<01:38,  1.12it/s, training_loss=1.1736]\u001b[A\n",
      "Epoch 12:  26%|██▋       | 39/148 [00:34<01:37,  1.12it/s, training_loss=1.1736]\u001b[A\n",
      "Epoch 12:  26%|██▋       | 39/148 [00:35<01:37,  1.12it/s, training_loss=1.5860]\u001b[A\n",
      "Epoch 12:  27%|██▋       | 40/148 [00:35<01:36,  1.12it/s, training_loss=1.5860]\u001b[A\n",
      "Epoch 12:  27%|██▋       | 40/148 [00:36<01:36,  1.12it/s, training_loss=0.9656]\u001b[A\n",
      "Epoch 12:  28%|██▊       | 41/148 [00:36<01:36,  1.11it/s, training_loss=0.9656]\u001b[A\n",
      "Epoch 12:  28%|██▊       | 41/148 [00:37<01:36,  1.11it/s, training_loss=0.9302]\u001b[A\n",
      "Epoch 12:  28%|██▊       | 42/148 [00:37<01:35,  1.11it/s, training_loss=0.9302]\u001b[A\n",
      "Epoch 12:  28%|██▊       | 42/148 [00:38<01:35,  1.11it/s, training_loss=1.5992]\u001b[A\n",
      "Epoch 12:  29%|██▉       | 43/148 [00:38<01:33,  1.12it/s, training_loss=1.5992]\u001b[A\n",
      "Epoch 12:  29%|██▉       | 43/148 [00:39<01:33,  1.12it/s, training_loss=1.0511]\u001b[A\n",
      "Epoch 12:  30%|██▉       | 44/148 [00:39<01:33,  1.12it/s, training_loss=1.0511]\u001b[A\n",
      "Epoch 12:  30%|██▉       | 44/148 [00:40<01:33,  1.12it/s, training_loss=0.8799]\u001b[A\n",
      "Epoch 12:  30%|███       | 45/148 [00:40<01:32,  1.11it/s, training_loss=0.8799]\u001b[A\n",
      "Epoch 12:  30%|███       | 45/148 [00:41<01:32,  1.11it/s, training_loss=0.9686]\u001b[A\n",
      "Epoch 12:  31%|███       | 46/148 [00:41<01:31,  1.11it/s, training_loss=0.9686]\u001b[A\n",
      "Epoch 12:  31%|███       | 46/148 [00:42<01:31,  1.11it/s, training_loss=0.8004]\u001b[A\n",
      "Epoch 12:  32%|███▏      | 47/148 [00:42<01:30,  1.11it/s, training_loss=0.8004]\u001b[A\n",
      "Epoch 12:  32%|███▏      | 47/148 [00:43<01:30,  1.11it/s, training_loss=1.5997]\u001b[A\n",
      "Epoch 12:  32%|███▏      | 48/148 [00:43<01:29,  1.12it/s, training_loss=1.5997]\u001b[A\n",
      "Epoch 12:  32%|███▏      | 48/148 [00:43<01:29,  1.12it/s, training_loss=0.9008]\u001b[A\n",
      "Epoch 12:  33%|███▎      | 49/148 [00:43<01:28,  1.11it/s, training_loss=0.9008]\u001b[A\n",
      "Epoch 12:  33%|███▎      | 49/148 [00:44<01:28,  1.11it/s, training_loss=1.5661]\u001b[A\n",
      "Epoch 12:  34%|███▍      | 50/148 [00:44<01:27,  1.12it/s, training_loss=1.5661]\u001b[A\n",
      "Epoch 12:  34%|███▍      | 50/148 [00:45<01:27,  1.12it/s, training_loss=1.5259]\u001b[A\n",
      "Epoch 12:  34%|███▍      | 51/148 [00:45<01:26,  1.12it/s, training_loss=1.5259]\u001b[A\n",
      "Epoch 12:  34%|███▍      | 51/148 [00:46<01:26,  1.12it/s, training_loss=0.8465]\u001b[A\n",
      "Epoch 12:  35%|███▌      | 52/148 [00:46<01:25,  1.12it/s, training_loss=0.8465]\u001b[A\n",
      "Epoch 12:  35%|███▌      | 52/148 [00:47<01:25,  1.12it/s, training_loss=0.8660]\u001b[A\n",
      "Epoch 12:  36%|███▌      | 53/148 [00:47<01:25,  1.11it/s, training_loss=0.8660]\u001b[A\n",
      "Epoch 12:  36%|███▌      | 53/148 [00:48<01:25,  1.11it/s, training_loss=1.5657]\u001b[A\n",
      "Epoch 12:  36%|███▋      | 54/148 [00:48<01:24,  1.11it/s, training_loss=1.5657]\u001b[A\n",
      "Epoch 12:  36%|███▋      | 54/148 [00:49<01:24,  1.11it/s, training_loss=1.5569]\u001b[A\n",
      "Epoch 12:  37%|███▋      | 55/148 [00:49<01:23,  1.12it/s, training_loss=1.5569]\u001b[A\n",
      "Epoch 12:  37%|███▋      | 55/148 [00:50<01:23,  1.12it/s, training_loss=0.8069]\u001b[A\n",
      "Epoch 12:  38%|███▊      | 56/148 [00:50<01:22,  1.11it/s, training_loss=0.8069]\u001b[A\n",
      "Epoch 12:  38%|███▊      | 56/148 [00:51<01:22,  1.11it/s, training_loss=1.5689]\u001b[A\n",
      "Epoch 12:  39%|███▊      | 57/148 [00:51<01:21,  1.11it/s, training_loss=1.5689]\u001b[A\n",
      "Epoch 12:  39%|███▊      | 57/148 [00:52<01:21,  1.11it/s, training_loss=0.9506]\u001b[A\n",
      "Epoch 12:  39%|███▉      | 58/148 [00:52<01:21,  1.11it/s, training_loss=0.9506]\u001b[A\n",
      "Epoch 12:  39%|███▉      | 58/148 [00:52<01:21,  1.11it/s, training_loss=1.0366]\u001b[A\n",
      "Epoch 12:  40%|███▉      | 59/148 [00:52<01:20,  1.11it/s, training_loss=1.0366]\u001b[A\n",
      "Epoch 12:  40%|███▉      | 59/148 [00:53<01:20,  1.11it/s, training_loss=1.6072]\u001b[A\n",
      "Epoch 12:  41%|████      | 60/148 [00:53<01:19,  1.11it/s, training_loss=1.6072]\u001b[A\n",
      "Epoch 12:  41%|████      | 60/148 [00:54<01:19,  1.11it/s, training_loss=0.9125]\u001b[A\n",
      "Epoch 12:  41%|████      | 61/148 [00:54<01:18,  1.11it/s, training_loss=0.9125]\u001b[A\n",
      "Epoch 12:  41%|████      | 61/148 [00:55<01:18,  1.11it/s, training_loss=0.9329]\u001b[A\n",
      "Epoch 12:  42%|████▏     | 62/148 [00:55<01:17,  1.11it/s, training_loss=0.9329]\u001b[A\n",
      "Epoch 12:  42%|████▏     | 62/148 [00:56<01:17,  1.11it/s, training_loss=1.0284]\u001b[A\n",
      "Epoch 12:  43%|████▎     | 63/148 [00:56<01:16,  1.11it/s, training_loss=1.0284]\u001b[A\n",
      "Epoch 12:  43%|████▎     | 63/148 [00:57<01:16,  1.11it/s, training_loss=0.8354]\u001b[A\n",
      "Epoch 12:  43%|████▎     | 64/148 [00:57<01:15,  1.11it/s, training_loss=0.8354]\u001b[A\n",
      "Epoch 12:  43%|████▎     | 64/148 [00:58<01:15,  1.11it/s, training_loss=1.5871]\u001b[A\n",
      "Epoch 12:  44%|████▍     | 65/148 [00:58<01:14,  1.11it/s, training_loss=1.5871]\u001b[A\n",
      "Epoch 12:  44%|████▍     | 65/148 [00:59<01:14,  1.11it/s, training_loss=1.5432]\u001b[A\n",
      "Epoch 12:  45%|████▍     | 66/148 [00:59<01:13,  1.11it/s, training_loss=1.5432]\u001b[A\n",
      "Epoch 12:  45%|████▍     | 66/148 [01:00<01:13,  1.11it/s, training_loss=0.8399]\u001b[A\n",
      "Epoch 12:  45%|████▌     | 67/148 [01:00<01:12,  1.11it/s, training_loss=0.8399]\u001b[A\n",
      "Epoch 12:  45%|████▌     | 67/148 [01:01<01:12,  1.11it/s, training_loss=1.6583]\u001b[A\n",
      "Epoch 12:  46%|████▌     | 68/148 [01:01<01:11,  1.11it/s, training_loss=1.6583]\u001b[A\n",
      "Epoch 12:  46%|████▌     | 68/148 [01:01<01:11,  1.11it/s, training_loss=0.8112]\u001b[A\n",
      "Epoch 12:  47%|████▋     | 69/148 [01:01<01:10,  1.12it/s, training_loss=0.8112]\u001b[A\n",
      "Epoch 12:  47%|████▋     | 69/148 [01:02<01:10,  1.12it/s, training_loss=0.9757]\u001b[A\n",
      "Epoch 12:  47%|████▋     | 70/148 [01:02<01:09,  1.12it/s, training_loss=0.9757]\u001b[A\n",
      "Epoch 12:  47%|████▋     | 70/148 [01:03<01:09,  1.12it/s, training_loss=0.8829]\u001b[A\n",
      "Epoch 12:  48%|████▊     | 71/148 [01:03<01:09,  1.11it/s, training_loss=0.8829]\u001b[A\n",
      "Epoch 12:  48%|████▊     | 71/148 [01:04<01:09,  1.11it/s, training_loss=1.5677]\u001b[A\n",
      "Epoch 12:  49%|████▊     | 72/148 [01:04<01:08,  1.11it/s, training_loss=1.5677]\u001b[A\n",
      "Epoch 12:  49%|████▊     | 72/148 [01:05<01:08,  1.11it/s, training_loss=0.8850]\u001b[A\n",
      "Epoch 12:  49%|████▉     | 73/148 [01:05<01:07,  1.11it/s, training_loss=0.8850]\u001b[A\n",
      "Epoch 12:  49%|████▉     | 73/148 [01:06<01:07,  1.11it/s, training_loss=1.5595]\u001b[A\n",
      "Epoch 12:  50%|█████     | 74/148 [01:06<01:06,  1.11it/s, training_loss=1.5595]\u001b[A\n",
      "Epoch 12:  50%|█████     | 74/148 [01:07<01:06,  1.11it/s, training_loss=1.5521]\u001b[A\n",
      "Epoch 12:  51%|█████     | 75/148 [01:07<01:05,  1.11it/s, training_loss=1.5521]\u001b[A\n",
      "Epoch 12:  51%|█████     | 75/148 [01:08<01:05,  1.11it/s, training_loss=1.5143]\u001b[A\n",
      "Epoch 12:  51%|█████▏    | 76/148 [01:08<01:04,  1.12it/s, training_loss=1.5143]\u001b[A\n",
      "Epoch 12:  51%|█████▏    | 76/148 [01:09<01:04,  1.12it/s, training_loss=0.9075]\u001b[A\n",
      "Epoch 12:  52%|█████▏    | 77/148 [01:09<01:03,  1.11it/s, training_loss=0.9075]\u001b[A\n",
      "Epoch 12:  52%|█████▏    | 77/148 [01:10<01:03,  1.11it/s, training_loss=0.8224]\u001b[A\n",
      "Epoch 12:  53%|█████▎    | 78/148 [01:10<01:02,  1.11it/s, training_loss=0.8224]\u001b[A\n",
      "Epoch 12:  53%|█████▎    | 78/148 [01:10<01:02,  1.11it/s, training_loss=0.8639]\u001b[A\n",
      "Epoch 12:  53%|█████▎    | 79/148 [01:10<01:02,  1.11it/s, training_loss=0.8639]\u001b[A\n",
      "Epoch 12:  53%|█████▎    | 79/148 [01:11<01:02,  1.11it/s, training_loss=0.9684]\u001b[A\n",
      "Epoch 12:  54%|█████▍    | 80/148 [01:11<01:01,  1.11it/s, training_loss=0.9684]\u001b[A\n",
      "Epoch 12:  54%|█████▍    | 80/148 [01:12<01:01,  1.11it/s, training_loss=0.8979]\u001b[A\n",
      "Epoch 12:  55%|█████▍    | 81/148 [01:12<01:00,  1.11it/s, training_loss=0.8979]\u001b[A\n",
      "Epoch 12:  55%|█████▍    | 81/148 [01:13<01:00,  1.11it/s, training_loss=1.4412]\u001b[A\n",
      "Epoch 12:  55%|█████▌    | 82/148 [01:13<00:59,  1.11it/s, training_loss=1.4412]\u001b[A\n",
      "Epoch 12:  55%|█████▌    | 82/148 [01:14<00:59,  1.11it/s, training_loss=0.9359]\u001b[A\n",
      "Epoch 12:  56%|█████▌    | 83/148 [01:14<00:58,  1.11it/s, training_loss=0.9359]\u001b[A\n",
      "Epoch 12:  56%|█████▌    | 83/148 [01:15<00:58,  1.11it/s, training_loss=1.5401]\u001b[A\n",
      "Epoch 12:  57%|█████▋    | 84/148 [01:15<00:57,  1.11it/s, training_loss=1.5401]\u001b[A\n",
      "Epoch 12:  57%|█████▋    | 84/148 [01:16<00:57,  1.11it/s, training_loss=0.8894]\u001b[A\n",
      "Epoch 12:  57%|█████▋    | 85/148 [01:16<00:56,  1.11it/s, training_loss=0.8894]\u001b[A\n",
      "Epoch 12:  57%|█████▋    | 85/148 [01:17<00:56,  1.11it/s, training_loss=0.9654]\u001b[A\n",
      "Epoch 12:  58%|█████▊    | 86/148 [01:17<00:55,  1.11it/s, training_loss=0.9654]\u001b[A\n",
      "Epoch 12:  58%|█████▊    | 86/148 [01:18<00:55,  1.11it/s, training_loss=1.5667]\u001b[A\n",
      "Epoch 12:  59%|█████▉    | 87/148 [01:18<00:54,  1.11it/s, training_loss=1.5667]\u001b[A\n",
      "Epoch 12:  59%|█████▉    | 87/148 [01:19<00:54,  1.11it/s, training_loss=0.8995]\u001b[A\n",
      "Epoch 12:  59%|█████▉    | 88/148 [01:19<00:54,  1.11it/s, training_loss=0.8995]\u001b[A\n",
      "Epoch 12:  59%|█████▉    | 88/148 [01:19<00:54,  1.11it/s, training_loss=0.9252]\u001b[A\n",
      "Epoch 12:  60%|██████    | 89/148 [01:19<00:53,  1.11it/s, training_loss=0.9252]\u001b[A\n",
      "Epoch 12:  60%|██████    | 89/148 [01:20<00:53,  1.11it/s, training_loss=0.8839]\u001b[A\n",
      "Epoch 12:  61%|██████    | 90/148 [01:20<00:52,  1.12it/s, training_loss=0.8839]\u001b[A\n",
      "Epoch 12:  61%|██████    | 90/148 [01:21<00:52,  1.12it/s, training_loss=0.8680]\u001b[A\n",
      "Epoch 12:  61%|██████▏   | 91/148 [01:21<00:51,  1.11it/s, training_loss=0.8680]\u001b[A\n",
      "Epoch 12:  61%|██████▏   | 91/148 [01:22<00:51,  1.11it/s, training_loss=1.6488]\u001b[A\n",
      "Epoch 12:  62%|██████▏   | 92/148 [01:22<00:50,  1.12it/s, training_loss=1.6488]\u001b[A\n",
      "Epoch 12:  62%|██████▏   | 92/148 [01:23<00:50,  1.12it/s, training_loss=1.0083]\u001b[A\n",
      "Epoch 12:  63%|██████▎   | 93/148 [01:23<00:49,  1.11it/s, training_loss=1.0083]\u001b[A\n",
      "Epoch 12:  63%|██████▎   | 93/148 [01:24<00:49,  1.11it/s, training_loss=0.8271]\u001b[A\n",
      "Epoch 12:  64%|██████▎   | 94/148 [01:24<00:48,  1.11it/s, training_loss=0.8271]\u001b[A\n",
      "Epoch 12:  64%|██████▎   | 94/148 [01:25<00:48,  1.11it/s, training_loss=0.8704]\u001b[A\n",
      "Epoch 12:  64%|██████▍   | 95/148 [01:25<00:47,  1.11it/s, training_loss=0.8704]\u001b[A\n",
      "Epoch 12:  64%|██████▍   | 95/148 [01:26<00:47,  1.11it/s, training_loss=0.8996]\u001b[A\n",
      "Epoch 12:  65%|██████▍   | 96/148 [01:26<00:46,  1.11it/s, training_loss=0.8996]\u001b[A\n",
      "Epoch 12:  65%|██████▍   | 96/148 [01:27<00:46,  1.11it/s, training_loss=0.9610]\u001b[A\n",
      "Epoch 12:  66%|██████▌   | 97/148 [01:27<00:45,  1.11it/s, training_loss=0.9610]\u001b[A\n",
      "Epoch 12:  66%|██████▌   | 97/148 [01:28<00:45,  1.11it/s, training_loss=1.6373]\u001b[A\n",
      "Epoch 12:  66%|██████▌   | 98/148 [01:28<00:44,  1.11it/s, training_loss=1.6373]\u001b[A\n",
      "Epoch 12:  66%|██████▌   | 98/148 [01:28<00:44,  1.11it/s, training_loss=1.2296]\u001b[A\n",
      "Epoch 12:  67%|██████▋   | 99/148 [01:28<00:43,  1.12it/s, training_loss=1.2296]\u001b[A\n",
      "Epoch 12:  67%|██████▋   | 99/148 [01:29<00:43,  1.12it/s, training_loss=0.9213]\u001b[A\n",
      "Epoch 12:  68%|██████▊   | 100/148 [01:29<00:43,  1.11it/s, training_loss=0.9213]\u001b[A\n",
      "Epoch 12:  68%|██████▊   | 100/148 [01:30<00:43,  1.11it/s, training_loss=0.9187]\u001b[A\n",
      "Epoch 12:  68%|██████▊   | 101/148 [01:30<00:42,  1.11it/s, training_loss=0.9187]\u001b[A\n",
      "Epoch 12:  68%|██████▊   | 101/148 [01:31<00:42,  1.11it/s, training_loss=1.6055]\u001b[A\n",
      "Epoch 12:  69%|██████▉   | 102/148 [01:31<00:41,  1.11it/s, training_loss=1.6055]\u001b[A\n",
      "Epoch 12:  69%|██████▉   | 102/148 [01:32<00:41,  1.11it/s, training_loss=1.5276]\u001b[A\n",
      "Epoch 12:  70%|██████▉   | 103/148 [01:32<00:40,  1.11it/s, training_loss=1.5276]\u001b[A\n",
      "Epoch 12:  70%|██████▉   | 103/148 [01:33<00:40,  1.11it/s, training_loss=1.4504]\u001b[A\n",
      "Epoch 12:  70%|███████   | 104/148 [01:33<00:39,  1.11it/s, training_loss=1.4504]\u001b[A\n",
      "Epoch 12:  70%|███████   | 104/148 [01:34<00:39,  1.11it/s, training_loss=1.5929]\u001b[A\n",
      "Epoch 12:  71%|███████   | 105/148 [01:34<00:38,  1.11it/s, training_loss=1.5929]\u001b[A\n",
      "Epoch 12:  71%|███████   | 105/148 [01:35<00:38,  1.11it/s, training_loss=1.3345]\u001b[A\n",
      "Epoch 12:  72%|███████▏  | 106/148 [01:35<00:37,  1.11it/s, training_loss=1.3345]\u001b[A\n",
      "Epoch 12:  72%|███████▏  | 106/148 [01:36<00:37,  1.11it/s, training_loss=1.6589]\u001b[A\n",
      "Epoch 12:  72%|███████▏  | 107/148 [01:36<00:36,  1.11it/s, training_loss=1.6589]\u001b[A\n",
      "Epoch 12:  72%|███████▏  | 107/148 [01:37<00:36,  1.11it/s, training_loss=0.9109]\u001b[A\n",
      "Epoch 12:  73%|███████▎  | 108/148 [01:37<00:36,  1.11it/s, training_loss=0.9109]\u001b[A\n",
      "Epoch 12:  73%|███████▎  | 108/148 [01:37<00:36,  1.11it/s, training_loss=0.9236]\u001b[A\n",
      "Epoch 12:  74%|███████▎  | 109/148 [01:37<00:35,  1.11it/s, training_loss=0.9236]\u001b[A\n",
      "Epoch 12:  74%|███████▎  | 109/148 [01:38<00:35,  1.11it/s, training_loss=1.5461]\u001b[A\n",
      "Epoch 12:  74%|███████▍  | 110/148 [01:38<00:34,  1.10it/s, training_loss=1.5461]\u001b[A\n",
      "Epoch 12:  74%|███████▍  | 110/148 [01:39<00:34,  1.10it/s, training_loss=0.8519]\u001b[A\n",
      "Epoch 12:  75%|███████▌  | 111/148 [01:39<00:33,  1.11it/s, training_loss=0.8519]\u001b[A\n",
      "Epoch 12:  75%|███████▌  | 111/148 [01:40<00:33,  1.11it/s, training_loss=1.5984]\u001b[A\n",
      "Epoch 12:  76%|███████▌  | 112/148 [01:40<00:32,  1.11it/s, training_loss=1.5984]\u001b[A\n",
      "Epoch 12:  76%|███████▌  | 112/148 [01:41<00:32,  1.11it/s, training_loss=1.5754]\u001b[A\n",
      "Epoch 12:  76%|███████▋  | 113/148 [01:41<00:31,  1.11it/s, training_loss=1.5754]\u001b[A\n",
      "Epoch 12:  76%|███████▋  | 113/148 [01:42<00:31,  1.11it/s, training_loss=1.5300]\u001b[A\n",
      "Epoch 12:  77%|███████▋  | 114/148 [01:42<00:30,  1.11it/s, training_loss=1.5300]\u001b[A\n",
      "Epoch 12:  77%|███████▋  | 114/148 [01:43<00:30,  1.11it/s, training_loss=0.9353]\u001b[A\n",
      "Epoch 12:  78%|███████▊  | 115/148 [01:43<00:29,  1.11it/s, training_loss=0.9353]\u001b[A\n",
      "Epoch 12:  78%|███████▊  | 115/148 [01:44<00:29,  1.11it/s, training_loss=1.5520]\u001b[A\n",
      "Epoch 12:  78%|███████▊  | 116/148 [01:44<00:28,  1.11it/s, training_loss=1.5520]\u001b[A\n",
      "Epoch 12:  78%|███████▊  | 116/148 [01:45<00:28,  1.11it/s, training_loss=1.5069]\u001b[A\n",
      "Epoch 12:  79%|███████▉  | 117/148 [01:45<00:27,  1.11it/s, training_loss=1.5069]\u001b[A\n",
      "Epoch 12:  79%|███████▉  | 117/148 [01:46<00:27,  1.11it/s, training_loss=1.5859]\u001b[A\n",
      "Epoch 12:  80%|███████▉  | 118/148 [01:46<00:27,  1.11it/s, training_loss=1.5859]\u001b[A\n",
      "Epoch 12:  80%|███████▉  | 118/148 [01:46<00:27,  1.11it/s, training_loss=0.8605]\u001b[A\n",
      "Epoch 12:  80%|████████  | 119/148 [01:46<00:26,  1.11it/s, training_loss=0.8605]\u001b[A\n",
      "Epoch 12:  80%|████████  | 119/148 [01:47<00:26,  1.11it/s, training_loss=1.5647]\u001b[A\n",
      "Epoch 12:  81%|████████  | 120/148 [01:47<00:25,  1.11it/s, training_loss=1.5647]\u001b[A\n",
      "Epoch 12:  81%|████████  | 120/148 [01:48<00:25,  1.11it/s, training_loss=0.9382]\u001b[A\n",
      "Epoch 12:  82%|████████▏ | 121/148 [01:48<00:24,  1.11it/s, training_loss=0.9382]\u001b[A\n",
      "Epoch 12:  82%|████████▏ | 121/148 [01:49<00:24,  1.11it/s, training_loss=1.5645]\u001b[A\n",
      "Epoch 12:  82%|████████▏ | 122/148 [01:49<00:23,  1.11it/s, training_loss=1.5645]\u001b[A\n",
      "Epoch 12:  82%|████████▏ | 122/148 [01:50<00:23,  1.11it/s, training_loss=0.8392]\u001b[A\n",
      "Epoch 12:  83%|████████▎ | 123/148 [01:50<00:22,  1.11it/s, training_loss=0.8392]\u001b[A\n",
      "Epoch 12:  83%|████████▎ | 123/148 [01:51<00:22,  1.11it/s, training_loss=0.8703]\u001b[A\n",
      "Epoch 12:  84%|████████▍ | 124/148 [01:51<00:21,  1.11it/s, training_loss=0.8703]\u001b[A\n",
      "Epoch 12:  84%|████████▍ | 124/148 [01:52<00:21,  1.11it/s, training_loss=1.5814]\u001b[A\n",
      "Epoch 12:  84%|████████▍ | 125/148 [01:52<00:20,  1.11it/s, training_loss=1.5814]\u001b[A\n",
      "Epoch 12:  84%|████████▍ | 125/148 [01:53<00:20,  1.11it/s, training_loss=1.6118]\u001b[A\n",
      "Epoch 12:  85%|████████▌ | 126/148 [01:53<00:19,  1.11it/s, training_loss=1.6118]\u001b[A\n",
      "Epoch 12:  85%|████████▌ | 126/148 [01:54<00:19,  1.11it/s, training_loss=0.9687]\u001b[A\n",
      "Epoch 12:  86%|████████▌ | 127/148 [01:54<00:18,  1.11it/s, training_loss=0.9687]\u001b[A\n",
      "Epoch 12:  86%|████████▌ | 127/148 [01:55<00:18,  1.11it/s, training_loss=1.1725]\u001b[A\n",
      "Epoch 12:  86%|████████▋ | 128/148 [01:55<00:17,  1.11it/s, training_loss=1.1725]\u001b[A\n",
      "Epoch 12:  86%|████████▋ | 128/148 [01:55<00:17,  1.11it/s, training_loss=0.9381]\u001b[A\n",
      "Epoch 12:  87%|████████▋ | 129/148 [01:55<00:17,  1.11it/s, training_loss=0.9381]\u001b[A\n",
      "Epoch 12:  87%|████████▋ | 129/148 [01:56<00:17,  1.11it/s, training_loss=0.8731]\u001b[A\n",
      "Epoch 12:  88%|████████▊ | 130/148 [01:56<00:16,  1.11it/s, training_loss=0.8731]\u001b[A\n",
      "Epoch 12:  88%|████████▊ | 130/148 [01:57<00:16,  1.11it/s, training_loss=0.8089]\u001b[A\n",
      "Epoch 12:  89%|████████▊ | 131/148 [01:57<00:15,  1.10it/s, training_loss=0.8089]\u001b[A\n",
      "Epoch 12:  89%|████████▊ | 131/148 [01:58<00:15,  1.10it/s, training_loss=0.8334]\u001b[A\n",
      "Epoch 12:  89%|████████▉ | 132/148 [01:58<00:14,  1.10it/s, training_loss=0.8334]\u001b[A\n",
      "Epoch 12:  89%|████████▉ | 132/148 [01:59<00:14,  1.10it/s, training_loss=0.8264]\u001b[A\n",
      "Epoch 12:  90%|████████▉ | 133/148 [01:59<00:13,  1.10it/s, training_loss=0.8264]\u001b[A\n",
      "Epoch 12:  90%|████████▉ | 133/148 [02:00<00:13,  1.10it/s, training_loss=1.5569]\u001b[A\n",
      "Epoch 12:  91%|█████████ | 134/148 [02:00<00:12,  1.10it/s, training_loss=1.5569]\u001b[A\n",
      "Epoch 12:  91%|█████████ | 134/148 [02:01<00:12,  1.10it/s, training_loss=0.9052]\u001b[A\n",
      "Epoch 12:  91%|█████████ | 135/148 [02:01<00:11,  1.10it/s, training_loss=0.9052]\u001b[A\n",
      "Epoch 12:  91%|█████████ | 135/148 [02:02<00:11,  1.10it/s, training_loss=0.8880]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 136/148 [02:02<00:10,  1.10it/s, training_loss=0.8880]\u001b[A\n",
      "Epoch 12:  92%|█████████▏| 136/148 [02:03<00:10,  1.10it/s, training_loss=0.9075]\u001b[A\n",
      "Epoch 12:  93%|█████████▎| 137/148 [02:03<00:09,  1.10it/s, training_loss=0.9075]\u001b[A\n",
      "Epoch 12:  93%|█████████▎| 137/148 [02:04<00:09,  1.10it/s, training_loss=0.9010]\u001b[A\n",
      "Epoch 12:  93%|█████████▎| 138/148 [02:04<00:09,  1.10it/s, training_loss=0.9010]\u001b[A\n",
      "Epoch 12:  93%|█████████▎| 138/148 [02:05<00:09,  1.10it/s, training_loss=0.9003]\u001b[A\n",
      "Epoch 12:  94%|█████████▍| 139/148 [02:05<00:08,  1.10it/s, training_loss=0.9003]\u001b[A\n",
      "Epoch 12:  94%|█████████▍| 139/148 [02:05<00:08,  1.10it/s, training_loss=1.0180]\u001b[A\n",
      "Epoch 12:  95%|█████████▍| 140/148 [02:05<00:07,  1.10it/s, training_loss=1.0180]\u001b[A\n",
      "Epoch 12:  95%|█████████▍| 140/148 [02:06<00:07,  1.10it/s, training_loss=1.4058]\u001b[A\n",
      "Epoch 12:  95%|█████████▌| 141/148 [02:06<00:06,  1.11it/s, training_loss=1.4058]\u001b[A\n",
      "Epoch 12:  95%|█████████▌| 141/148 [02:07<00:06,  1.11it/s, training_loss=1.6452]\u001b[A\n",
      "Epoch 12:  96%|█████████▌| 142/148 [02:07<00:05,  1.11it/s, training_loss=1.6452]\u001b[A\n",
      "Epoch 12:  96%|█████████▌| 142/148 [02:08<00:05,  1.11it/s, training_loss=1.5416]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 143/148 [02:08<00:04,  1.11it/s, training_loss=1.5416]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 143/148 [02:09<00:04,  1.11it/s, training_loss=1.0052]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 144/148 [02:09<00:03,  1.11it/s, training_loss=1.0052]\u001b[A\n",
      "Epoch 12:  97%|█████████▋| 144/148 [02:10<00:03,  1.11it/s, training_loss=1.6242]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 145/148 [02:10<00:02,  1.11it/s, training_loss=1.6242]\u001b[A\n",
      "Epoch 12:  98%|█████████▊| 145/148 [02:11<00:02,  1.11it/s, training_loss=1.5414]\u001b[A\n",
      "Epoch 12:  99%|█████████▊| 146/148 [02:11<00:01,  1.11it/s, training_loss=1.5414]\u001b[A\n",
      "Epoch 12:  99%|█████████▊| 146/148 [02:12<00:01,  1.11it/s, training_loss=0.8260]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 147/148 [02:12<00:00,  1.11it/s, training_loss=0.8260]\u001b[A\n",
      "Epoch 12:  99%|█████████▉| 147/148 [02:12<00:00,  1.11it/s, training_loss=0.8177]\u001b[A\n",
      "Epoch 12: 100%|██████████| 148/148 [02:12<00:00,  1.21it/s, training_loss=0.8177]\u001b[A\n",
      "                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:17:50,591 - INFO - Starting model evaluation...\n",
      "2025-02-19 11:17:50,592 - INFO - Memory usage after evaluation start: 4052.03 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s, Accuracy=74.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.71it/s, Accuracy=74.00%]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.71it/s, Accuracy=75.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.66it/s, Accuracy=75.00%]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.66it/s, Accuracy=74.00%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.64it/s, Accuracy=74.00%]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:06,  3.64it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.63it/s, Accuracy=71.00%]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.63it/s, Accuracy=71.60%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.64it/s, Accuracy=71.60%]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.64it/s, Accuracy=71.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.63it/s, Accuracy=71.67%]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.63it/s, Accuracy=69.71%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.63it/s, Accuracy=69.71%]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:05,  3.63it/s, Accuracy=69.00%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.64it/s, Accuracy=69.00%]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.64it/s, Accuracy=68.89%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.64it/s, Accuracy=68.89%]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.64it/s, Accuracy=69.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.64it/s, Accuracy=69.80%]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:04,  3.64it/s, Accuracy=69.64%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.62it/s, Accuracy=69.64%]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.62it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.64it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.64it/s, Accuracy=69.08%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.64it/s, Accuracy=69.08%]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.64it/s, Accuracy=69.14%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.64it/s, Accuracy=69.14%]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:03,  3.64it/s, Accuracy=69.20%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.64it/s, Accuracy=69.20%]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.64it/s, Accuracy=68.62%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.64it/s, Accuracy=68.62%]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.64it/s, Accuracy=68.35%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.63it/s, Accuracy=68.35%]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.63it/s, Accuracy=69.11%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.64it/s, Accuracy=69.11%]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.64it/s, Accuracy=69.26%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.64it/s, Accuracy=69.26%]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.64it/s, Accuracy=69.60%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.64it/s, Accuracy=69.60%]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.64it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.63it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:06<00:01,  3.63it/s, Accuracy=69.91%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.63it/s, Accuracy=69.91%]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.63it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.63it/s, Accuracy=70.00%]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.63it/s, Accuracy=69.58%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.63it/s, Accuracy=69.58%]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.63it/s, Accuracy=69.44%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.62it/s, Accuracy=69.44%]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:07<00:00,  3.62it/s, Accuracy=69.85%]\u001b[A\n",
      "Evaluating:  96%|█████████▋| 26/27 [00:07<00:00,  3.62it/s, Accuracy=69.85%]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.75it/s, Accuracy=69.89%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:17:57,790 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-19 11:17:57,796 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-19 11:17:57,796 - INFO - Accuracy: 0.5785\n",
      "2025-02-19 11:17:57,797 - INFO - F1_score: 0.5299\n",
      "2025-02-19 11:17:57,797 - INFO - Precision: 0.3875\n",
      "2025-02-19 11:17:57,798 - INFO - Recall: 0.8378\n",
      "2025-02-19 11:17:57,804 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-19 11:17:57,805 - INFO - Accuracy: 0.8008\n",
      "2025-02-19 11:17:57,806 - INFO - F1_score: 0.6667\n",
      "2025-02-19 11:17:57,806 - INFO - Precision: 0.5253\n",
      "2025-02-19 11:17:57,807 - INFO - Recall: 0.9123\n",
      "2025-02-19 11:17:57,814 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-19 11:17:57,814 - INFO - Accuracy: 0.6015\n",
      "2025-02-19 11:17:57,815 - INFO - F1_score: 0.4800\n",
      "2025-02-19 11:17:57,816 - INFO - Precision: 0.3380\n",
      "2025-02-19 11:17:57,816 - INFO - Recall: 0.8276\n",
      "2025-02-19 11:17:57,823 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-19 11:17:57,823 - INFO - Accuracy: 0.7011\n",
      "2025-02-19 11:17:57,824 - INFO - F1_score: 0.3036\n",
      "2025-02-19 11:17:57,825 - INFO - Precision: 0.2297\n",
      "2025-02-19 11:17:57,826 - INFO - Recall: 0.4474\n",
      "2025-02-19 11:17:57,832 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-19 11:17:57,832 - INFO - Accuracy: 0.8123\n",
      "2025-02-19 11:17:57,833 - INFO - F1_score: 0.4494\n",
      "2025-02-19 11:17:57,834 - INFO - Precision: 0.3636\n",
      "2025-02-19 11:17:57,835 - INFO - Recall: 0.5882\n",
      "2025-02-19 11:17:57,837 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:18:01,705 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices\n",
      "2025-02-19 11:18:01,706 - INFO - Memory usage after evaluation end: 4057.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  11%|█         | 11/100 [30:46<3:46:09, 152.47s/it, Train Loss=1.1950, Val Loss=0.0529, Accuracy=0.6989]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:18:08,831 - INFO - \n",
      "Early stopping triggered after 12 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:  11%|█         | 11/100 [30:46<4:09:02, 167.89s/it, Train Loss=1.1950, Val Loss=0.0529, Accuracy=0.6989]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:18:09,902 - INFO - Saved training history plots to /kaggle/working/logs/experiments/20250219_084004/plots/training_history.png\n",
      "2025-02-19 11:18:09,903 - INFO - Training history saved successfully\n",
      "2025-02-19 11:18:12,454 - INFO - \n",
      "Testing model on a sample...\n",
      "2025-02-19 11:18:12,473 - INFO - Loading and preprocessing data...\n",
      "2025-02-19 11:18:12,474 - INFO - Memory usage after start: 4059.28 MB\n",
      "2025-02-19 11:18:12,487 - INFO - Successfully loaded data using utf-8 encoding\n",
      "2025-02-19 11:18:12,488 - INFO - Memory usage after data loading: 4059.28 MB\n",
      "2025-02-19 11:18:12,489 - INFO - Taking sample of 1 from 1738 total samples\n",
      "2025-02-19 11:18:12,490 - INFO - \n",
      "Sample data:\n",
      "2025-02-19 11:18:12,491 - INFO - \n",
      "Sample 1:\n",
      "2025-02-19 11:18:12,492 - INFO - Synopsis: Setelah kematian yang tampak, Siena mampu melihat tanda-tanda bahwa orang-orang akan meninggal. Namu...\n",
      "2025-02-19 11:18:12,493 - INFO - Genre: Horor\n",
      "2025-02-19 11:18:12,494 - INFO - \n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2542.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:18:12,501 - INFO - Memory usage after preprocessing: 4059.28 MB\n",
      "2025-02-19 11:18:12,552 - INFO - \n",
      "Sample prediction results:\n",
      "2025-02-19 11:18:12,552 - INFO - Sample text: setelah kematian yang tampak siena mampu melihat tanda tanda bahwa orang orang akan meninggal namun ...\n",
      "2025-02-19 11:18:12,553 - INFO - Horor: 0.9210\n",
      "2025-02-19 11:18:12,555 - INFO - Drama: 0.5230\n",
      "2025-02-19 11:18:12,556 - INFO - \n",
      "Training completed successfully!\n",
      "2025-02-19 11:18:12,556 - INFO - All results and models saved in: /kaggle/working/logs/experiments/20250219_084004\n",
      "2025-02-19 11:18:12,557 - INFO - \n",
      "Cleaning up resources...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 11:18:13,863 - INFO - Cleaning up resources...\n"
     ]
    }
   ],
   "source": [
    "# BAGIAN KEEMPAT - Training dan Hyperparameter Optimization\n",
    "\n",
    "class ModelTrainer:\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def train_model(sample_size: Optional[int] = None) -> Tuple:\n",
    "        Config.SAMPLE_SIZE = sample_size\n",
    "        logging.info(\"Starting model training\")\n",
    "        log_memory(\"training start\")\n",
    "\n",
    "        try:\n",
    "            # Load dan preprocess data\n",
    "            df = DataProcessor.load_and_preprocess_data(Config.DATA_PATH, Config.SAMPLE_SIZE)\n",
    "            logging.info(f\"\\nDataset statistics:\")\n",
    "            logging.info(f\"Total samples after preprocessing: {len(df)}\")\n",
    "\n",
    "            # Prepare data\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            X_train, X_test, y_train, y_test = DataProcessor.prepare_data(df, mlb)\n",
    "\n",
    "            # Log genre distribution\n",
    "            genre_labels = mlb.fit_transform(df['genre'])\n",
    "            genre_counts = genre_labels.sum(axis=0)\n",
    "            for genre, count in zip(mlb.classes_, genre_counts):\n",
    "                logging.info(f\"Genre '{genre}': {count} samples\")\n",
    "\n",
    "            logging.info(f\"\\nTraining set size: {len(X_train)}\")\n",
    "            logging.info(f\"Testing set size: {len(X_test)}\")\n",
    "\n",
    "            # Setup model dan data loaders\n",
    "            with ModelManager(*ModelSetup.setup_model_and_tokenizer(len(mlb.classes_))) as (model, tokenizer):\n",
    "                train_loader, val_loader = ModelSetup.setup_dataloaders(\n",
    "                    X_train, X_test, y_train, y_test,\n",
    "                    tokenizer, Config.MODEL_PARAMS['BATCH_SIZE']\n",
    "                )\n",
    "\n",
    "                # Training loop\n",
    "                best_val_loss = float('inf')\n",
    "                best_accuracy = 0.0\n",
    "                patience_counter = 0\n",
    "                training_losses = []\n",
    "                validation_losses = []\n",
    "                accuracies = []\n",
    "\n",
    "                optimizer = torch.optim.AdamW(\n",
    "                    model.parameters(),\n",
    "                    lr=Config.MODEL_PARAMS['LEARNING_RATE'],\n",
    "                    weight_decay=Config.MODEL_PARAMS['WEIGHT_DECAY']\n",
    "                )\n",
    "\n",
    "                scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                    optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "                )\n",
    "\n",
    "                # Training epochs with progress bar\n",
    "                epochs_range = tqdm(range(Config.MODEL_PARAMS['EPOCHS']), desc=\"Training Progress\",\n",
    "                                  position=0, leave=True)\n",
    "                for epoch in epochs_range:\n",
    "                    try:\n",
    "                        # Training phase\n",
    "                        model.train()\n",
    "                        epoch_metrics = ModelTrainer._train_epoch(\n",
    "                            model, train_loader, optimizer,\n",
    "                            epoch + 1\n",
    "                        )\n",
    "                        training_losses.append(epoch_metrics['train_loss'])\n",
    "\n",
    "                        # Evaluation phase\n",
    "                        validation_metrics = ModelEvaluator.evaluate_model(model, val_loader, mlb)\n",
    "                        current_accuracy = validation_metrics['accuracy']\n",
    "                        accuracies.append(current_accuracy)\n",
    "\n",
    "                        # Validation loss calculation\n",
    "                        avg_val_loss = ModelTrainer._calculate_validation_loss(\n",
    "                            model, val_loader\n",
    "                        )\n",
    "                        validation_losses.append(avg_val_loss)\n",
    "\n",
    "                        # Update progress bar\n",
    "                        epochs_range.set_postfix({\n",
    "                            'Train Loss': f\"{epoch_metrics['train_loss']:.4f}\",\n",
    "                            'Val Loss': f\"{avg_val_loss:.4f}\",\n",
    "                            'Accuracy': f\"{current_accuracy:.4f}\"\n",
    "                        })\n",
    "\n",
    "                        # Model improvement check\n",
    "                        model_improved = ModelTrainer._check_model_improvement(\n",
    "                            model, tokenizer, current_accuracy, avg_val_loss,\n",
    "                            best_accuracy, best_val_loss\n",
    "                        )\n",
    "\n",
    "                        if model_improved:\n",
    "                            best_accuracy = max(best_accuracy, current_accuracy)\n",
    "                            best_val_loss = min(best_val_loss, avg_val_loss)\n",
    "                            patience_counter = 0\n",
    "                        else:\n",
    "                            patience_counter += 1\n",
    "\n",
    "                        # Early stopping check\n",
    "                        if patience_counter >= Config.MODEL_PARAMS['PATIENCE']:\n",
    "                            logging.info(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "                            break\n",
    "\n",
    "                        scheduler.step(avg_val_loss)\n",
    "                        logging.info(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "                        # Clear GPU cache periodically\n",
    "                        if torch.cuda.is_available() and (epoch + 1) % 5 == 0:\n",
    "                            torch.cuda.empty_cache()\n",
    "                            gc.collect()\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Error during epoch {epoch + 1}: {str(e)}\")\n",
    "                        raise\n",
    "\n",
    "                # Save training history\n",
    "                ModelTrainer._save_training_history(\n",
    "                    training_losses, validation_losses, accuracies,\n",
    "                    best_accuracy, best_val_loss, df, mlb, genre_counts\n",
    "                )\n",
    "\n",
    "                return model, tokenizer, mlb\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in training: {str(e)}\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Cleanup\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    @staticmethod\n",
    "    def _train_epoch(model: torch.nn.Module,\n",
    "                    train_loader: DataLoader,\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    epoch: int) -> Dict:\n",
    "        \"\"\"Train model for one epoch\"\"\"\n",
    "        total_loss = 0\n",
    "        steps = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\",\n",
    "                          position=1, leave=False)\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            try:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if np.random.random() < Config.MODEL_PARAMS['MIXUP_PROB']:\n",
    "                    batch = DataAugmentation.apply_mixup(batch)\n",
    "\n",
    "                input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = LossFunctions.label_smoothing_loss(\n",
    "                    outputs.logits, labels, Config.MODEL_PARAMS['SMOOTHING']\n",
    "                )\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                steps += 1\n",
    "                progress_bar.set_postfix({'training_loss': f'{loss.item():.4f}'})\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                    logging.error(\"GPU out of memory during training. Try reducing batch size.\")\n",
    "                raise\n",
    "\n",
    "        return {'train_loss': total_loss / steps}\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_validation_loss(model: torch.nn.Module,\n",
    "                                 val_loader: DataLoader) -> float:\n",
    "        \"\"\"Calculate validation loss\"\"\"\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        steps = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                try:\n",
    "                    input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                    attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                    labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = LossFunctions.focal_loss(outputs.logits, labels)\n",
    "                    total_loss += loss.item()\n",
    "                    steps += 1\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                        logging.error(\"GPU out of memory during validation. Try reducing batch size.\")\n",
    "                    raise\n",
    "\n",
    "        return total_loss / steps\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_model_improvement(model: torch.nn.Module,\n",
    "                               tokenizer,\n",
    "                               current_accuracy: float,\n",
    "                               current_loss: float,\n",
    "                               best_accuracy: float,\n",
    "                               best_loss: float) -> bool:\n",
    "        \"\"\"Check if model improved and save if necessary\"\"\"\n",
    "        improved = False\n",
    "\n",
    "        try:\n",
    "            if current_accuracy > best_accuracy:\n",
    "                logging.info(f\"New best accuracy: {current_accuracy:.4f}\")\n",
    "                model.save_pretrained(str(Config.MODEL_BEST_ACC))  # Convert to string for Colab\n",
    "                tokenizer.save_pretrained(str(Config.TOKENIZER_BEST_ACC))\n",
    "                improved = True\n",
    "\n",
    "            if current_loss < best_loss:\n",
    "                logging.info(f\"New best loss: {current_loss:.4f}\")\n",
    "                model.save_pretrained(str(Config.MODEL_BEST_LOSS))\n",
    "                tokenizer.save_pretrained(str(Config.TOKENIZER_BEST_LOSS))\n",
    "                improved = True\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "        return improved\n",
    "\n",
    "    @staticmethod\n",
    "    def _save_training_history(training_losses: List[float],\n",
    "                             validation_losses: List[float],\n",
    "                             accuracies: List[float],\n",
    "                             best_accuracy: float,\n",
    "                             best_val_loss: float,\n",
    "                             df: pd.DataFrame,\n",
    "                             mlb: MultiLabelBinarizer,\n",
    "                             genre_counts: np.ndarray) -> None:\n",
    "        \"\"\"Save training history and plot results\"\"\"\n",
    "        try:\n",
    "            history_data = {\n",
    "                'model_info': {\n",
    "                    'classes': mlb.classes_.tolist(),\n",
    "                    'total_samples': len(df),\n",
    "                    'genre_distribution': {\n",
    "                        genre: int(count) for genre, count in zip(mlb.classes_, genre_counts)\n",
    "                    }\n",
    "                },\n",
    "                'training_config': {\n",
    "                    'batch_size': Config.MODEL_PARAMS['BATCH_SIZE'],\n",
    "                    'learning_rate': Config.MODEL_PARAMS['LEARNING_RATE'],\n",
    "                    'max_length': Config.MODEL_PARAMS['MAX_LENGTH'],\n",
    "                    'weight_decay': Config.MODEL_PARAMS['WEIGHT_DECAY'],\n",
    "                    'early_stopping': Config.MODEL_PARAMS['PATIENCE'],\n",
    "                    'mixup_prob': Config.MODEL_PARAMS['MIXUP_PROB'],\n",
    "                    'train_split': 1-Config.MODEL_PARAMS['TEST_SIZE'],\n",
    "                    'test_split': Config.MODEL_PARAMS['TEST_SIZE']\n",
    "                },\n",
    "                'training_history': {\n",
    "                    'epochs': list(range(1, len(training_losses) + 1)),\n",
    "                    'training_loss': [float(loss) for loss in training_losses],\n",
    "                    'validation_loss': [float(loss) for loss in validation_losses],\n",
    "                    'accuracy': [float(acc) for acc in accuracies],\n",
    "                    'best_accuracy': float(best_accuracy),\n",
    "                    'best_val_loss': float(best_val_loss)\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Save history to JSON\n",
    "            history_file = Config.METRICS_DIR / 'training_history.json'\n",
    "            with open(history_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(history_data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            # Plot training history\n",
    "            Visualization.plot_training_history(history_data['training_history'])\n",
    "            logging.info(\"Training history saved successfully\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving training history: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "class HyperparameterOptimizer:\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def objective(trial: Trial, df: pd.DataFrame, mlb: MultiLabelBinarizer) -> float:\n",
    "        \"\"\"Objective function untuk Optuna optimization\"\"\"\n",
    "        try:\n",
    "            # Get trial parameters\n",
    "            params = HyperparameterOptimizer._get_trial_parameters(trial)\n",
    "\n",
    "            # Prepare data\n",
    "            X_train, X_test, y_train, y_test = DataProcessor.prepare_data(df, mlb)\n",
    "\n",
    "            # Setup model dan data loaders\n",
    "            with ModelManager(*ModelSetup.setup_model_and_tokenizer(len(mlb.classes_))) as (model, tokenizer):\n",
    "                train_loader, val_loader = ModelSetup.setup_dataloaders(\n",
    "                    X_train, X_test, y_train, y_test,\n",
    "                    tokenizer, params['batch_size']\n",
    "                )\n",
    "\n",
    "                # Training loop singkat untuk optimasi\n",
    "                best_val_metrics = HyperparameterOptimizer._train_trial(\n",
    "                    trial, model, train_loader, val_loader, mlb, params\n",
    "                )\n",
    "\n",
    "                # Clear GPU cache after each trial\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            return best_val_metrics['macro_f1']\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in optimization objective: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_trial_parameters(trial: Trial) -> Dict:\n",
    "        \"\"\"Get parameters for trial\"\"\"\n",
    "        params = {}\n",
    "        try:\n",
    "            # Batch size dari list nilai diskrit\n",
    "            params['batch_size'] = trial.suggest_categorical('batch_size',\n",
    "                Config.OPTIM_PARAMS['batch_size'])\n",
    "\n",
    "            # Learning rate dari list nilai diskrit\n",
    "            params['learning_rate'] = trial.suggest_categorical('learning_rate',\n",
    "                Config.OPTIM_PARAMS['learning_rate'])\n",
    "\n",
    "            # Weight decay dari list nilai diskrit\n",
    "            params['weight_decay'] = trial.suggest_categorical('weight_decay',\n",
    "                Config.OPTIM_PARAMS['weight_decay'])\n",
    "\n",
    "            # Mixup probability dari list nilai diskrit\n",
    "            params['mixup_prob'] = trial.suggest_categorical('mixup_prob',\n",
    "                Config.OPTIM_PARAMS['mixup_prob'])\n",
    "\n",
    "            # Smoothing dari list nilai diskrit\n",
    "            params['smoothing'] = trial.suggest_categorical('smoothing',\n",
    "                Config.OPTIM_PARAMS['smoothing'])\n",
    "\n",
    "            logging.info(f\"Trial parameter set: {params}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error getting trial parameters: {str(e)}\")\n",
    "            raise\n",
    "        return params\n",
    "\n",
    "    @staticmethod\n",
    "    def _train_trial(trial: Trial,\n",
    "                    model: torch.nn.Module,\n",
    "                    train_loader: DataLoader,\n",
    "                    val_loader: DataLoader,\n",
    "                    mlb: MultiLabelBinarizer,\n",
    "                    params: Dict) -> Dict:\n",
    "        \"\"\"Train model for one trial\"\"\"\n",
    "        try:\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=params['learning_rate'],\n",
    "                weight_decay=params['weight_decay']\n",
    "            )\n",
    "\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "            )\n",
    "\n",
    "            best_val_metrics = None\n",
    "\n",
    "            for epoch in range(3):  # Reduced epochs for optimization\n",
    "                # Training\n",
    "                model.train()\n",
    "                total_loss = 0\n",
    "                steps = 0\n",
    "\n",
    "                progress_bar = tqdm(train_loader,\n",
    "                                  desc=f\"Epoch {epoch+1}/3\",\n",
    "                                  position=0,\n",
    "                                  leave=False)\n",
    "\n",
    "                for batch in progress_bar:\n",
    "                    try:\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        if np.random.random() < params['mixup_prob']:\n",
    "                            batch = DataAugmentation.apply_mixup(batch)\n",
    "\n",
    "                        input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                        attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                        labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                        loss = LossFunctions.label_smoothing_loss(\n",
    "                            outputs.logits, labels, params['smoothing']\n",
    "                        )\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        total_loss += loss.item()\n",
    "                        steps += 1\n",
    "\n",
    "                        # Update progress bar\n",
    "                        progress_bar.set_postfix({\n",
    "                            'loss': f'{loss.item():.4f}',\n",
    "                            'avg_loss': f'{(total_loss/steps):.4f}'\n",
    "                        })\n",
    "\n",
    "                    except RuntimeError as e:\n",
    "                        if \"out of memory\" in str(e):\n",
    "                            if torch.cuda.is_available():\n",
    "                                torch.cuda.empty_cache()\n",
    "                            logging.error(\"GPU OOM in trial. Trying to recover...\")\n",
    "                            continue\n",
    "                        raise\n",
    "\n",
    "                avg_loss = total_loss / steps\n",
    "\n",
    "                # Evaluation\n",
    "                metrics = ModelEvaluator.evaluate_model(model, val_loader, mlb)\n",
    "                current_f1 = metrics['macro_f1']\n",
    "\n",
    "                logging.info(f\"Trial {trial.number}, Epoch {epoch+1}: \"\n",
    "                           f\"Loss = {avg_loss:.4f}, F1 = {current_f1:.4f}\")\n",
    "\n",
    "                if best_val_metrics is None or current_f1 > best_val_metrics['macro_f1']:\n",
    "                    best_val_metrics = metrics\n",
    "\n",
    "                scheduler.step(metrics['macro_f1'])\n",
    "\n",
    "                # Report intermediate value\n",
    "                trial.report(metrics['macro_f1'], epoch)\n",
    "\n",
    "                # Handle pruning based on the intermediate value\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "                # Clear GPU cache\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            return best_val_metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in trial training: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def run_optimization(df: pd.DataFrame,\n",
    "                        mlb: MultiLabelBinarizer,\n",
    "                        n_trials: int = 30) -> Dict:\n",
    "\n",
    "        try:\n",
    "            study = optuna.create_study(\n",
    "                direction=\"maximize\",\n",
    "                sampler=optuna.samplers.TPESampler(seed=42),\n",
    "                pruner=optuna.pruners.MedianPruner()\n",
    "            )\n",
    "\n",
    "            objective_func = lambda trial: HyperparameterOptimizer.objective(trial, df, mlb)\n",
    "\n",
    "            logging.info(\"Starting hyperparameter optimization...\")\n",
    "            study.optimize(objective_func, n_trials=n_trials,\n",
    "                         callbacks=[lambda study, trial: gc.collect()])\n",
    "\n",
    "            # Log results\n",
    "            logging.info(\"\\nHyperparameter Optimization Results:\")\n",
    "            logging.info(f\"Best trial number: {study.best_trial.number}\")\n",
    "            logging.info(f\"Best F1-score: {study.best_trial.value:.4f}\")\n",
    "            logging.info(\"\\nBest hyperparameters:\")\n",
    "            for param, value in study.best_trial.params.items():\n",
    "                logging.info(f\"{param}: {value}\")\n",
    "\n",
    "            # Save study results\n",
    "            results_file = Config.METRICS_DIR / 'optuna_results.json'\n",
    "            results = {\n",
    "                'best_trial': {\n",
    "                    'number': study.best_trial.number,\n",
    "                    'value': study.best_trial.value,\n",
    "                    'params': study.best_trial.params\n",
    "                },\n",
    "                'all_trials': [\n",
    "                    {\n",
    "                        'number': trial.number,\n",
    "                        'value': trial.value,\n",
    "                        'params': trial.params\n",
    "                    }\n",
    "                    for trial in study.trials if trial.value is not None\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            with open(results_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            # Save visualizations\n",
    "            try:\n",
    "                # Optimization history plot\n",
    "                fig1 = optuna.visualization.plot_optimization_history(study)\n",
    "                fig1.write_image(str(Config.PLOTS_DIR / \"optuna_optimization_history.png\"))\n",
    "\n",
    "                # Parameter importance plot\n",
    "                fig2 = optuna.visualization.plot_param_importances(study)\n",
    "                fig2.write_image(str(Config.PLOTS_DIR / \"optuna_param_importances.png\"))\n",
    "\n",
    "                # Parameter relationships plot\n",
    "                fig3 = optuna.visualization.plot_parallel_coordinate(study)\n",
    "                fig3.write_image(str(Config.PLOTS_DIR / \"optuna_param_relationships.png\"))\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Could not create optimization plots: {str(e)}\")\n",
    "\n",
    "            return study.best_trial.params\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during optimization: {str(e)}\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Clean up\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "# Fungsi get_args untuk Colab\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Training parameters\n",
    "        self.sample_size = None  # Number of samples to use (default: use all data)\n",
    "        self.epochs = Config.MODEL_PARAMS['EPOCHS']\n",
    "        self.batch_size = Config.MODEL_PARAMS['BATCH_SIZE']\n",
    "        self.learning_rate = Config.MODEL_PARAMS['LEARNING_RATE']\n",
    "        self.max_length = Config.MODEL_PARAMS['MAX_LENGTH']\n",
    "\n",
    "        # Model configuration\n",
    "        self.test_size = Config.MODEL_PARAMS['TEST_SIZE']\n",
    "        self.weight_decay = Config.MODEL_PARAMS['WEIGHT_DECAY']\n",
    "        self.mixup_prob = Config.MODEL_PARAMS['MIXUP_PROB']\n",
    "        self.patience = Config.MODEL_PARAMS['PATIENCE']\n",
    "\n",
    "        # System configuration\n",
    "        self.output_dir = None\n",
    "        self.no_cuda = False\n",
    "        self.seed = 42\n",
    "\n",
    "        # Label Smoothing\n",
    "        self.smoothing = Config.MODEL_PARAMS['SMOOTHING']\n",
    "\n",
    "        # Optuna specific\n",
    "        self.n_trials = 20\n",
    "\n",
    "# Modifikasi fungsi get_args\n",
    "def get_args():\n",
    "    return Args()\n",
    "\n",
    "def main(args: Args) -> None:\n",
    "    \"\"\"Main function\"\"\"\n",
    "    try:\n",
    "        # Check environment first\n",
    "        if not check_environment():\n",
    "            raise RuntimeError(\"Environment check failed!\")\n",
    "\n",
    "        # Update configuration\n",
    "        Config.MODEL_PARAMS.update({\n",
    "            'EPOCHS': args.epochs,\n",
    "            'BATCH_SIZE': args.batch_size,\n",
    "            'LEARNING_RATE': args.learning_rate,\n",
    "            'MAX_LENGTH': args.max_length,\n",
    "            'TEST_SIZE': args.test_size,\n",
    "            'WEIGHT_DECAY': args.weight_decay,\n",
    "            'MIXUP_PROB': args.mixup_prob,\n",
    "            'PATIENCE': args.patience,\n",
    "            'SMOOTHING': args.smoothing\n",
    "        })\n",
    "\n",
    "        if args.no_cuda:\n",
    "            Config.DEVICE = torch.device('cpu')\n",
    "            logging.info(\"CUDA disabled by user\")\n",
    "\n",
    "        # Initialize logging dan experiment info\n",
    "        log_system_info()\n",
    "\n",
    "        logging.info(\"Starting movie genre classification with hyperparameter optimization\")\n",
    "        logging.info(f\"Using device: {Config.DEVICE}\")\n",
    "\n",
    "        # Log initial configuration\n",
    "        logging.info(\"\\nInitial Configuration:\")\n",
    "        logging.info(f\"Sample Size: {Config.SAMPLE_SIZE if Config.SAMPLE_SIZE else 'Full Dataset'}\")\n",
    "        for param, value in Config.MODEL_PARAMS.items():\n",
    "            logging.info(f\"{param}: {value}\")\n",
    "\n",
    "        # Load and preprocess data\n",
    "        logging.info(\"\\nLoading and preprocessing data...\")\n",
    "        df = DataProcessor.load_and_preprocess_data(Config.DATA_PATH, Config.SAMPLE_SIZE)\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        # Run hyperparameter optimization\n",
    "        logging.info(\"\\nStarting hyperparameter optimization...\")\n",
    "        best_params = HyperparameterOptimizer.run_optimization(df, mlb, args.n_trials)\n",
    "\n",
    "        # Update configuration with best parameters\n",
    "        logging.info(\"\\nBest Hyperparameters found:\")\n",
    "        for param, value in best_params.items():\n",
    "            logging.info(f\"{param}: {value}\")\n",
    "            if param in Config.MODEL_PARAMS:\n",
    "                Config.MODEL_PARAMS[param] = value\n",
    "\n",
    "        # Train final model with best parameters\n",
    "        logging.info(\"\\nTraining final model with optimized parameters...\")\n",
    "        model, tokenizer, mlb = ModelTrainer.train_model(Config.SAMPLE_SIZE)\n",
    "\n",
    "        # Test on a sample\n",
    "        logging.info(\"\\nTesting model on a sample...\")\n",
    "        df_sample = DataProcessor.load_and_preprocess_data(Config.DATA_PATH, sample_size=1)\n",
    "        sample_text = df_sample['sinopsis'].iloc[0]\n",
    "\n",
    "        model.eval()\n",
    "        inputs = tokenizer(\n",
    "            sample_text,\n",
    "            return_tensors='pt',\n",
    "            max_length=Config.MODEL_PARAMS['MAX_LENGTH'],\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids'].to(Config.DEVICE)\n",
    "        attention_mask = inputs['attention_mask'].to(Config.DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.sigmoid(outputs.logits)\n",
    "\n",
    "        predictions = []\n",
    "        for idx, prob in enumerate(probs[0]):\n",
    "            if prob > 0.5:\n",
    "                predictions.append({\n",
    "                    'genre': mlb.classes_[idx],\n",
    "                    'probability': float(prob.item())\n",
    "                })\n",
    "\n",
    "        predictions.sort(key=lambda x: x['probability'], reverse=True)\n",
    "\n",
    "        # Log prediction results\n",
    "        logging.info(\"\\nSample prediction results:\")\n",
    "        logging.info(f\"Sample text: {sample_text[:100]}...\")\n",
    "        for pred in predictions:\n",
    "            logging.info(f\"{pred['genre']}: {pred['probability']:.4f}\")\n",
    "\n",
    "        # Save final configuration\n",
    "        final_config = {\n",
    "            'hyperparameters': best_params,\n",
    "            'model_info': {\n",
    "                'num_classes': len(mlb.classes_),\n",
    "                'classes': mlb.classes_.tolist()\n",
    "            },\n",
    "            'training_info': {\n",
    "                'device': str(Config.DEVICE),\n",
    "                'final_sample_size': len(df),\n",
    "                'optimization_trials': args.n_trials\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(Config.EXPERIMENT_DIR / 'final_configuration.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_config, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        logging.info(\"\\nTraining completed successfully!\")\n",
    "        logging.info(f\"All results and models saved in: {Config.EXPERIMENT_DIR}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"\\nTraining interrupted by user\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"\\nError during execution: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logging.info(\"\\nCleaning up resources...\")\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# Entry point for Colab\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seeds for reproducibility\n",
    "    args = get_args()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    try:\n",
    "        main(args)\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"\\nTraining interrupted by user\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Training failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logging.info(\"Cleaning up resources...\")\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74f13f34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T11:18:21.627695Z",
     "iopub.status.busy": "2025-02-19T11:18:21.627344Z",
     "iopub.status.idle": "2025-02-19T11:19:13.178237Z",
     "shell.execute_reply": "2025-02-19T11:19:13.176911Z"
    },
    "papermill": {
     "duration": 57.75422,
     "end_time": "2025-02-19T11:19:16.211627",
     "exception": false,
     "start_time": "2025-02-19T11:18:18.457407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/logs/experiments/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/metrics/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/metrics/training_history.json (deflated 66%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/metrics/evaluation_metrics.json (deflated 69%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/metrics/optuna_results.json (deflated 90%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/final_configuration.json (deflated 52%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/training.log (deflated 86%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/best_loss/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/best_loss/tokenizer.json (deflated 71%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/best_loss/vocab.txt (deflated 53%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/best_loss/special_tokens_map.json (deflated 42%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/best_loss/tokenizer_config.json (deflated 74%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/best_accuracy/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/best_accuracy/tokenizer.json (deflated 71%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/best_accuracy/vocab.txt (deflated 53%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/best_accuracy/special_tokens_map.json (deflated 42%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/tokenizer/best_accuracy/tokenizer_config.json (deflated 74%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/plots/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/plots/training_history.png (deflated 15%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices/confusion_matrix_Komedi.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices/confusion_matrix_Laga.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices/confusion_matrix_Drama.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices/confusion_matrix_Romantis.png (deflated 18%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/plots/confusion_matrices/confusion_matrix_Horor.png (deflated 20%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/model/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/model/best_loss/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/model/best_loss/model.safetensors (deflated 7%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/model/best_loss/config.json (deflated 56%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/model/best_accuracy/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/model/best_accuracy/model.safetensors (deflated 7%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250219_084004/model/best_accuracy/config.json (deflated 56%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r folder.zip /kaggle/working/logs/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a86f1573",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T11:19:22.720194Z",
     "iopub.status.busy": "2025-02-19T11:19:22.719504Z",
     "iopub.status.idle": "2025-02-19T11:19:22.726699Z",
     "shell.execute_reply": "2025-02-19T11:19:22.726010Z"
    },
    "papermill": {
     "duration": 3.242215,
     "end_time": "2025-02-19T11:19:22.727969",
     "exception": false,
     "start_time": "2025-02-19T11:19:19.485754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='folder.zip' target='_blank'>folder.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/folder.zip"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'folder.zip')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6639588,
     "sourceId": 10712322,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9585.597987,
   "end_time": "2025-02-19T11:19:28.799507",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-19T08:39:43.201520",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "030699208b2342acbd3610f8a792b99e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8c0ae9e88fbf4b82942cfaf8f38ac38c",
       "placeholder": "​",
       "style": "IPY_MODEL_d363ca90d25141bbb63df0996e58b65e",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 6.06MB/s]"
      }
     },
     "05bab9eb0ef64099a4075357d44b7294": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8478d06bcb754caebe4a94167957d7d6",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8d3a5d39ccf143128e73baf72fb109cd",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "0b61022794f24ec3ab3d4f412f60d94f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0ce9155e4ed943eaac6341d160a4f956": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_fad52a8fa38b4773aab5a72ac4566893",
       "placeholder": "​",
       "style": "IPY_MODEL_6c3ac0a8693541cba989ab4b9f34a1a2",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "0d16619b0f0d42278329bfb21e5f07fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_83b11d0eb0a344748d8347d2e1e8b9a0",
       "placeholder": "​",
       "style": "IPY_MODEL_65d725363dac4310829845274da738b6",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "0e89d097b95e442d9c86320779c39fb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8bad3b0c782b415da13ab07b0f881570",
       "placeholder": "​",
       "style": "IPY_MODEL_a6656fad04bb48459f655b23b8bc0ef0",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "1a1b0b29b6324479bb29904c5457bd16": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0ce9155e4ed943eaac6341d160a4f956",
        "IPY_MODEL_79cfd456a245457c9b17fcddaaf5aebb",
        "IPY_MODEL_842cc9af08f544678a687f583e1d0d0d"
       ],
       "layout": "IPY_MODEL_dfda9e6255cf4d4faaa926616707b65f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2bdb3f9d8a4d421d8004b9590e6682b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f95ba06d46044468d2d2d42ad927f7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_93592945c5ec4b4189f6eb99c220298f",
       "placeholder": "​",
       "style": "IPY_MODEL_69c45fb2843448869f6a286cbc40d983",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 13.2kB/s]"
      }
     },
     "32b1f24acd894c259aed93997d739b31": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "34592f3ce72c4ef889b464acce01bdd5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "3b6f593f17514ed58079323a07392439": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0e89d097b95e442d9c86320779c39fb3",
        "IPY_MODEL_05bab9eb0ef64099a4075357d44b7294",
        "IPY_MODEL_030699208b2342acbd3610f8a792b99e"
       ],
       "layout": "IPY_MODEL_32b1f24acd894c259aed93997d739b31",
       "tabbable": null,
       "tooltip": null
      }
     },
     "431f3586ba344703acb7311bb459bb41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4370a82b5dda4ff1b71e2ec3656a12f8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4e36ff3960fa4cc1bb7a95c03653a187",
        "IPY_MODEL_e58ff57d31c649b7b638e90f1d1fc985",
        "IPY_MODEL_ad834acc00e343989cf9c0fa3dca37e8"
       ],
       "layout": "IPY_MODEL_2bdb3f9d8a4d421d8004b9590e6682b2",
       "tabbable": null,
       "tooltip": null
      }
     },
     "4962fd57d34f47f086119dc4de5589ee": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e36ff3960fa4cc1bb7a95c03653a187": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8b8c7962ce9a4bfb84a4e834854fb7aa",
       "placeholder": "​",
       "style": "IPY_MODEL_34592f3ce72c4ef889b464acce01bdd5",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "5218ed9466954e68a816c788317f0a8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "532685ee9af447ca98fe5f00331d0a76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "54ed7a5d31bb44f69c55ffed2e509a2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5a745d1007e34ad7bfa9d7200fc7e6cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9b80e99c2ec64045aa8a6c2131a9b53e",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ed26c42ba8624157b27880798e078864",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "647b919fb2604c328eac91817c92fd0b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65d725363dac4310829845274da738b6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "69c45fb2843448869f6a286cbc40d983": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6aba2eea66b9473d965b878b45a6b2d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6c3ac0a8693541cba989ab4b9f34a1a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6cba05922f144fdb9070e06b1ff927e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "792197a343ac4fb29592e796ada0fac2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8a876cb2b8de4c3980b6081c6f798008",
       "placeholder": "​",
       "style": "IPY_MODEL_6aba2eea66b9473d965b878b45a6b2d3",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "79cfd456a245457c9b17fcddaaf5aebb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_4962fd57d34f47f086119dc4de5589ee",
       "max": 497810400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_cffef1eac2af43f5b9a41fab282d1980",
       "tabbable": null,
       "tooltip": null,
       "value": 497810400.0
      }
     },
     "83b11d0eb0a344748d8347d2e1e8b9a0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "842cc9af08f544678a687f583e1d0d0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0b61022794f24ec3ab3d4f412f60d94f",
       "placeholder": "​",
       "style": "IPY_MODEL_d0e5996df9d048ad880d936c8ba4f274",
       "tabbable": null,
       "tooltip": null,
       "value": " 498M/498M [00:02&lt;00:00, 212MB/s]"
      }
     },
     "8478d06bcb754caebe4a94167957d7d6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "885d1c3051a04fdb830a43f4f925b524": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0d16619b0f0d42278329bfb21e5f07fb",
        "IPY_MODEL_5a745d1007e34ad7bfa9d7200fc7e6cf",
        "IPY_MODEL_2f95ba06d46044468d2d2d42ad927f7b"
       ],
       "layout": "IPY_MODEL_431f3586ba344703acb7311bb459bb41",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8a876cb2b8de4c3980b6081c6f798008": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8b8c7962ce9a4bfb84a4e834854fb7aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8bad3b0c782b415da13ab07b0f881570": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c0ae9e88fbf4b82942cfaf8f38ac38c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d3a5d39ccf143128e73baf72fb109cd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "93592945c5ec4b4189f6eb99c220298f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a60ffec00a347f599bc32fe89f5f131": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d4c3cdc53d9b431db727959be91016d0",
       "placeholder": "​",
       "style": "IPY_MODEL_6cba05922f144fdb9070e06b1ff927e4",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 187B/s]"
      }
     },
     "9b80e99c2ec64045aa8a6c2131a9b53e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f9d2550cc2b4aff9768639a9e3703f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a6656fad04bb48459f655b23b8bc0ef0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ad834acc00e343989cf9c0fa3dca37e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b28a9814e3a241b0b94d88080d34c58a",
       "placeholder": "​",
       "style": "IPY_MODEL_5218ed9466954e68a816c788317f0a8f",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 151kB/s]"
      }
     },
     "ae2c3c7249c743cb97f2d172bcf8edb3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_792197a343ac4fb29592e796ada0fac2",
        "IPY_MODEL_c0c206065ccf499b814cb6e29f7bf202",
        "IPY_MODEL_9a60ffec00a347f599bc32fe89f5f131"
       ],
       "layout": "IPY_MODEL_9f9d2550cc2b4aff9768639a9e3703f9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "b28a9814e3a241b0b94d88080d34c58a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bc8ad4aa651243098e980bc63248b3b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c0c206065ccf499b814cb6e29f7bf202": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_647b919fb2604c328eac91817c92fd0b",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_54ed7a5d31bb44f69c55ffed2e509a2e",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "cffef1eac2af43f5b9a41fab282d1980": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d0e5996df9d048ad880d936c8ba4f274": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d363ca90d25141bbb63df0996e58b65e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d4c3cdc53d9b431db727959be91016d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dfda9e6255cf4d4faaa926616707b65f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e58ff57d31c649b7b638e90f1d1fc985": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_532685ee9af447ca98fe5f00331d0a76",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_bc8ad4aa651243098e980bc63248b3b8",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "ed26c42ba8624157b27880798e078864": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "fad52a8fa38b4773aab5a72ac4566893": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
