{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e42ba82c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-10T22:03:12.273840Z",
     "iopub.status.busy": "2025-02-10T22:03:12.273444Z",
     "iopub.status.idle": "2025-02-10T22:03:13.274576Z",
     "shell.execute_reply": "2025-02-10T22:03:13.273487Z"
    },
    "papermill": {
     "duration": 1.009138,
     "end_time": "2025-02-10T22:03:13.276136",
     "exception": false,
     "start_time": "2025-02-10T22:03:12.266998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datasets-classificationsynopsis/final_combined_movies_5genres.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73ea9864",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T22:03:13.284396Z",
     "iopub.status.busy": "2025-02-10T22:03:13.284038Z",
     "iopub.status.idle": "2025-02-10T22:03:18.490145Z",
     "shell.execute_reply": "2025-02-10T22:03:18.489102Z"
    },
    "papermill": {
     "duration": 5.212209,
     "end_time": "2025-02-10T22:03:18.492206",
     "exception": false,
     "start_time": "2025-02-10T22:03:13.279997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.2.0)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.1)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2.4.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->optuna) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Movie Genre Classification with IndoBERT\n",
    "Environment: Kaggle\n",
    "\"\"\"\n",
    "\n",
    "!pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5efb44",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T22:03:18.501184Z",
     "iopub.status.busy": "2025-02-10T22:03:18.500937Z",
     "iopub.status.idle": "2025-02-10T22:03:31.665403Z",
     "shell.execute_reply": "2025-02-10T22:03:31.664505Z"
    },
    "papermill": {
     "duration": 13.170496,
     "end_time": "2025-02-10T22:03:31.667008",
     "exception": false,
     "start_time": "2025-02-10T22:03:18.496512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAGIAN PERTAMA - Import dan Konfigurasi\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "import argparse\n",
    "import gc\n",
    "import sys\n",
    "import codecs\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import psutil\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "\n",
    "# Define Base Path for Kaggle\n",
    "BASE_PATH = Path('/kaggle/working/genrematics-optuna-app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15eac8df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T22:03:31.675717Z",
     "iopub.status.busy": "2025-02-10T22:03:31.675231Z",
     "iopub.status.idle": "2025-02-10T22:03:31.823000Z",
     "shell.execute_reply": "2025-02-10T22:03:31.822266Z"
    },
    "papermill": {
     "duration": 0.153611,
     "end_time": "2025-02-10T22:03:31.824461",
     "exception": false,
     "start_time": "2025-02-10T22:03:31.670850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU tersedia: Tesla T4\n",
      "GPU Memory: 15.83 GB\n",
      "Created directory: /kaggle/working/genrematics-optuna-app/logs\n",
      "Created directory: /kaggle/working/genrematics-optuna-app/backups\n",
      "Created directory: /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331\n",
      "Created directory: /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/model\n",
      "Created directory: /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/tokenizer\n",
      "Created directory: /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/metrics\n",
      "Created directory: /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots\n",
      "Created directory: /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices\n",
      "2025-02-10 22:03:31,806 - INFO - Log file created at: /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/training.log\n",
      "2025-02-10 22:03:31,807 - INFO - System Information:\n",
      "2025-02-10 22:03:31,807 - INFO - Python Version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "2025-02-10 22:03:31,815 - INFO - CPU Count: 4\n",
      "2025-02-10 22:03:31,816 - INFO - Initial Memory Usage: 634.65 MB\n",
      "2025-02-10 22:03:31,817 - INFO - GPU Device: Tesla T4\n",
      "2025-02-10 22:03:31,817 - INFO - GPU Memory Total: 15.83 GB\n",
      "2025-02-10 22:03:31,818 - INFO - CUDA Version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# Configuration Constants\n",
    "class Config:\n",
    "    # Model Parameters dengan fixed values\n",
    "    MODEL_PARAMS = {\n",
    "        'EPOCHS': 20,\n",
    "        'BATCH_SIZE': 16,  # Fixed\n",
    "        'LEARNING_RATE': 2e-5,  # Fixed\n",
    "        'MAX_LENGTH': 512,\n",
    "        'TEST_SIZE': 0.15,\n",
    "        'WEIGHT_DECAY': 0.01,  # Fixed\n",
    "        'MIXUP_PROB': 0.3,  # Fixed\n",
    "        'PATIENCE': 5,\n",
    "        'SMOOTHING': 0.1  # Fixed\n",
    "    }\n",
    "\n",
    "    # Optimization Parameters dengan fixed options\n",
    "    OPTIM_PARAMS = {\n",
    "        'batch_size': [8, 16, 32],  # Fixed values\n",
    "        'learning_rate': [1e-5, 2e-5, 3e-5],\n",
    "        'weight_decay': [0.01, 0.02],\n",
    "        'mixup_prob': [0.2, 0.3],\n",
    "        'smoothing': [0.1, 0.15]\n",
    "    }\n",
    "\n",
    "    # Paths Configuration untuk Kaggle\n",
    "    BASE_DIR = BASE_PATH\n",
    "    DATA_DIR = Path('/kaggle/input/datasets-classificationsynopsis')\n",
    "    LOG_DIR = BASE_DIR / 'logs'\n",
    "    BACKUP_DIR = BASE_DIR / 'backups'\n",
    "    TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    EXPERIMENT_DIR = LOG_DIR / 'experiments' / TIMESTAMP\n",
    "\n",
    "    # Model and Data Paths\n",
    "    MODEL_SAVE_DIR = EXPERIMENT_DIR / 'model'\n",
    "    TOKENIZER_SAVE_DIR = EXPERIMENT_DIR / 'tokenizer'\n",
    "    METRICS_DIR = EXPERIMENT_DIR / 'metrics'\n",
    "    PLOTS_DIR = EXPERIMENT_DIR / 'plots'\n",
    "    CM_DIR = PLOTS_DIR / 'confusion_matrices'\n",
    "\n",
    "    # Model Files\n",
    "    MODEL_BEST_ACC = MODEL_SAVE_DIR / \"best_accuracy\"\n",
    "    MODEL_BEST_LOSS = MODEL_SAVE_DIR / \"best_loss\"\n",
    "    TOKENIZER_BEST_ACC = TOKENIZER_SAVE_DIR / \"best_accuracy\"\n",
    "    TOKENIZER_BEST_LOSS = TOKENIZER_SAVE_DIR / \"best_loss\"\n",
    "    DATA_PATH = DATA_DIR / \"final_combined_movies_5genres.csv\"\n",
    "\n",
    "    # Device Configuration\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    SAMPLE_SIZE: Optional[int] = None\n",
    "\n",
    "    @classmethod\n",
    "    def create_directories(cls) -> None:\n",
    "        \"\"\"Create all necessary directories in Kaggle working directory\"\"\"\n",
    "        directories = [\n",
    "            cls.LOG_DIR, cls.BACKUP_DIR,\n",
    "            cls.EXPERIMENT_DIR, cls.MODEL_SAVE_DIR, cls.TOKENIZER_SAVE_DIR,\n",
    "            cls.METRICS_DIR, cls.PLOTS_DIR, cls.CM_DIR\n",
    "        ]\n",
    "        for dir_path in directories:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "    @classmethod\n",
    "    def setup_logging(cls) -> None:\n",
    "        \"\"\"Setup logging configuration untuk Kaggle\"\"\"\n",
    "        log_file = cls.EXPERIMENT_DIR / 'training.log'\n",
    "        for handler in logging.root.handlers[:]:\n",
    "            logging.root.removeHandler(handler)\n",
    "\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file, encoding='utf-8', mode='a'),\n",
    "                logging.StreamHandler(sys.stdout)\n",
    "            ]\n",
    "        )\n",
    "        logging.info(f\"Log file created at: {log_file}\")\n",
    "\n",
    "# Environment Check Function\n",
    "def check_environment() -> bool:\n",
    "    \"\"\"Verify Kaggle environment and paths\"\"\"\n",
    "    try:\n",
    "        # Check if data directory exists\n",
    "        if not Config.DATA_DIR.exists():\n",
    "            raise RuntimeError(f\"Data directory tidak ditemukan di: {Config.DATA_DIR}\")\n",
    "\n",
    "        # Check if dataset exists\n",
    "        if not Config.DATA_PATH.exists():\n",
    "            raise RuntimeError(f\"Dataset tidak ditemukan di: {Config.DATA_PATH}\")\n",
    "\n",
    "        # Check GPU availability\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n",
    "            print(f\"GPU tersedia: {gpu_name}\")\n",
    "            print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
    "        else:\n",
    "            print(\"WARNING: GPU tidak tersedia, menggunakan CPU\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error dalam setup environment: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Memory Management\n",
    "class ModelManager:\n",
    "    \"\"\"Context manager for model memory management\"\"\"\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.model, self.tokenizer\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        del self.model\n",
    "        del self.tokenizer\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# Error Handling\n",
    "def error_handler(func):\n",
    "    \"\"\"Decorator for consistent error handling\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in {func.__name__}: {str(e)}\")\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "# Utility Functions\n",
    "def get_memory_usage() -> float:\n",
    "    \"\"\"Get current memory usage of the program\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024  # in MB\n",
    "\n",
    "def log_memory(step_name: str) -> None:\n",
    "    \"\"\"Log memory usage with consistent format\"\"\"\n",
    "    memory = get_memory_usage()\n",
    "    logging.info(f\"Memory usage after {step_name}: {memory:.2f} MB\")\n",
    "\n",
    "def log_system_info() -> None:\n",
    "    \"\"\"Log system information including GPU details\"\"\"\n",
    "    logging.info(\"System Information:\")\n",
    "    logging.info(f\"Python Version: {sys.version}\")\n",
    "    logging.info(f\"CPU Count: {os.cpu_count()}\")\n",
    "    logging.info(f\"Initial Memory Usage: {get_memory_usage():.2f} MB\")\n",
    "    if torch.cuda.is_available():\n",
    "        logging.info(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "        logging.info(f\"GPU Memory Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        logging.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# Create directories and setup logging\n",
    "if check_environment():\n",
    "    Config.create_directories()\n",
    "    Config.setup_logging()\n",
    "    log_system_info()\n",
    "else:\n",
    "    print(\"Failed to initialize environment. Please check the setup.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ff5e7ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T22:03:31.833826Z",
     "iopub.status.busy": "2025-02-10T22:03:31.833585Z",
     "iopub.status.idle": "2025-02-10T22:03:31.857179Z",
     "shell.execute_reply": "2025-02-10T22:03:31.856545Z"
    },
    "papermill": {
     "duration": 0.02959,
     "end_time": "2025-02-10T22:03:31.858419",
     "exception": false,
     "start_time": "2025-02-10T22:03:31.828829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MovieDataset(Dataset):\n",
    "    \"\"\"Dataset class untuk movie genre classification\"\"\"\n",
    "    def __init__(self, texts: Union[List, np.ndarray],\n",
    "                 labels: Union[List, np.ndarray],\n",
    "                 tokenizer,\n",
    "                 max_length: int = 512):\n",
    "        # Input validation\n",
    "        if not isinstance(texts, (list, np.ndarray)):\n",
    "            raise ValueError(\"texts must be a list or numpy array\")\n",
    "        if not isinstance(labels, (list, np.ndarray)):\n",
    "            raise ValueError(\"labels must be a list or numpy array\")\n",
    "        if len(texts) != len(labels):\n",
    "            raise ValueError(\"texts and labels must have the same length\")\n",
    "\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        # Pastikan labels dalam format yang benar\n",
    "        if isinstance(self.labels[idx], (list, np.ndarray)):\n",
    "            labels = self.labels[idx]\n",
    "        else:\n",
    "            labels = [self.labels[idx]]\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten().long(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten().long(),\n",
    "            'labels': torch.FloatTensor(labels)\n",
    "        }\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Class for handling data preprocessing and loading\"\"\"\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"Clean and preprocess text data\"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "            text = re.sub(r'\\S+@\\S+', '', text)\n",
    "            text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            return text.strip().lower()\n",
    "        return ''\n",
    "\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def load_and_preprocess_data(data_path: Path, sample_size: Optional[int] = None) -> pd.DataFrame:\n",
    "        \"\"\"Load and preprocess data with proper encoding handling\"\"\"\n",
    "        if not data_path.exists():\n",
    "            raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "\n",
    "        if sample_size is not None and (not isinstance(sample_size, int) or sample_size <= 0):\n",
    "            raise ValueError(\"sample_size must be a positive integer\")\n",
    "\n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        log_memory(\"start\")\n",
    "        initial_size = None\n",
    "\n",
    "        # Try different encodings for Kaggle compatibility\n",
    "        encodings_to_try = ['utf-8', 'utf-8-sig', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "        df = None\n",
    "\n",
    "        for encoding in encodings_to_try:\n",
    "            try:\n",
    "                df = pd.read_csv(data_path, encoding=encoding)\n",
    "                logging.info(f\"Successfully loaded data using {encoding} encoding\")\n",
    "                initial_size = len(df)\n",
    "                break\n",
    "            except (UnicodeDecodeError, UnicodeError):\n",
    "                continue\n",
    "\n",
    "        if df is None:\n",
    "            raise UnicodeError(f\"Failed to read file with any of these encodings: {encodings_to_try}\")\n",
    "\n",
    "        log_memory(\"data loading\")\n",
    "\n",
    "        # Sample data if requested\n",
    "        if sample_size:\n",
    "            if sample_size > initial_size:\n",
    "                logging.warning(f\"Requested sample_size ({sample_size}) is larger than dataset size ({initial_size})\")\n",
    "                sample_size = initial_size\n",
    "            logging.info(f\"Taking sample of {sample_size} from {initial_size} total samples\")\n",
    "            df = df.head(sample_size)\n",
    "        else:\n",
    "            logging.info(f\"Using full dataset with {initial_size} samples\")\n",
    "\n",
    "        # Log sample data\n",
    "        logging.info(\"\\nSample data:\")\n",
    "        for i, row in df.head(3).iterrows():\n",
    "            logging.info(f\"\\nSample {i+1}:\")\n",
    "            logging.info(f\"Synopsis: {row['sinopsis'][:100]}...\")\n",
    "            logging.info(f\"Genre: {row['genre']}\")\n",
    "\n",
    "        # Preprocess data\n",
    "        logging.info(\"\\nPreprocessing text data...\")\n",
    "        tqdm.pandas()\n",
    "        df['sinopsis'] = df['sinopsis'].progress_apply(DataProcessor.clean_text)\n",
    "        df['genre'] = df['genre'].str.split(',')\n",
    "        df = df.dropna(subset=['sinopsis', 'genre'])\n",
    "\n",
    "        # Calculate and log dataset statistics\n",
    "        stats = DataProcessor.calculate_dataset_statistics(df)\n",
    "\n",
    "        # Save statistics to file\n",
    "        stats_file = Config.METRICS_DIR / 'dataset_statistics.json'\n",
    "        with open(stats_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(stats, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        log_memory(\"preprocessing\")\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_data(df: pd.DataFrame, mlb: MultiLabelBinarizer) -> Tuple:\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        genre_labels = mlb.fit_transform(df['genre'])\n",
    "        return train_test_split(\n",
    "            df['sinopsis'].values,\n",
    "            genre_labels,\n",
    "            test_size=Config.MODEL_PARAMS['TEST_SIZE'],\n",
    "            random_state=42,\n",
    "            stratify=genre_labels if len(genre_labels.shape) == 1 else None\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def create_weighted_sampler(genre_labels: np.ndarray) -> WeightedRandomSampler:\n",
    "        \"\"\"Create weighted sampler for balanced batch sampling\"\"\"\n",
    "        logging.info(\"Creating weighted sampler for balanced batch sampling...\")\n",
    "\n",
    "        sample_weights = np.zeros(len(genre_labels))\n",
    "        for i in range(genre_labels.shape[1]):\n",
    "            sample_weights += genre_labels[:, i] * (1.0 / np.sum(genre_labels[:, i]))\n",
    "\n",
    "        sample_weights = sample_weights / sample_weights.sum()\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Created sampler with {len(sample_weights)} weights\")\n",
    "        return sampler\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_class_weights(genre_labels: np.ndarray, mlb: MultiLabelBinarizer) -> torch.Tensor:\n",
    "        \"\"\"Calculate class weights for handling imbalanced data\"\"\"\n",
    "        class_weights = []\n",
    "        logging.info(\"\\nCalculating class weights for handling imbalanced data...\")\n",
    "\n",
    "        for i in range(genre_labels.shape[1]):\n",
    "            genre = mlb.classes_[i]\n",
    "            positive_samples = np.sum(genre_labels[:, i])\n",
    "            total_samples = len(genre_labels)\n",
    "\n",
    "            weights = compute_class_weight(\n",
    "                class_weight='balanced',\n",
    "                classes=np.array([0, 1]),\n",
    "                y=genre_labels[:, i]\n",
    "            )\n",
    "            class_weights.append(weights[1])\n",
    "\n",
    "            logging.info(f\"{genre}:\")\n",
    "            logging.info(f\"  Positive samples: {positive_samples}\")\n",
    "            logging.info(f\"  Negative samples: {total_samples - positive_samples}\")\n",
    "            logging.info(f\"  Weight: {weights[1]:.2f}\")\n",
    "\n",
    "        return torch.FloatTensor(class_weights).to(Config.DEVICE)\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_dataset_statistics(df: pd.DataFrame) -> Dict:\n",
    "        \"\"\"Calculate comprehensive dataset statistics\"\"\"\n",
    "        logging.info(\"Calculating dataset statistics...\")\n",
    "        stats = {\n",
    "            'general_stats': {\n",
    "                'total_samples': len(df),\n",
    "                'unique_genres': len(set([g for genres in df['genre'] for g in genres])),\n",
    "                'avg_synopsis_length': float(df['sinopsis'].str.len().mean()),\n",
    "                'null_values': df.isnull().sum().to_dict()\n",
    "            },\n",
    "            'genre_stats': DataProcessor.analyze_genre_combinations(df['genre'].values),\n",
    "            'text_stats': DataProcessor.calculate_text_statistics(df['sinopsis'].values)\n",
    "        }\n",
    "\n",
    "        logging.info(\"\\nDataset Statistics:\")\n",
    "        logging.info(f\"Total samples: {stats['general_stats']['total_samples']}\")\n",
    "        logging.info(f\"Unique genres: {stats['general_stats']['unique_genres']}\")\n",
    "\n",
    "        return stats\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_text_statistics(texts: np.ndarray) -> Dict:\n",
    "        \"\"\"Calculate detailed text statistics\"\"\"\n",
    "        tokenizer = AutoTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "        token_lengths = []\n",
    "        char_lengths = []\n",
    "        truncated_count = 0\n",
    "\n",
    "        logging.info(\"Calculating text statistics...\")\n",
    "        for text in tqdm(texts, desc=\"Analyzing texts\"):\n",
    "            tokens = tokenizer.tokenize(text)\n",
    "            token_lengths.append(len(tokens))\n",
    "            char_lengths.append(len(text))\n",
    "            if len(tokens) > Config.MODEL_PARAMS['MAX_LENGTH']:\n",
    "                truncated_count += 1\n",
    "\n",
    "        return {\n",
    "            'avg_token_length': float(np.mean(token_lengths)),\n",
    "            'max_token_length': int(np.max(token_lengths)),\n",
    "            'min_token_length': int(np.min(token_lengths)),\n",
    "            'avg_char_length': float(np.mean(char_lengths)),\n",
    "            'max_char_length': int(np.max(char_lengths)),\n",
    "            'min_char_length': int(np.min(char_lengths)),\n",
    "            'truncated_sequences': truncated_count,\n",
    "            'total_sequences': len(texts),\n",
    "            'truncation_percentage': float(truncated_count / len(texts) * 100)\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def analyze_genre_combinations(genres: List[List[str]]) -> Dict:\n",
    "        \"\"\"Analyze genre combination patterns\"\"\"\n",
    "        logging.info(\"Analyzing genre combinations...\")\n",
    "        combinations = []\n",
    "        for genre_list in genres:\n",
    "            combinations.append(','.join(sorted(genre_list)))\n",
    "\n",
    "        combination_counts = pd.Series(combinations).value_counts()\n",
    "\n",
    "        return {\n",
    "            'total_combinations': len(combination_counts),\n",
    "            'unique_combinations': combination_counts.to_dict(),\n",
    "            'top_combinations': combination_counts.head(10).to_dict(),\n",
    "            'single_genre_count': sum(len(g) == 1 for g in genres),\n",
    "            'multi_genre_count': sum(len(g) > 1 for g in genres),\n",
    "            'max_genres_per_item': max(len(g) for g in genres),\n",
    "            'avg_genres_per_item': float(np.mean([len(g) for g in genres]))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031a4e37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T22:03:31.867981Z",
     "iopub.status.busy": "2025-02-10T22:03:31.867591Z",
     "iopub.status.idle": "2025-02-10T22:03:31.878731Z",
     "shell.execute_reply": "2025-02-10T22:03:31.877825Z"
    },
    "papermill": {
     "duration": 0.017475,
     "end_time": "2025-02-10T22:03:31.879986",
     "exception": false,
     "start_time": "2025-02-10T22:03:31.862511",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelSetup:\n",
    "    \"\"\"Class for handling model setup and data loaders\"\"\"\n",
    "    @staticmethod\n",
    "    def setup_model_and_tokenizer(num_labels: int) -> Tuple:\n",
    "        \"\"\"Setup model dan tokenizer\"\"\"\n",
    "        logging.info(\"Setting up model and tokenizer...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p1',\n",
    "            num_labels=num_labels,\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        ).to(Config.DEVICE)\n",
    "        logging.info(\"Model and tokenizer setup completed\")\n",
    "        return model, tokenizer\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_dataloaders(X_train: np.ndarray,\n",
    "                         X_test: np.ndarray,\n",
    "                         y_train: np.ndarray,\n",
    "                         y_test: np.ndarray,\n",
    "                         tokenizer,\n",
    "                         batch_size: int) -> Tuple:\n",
    "        \"\"\"Setup data loaders\"\"\"\n",
    "        logging.info(\"Setting up data loaders...\")\n",
    "        train_dataset = MovieDataset(X_train, y_train, tokenizer)\n",
    "        val_dataset = MovieDataset(X_test, y_test, tokenizer)\n",
    "        sampler = DataProcessor.create_weighted_sampler(y_train)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            num_workers=2,  # Adjusted for Kaggle\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=2,  # Adjusted for Kaggle\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Created data loaders with batch size {batch_size}\")\n",
    "        logging.info(f\"Training batches: {len(train_loader)}\")\n",
    "        logging.info(f\"Validation batches: {len(val_loader)}\")\n",
    "        \n",
    "        return train_loader, val_loader\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_model_setup(model, tokenizer, num_labels: int) -> bool:\n",
    "        \"\"\"Validate model and tokenizer setup\"\"\"\n",
    "        try:\n",
    "            # Check model configuration\n",
    "            if model.num_labels != num_labels:\n",
    "                raise ValueError(f\"Model has {model.num_labels} labels, expected {num_labels}\")\n",
    "            \n",
    "            # Validate tokenizer\n",
    "            sample_text = \"Contoh teks untuk validasi\"\n",
    "            tokens = tokenizer(\n",
    "                sample_text,\n",
    "                max_length=Config.MODEL_PARAMS['MAX_LENGTH'],\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                return_tensors='pt'\n",
    "            )\n",
    "            \n",
    "            # Check token shapes\n",
    "            if tokens['input_ids'].shape[1] > Config.MODEL_PARAMS['MAX_LENGTH']:\n",
    "                raise ValueError(\"Tokenizer producing sequences longer than max_length\")\n",
    "            \n",
    "            # Test model forward pass\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**tokens)\n",
    "                if outputs.logits.shape[1] != num_labels:\n",
    "                    raise ValueError(f\"Model output shape mismatch: got {outputs.logits.shape[1]}, expected {num_labels}\")\n",
    "            \n",
    "            logging.info(\"Model and tokenizer validation successful\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Model validation failed: {str(e)}\")\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def log_model_info(model) -> None:\n",
    "        \"\"\"Log model architecture and parameters\"\"\"\n",
    "        try:\n",
    "            total_params = sum(p.numel() for p in model.parameters())\n",
    "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "            \n",
    "            logging.info(\"\\nModel Information:\")\n",
    "            logging.info(f\"Model Type: {model.__class__.__name__}\")\n",
    "            logging.info(f\"Total Parameters: {total_params:,}\")\n",
    "            logging.info(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "            logging.info(f\"Non-trainable Parameters: {total_params - trainable_params:,}\")\n",
    "            \n",
    "            # Log memory usage\n",
    "            if torch.cuda.is_available():\n",
    "                memory_allocated = torch.cuda.memory_allocated() / 1024**2\n",
    "                memory_reserved = torch.cuda.memory_reserved() / 1024**2\n",
    "                logging.info(f\"GPU Memory Allocated: {memory_allocated:.2f} MB\")\n",
    "                logging.info(f\"GPU Memory Reserved: {memory_reserved:.2f} MB\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error logging model info: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac530c32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T22:03:31.888694Z",
     "iopub.status.busy": "2025-02-10T22:03:31.888438Z",
     "iopub.status.idle": "2025-02-10T22:03:31.902457Z",
     "shell.execute_reply": "2025-02-10T22:03:31.901589Z"
    },
    "papermill": {
     "duration": 0.020061,
     "end_time": "2025-02-10T22:03:31.903964",
     "exception": false,
     "start_time": "2025-02-10T22:03:31.883903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LossFunctions:\n",
    "    \"\"\"Class untuk menangani berbagai loss functions\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def focal_loss(predictions: torch.Tensor,\n",
    "                  targets: torch.Tensor,\n",
    "                  gamma: float = 2.0,\n",
    "                  alpha: float = 0.25) -> torch.Tensor:\n",
    "        \"\"\"Calculate focal loss for multi-label classification\"\"\"\n",
    "        ce_loss = F.binary_cross_entropy_with_logits(predictions, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = alpha * (1-pt)**gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def label_smoothing_loss(outputs: torch.Tensor,\n",
    "                           targets: torch.Tensor,\n",
    "                           smoothing: float) -> torch.Tensor:\n",
    "        \"\"\"Calculate loss with label smoothing\"\"\"\n",
    "        log_probs = F.log_softmax(outputs, dim=-1)\n",
    "        targets = torch.clamp(targets * (1.0 - smoothing), min=smoothing / (targets.size(-1) - 1))\n",
    "        return torch.mean(torch.sum(-targets * log_probs, dim=-1))\n",
    "\n",
    "class DataAugmentation:\n",
    "    \"\"\"Class untuk menangani augmentasi data\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_mixup(batch: Dict[str, torch.Tensor], alpha: float = 0.2) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Apply mixup augmentation to batch\"\"\"\n",
    "        # Move tensors to device\n",
    "        input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "        labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        mixed_input_ids = lam * input_ids + (1 - lam) * input_ids.flip(0)\n",
    "        mixed_attention_mask = lam * attention_mask + (1 - lam) * attention_mask.flip(0)\n",
    "        mixed_labels = lam * labels + (1 - lam) * labels.flip(0)\n",
    "\n",
    "        return {\n",
    "            'input_ids': mixed_input_ids.long(),\n",
    "            'attention_mask': mixed_attention_mask.long(),\n",
    "            'labels': mixed_labels\n",
    "        }\n",
    "\n",
    "class Visualization:\n",
    "    \"\"\"Class untuk menangani visualisasi data\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def plot_training_history(history_data: Dict) -> None:\n",
    "        \"\"\"Plot and save training metrics visualization with consistent dict structure\n",
    "        \n",
    "        Args:\n",
    "            history_data: Dictionary containing training history with keys:\n",
    "                - epoch: List of epoch numbers\n",
    "                - train_loss: List of training losses\n",
    "                - val_loss: List of validation losses \n",
    "                - val_f1: List of validation F1 scores\n",
    "                - val_precision: List of validation precision scores\n",
    "                - val_recall: List of validation recall scores\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(20, 12))\n",
    "\n",
    "        # Loss Plot\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(history_data['epoch'], history_data['train_loss'],\n",
    "                label='Training Loss', marker='o', linewidth=2)\n",
    "        plt.plot(history_data['epoch'], history_data['val_loss'],\n",
    "                label='Validation Loss', marker='o', linewidth=2)\n",
    "        plt.title('Training vs Validation Loss', fontsize=12, pad=15)\n",
    "        plt.xlabel('Epoch', fontsize=10)\n",
    "        plt.ylabel('Loss', fontsize=10)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "        # F1 Score Plot \n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(history_data['epoch'], history_data['val_f1'],\n",
    "                label='F1 Score', marker='o', color='green', linewidth=2)\n",
    "        plt.title('F1 Score Over Time', fontsize=12, pad=15)\n",
    "        plt.xlabel('Epoch', fontsize=10)\n",
    "        plt.ylabel('F1 Score', fontsize=10)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "        # Learning Curve\n",
    "        plt.subplot(2, 2, 3)\n",
    "        loss_diff = np.array(history_data['train_loss']) - np.array(history_data['val_loss'])\n",
    "        plt.plot(history_data['epoch'], loss_diff,\n",
    "                label='Train-Val Loss Difference', marker='o', color='purple', linewidth=2)\n",
    "        plt.axhline(y=0, color='r', linestyle='--', label='Ideal Difference')\n",
    "        plt.title('Learning Curve', fontsize=12, pad=15)\n",
    "        plt.xlabel('Epoch', fontsize=10)\n",
    "        plt.ylabel('Loss Difference', fontsize=10)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "        # Save plot\n",
    "        plot_path = Config.PLOTS_DIR / 'training_history.png'\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "\n",
    "        logging.info(f\"Training history plots saved to {plot_path}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_confusion_matrices(predictions: np.ndarray,\n",
    "                              true_labels: np.ndarray,\n",
    "                              class_names: List[str]) -> None:\n",
    "        \"\"\"Plot confusion matrices for each class\n",
    "        \n",
    "        Args:\n",
    "            predictions: Binary predictions array\n",
    "            true_labels: True binary labels array\n",
    "            class_names: List of class names\n",
    "        \"\"\"\n",
    "        for idx, class_name in enumerate(class_names):\n",
    "            cm = confusion_matrix(true_labels[:, idx], predictions[:, idx])\n",
    "            \n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "            plt.title(f'Confusion Matrix - {class_name}')\n",
    "            plt.ylabel('True Label')\n",
    "            plt.xlabel('Predicted Label')\n",
    "            \n",
    "            plot_path = Config.CM_DIR / f'confusion_matrix_{class_name}.png'\n",
    "            plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "            plt.close()\n",
    "\n",
    "        logging.info(f\"Training history plots saved to {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39352992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T22:03:31.913245Z",
     "iopub.status.busy": "2025-02-10T22:03:31.913030Z",
     "iopub.status.idle": "2025-02-10T22:03:31.934926Z",
     "shell.execute_reply": "2025-02-10T22:03:31.934252Z"
    },
    "papermill": {
     "duration": 0.028121,
     "end_time": "2025-02-10T22:03:31.936252",
     "exception": false,
     "start_time": "2025-02-10T22:03:31.908131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelEvaluator:\n",
    "    \"\"\"Class untuk evaluasi model\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def evaluate_model(model: torch.nn.Module,\n",
    "                      val_loader: DataLoader,\n",
    "                      mlb: MultiLabelBinarizer) -> Dict:\n",
    "        \"\"\"Evaluate model performance\"\"\"\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "                input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = LossFunctions.focal_loss(outputs.logits, labels)\n",
    "                total_loss += loss.item()\n",
    "                n_batches += 1\n",
    "\n",
    "                preds = torch.sigmoid(outputs.logits).cpu().numpy()\n",
    "                preds_binary = (preds > 0.5).astype(int)\n",
    "                \n",
    "                all_preds.extend(preds_binary)\n",
    "                all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "\n",
    "        metrics = {\n",
    "            'loss': total_loss / n_batches,\n",
    "            'macro_f1': f1_score(all_labels, all_preds, average='macro'),\n",
    "            'macro_precision': precision_score(all_labels, all_preds, average='macro'),\n",
    "            'macro_recall': recall_score(all_labels, all_preds, average='macro'),\n",
    "            'per_class': {\n",
    "                genre: {\n",
    "                    'f1': f1_score(all_labels[:, i], all_preds[:, i]),\n",
    "                    'precision': precision_score(all_labels[:, i], all_preds[:, i]),\n",
    "                    'recall': recall_score(all_labels[:, i], all_preds[:, i])\n",
    "                }\n",
    "                for i, genre in enumerate(mlb.classes_)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        # Plot confusion matrices\n",
    "        Visualization.plot_confusion_matrices(all_preds, all_labels, mlb.classes_)\n",
    "\n",
    "        return metrics\n",
    "\n",
    "class ModelTrainer:\n",
    "    \"\"\"Class untuk menangani training model\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def train(model: torch.nn.Module,\n",
    "             train_loader: DataLoader,\n",
    "             val_loader: DataLoader,\n",
    "             mlb: MultiLabelBinarizer,\n",
    "             n_epochs: int) -> Dict:\n",
    "        \"\"\"Full training loop dengan history tracking yang konsisten\n",
    "        \n",
    "        Args:\n",
    "            model: Model PyTorch yang akan dilatih\n",
    "            train_loader: DataLoader untuk data training\n",
    "            val_loader: DataLoader untuk data validasi\n",
    "            mlb: MultiLabelBinarizer yang sudah difit\n",
    "            n_epochs: Jumlah epoch untuk training\n",
    "            \n",
    "        Returns:\n",
    "            Dict berisi history training dan metrics terbaik\n",
    "        \"\"\"\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=Config.MODEL_PARAMS['LEARNING_RATE'],\n",
    "            weight_decay=Config.MODEL_PARAMS['WEIGHT_DECAY']\n",
    "        )\n",
    "        \n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer,\n",
    "            num_warmup_steps=0,\n",
    "            num_training_steps=len(train_loader) * n_epochs\n",
    "        )\n",
    "\n",
    "        best_metrics = None\n",
    "        best_loss = float('inf')\n",
    "        patience_counter = 0\n",
    "        \n",
    "        history = {\n",
    "            'epoch': [],\n",
    "            'train_loss': [],\n",
    "            'val_loss': [],\n",
    "            'val_f1': [],\n",
    "            'val_precision': [],\n",
    "            'val_recall': []\n",
    "        }\n",
    "\n",
    "        start_time = datetime.datetime.now()\n",
    "\n",
    "        for epoch in range(n_epochs):\n",
    "            epoch_start_time = datetime.datetime.now()\n",
    "            \n",
    "            # Training phase\n",
    "            train_metrics = ModelTrainer.train_epoch(\n",
    "                model=model,\n",
    "                train_loader=train_loader,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                epoch=epoch + 1\n",
    "            )\n",
    "            \n",
    "            # Validation phase\n",
    "            val_metrics = ModelEvaluator.evaluate_model(model, val_loader, mlb)\n",
    "            \n",
    "            # Update training history\n",
    "            history['epoch'].append(epoch + 1)\n",
    "            history['train_loss'].append(train_metrics['loss'])\n",
    "            history['val_loss'].append(val_metrics['loss'])\n",
    "            history['val_f1'].append(val_metrics['macro_f1'])\n",
    "            history['val_precision'].append(val_metrics['macro_precision'])\n",
    "            history['val_recall'].append(val_metrics['macro_recall'])\n",
    "\n",
    "            # Save best model based on F1 score\n",
    "            if best_metrics is None or val_metrics['macro_f1'] > best_metrics['macro_f1']:\n",
    "                best_metrics = val_metrics\n",
    "                ModelTrainer.save_model(model, Config.MODEL_BEST_ACC)\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            # Save best model based on loss\n",
    "            if val_metrics['loss'] < best_loss:\n",
    "                best_loss = val_metrics['loss']\n",
    "                ModelTrainer.save_model(model, Config.MODEL_BEST_LOSS)\n",
    "\n",
    "            # Early stopping check\n",
    "            if patience_counter >= Config.MODEL_PARAMS['PATIENCE']:\n",
    "                logging.info(f\"Early stopping triggered after {epoch + 1} epochs\")\n",
    "                break\n",
    "\n",
    "            # Calculate epoch time\n",
    "            epoch_time = datetime.datetime.now() - epoch_start_time\n",
    "            \n",
    "            # Log metrics\n",
    "            logging.info(\n",
    "                f\"Epoch {epoch+1}/{n_epochs} - Time: {epoch_time.total_seconds():.2f}s - \"\n",
    "                f\"Train Loss: {train_metrics['loss']:.4f}, \"\n",
    "                f\"Val Loss: {val_metrics['loss']:.4f}, \"\n",
    "                f\"Val F1: {val_metrics['macro_f1']:.4f}, \"\n",
    "                f\"Val Precision: {val_metrics['macro_precision']:.4f}, \"\n",
    "                f\"Val Recall: {val_metrics['macro_recall']:.4f}\"\n",
    "            )\n",
    "\n",
    "            # Plot training history\n",
    "            Visualization.plot_training_history(history)\n",
    "            \n",
    "            # Save metrics to JSON for web app\n",
    "            metrics_file = Config.METRICS_DIR / 'training_history.json'\n",
    "            with open(metrics_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump({\n",
    "                    'training_history': {\n",
    "                        'epochs': history['epoch'],\n",
    "                        'training_loss': history['train_loss'],\n",
    "                        'validation_loss': history['val_loss'],\n",
    "                        'accuracy': history['val_f1'],\n",
    "                        'best_accuracy': max(history['val_f1']),\n",
    "                        'best_val_loss': min(history['val_loss'])\n",
    "                    },\n",
    "                    'model_info': {\n",
    "                        'classes': mlb.classes_.tolist(),\n",
    "                        'total_samples': len(train_loader.dataset),\n",
    "                        'training_time': str(datetime.datetime.now() - start_time),\n",
    "                        'parameters': {\n",
    "                            'total_parameters': sum(p.numel() for p in model.parameters()),\n",
    "                            'trainable_parameters': sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "                        }\n",
    "                    }\n",
    "                }, f, indent=4)\n",
    "\n",
    "            # Memory cleanup after each epoch\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "        total_time = datetime.datetime.now() - start_time\n",
    "        logging.info(f\"Training completed in {total_time}\")\n",
    "        \n",
    "        return history, best_metrics\n",
    "\n",
    "    @staticmethod\n",
    "    def train_epoch(model: torch.nn.Module,\n",
    "                   train_loader: DataLoader,\n",
    "                   optimizer: torch.optim.Optimizer,\n",
    "                   scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
    "                   epoch: int) -> Dict[str, float]:\n",
    "        \"\"\"Training untuk satu epoch\n",
    "        \n",
    "        Args:\n",
    "            model: Model PyTorch yang akan dilatih\n",
    "            train_loader: DataLoader untuk data training\n",
    "            optimizer: Optimizer yang digunakan\n",
    "            scheduler: Learning rate scheduler\n",
    "            epoch: Nomor epoch saat ini\n",
    "            \n",
    "        Returns:\n",
    "            Dict berisi metrics training untuk epoch ini\n",
    "        \"\"\"\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        n_batches = 0\n",
    "        \n",
    "        # Progress bar\n",
    "        progress_bar = tqdm(train_loader, desc=f'Training Epoch {epoch}')\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            # Move batch to device\n",
    "            input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "            labels = batch['labels'].to(Config.DEVICE)\n",
    "            \n",
    "            # Clear gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Apply mixup augmentation dengan probability\n",
    "            if np.random.random() < Config.MODEL_PARAMS['MIXUP_PROB']:\n",
    "                batch = DataAugmentation.apply_mixup(batch)\n",
    "                input_ids = batch['input_ids']\n",
    "                attention_mask = batch['attention_mask']\n",
    "                labels = batch['labels']\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            \n",
    "            # Calculate loss dengan label smoothing\n",
    "            loss = LossFunctions.label_smoothing_loss(\n",
    "                outputs.logits,\n",
    "                labels,\n",
    "                Config.MODEL_PARAMS['SMOOTHING']\n",
    "            )\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient clipping\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            \n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Update metrics\n",
    "            total_loss += loss.item()\n",
    "            n_batches += 1\n",
    "            \n",
    "            # Update progress bar\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'avg_loss': f'{total_loss/n_batches:.4f}',\n",
    "                'lr': f'{scheduler.get_last_lr()[0]:.2e}'\n",
    "            })\n",
    "            \n",
    "            # Memory cleanup every few batches\n",
    "            if n_batches % 10 == 0:\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "        \n",
    "        # Calculate average loss\n",
    "        avg_loss = total_loss / n_batches\n",
    "        \n",
    "        return {\n",
    "            'loss': avg_loss,\n",
    "            'learning_rate': scheduler.get_last_lr()[0]\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(model: torch.nn.Module, path: Path) -> None:\n",
    "        \"\"\"Save model checkpoint dengan proper error handling\n",
    "        \n",
    "        Args:\n",
    "            model: Model PyTorch yang akan disimpan\n",
    "            path: Path untuk menyimpan model\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create directory if not exists\n",
    "            path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Prepare checkpoint data\n",
    "            checkpoint = {\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'config': model.config.to_dict(),\n",
    "                'save_time': datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"),\n",
    "                'device': str(next(model.parameters()).device)\n",
    "            }\n",
    "            \n",
    "            # Save temporary file first\n",
    "            temp_path = path.parent / f\"{path.name}.tmp\"\n",
    "            torch.save(checkpoint, temp_path)\n",
    "            \n",
    "            # Atomic rename to final path\n",
    "            temp_path.replace(path)\n",
    "            \n",
    "            logging.info(f\"Model saved successfully to {path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving model: {str(e)}\")\n",
    "            if temp_path.exists():\n",
    "                temp_path.unlink()\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a246ccc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T22:03:31.945592Z",
     "iopub.status.busy": "2025-02-10T22:03:31.945333Z",
     "iopub.status.idle": "2025-02-10T22:03:31.957471Z",
     "shell.execute_reply": "2025-02-10T22:03:31.956855Z"
    },
    "papermill": {
     "duration": 0.018128,
     "end_time": "2025-02-10T22:03:31.958781",
     "exception": false,
     "start_time": "2025-02-10T22:03:31.940653",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HyperparameterOptimizer:\n",
    "    @staticmethod\n",
    "    def objective(trial: Trial, df: pd.DataFrame, mlb: MultiLabelBinarizer) -> float:\n",
    "        try:\n",
    "            params = HyperparameterOptimizer._get_trial_parameters(trial)\n",
    "            logging.info(f\"\\nTrial {trial.number} Parameters:\")\n",
    "            for name, value in params.items():\n",
    "                logging.info(f\"{name}: {value}\")\n",
    "\n",
    "            X_train, X_test, y_train, y_test = DataProcessor.prepare_data(df, mlb)\n",
    "\n",
    "            with ModelManager(*ModelSetup.setup_model_and_tokenizer(len(mlb.classes_))) as (model, tokenizer):\n",
    "                train_loader, val_loader = ModelSetup.setup_dataloaders(\n",
    "                    X_train, X_test, y_train, y_test,\n",
    "                    tokenizer, params['batch_size']\n",
    "                )\n",
    "\n",
    "                optimizer = torch.optim.AdamW(\n",
    "                    model.parameters(),\n",
    "                    lr=params['learning_rate'],\n",
    "                    weight_decay=params['weight_decay']\n",
    "                )\n",
    "\n",
    "                # Training loop untuk optimization\n",
    "                best_f1 = 0.0\n",
    "                for epoch in range(3):  # Reduced epochs for optimization\n",
    "                    model.train()\n",
    "                    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/3\"):\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        if np.random.random() < params['mixup_prob']:\n",
    "                            batch = DataAugmentation.apply_mixup(batch)\n",
    "\n",
    "                        input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                        attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                        labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                        loss = LossFunctions.label_smoothing_loss(\n",
    "                            outputs.logits, labels, params['smoothing']\n",
    "                        )\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # Evaluation\n",
    "                    metrics = ModelEvaluator.evaluate_model(model, val_loader, mlb)\n",
    "                    current_f1 = metrics['macro_f1']\n",
    "                    best_f1 = max(best_f1, current_f1)\n",
    "\n",
    "                    trial.report(current_f1, epoch)\n",
    "                    if trial.should_prune():\n",
    "                        raise optuna.TrialPruned()\n",
    "\n",
    "                return best_f1\n",
    "\n",
    "        except optuna.TrialPruned:\n",
    "            raise\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in trial: {str(e)}\")\n",
    "            return float('-inf')\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_trial_parameters(trial: Trial) -> Dict:\n",
    "        params = {}\n",
    "        try:\n",
    "            for name, values in Config.OPTIM_PARAMS.items():\n",
    "                params[name] = trial.suggest_categorical(name, values)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error getting trial parameters: {str(e)}\")\n",
    "            raise\n",
    "        return params\n",
    "\n",
    "    @staticmethod\n",
    "    def optimize(df: pd.DataFrame, mlb: MultiLabelBinarizer, n_trials: int = 20) -> Dict:\n",
    "        study = optuna.create_study(\n",
    "            direction=\"maximize\",\n",
    "            sampler=optuna.samplers.TPESampler(seed=42),\n",
    "            pruner=optuna.pruners.MedianPruner()\n",
    "        )\n",
    "\n",
    "        study.optimize(\n",
    "            lambda trial: HyperparameterOptimizer.objective(trial, df, mlb),\n",
    "            n_trials=n_trials\n",
    "        )\n",
    "\n",
    "        logging.info(\"\\nOptimization Results:\")\n",
    "        logging.info(f\"Best trial:\")\n",
    "        logging.info(f\"  Value: {study.best_trial.value:.4f}\")\n",
    "        logging.info(\"  Params:\")\n",
    "        for key, value in study.best_trial.params.items():\n",
    "            logging.info(f\"    {key}: {value}\")\n",
    "\n",
    "        results_file = Config.METRICS_DIR / 'optuna_results.json'\n",
    "        with open(results_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump({\n",
    "                'best_trial': {\n",
    "                    'number': study.best_trial.number,\n",
    "                    'value': study.best_trial.value,\n",
    "                    'params': study.best_trial.params\n",
    "                },\n",
    "                'all_trials': [{\n",
    "                    'number': trial.number,\n",
    "                    'value': trial.value,\n",
    "                    'params': trial.params\n",
    "                } for trial in study.trials if trial.value is not None]\n",
    "            }, f, indent=4)\n",
    "\n",
    "        return study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa943e3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T22:03:31.967952Z",
     "iopub.status.busy": "2025-02-10T22:03:31.967687Z",
     "iopub.status.idle": "2025-02-11T00:21:54.837996Z",
     "shell.execute_reply": "2025-02-11T00:21:54.836933Z"
    },
    "papermill": {
     "duration": 8302.876855,
     "end_time": "2025-02-11T00:21:54.839785",
     "exception": false,
     "start_time": "2025-02-10T22:03:31.962930",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU tersedia: Tesla T4\n",
      "GPU Memory: 15.83 GB\n",
      "2025-02-10 22:03:31,980 - INFO - Starting movie genre classification\n",
      "2025-02-10 22:03:31,981 - INFO - Using device: cuda\n",
      "2025-02-10 22:03:31,982 - INFO - Loading and preprocessing data...\n",
      "2025-02-10 22:03:31,984 - INFO - Memory usage after start: 635.15 MB\n",
      "2025-02-10 22:03:32,048 - INFO - Successfully loaded data using utf-8 encoding\n",
      "2025-02-10 22:03:32,049 - INFO - Memory usage after data loading: 637.70 MB\n",
      "2025-02-10 22:03:32,050 - INFO - Using full dataset with 1738 samples\n",
      "2025-02-10 22:03:32,051 - INFO - \n",
      "Sample data:\n",
      "2025-02-10 22:03:32,052 - INFO - \n",
      "Sample 1:\n",
      "2025-02-10 22:03:32,057 - INFO - Synopsis: Setelah kematian yang tampak, Siena mampu melihat tanda-tanda bahwa orang-orang akan meninggal. Namu...\n",
      "2025-02-10 22:03:32,057 - INFO - Genre: Horor\n",
      "2025-02-10 22:03:32,058 - INFO - \n",
      "Sample 2:\n",
      "2025-02-10 22:03:32,060 - INFO - Synopsis: Alfi (Al Ghazali) bertemu dengan Alana (Caitlin Halderman), seorang siswa baru di sekolahnya. Ternya...\n",
      "2025-02-10 22:03:32,061 - INFO - Genre: Drama\n",
      "2025-02-10 22:03:32,062 - INFO - \n",
      "Sample 3:\n",
      "2025-02-10 22:03:32,062 - INFO - Synopsis: Ketika gaji staf di sekolahnya dicuri, seorang guru baru yang enggan berusaha untuk mendapatkan kemb...\n",
      "2025-02-10 22:03:32,063 - INFO - Genre: Komedi\n",
      "2025-02-10 22:03:32,064 - INFO - \n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1738/1738 [00:00<00:00, 14018.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:03:32,205 - INFO - Calculating dataset statistics...\n",
      "2025-02-10 22:03:32,208 - INFO - Analyzing genre combinations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e09ad81aec44bcabf3bc08101cda6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa667254108b48e6b86497c6af3570eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc84b088a4ac4c7483d6340c833cc080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd8fd1c34274f6c9c5f684fa94f2b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:03:32,975 - INFO - Calculating text statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing texts: 100%|██████████| 1738/1738 [00:00<00:00, 2841.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:03:33,596 - INFO - \n",
      "Dataset Statistics:\n",
      "2025-02-10 22:03:33,597 - INFO - Total samples: 1738\n",
      "2025-02-10 22:03:33,598 - INFO - Unique genres: 5\n",
      "2025-02-10 22:03:33,600 - INFO - Memory usage after preprocessing: 649.95 MB\n",
      "2025-02-10 22:03:33,601 - INFO - \n",
      "Starting hyperparameter optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-02-10 22:03:33,603] A new study created in memory with name: no-name-d8832ea2-9a13-4b18-8461-49fea63a2406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:03:33,605 - INFO - \n",
      "Trial 0 Parameters:\n",
      "2025-02-10 22:03:33,606 - INFO - batch_size: 16\n",
      "2025-02-10 22:03:33,606 - INFO - learning_rate: 1e-05\n",
      "2025-02-10 22:03:33,607 - INFO - weight_decay: 0.02\n",
      "2025-02-10 22:03:33,608 - INFO - mixup_prob: 0.3\n",
      "2025-02-10 22:03:33,608 - INFO - smoothing: 0.15\n",
      "2025-02-10 22:03:33,617 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d09d3351447a4735ba2e3f7acce6d805",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:03:52,145 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 22:03:52,147 - INFO - Setting up data loaders...\n",
      "2025-02-10 22:03:52,148 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 22:03:52,151 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 22:03:52,153 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 22:03:52,154 - INFO - Training batches: 93\n",
      "2025-02-10 22:03:52,155 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:01<00:00,  1.31s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:06:03,814 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 93/93 [02:07<00:00,  1.37s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:08:21,053 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 93/93 [02:10<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:10:41,434 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 22:10:41,893] Trial 0 finished with value: 0.46768909798416186 and parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 0 with value: 0.46768909798416186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:10:41,895 - INFO - \n",
      "Trial 1 Parameters:\n",
      "2025-02-10 22:10:41,896 - INFO - batch_size: 8\n",
      "2025-02-10 22:10:41,897 - INFO - learning_rate: 3e-05\n",
      "2025-02-10 22:10:41,897 - INFO - weight_decay: 0.01\n",
      "2025-02-10 22:10:41,898 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 22:10:41,899 - INFO - smoothing: 0.15\n",
      "2025-02-10 22:10:41,905 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:10:42,906 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 22:10:42,907 - INFO - Setting up data loaders...\n",
      "2025-02-10 22:10:42,908 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 22:10:42,911 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 22:10:42,912 - INFO - Created data loaders with batch size 8\n",
      "2025-02-10 22:10:42,913 - INFO - Training batches: 185\n",
      "2025-02-10 22:10:42,913 - INFO - Validation batches: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 185/185 [02:14<00:00,  1.38it/s]\n",
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:13:06,679 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 185/185 [02:14<00:00,  1.37it/s]\n",
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:15:30,639 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 185/185 [02:14<00:00,  1.38it/s]\n",
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:17:54,619 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 22:17:55,104] Trial 1 finished with value: 0.49078045350690325 and parameters: {'batch_size': 8, 'learning_rate': 3e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}. Best is trial 1 with value: 0.49078045350690325.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:17:55,106 - INFO - \n",
      "Trial 2 Parameters:\n",
      "2025-02-10 22:17:55,107 - INFO - batch_size: 16\n",
      "2025-02-10 22:17:55,108 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 22:17:55,109 - INFO - weight_decay: 0.01\n",
      "2025-02-10 22:17:55,110 - INFO - mixup_prob: 0.3\n",
      "2025-02-10 22:17:55,111 - INFO - smoothing: 0.1\n",
      "2025-02-10 22:17:55,120 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:17:55,991 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 22:17:55,992 - INFO - Setting up data loaders...\n",
      "2025-02-10 22:17:55,993 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 22:17:55,996 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 22:17:55,997 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 22:17:55,998 - INFO - Training batches: 93\n",
      "2025-02-10 22:17:55,999 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:10<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:20:16,018 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:22:36,247 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 93/93 [02:10<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:24:56,343 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 22:24:56,899] Trial 2 finished with value: 0.4930665075070929 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}. Best is trial 2 with value: 0.4930665075070929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:24:56,902 - INFO - \n",
      "Trial 3 Parameters:\n",
      "2025-02-10 22:24:56,903 - INFO - batch_size: 32\n",
      "2025-02-10 22:24:56,904 - INFO - learning_rate: 3e-05\n",
      "2025-02-10 22:24:56,905 - INFO - weight_decay: 0.02\n",
      "2025-02-10 22:24:56,906 - INFO - mixup_prob: 0.3\n",
      "2025-02-10 22:24:56,906 - INFO - smoothing: 0.15\n",
      "2025-02-10 22:24:56,916 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:24:57,790 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 22:24:57,790 - INFO - Setting up data loaders...\n",
      "2025-02-10 22:24:57,791 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 22:24:57,793 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 22:24:57,794 - INFO - Created data loaders with batch size 32\n",
      "2025-02-10 22:24:57,795 - INFO - Training batches: 47\n",
      "2025-02-10 22:24:57,795 - INFO - Validation batches: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 47/47 [02:09<00:00,  2.74s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:27:16,394 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 47/47 [02:09<00:00,  2.75s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:29:35,061 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 47/47 [02:09<00:00,  2.75s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:31:53,786 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 22:31:54,421] Trial 3 finished with value: 0.45861383892833524 and parameters: {'batch_size': 32, 'learning_rate': 3e-05, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 2 with value: 0.4930665075070929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:31:54,423 - INFO - \n",
      "Trial 4 Parameters:\n",
      "2025-02-10 22:31:54,424 - INFO - batch_size: 32\n",
      "2025-02-10 22:31:54,425 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 22:31:54,427 - INFO - weight_decay: 0.02\n",
      "2025-02-10 22:31:54,427 - INFO - mixup_prob: 0.3\n",
      "2025-02-10 22:31:54,428 - INFO - smoothing: 0.15\n",
      "2025-02-10 22:31:54,433 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:31:55,348 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 22:31:55,350 - INFO - Setting up data loaders...\n",
      "2025-02-10 22:31:55,351 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 22:31:55,353 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 22:31:55,353 - INFO - Created data loaders with batch size 32\n",
      "2025-02-10 22:31:55,354 - INFO - Training batches: 47\n",
      "2025-02-10 22:31:55,355 - INFO - Validation batches: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 47/47 [02:08<00:00,  2.74s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:34:13,949 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 47/47 [02:09<00:00,  2.75s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:36:32,564 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 47/47 [02:09<00:00,  2.75s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:38:51,445 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 22:38:52,109] Trial 4 finished with value: 0.5059288514665811 and parameters: {'batch_size': 32, 'learning_rate': 2e-05, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 4 with value: 0.5059288514665811.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:38:52,111 - INFO - \n",
      "Trial 5 Parameters:\n",
      "2025-02-10 22:38:52,112 - INFO - batch_size: 32\n",
      "2025-02-10 22:38:52,113 - INFO - learning_rate: 3e-05\n",
      "2025-02-10 22:38:52,114 - INFO - weight_decay: 0.02\n",
      "2025-02-10 22:38:52,114 - INFO - mixup_prob: 0.3\n",
      "2025-02-10 22:38:52,115 - INFO - smoothing: 0.1\n",
      "2025-02-10 22:38:52,121 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:38:53,021 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 22:38:53,022 - INFO - Setting up data loaders...\n",
      "2025-02-10 22:38:53,023 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 22:38:53,024 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 22:38:53,026 - INFO - Created data loaders with batch size 32\n",
      "2025-02-10 22:38:53,026 - INFO - Training batches: 47\n",
      "2025-02-10 22:38:53,028 - INFO - Validation batches: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 47/47 [02:09<00:00,  2.75s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:41:11,763 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 22:41:12,425] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:41:12,428 - INFO - \n",
      "Trial 6 Parameters:\n",
      "2025-02-10 22:41:12,428 - INFO - batch_size: 16\n",
      "2025-02-10 22:41:12,429 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 22:41:12,430 - INFO - weight_decay: 0.01\n",
      "2025-02-10 22:41:12,431 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 22:41:12,431 - INFO - smoothing: 0.1\n",
      "2025-02-10 22:41:12,437 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:41:13,667 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 22:41:13,668 - INFO - Setting up data loaders...\n",
      "2025-02-10 22:41:13,669 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 22:41:13,671 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 22:41:13,673 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 22:41:13,673 - INFO - Training batches: 93\n",
      "2025-02-10 22:41:13,674 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:43:34,165 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:45:54,660 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 93/93 [02:10<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:48:14,966 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 22:48:15,663] Trial 6 finished with value: 0.5081454955309341 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 6 with value: 0.5081454955309341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:48:15,666 - INFO - \n",
      "Trial 7 Parameters:\n",
      "2025-02-10 22:48:15,666 - INFO - batch_size: 32\n",
      "2025-02-10 22:48:15,667 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 22:48:15,668 - INFO - weight_decay: 0.02\n",
      "2025-02-10 22:48:15,668 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 22:48:15,669 - INFO - smoothing: 0.1\n",
      "2025-02-10 22:48:15,674 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:48:16,575 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 22:48:16,576 - INFO - Setting up data loaders...\n",
      "2025-02-10 22:48:16,577 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 22:48:16,579 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 22:48:16,581 - INFO - Created data loaders with batch size 32\n",
      "2025-02-10 22:48:16,581 - INFO - Training batches: 47\n",
      "2025-02-10 22:48:16,582 - INFO - Validation batches: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 47/47 [02:09<00:00,  2.75s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:50:35,222 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 22:50:35,912] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:50:35,915 - INFO - \n",
      "Trial 8 Parameters:\n",
      "2025-02-10 22:50:35,916 - INFO - batch_size: 8\n",
      "2025-02-10 22:50:35,916 - INFO - learning_rate: 3e-05\n",
      "2025-02-10 22:50:35,917 - INFO - weight_decay: 0.02\n",
      "2025-02-10 22:50:35,919 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 22:50:35,920 - INFO - smoothing: 0.15\n",
      "2025-02-10 22:50:35,925 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:50:36,840 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 22:50:36,841 - INFO - Setting up data loaders...\n",
      "2025-02-10 22:50:36,842 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 22:50:36,844 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 22:50:36,845 - INFO - Created data loaders with batch size 8\n",
      "2025-02-10 22:50:36,846 - INFO - Training batches: 185\n",
      "2025-02-10 22:50:36,847 - INFO - Validation batches: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 185/185 [02:14<00:00,  1.37it/s]\n",
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:53:00,838 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 185/185 [02:14<00:00,  1.37it/s]\n",
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:55:24,898 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 185/185 [02:14<00:00,  1.37it/s]\n",
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:57:48,812 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 22:57:49,453] Trial 8 finished with value: 0.5039305386522426 and parameters: {'batch_size': 8, 'learning_rate': 3e-05, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.15}. Best is trial 6 with value: 0.5081454955309341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:57:49,455 - INFO - \n",
      "Trial 9 Parameters:\n",
      "2025-02-10 22:57:49,457 - INFO - batch_size: 32\n",
      "2025-02-10 22:57:49,458 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 22:57:49,459 - INFO - weight_decay: 0.02\n",
      "2025-02-10 22:57:49,459 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 22:57:49,460 - INFO - smoothing: 0.1\n",
      "2025-02-10 22:57:49,465 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 22:57:50,375 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 22:57:50,376 - INFO - Setting up data loaders...\n",
      "2025-02-10 22:57:50,377 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 22:57:50,379 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 22:57:50,380 - INFO - Created data loaders with batch size 32\n",
      "2025-02-10 22:57:50,381 - INFO - Training batches: 47\n",
      "2025-02-10 22:57:50,382 - INFO - Validation batches: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 47/47 [02:09<00:00,  2.75s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:00:09,060 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 47/47 [02:09<00:00,  2.75s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:02:27,617 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 47/47 [02:09<00:00,  2.75s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:04:46,156 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:04:47,014] Trial 9 finished with value: 0.5077956186041643 and parameters: {'batch_size': 32, 'learning_rate': 2e-05, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 6 with value: 0.5081454955309341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:04:47,028 - INFO - \n",
      "Trial 10 Parameters:\n",
      "2025-02-10 23:04:47,029 - INFO - batch_size: 16\n",
      "2025-02-10 23:04:47,029 - INFO - learning_rate: 1e-05\n",
      "2025-02-10 23:04:47,031 - INFO - weight_decay: 0.01\n",
      "2025-02-10 23:04:47,031 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 23:04:47,033 - INFO - smoothing: 0.1\n",
      "2025-02-10 23:04:47,037 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:04:47,954 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:04:47,955 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:04:47,956 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:04:47,958 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:04:47,959 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 23:04:47,960 - INFO - Training batches: 93\n",
      "2025-02-10 23:04:47,961 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:07:08,090 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:09:28,280 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:11:48,612 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:11:49,326] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:11:49,332 - INFO - \n",
      "Trial 11 Parameters:\n",
      "2025-02-10 23:11:49,332 - INFO - batch_size: 16\n",
      "2025-02-10 23:11:49,333 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 23:11:49,333 - INFO - weight_decay: 0.01\n",
      "2025-02-10 23:11:49,334 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 23:11:49,335 - INFO - smoothing: 0.1\n",
      "2025-02-10 23:11:49,340 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:11:50,221 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:11:50,222 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:11:50,223 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:11:50,225 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:11:50,226 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 23:11:50,226 - INFO - Training batches: 93\n",
      "2025-02-10 23:11:50,227 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:10<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:14:10,357 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:16:30,589 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 93/93 [02:10<00:00,  1.40s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:18:50,800 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:18:51,649] Trial 11 finished with value: 0.5063139944895106 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 6 with value: 0.5081454955309341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:18:51,656 - INFO - \n",
      "Trial 12 Parameters:\n",
      "2025-02-10 23:18:51,657 - INFO - batch_size: 32\n",
      "2025-02-10 23:18:51,658 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 23:18:51,659 - INFO - weight_decay: 0.01\n",
      "2025-02-10 23:18:51,660 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 23:18:51,661 - INFO - smoothing: 0.1\n",
      "2025-02-10 23:18:51,667 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:18:52,567 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:18:52,568 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:18:52,569 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:18:52,571 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:18:52,572 - INFO - Created data loaders with batch size 32\n",
      "2025-02-10 23:18:52,573 - INFO - Training batches: 47\n",
      "2025-02-10 23:18:52,574 - INFO - Validation batches: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 47/47 [02:09<00:00,  2.75s/it]\n",
      "Evaluating: 100%|██████████| 9/9 [00:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:21:11,500 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:21:12,321] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:21:12,327 - INFO - \n",
      "Trial 13 Parameters:\n",
      "2025-02-10 23:21:12,328 - INFO - batch_size: 16\n",
      "2025-02-10 23:21:12,328 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 23:21:12,329 - INFO - weight_decay: 0.01\n",
      "2025-02-10 23:21:12,329 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 23:21:12,330 - INFO - smoothing: 0.1\n",
      "2025-02-10 23:21:12,336 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:21:13,193 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:21:13,194 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:21:13,195 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:21:13,198 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:21:13,199 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 23:21:13,199 - INFO - Training batches: 93\n",
      "2025-02-10 23:21:13,201 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:23:33,932 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:25:54,644 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:28:15,449 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:28:16,370] Trial 13 finished with value: 0.515370293250627 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 13 with value: 0.515370293250627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:28:16,378 - INFO - \n",
      "Trial 14 Parameters:\n",
      "2025-02-10 23:28:16,378 - INFO - batch_size: 16\n",
      "2025-02-10 23:28:16,379 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 23:28:16,381 - INFO - weight_decay: 0.01\n",
      "2025-02-10 23:28:16,382 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 23:28:16,384 - INFO - smoothing: 0.1\n",
      "2025-02-10 23:28:16,388 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:28:17,343 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:28:17,344 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:28:17,345 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:28:17,347 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:28:17,348 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 23:28:17,348 - INFO - Training batches: 93\n",
      "2025-02-10 23:28:17,349 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:11<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:30:38,322 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:32:59,016 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:35:19,772 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:35:20,679] Trial 14 finished with value: 0.5070196760216448 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 13 with value: 0.515370293250627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:35:20,687 - INFO - \n",
      "Trial 15 Parameters:\n",
      "2025-02-10 23:35:20,688 - INFO - batch_size: 16\n",
      "2025-02-10 23:35:20,689 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 23:35:20,690 - INFO - weight_decay: 0.01\n",
      "2025-02-10 23:35:20,690 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 23:35:20,691 - INFO - smoothing: 0.1\n",
      "2025-02-10 23:35:20,697 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:35:21,664 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:35:21,665 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:35:21,666 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:35:21,669 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:35:21,670 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 23:35:21,671 - INFO - Training batches: 93\n",
      "2025-02-10 23:35:21,671 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:37:42,409 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:40:03,052 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 93/93 [02:11<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:42:24,163 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:42:25,055] Trial 15 finished with value: 0.4946466454699829 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 13 with value: 0.515370293250627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:42:25,063 - INFO - \n",
      "Trial 16 Parameters:\n",
      "2025-02-10 23:42:25,064 - INFO - batch_size: 16\n",
      "2025-02-10 23:42:25,064 - INFO - learning_rate: 1e-05\n",
      "2025-02-10 23:42:25,065 - INFO - weight_decay: 0.01\n",
      "2025-02-10 23:42:25,066 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 23:42:25,067 - INFO - smoothing: 0.1\n",
      "2025-02-10 23:42:25,072 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:42:26,292 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:42:26,293 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:42:26,294 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:42:26,296 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:42:26,297 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 23:42:26,298 - INFO - Training batches: 93\n",
      "2025-02-10 23:42:26,299 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:44:46,590 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:44:47,456] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:44:47,461 - INFO - \n",
      "Trial 17 Parameters:\n",
      "2025-02-10 23:44:47,462 - INFO - batch_size: 16\n",
      "2025-02-10 23:44:47,463 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 23:44:47,463 - INFO - weight_decay: 0.01\n",
      "2025-02-10 23:44:47,464 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 23:44:47,465 - INFO - smoothing: 0.1\n",
      "2025-02-10 23:44:47,470 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:44:48,383 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:44:48,384 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:44:48,385 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:44:48,387 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:44:48,388 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 23:44:48,389 - INFO - Training batches: 93\n",
      "2025-02-10 23:44:48,389 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:47:08,558 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:49:28,777 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/3: 100%|██████████| 93/93 [02:10<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:51:49,033 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:51:50,092] Trial 17 finished with value: 0.5064335798437446 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 13 with value: 0.515370293250627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:51:50,099 - INFO - \n",
      "Trial 18 Parameters:\n",
      "2025-02-10 23:51:50,100 - INFO - batch_size: 8\n",
      "2025-02-10 23:51:50,100 - INFO - learning_rate: 2e-05\n",
      "2025-02-10 23:51:50,101 - INFO - weight_decay: 0.01\n",
      "2025-02-10 23:51:50,103 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 23:51:50,104 - INFO - smoothing: 0.1\n",
      "2025-02-10 23:51:50,108 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:51:51,077 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:51:51,078 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:51:51,079 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:51:51,081 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:51:51,082 - INFO - Created data loaders with batch size 8\n",
      "2025-02-10 23:51:51,083 - INFO - Training batches: 185\n",
      "2025-02-10 23:51:51,084 - INFO - Validation batches: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 185/185 [02:14<00:00,  1.38it/s]\n",
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:54:14,883 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/3: 100%|██████████| 185/185 [02:14<00:00,  1.37it/s]\n",
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:56:38,766 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:56:39,630] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:56:39,637 - INFO - \n",
      "Trial 19 Parameters:\n",
      "2025-02-10 23:56:39,638 - INFO - batch_size: 16\n",
      "2025-02-10 23:56:39,639 - INFO - learning_rate: 1e-05\n",
      "2025-02-10 23:56:39,640 - INFO - weight_decay: 0.01\n",
      "2025-02-10 23:56:39,641 - INFO - mixup_prob: 0.2\n",
      "2025-02-10 23:56:39,642 - INFO - smoothing: 0.1\n",
      "2025-02-10 23:56:39,647 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:56:40,592 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:56:40,593 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:56:40,594 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:56:40,596 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:56:40,597 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 23:56:40,598 - INFO - Training batches: 93\n",
      "2025-02-10 23:56:40,599 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/3: 100%|██████████| 93/93 [02:11<00:00,  1.41s/it]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:59:01,072 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:59:02,013] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:59:02,014 - INFO - \n",
      "Optimization Results:\n",
      "2025-02-10 23:59:02,015 - INFO - Best trial:\n",
      "2025-02-10 23:59:02,016 - INFO -   Value: 0.5154\n",
      "2025-02-10 23:59:02,017 - INFO -   Params:\n",
      "2025-02-10 23:59:02,019 - INFO -     batch_size: 16\n",
      "2025-02-10 23:59:02,019 - INFO -     learning_rate: 2e-05\n",
      "2025-02-10 23:59:02,020 - INFO -     weight_decay: 0.01\n",
      "2025-02-10 23:59:02,021 - INFO -     mixup_prob: 0.2\n",
      "2025-02-10 23:59:02,021 - INFO -     smoothing: 0.1\n",
      "2025-02-10 23:59:02,029 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-10 23:59:02,916 - INFO - Model and tokenizer setup completed\n",
      "2025-02-10 23:59:02,917 - INFO - Setting up data loaders...\n",
      "2025-02-10 23:59:02,918 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-10 23:59:02,920 - INFO - Created sampler with 1477 weights\n",
      "2025-02-10 23:59:02,921 - INFO - Created data loaders with batch size 16\n",
      "2025-02-10 23:59:02,922 - INFO - Training batches: 93\n",
      "2025-02-10 23:59:02,923 - INFO - Validation batches: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1: 100%|██████████| 93/93 [02:19<00:00,  1.50s/it, loss=1.3835, avg_loss=1.5325, lr=1.90e-05]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-11 00:01:31,882 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n",
      "2025-02-11 00:01:32,546 - INFO - Model saved successfully to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/model/best_accuracy\n",
      "2025-02-11 00:01:33,219 - INFO - Model saved successfully to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/model/best_loss\n",
      "2025-02-11 00:01:33,220 - INFO - Epoch 1/20 - Time: 150.29s - Train Loss: 1.5325, Val Loss: 0.0518, Val F1: 0.4668, Val Precision: 0.3382, Val Recall: 0.8325\n",
      "2025-02-11 00:01:34,526 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/training_history.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2: 100%|██████████| 93/93 [02:19<00:00,  1.50s/it, loss=0.7769, avg_loss=1.3438, lr=1.80e-05]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-11 00:04:04,366 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n",
      "2025-02-11 00:04:05,581 - INFO - Model saved successfully to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/model/best_accuracy\n",
      "2025-02-11 00:04:05,583 - INFO - Epoch 2/20 - Time: 150.10s - Train Loss: 1.3438, Val Loss: 0.0525, Val F1: 0.4788, Val Precision: 0.3538, Val Recall: 0.7805\n",
      "2025-02-11 00:04:06,979 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/training_history.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3: 100%|██████████| 93/93 [02:19<00:00,  1.51s/it, loss=0.7898, avg_loss=1.1738, lr=1.70e-05]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-11 00:06:37,100 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n",
      "2025-02-11 00:06:38,121 - INFO - Model saved successfully to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/model/best_accuracy\n",
      "2025-02-11 00:06:38,124 - INFO - Epoch 3/20 - Time: 150.16s - Train Loss: 1.1738, Val Loss: 0.0565, Val F1: 0.4930, Val Precision: 0.3606, Val Recall: 0.7932\n",
      "2025-02-11 00:06:39,580 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/training_history.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4: 100%|██████████| 93/93 [02:20<00:00,  1.51s/it, loss=0.6067, avg_loss=1.0497, lr=1.60e-05]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-11 00:09:09,787 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n",
      "2025-02-11 00:09:10,880 - INFO - Model saved successfully to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/model/best_accuracy\n",
      "2025-02-11 00:09:10,881 - INFO - Epoch 4/20 - Time: 150.29s - Train Loss: 1.0497, Val Loss: 0.0657, Val F1: 0.5257, Val Precision: 0.3991, Val Recall: 0.8363\n",
      "2025-02-11 00:09:12,322 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/training_history.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5: 100%|██████████| 93/93 [02:20<00:00,  1.51s/it, loss=0.9857, avg_loss=0.9882, lr=1.50e-05]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-11 00:11:42,614 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n",
      "2025-02-11 00:11:42,616 - INFO - Epoch 5/20 - Time: 149.28s - Train Loss: 0.9882, Val Loss: 0.0624, Val F1: 0.5051, Val Precision: 0.3871, Val Recall: 0.7478\n",
      "2025-02-11 00:11:44,164 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/training_history.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6: 100%|██████████| 93/93 [02:20<00:00,  1.51s/it, loss=1.8860, avg_loss=0.9523, lr=1.40e-05]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-11 00:14:14,688 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n",
      "2025-02-11 00:14:14,689 - INFO - Epoch 6/20 - Time: 149.50s - Train Loss: 0.9523, Val Loss: 0.0692, Val F1: 0.4775, Val Precision: 0.3819, Val Recall: 0.7078\n",
      "2025-02-11 00:14:16,176 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/training_history.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7: 100%|██████████| 93/93 [02:20<00:00,  1.51s/it, loss=0.4812, avg_loss=0.8976, lr=1.30e-05]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-11 00:16:47,185 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n",
      "2025-02-11 00:16:47,186 - INFO - Epoch 7/20 - Time: 149.98s - Train Loss: 0.8976, Val Loss: 0.0705, Val F1: 0.5053, Val Precision: 0.4084, Val Recall: 0.7064\n",
      "2025-02-11 00:16:48,742 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/training_history.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8: 100%|██████████| 93/93 [02:20<00:00,  1.51s/it, loss=1.2877, avg_loss=0.9759, lr=1.20e-05]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-11 00:19:19,807 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n",
      "2025-02-11 00:19:19,809 - INFO - Epoch 8/20 - Time: 149.98s - Train Loss: 0.9759, Val Loss: 0.0714, Val F1: 0.5207, Val Precision: 0.4215, Val Recall: 0.7136\n",
      "2025-02-11 00:19:21,361 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/training_history.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9: 100%|██████████| 93/93 [02:21<00:00,  1.52s/it, loss=0.4953, avg_loss=0.8092, lr=1.10e-05]\n",
      "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-11 00:21:52,781 - INFO - Training history plots saved to /kaggle/working/genrematics-optuna-app/logs/experiments/20250210_220331/plots/confusion_matrices/confusion_matrix_Romantis.png\n",
      "2025-02-11 00:21:52,783 - INFO - Early stopping triggered after 9 epochs\n",
      "2025-02-11 00:21:52,784 - INFO - Training completed in 0:22:49.858228\n",
      "2025-02-11 00:21:53,935 - INFO - \n",
      "Training completed successfully!\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.sample_size = None\n",
    "        self.epochs = Config.MODEL_PARAMS['EPOCHS']\n",
    "        self.batch_size = Config.MODEL_PARAMS['BATCH_SIZE']\n",
    "        self.learning_rate = Config.MODEL_PARAMS['LEARNING_RATE']\n",
    "        self.max_length = Config.MODEL_PARAMS['MAX_LENGTH']\n",
    "        self.test_size = Config.MODEL_PARAMS['TEST_SIZE']\n",
    "        self.weight_decay = Config.MODEL_PARAMS['WEIGHT_DECAY']\n",
    "        self.mixup_prob = Config.MODEL_PARAMS['MIXUP_PROB']\n",
    "        self.patience = Config.MODEL_PARAMS['PATIENCE']\n",
    "        self.smoothing = Config.MODEL_PARAMS['SMOOTHING']\n",
    "        self.n_trials = 20\n",
    "        self.no_cuda = False\n",
    "        self.seed = 42\n",
    "\n",
    "def main():\n",
    "    args = Args()\n",
    "    \n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    try:\n",
    "        if not check_environment():\n",
    "            raise RuntimeError(\"Environment check failed!\")\n",
    "\n",
    "        logging.info(\"Starting movie genre classification\")\n",
    "        logging.info(f\"Using device: {Config.DEVICE}\")\n",
    "\n",
    "        df = DataProcessor.load_and_preprocess_data(Config.DATA_PATH, Config.SAMPLE_SIZE)\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        # Hyperparameter optimization\n",
    "        logging.info(\"\\nStarting hyperparameter optimization...\")\n",
    "        best_params = HyperparameterOptimizer.optimize(df, mlb, args.n_trials)\n",
    "\n",
    "        # Update config with best parameters\n",
    "        for param, value in best_params.items():\n",
    "            if param in Config.MODEL_PARAMS:\n",
    "                Config.MODEL_PARAMS[param] = value\n",
    "                logging.info(f\"Updated {param}: {value}\")\n",
    "\n",
    "        # Final training with best parameters\n",
    "        X_train, X_test, y_train, y_test = DataProcessor.prepare_data(df, mlb)\n",
    "        \n",
    "        with ModelManager(*ModelSetup.setup_model_and_tokenizer(len(mlb.classes_))) as (model, tokenizer):\n",
    "            train_loader, val_loader = ModelSetup.setup_dataloaders(\n",
    "                X_train, X_test, y_train, y_test,\n",
    "                tokenizer, Config.MODEL_PARAMS['BATCH_SIZE']\n",
    "            )\n",
    "\n",
    "            history, best_metrics = ModelTrainer.train(\n",
    "                model, train_loader, val_loader, mlb, Config.MODEL_PARAMS['EPOCHS']\n",
    "            )\n",
    "\n",
    "            # Save final results\n",
    "            results = {\n",
    "                'config': Config.MODEL_PARAMS,\n",
    "                'best_metrics': best_metrics,\n",
    "                'history': history,\n",
    "                'classes': mlb.classes_.tolist()\n",
    "            }\n",
    "\n",
    "            with open(Config.METRICS_DIR / 'final_results.json', 'w') as f:\n",
    "                json.dump(results, f, indent=4)\n",
    "\n",
    "        logging.info(\"\\nTraining completed successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Training failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6639588,
     "sourceId": 10712322,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 8329.031646,
   "end_time": "2025-02-11T00:21:58.146360",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-10T22:03:09.114714",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01e2f49025364564b5fc59bbf44328d5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_de0c2f66923248b48f88c4027cd6322a",
       "max": 497810400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a53b21674eb24f3abe3b1c0d167b0b9b",
       "tabbable": null,
       "tooltip": null,
       "value": 497810400.0
      }
     },
     "02dac06f32484bb09ec21091ab8a1114": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "03254129db2948d1b94f6fad43a92d04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "057fbca61140474ba902daa25f85bef9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a6a72db054b41758044bbce0d8e9ce5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_58d5a7f1bf67420cb2cb8915fad37103",
       "placeholder": "​",
       "style": "IPY_MODEL_d450f612132b47998514181d16728c91",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "0babb1b5ed74422296c5b96226839787": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "0bd21253e7ee408a9c671d0fed34d000": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0dd8fd1c34274f6c9c5f684fa94f2b60": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7655ef8b3c484cd39a4e70cd2de34d1e",
        "IPY_MODEL_f9839fe62303438c9dc882069e0bcca1",
        "IPY_MODEL_d36468ac017b48b39f775e04c260284f"
       ],
       "layout": "IPY_MODEL_ebaeb5bbcabb4b13b79b18b0e921b582",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0edf7c5b19004d9b90974a4d66b63680": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_af39cdc46c67453a8f0e37b5b29b8cca",
       "placeholder": "​",
       "style": "IPY_MODEL_0babb1b5ed74422296c5b96226839787",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 138kB/s]"
      }
     },
     "2294a6e564e04c769af27ef439830c1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "287a2d8f198546509f3e21e5b979e278": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f2f82bebbc744a5580de0a5f8fce87ca",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_e51dbbd2b9d449ce9d1953efcf64d323",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "2a6d63d095c846538d86104b5125915f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2aca7baab091425f82f72454451168c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "34b76f836fc6485aa30d2464ecdba4f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35b43a72fbec4b27a570d604933adc74": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_02dac06f32484bb09ec21091ab8a1114",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_03254129db2948d1b94f6fad43a92d04",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "3bbc1f8041a44175879c12437123b5b7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3c4f7ed89d794f15901fd3808552f4a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d46ecc3b96042a681e94b981b1e2d12": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48036fa38f004b0da8be0993edc9bf7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48baa075b1ad40cf8113ba40ae33ee02": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5246e9672d4840359831013a29c29451": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5793abdb79474e1189f8477d96f5ac4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3c4f7ed89d794f15901fd3808552f4a9",
       "placeholder": "​",
       "style": "IPY_MODEL_fcf519331ce347b588df8f5e8860474a",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "58d5a7f1bf67420cb2cb8915fad37103": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70e601de6e24410587c102b0a1945c18": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7655ef8b3c484cd39a4e70cd2de34d1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_34b76f836fc6485aa30d2464ecdba4f1",
       "placeholder": "​",
       "style": "IPY_MODEL_821060cb9fbd4b05b323f19a8e3f12f0",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "76f3ab93f35f4dbf80c97faaacbe47fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7d76e853b77048feafd09ec1225f2cac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ea788ad910a4639871049b674ee6b6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_0bd21253e7ee408a9c671d0fed34d000",
       "placeholder": "​",
       "style": "IPY_MODEL_d57e0e7fa74043a7a68524c205e7a1ed",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 5.04MB/s]"
      }
     },
     "821060cb9fbd4b05b323f19a8e3f12f0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "82794d44bac4416b9cd87ccfc58a49c0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "90bab57f260f4839a0609e9f06926836": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5246e9672d4840359831013a29c29451",
       "placeholder": "​",
       "style": "IPY_MODEL_82794d44bac4416b9cd87ccfc58a49c0",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "9cd0d646507f470aaf83e5e7d01f9de5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a2e09ad81aec44bcabf3bc08101cda6c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5793abdb79474e1189f8477d96f5ac4d",
        "IPY_MODEL_35b43a72fbec4b27a570d604933adc74",
        "IPY_MODEL_b9cabfea62644aa580c2004a8cb6ada0"
       ],
       "layout": "IPY_MODEL_3bbc1f8041a44175879c12437123b5b7",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a53b21674eb24f3abe3b1c0d167b0b9b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "aa02f4624c9f4e289ba17e6542ccb901": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "af39cdc46c67453a8f0e37b5b29b8cca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b8c8abdb9ed2410388437a913d370da4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3d46ecc3b96042a681e94b981b1e2d12",
       "placeholder": "​",
       "style": "IPY_MODEL_76f3ab93f35f4dbf80c97faaacbe47fd",
       "tabbable": null,
       "tooltip": null,
       "value": " 498M/498M [00:02&lt;00:00, 229MB/s]"
      }
     },
     "b9cabfea62644aa580c2004a8cb6ada0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d76e853b77048feafd09ec1225f2cac",
       "placeholder": "​",
       "style": "IPY_MODEL_2aca7baab091425f82f72454451168c5",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 194B/s]"
      }
     },
     "c53bb0aec58643b1b42ce8789a5b217e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_48036fa38f004b0da8be0993edc9bf7f",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_48baa075b1ad40cf8113ba40ae33ee02",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "c9a61e730952477799f0509aed32c495": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d09d3351447a4735ba2e3f7acce6d805": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_90bab57f260f4839a0609e9f06926836",
        "IPY_MODEL_01e2f49025364564b5fc59bbf44328d5",
        "IPY_MODEL_b8c8abdb9ed2410388437a913d370da4"
       ],
       "layout": "IPY_MODEL_d108e1f2230c455493011685d31c5a4e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d108e1f2230c455493011685d31c5a4e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d36468ac017b48b39f775e04c260284f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9cd0d646507f470aaf83e5e7d01f9de5",
       "placeholder": "​",
       "style": "IPY_MODEL_aa02f4624c9f4e289ba17e6542ccb901",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 9.94kB/s]"
      }
     },
     "d450f612132b47998514181d16728c91": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d57e0e7fa74043a7a68524c205e7a1ed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "db35d833d6be493f89a59a0069b9905d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c9a61e730952477799f0509aed32c495",
       "placeholder": "​",
       "style": "IPY_MODEL_2294a6e564e04c769af27ef439830c1e",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "dc84b088a4ac4c7483d6340c833cc080": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_db35d833d6be493f89a59a0069b9905d",
        "IPY_MODEL_287a2d8f198546509f3e21e5b979e278",
        "IPY_MODEL_7ea788ad910a4639871049b674ee6b6a"
       ],
       "layout": "IPY_MODEL_2a6d63d095c846538d86104b5125915f",
       "tabbable": null,
       "tooltip": null
      }
     },
     "de0c2f66923248b48f88c4027cd6322a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e51dbbd2b9d449ce9d1953efcf64d323": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ebaeb5bbcabb4b13b79b18b0e921b582": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "eec0ab466a8847bba182c92eca771050": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f2f82bebbc744a5580de0a5f8fce87ca": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9839fe62303438c9dc882069e0bcca1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_eec0ab466a8847bba182c92eca771050",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_70e601de6e24410587c102b0a1945c18",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "fa667254108b48e6b86497c6af3570eb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0a6a72db054b41758044bbce0d8e9ce5",
        "IPY_MODEL_c53bb0aec58643b1b42ce8789a5b217e",
        "IPY_MODEL_0edf7c5b19004d9b90974a4d66b63680"
       ],
       "layout": "IPY_MODEL_057fbca61140474ba902daa25f85bef9",
       "tabbable": null,
       "tooltip": null
      }
     },
     "fcf519331ce347b588df8f5e8860474a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
