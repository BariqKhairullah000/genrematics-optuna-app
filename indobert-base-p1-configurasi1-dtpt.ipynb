{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee0d7b9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-15T21:42:06.002721Z",
     "iopub.status.busy": "2025-02-15T21:42:06.002401Z",
     "iopub.status.idle": "2025-02-15T21:42:06.834997Z",
     "shell.execute_reply": "2025-02-15T21:42:06.834064Z"
    },
    "papermill": {
     "duration": 0.839203,
     "end_time": "2025-02-15T21:42:06.836533",
     "exception": false,
     "start_time": "2025-02-15T21:42:05.997330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datasets-classificationsynopsis/final_combined_movies_5genres.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23851a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T21:42:06.844743Z",
     "iopub.status.busy": "2025-02-15T21:42:06.844391Z",
     "iopub.status.idle": "2025-02-15T21:42:11.477443Z",
     "shell.execute_reply": "2025-02-15T21:42:11.476541Z"
    },
    "papermill": {
     "duration": 4.63874,
     "end_time": "2025-02-15T21:42:11.479151",
     "exception": false,
     "start_time": "2025-02-15T21:42:06.840411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.2.0)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.1)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2.4.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->optuna) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Movie Genre Classification with IndoBERT\n",
    "Environment: Kaggle\n",
    "\"\"\"\n",
    "\n",
    "!pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73fa8cba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T21:42:11.488126Z",
     "iopub.status.busy": "2025-02-15T21:42:11.487867Z",
     "iopub.status.idle": "2025-02-15T21:42:23.052111Z",
     "shell.execute_reply": "2025-02-15T21:42:23.051493Z"
    },
    "papermill": {
     "duration": 11.570016,
     "end_time": "2025-02-15T21:42:23.053227",
     "exception": false,
     "start_time": "2025-02-15T21:42:11.483211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files in dataset directory:\n",
      "- final_combined_movies_5genres.csv\n",
      "GPU tersedia: Tesla T4\n",
      "GPU Memory: 15.83 GB\n",
      "Created directory: /kaggle/working/logs\n",
      "Created directory: /kaggle/working/backups\n",
      "Created directory: /kaggle/working/logs/experiments/20250215_214222\n",
      "Created directory: /kaggle/working/logs/experiments/20250215_214222/model\n",
      "Created directory: /kaggle/working/logs/experiments/20250215_214222/tokenizer\n",
      "Created directory: /kaggle/working/logs/experiments/20250215_214222/metrics\n",
      "Created directory: /kaggle/working/logs/experiments/20250215_214222/plots\n",
      "Created directory: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 21:42:23,036 - INFO - Log file created at: /kaggle/working/logs/experiments/20250215_214222/training.log\n",
      "2025-02-15 21:42:23,036 - INFO - System Information:\n",
      "2025-02-15 21:42:23,037 - INFO - Python Version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "2025-02-15 21:42:23,044 - INFO - CPU Count: 4\n",
      "2025-02-15 21:42:23,046 - INFO - Initial Memory Usage: 634.80 MB\n",
      "2025-02-15 21:42:23,046 - INFO - GPU Device: Tesla T4\n",
      "2025-02-15 21:42:23,047 - INFO - GPU Memory Total: 15.83 GB\n",
      "2025-02-15 21:42:23,048 - INFO - CUDA Version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# BAGIAN PERTAMA - Import dan Konfigurasi\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "import argparse\n",
    "import gc\n",
    "import sys\n",
    "import codecs\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import psutil\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "\n",
    "# Define Base Path for Kaggle\n",
    "BASE_PATH = Path('/kaggle/working')\n",
    "DATASETS_PATH = Path('/kaggle/input/datasets-classificationsynopsis')\n",
    "\n",
    "# Configuration Constants\n",
    "class Config:\n",
    "    # Model Parameters\n",
    "    MODEL_PARAMS = {\n",
    "        'EPOCHS': 100,\n",
    "        'BATCH_SIZE': 10,\n",
    "        'LEARNING_RATE': 1e-5,\n",
    "        'MAX_LENGTH': 512,\n",
    "        'TEST_SIZE': 0.15,\n",
    "        'WEIGHT_DECAY': 0.05,\n",
    "        'MIXUP_PROB': 0.5,\n",
    "        'PATIENCE': 5,\n",
    "        'SMOOTHING': 0.2\n",
    "    }\n",
    "\n",
    "    # Optimization Parameters\n",
    "    OPTIM_PARAMS = {\n",
    "        'batch_size': [8, 16, 32],\n",
    "        'learning_rate': [1e-5, 2e-5, 3e-5],\n",
    "        'weight_decay': [0.01, 0.02],\n",
    "        'mixup_prob': [0.2, 0.3],\n",
    "        'smoothing': [0.1, 0.15]\n",
    "    }\n",
    "\n",
    "    # Paths Configuration untuk Kaggle\n",
    "    BASE_DIR = BASE_PATH\n",
    "    DATA_PATH = Path('/kaggle/input/datasets-classificationsynopsis/final_combined_movies_5genres.csv')\n",
    "    LOG_DIR = BASE_DIR / 'logs'\n",
    "    BACKUP_DIR = BASE_DIR / 'backups'\n",
    "    TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    EXPERIMENT_DIR = LOG_DIR / 'experiments' / TIMESTAMP\n",
    "\n",
    "    # Model and Data Paths\n",
    "    MODEL_SAVE_DIR = EXPERIMENT_DIR / 'model'\n",
    "    TOKENIZER_SAVE_DIR = EXPERIMENT_DIR / 'tokenizer'\n",
    "    METRICS_DIR = EXPERIMENT_DIR / 'metrics'\n",
    "    PLOTS_DIR = EXPERIMENT_DIR / 'plots'\n",
    "    CM_DIR = PLOTS_DIR / 'confusion_matrices'\n",
    "\n",
    "    # Model Files\n",
    "    MODEL_BEST_ACC = MODEL_SAVE_DIR / \"best_accuracy\"\n",
    "    MODEL_BEST_LOSS = MODEL_SAVE_DIR / \"best_loss\"\n",
    "    TOKENIZER_BEST_ACC = TOKENIZER_SAVE_DIR / \"best_accuracy\"\n",
    "    TOKENIZER_BEST_LOSS = TOKENIZER_SAVE_DIR / \"best_loss\"\n",
    "    DATA_PATH = Path('/kaggle/input/datasets-classificationsynopsis/final_combined_movies_5genres.csv')  # Path langsung ke file CSV\n",
    "\n",
    "    # Device Configuration\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    SAMPLE_SIZE: Optional[int] = None\n",
    "\n",
    "    @classmethod\n",
    "    def create_directories(cls) -> None:\n",
    "        \"\"\"Create all necessary directories in Kaggle working directory\"\"\"\n",
    "        directories = [\n",
    "            cls.LOG_DIR, cls.BACKUP_DIR,\n",
    "            cls.EXPERIMENT_DIR, cls.MODEL_SAVE_DIR, cls.TOKENIZER_SAVE_DIR,\n",
    "            cls.METRICS_DIR, cls.PLOTS_DIR, cls.CM_DIR\n",
    "        ]\n",
    "        for dir_path in directories:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "    @classmethod\n",
    "    def setup_logging(cls) -> None:\n",
    "        \"\"\"Setup logging configuration untuk Kaggle\"\"\"\n",
    "        log_file = cls.EXPERIMENT_DIR / 'training.log'\n",
    "        for handler in logging.root.handlers[:]:\n",
    "            logging.root.removeHandler(handler)\n",
    "\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file, encoding='utf-8', mode='a'),\n",
    "                logging.StreamHandler(sys.stdout)\n",
    "            ]\n",
    "        )\n",
    "        logging.info(f\"Log file created at: {log_file}\")\n",
    "\n",
    "# Environment Check Function\n",
    "def check_environment() -> bool:\n",
    "    \"\"\"Verify Kaggle environment and paths\"\"\"\n",
    "    try:\n",
    "        # Check if datasets directory exists\n",
    "        if not DATASETS_PATH.exists():\n",
    "            raise RuntimeError(f\"Dataset directory tidak ditemukan di: {DATASETS_PATH}\")\n",
    "        \n",
    "        # List available files in dataset directory\n",
    "        print(\"\\nFiles in dataset directory:\")\n",
    "        for file in DATASETS_PATH.glob('*'):\n",
    "            print(f\"- {file.name}\")\n",
    "\n",
    "        # Check if dataset exists\n",
    "        if not Config.DATA_PATH.exists():\n",
    "            raise RuntimeError(f\"Dataset tidak ditemukan di: {Config.DATA_PATH}\")\n",
    "\n",
    "        # Check GPU availability\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n",
    "            print(f\"GPU tersedia: {gpu_name}\")\n",
    "            print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
    "        else:\n",
    "            print(\"WARNING: GPU tidak tersedia, menggunakan CPU\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error dalam setup environment: {str(e)}\")\n",
    "        return False\n",
    "class DynamicThresholdOptimizer:\n",
    "    \"\"\"Class untuk mengoptimalkan threshold per-class secara dinamis\"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.thresholds = [0.5] * num_classes  # Initial thresholds\n",
    "        self.performance_history = {i: [] for i in range(num_classes)}\n",
    "        self.best_thresholds = [0.5] * num_classes\n",
    "        self.best_f1_scores = [0.0] * num_classes\n",
    "\n",
    "    def optimize_thresholds(self, true_labels, predictions, class_names):\n",
    "        \"\"\"Optimize thresholds based on F1 score\"\"\"\n",
    "        logging.info(\"Optimizing classification thresholds...\")\n",
    "        \n",
    "        for class_idx in range(self.num_classes):\n",
    "            best_threshold = 0.5\n",
    "            best_f1 = 0.0\n",
    "            \n",
    "            # Test different thresholds\n",
    "            for threshold in np.arange(0.3, 0.8, 0.05):\n",
    "                class_preds = (predictions[:, class_idx] > threshold).astype(int)\n",
    "                f1 = f1_score(true_labels[:, class_idx], class_preds, zero_division=0)\n",
    "                \n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_threshold = threshold\n",
    "            \n",
    "            self.thresholds[class_idx] = best_threshold\n",
    "            self.performance_history[class_idx].append({\n",
    "                'threshold': best_threshold,\n",
    "                'f1_score': best_f1\n",
    "            })\n",
    "            \n",
    "            if best_f1 > self.best_f1_scores[class_idx]:\n",
    "                self.best_f1_scores[class_idx] = best_f1\n",
    "                self.best_thresholds[class_idx] = best_threshold\n",
    "            \n",
    "            logging.info(f\"Class '{class_names[class_idx]}': Optimal threshold = {best_threshold:.3f}, F1 Score = {best_f1:.3f}\")\n",
    "\n",
    "    def apply_thresholds(self, predictions):\n",
    "        \"\"\"Apply optimized thresholds to predictions\"\"\"\n",
    "        thresholded_preds = np.zeros_like(predictions)\n",
    "        for i in range(self.num_classes):\n",
    "            thresholded_preds[:, i] = (predictions[:, i] > self.thresholds[i]).astype(int)\n",
    "        return thresholded_preds\n",
    "\n",
    "    def save_threshold_history(self, save_path, class_names):\n",
    "        \"\"\"Save threshold optimization history\"\"\"\n",
    "        history_data = {\n",
    "            'class_thresholds': {\n",
    "                class_names[i]: {\n",
    "                    'current_threshold': self.thresholds[i],\n",
    "                    'best_threshold': self.best_thresholds[i],\n",
    "                    'best_f1_score': self.best_f1_scores[i],\n",
    "                    'history': self.performance_history[i]\n",
    "                } for i in range(self.num_classes)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(save_path / 'threshold_history.json', 'w') as f:\n",
    "            json.dump(history_data, f, indent=4)\n",
    "\n",
    "class PerformanceTracker:\n",
    "    \"\"\"Class untuk melacak performa per-class selama training\"\"\"\n",
    "    def __init__(self, num_classes, class_names):\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = class_names\n",
    "        self.metrics_history = {name: {\n",
    "            'f1_scores': [],\n",
    "            'precisions': [],\n",
    "            'recalls': [],\n",
    "            'accuracies': []\n",
    "        } for name in class_names}\n",
    "        self.best_metrics = {name: {\n",
    "            'f1_score': 0.0,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'accuracy': 0.0,\n",
    "            'epoch': 0\n",
    "        } for name in class_names}\n",
    "\n",
    "    def update_metrics(self, true_labels, predictions, epoch):\n",
    "        \"\"\"Update performance metrics for each class\"\"\"\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(true_labels[:, i], predictions[:, i])\n",
    "            precision = precision_score(true_labels[:, i], predictions[:, i], zero_division=0)\n",
    "            recall = recall_score(true_labels[:, i], predictions[:, i], zero_division=0)\n",
    "            f1 = f1_score(true_labels[:, i], predictions[:, i], zero_division=0)\n",
    "            \n",
    "            # Update history\n",
    "            self.metrics_history[class_name]['accuracies'].append(accuracy)\n",
    "            self.metrics_history[class_name]['precisions'].append(precision)\n",
    "            self.metrics_history[class_name]['recalls'].append(recall)\n",
    "            self.metrics_history[class_name]['f1_scores'].append(f1)\n",
    "            \n",
    "            # Update best metrics if necessary\n",
    "            if f1 > self.best_metrics[class_name]['f1_score']:\n",
    "                self.best_metrics[class_name].update({\n",
    "                    'f1_score': f1,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'accuracy': accuracy,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "\n",
    "    def plot_performance_trends(self, save_path):\n",
    "        \"\"\"Plot performance trends untuk setiap class\"\"\"\n",
    "        for metric in ['f1_scores', 'precisions', 'recalls', 'accuracies']:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for class_name in self.class_names:\n",
    "                plt.plot(\n",
    "                    self.metrics_history[class_name][metric],\n",
    "                    label=class_name\n",
    "                )\n",
    "            \n",
    "            plt.title(f'{metric.replace(\"_\", \" \").title()} Trends per Class')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Score')\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path / f'{metric}_trends.png')\n",
    "            plt.close()\n",
    "\n",
    "    def save_performance_history(self, save_path):\n",
    "        \"\"\"Save performance history ke file\"\"\"\n",
    "        history_data = {\n",
    "            'metrics_history': self.metrics_history,\n",
    "            'best_metrics': self.best_metrics\n",
    "        }\n",
    "        \n",
    "        with open(save_path / 'performance_history.json', 'w') as f:\n",
    "            json.dump(history_data, f, indent=4)\n",
    "\n",
    "# Memory Management\n",
    "class ModelManager:\n",
    "    \"\"\"Context manager for model memory management\"\"\"\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.model, self.tokenizer\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        del self.model\n",
    "        del self.tokenizer\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# Error Handling\n",
    "def error_handler(func):\n",
    "    \"\"\"Decorator for consistent error handling\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in {func.__name__}: {str(e)}\")\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "# Utility Functions\n",
    "def get_memory_usage() -> float:\n",
    "    \"\"\"Get current memory usage of the program\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024  # in MB\n",
    "\n",
    "def log_memory(step_name: str) -> None:\n",
    "    \"\"\"Log memory usage with consistent format\"\"\"\n",
    "    memory = get_memory_usage()\n",
    "    logging.info(f\"Memory usage after {step_name}: {memory:.2f} MB\")\n",
    "\n",
    "def log_system_info() -> None:\n",
    "    \"\"\"Log system information including GPU details\"\"\"\n",
    "    logging.info(\"System Information:\")\n",
    "    logging.info(f\"Python Version: {sys.version}\")\n",
    "    logging.info(f\"CPU Count: {os.cpu_count()}\")\n",
    "    logging.info(f\"Initial Memory Usage: {get_memory_usage():.2f} MB\")\n",
    "    if torch.cuda.is_available():\n",
    "        logging.info(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "        logging.info(f\"GPU Memory Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        logging.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# Create directories and setup logging\n",
    "if check_environment():\n",
    "    Config.create_directories()\n",
    "    Config.setup_logging()\n",
    "    log_system_info()\n",
    "else:\n",
    "    print(\"Failed to initialize environment. Please check the setup.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9658175b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T21:42:23.062595Z",
     "iopub.status.busy": "2025-02-15T21:42:23.062208Z",
     "iopub.status.idle": "2025-02-15T21:42:23.081588Z",
     "shell.execute_reply": "2025-02-15T21:42:23.080890Z"
    },
    "papermill": {
     "duration": 0.025357,
     "end_time": "2025-02-15T21:42:23.082896",
     "exception": false,
     "start_time": "2025-02-15T21:42:23.057539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAGIAN KEDUA - Dataset dan Data Processing\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    \"\"\"Dataset class untuk movie genre classification\"\"\"\n",
    "    def __init__(self, texts: Union[List, np.ndarray],\n",
    "                 labels: Union[List, np.ndarray],\n",
    "                 tokenizer,\n",
    "                 max_length: int = 512):\n",
    "        # Input validation\n",
    "        if not isinstance(texts, (list, np.ndarray)):\n",
    "            raise ValueError(\"texts must be a list or numpy array\")\n",
    "        if not isinstance(labels, (list, np.ndarray)):\n",
    "            raise ValueError(\"labels must be a list or numpy array\")\n",
    "        if len(texts) != len(labels):\n",
    "            raise ValueError(\"texts and labels must have the same length\")\n",
    "\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten().long(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten().long(),\n",
    "            'labels': torch.FloatTensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Class for handling data preprocessing and loading\"\"\"\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"Clean and preprocess text data\"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "            text = re.sub(r'\\S+@\\S+', '', text)\n",
    "            text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            return text.strip().lower()\n",
    "        return ''\n",
    "\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def load_and_preprocess_data(data_path: Path, sample_size: Optional[int] = None) -> pd.DataFrame:\n",
    "        \"\"\"Load and preprocess data with proper encoding handling\"\"\"\n",
    "        if not data_path.exists():\n",
    "            raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "\n",
    "        if sample_size is not None and (not isinstance(sample_size, int) or sample_size <= 0):\n",
    "            raise ValueError(\"sample_size must be a positive integer\")\n",
    "\n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        log_memory(\"start\")\n",
    "        initial_size = None\n",
    "\n",
    "        # Try different encodings for Google Drive compatibility\n",
    "        encodings_to_try = ['utf-8', 'utf-8-sig', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "        df = None\n",
    "\n",
    "        for encoding in encodings_to_try:\n",
    "            try:\n",
    "                df = pd.read_csv(data_path, encoding=encoding)\n",
    "                logging.info(f\"Successfully loaded data using {encoding} encoding\")\n",
    "                initial_size = len(df)\n",
    "                break\n",
    "            except (UnicodeDecodeError, UnicodeError):\n",
    "                continue\n",
    "\n",
    "        if df is None:\n",
    "            raise UnicodeError(f\"Failed to read file with any of these encodings: {encodings_to_try}\")\n",
    "\n",
    "        log_memory(\"data loading\")\n",
    "\n",
    "        # Sample data if requested\n",
    "        if sample_size:\n",
    "            if sample_size > initial_size:\n",
    "                logging.warning(f\"Requested sample_size ({sample_size}) is larger than dataset size ({initial_size})\")\n",
    "                sample_size = initial_size\n",
    "            logging.info(f\"Taking sample of {sample_size} from {initial_size} total samples\")\n",
    "            df = df.head(sample_size)\n",
    "        else:\n",
    "            logging.info(f\"Using full dataset with {initial_size} samples\")\n",
    "\n",
    "        # Log sample data\n",
    "        logging.info(\"\\nSample data:\")\n",
    "        for i, row in df.head(3).iterrows():\n",
    "            logging.info(f\"\\nSample {i+1}:\")\n",
    "            logging.info(f\"Synopsis: {row['sinopsis'][:100]}...\")\n",
    "            logging.info(f\"Genre: {row['genre']}\")\n",
    "\n",
    "        # Preprocess data\n",
    "        logging.info(\"\\nPreprocessing text data...\")\n",
    "        tqdm.pandas()\n",
    "        df['sinopsis'] = df['sinopsis'].progress_apply(DataProcessor.clean_text)\n",
    "        df['genre'] = df['genre'].str.split(',')\n",
    "        df = df.dropna(subset=['sinopsis', 'genre'])\n",
    "\n",
    "        log_memory(\"preprocessing\")\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_data(df: pd.DataFrame, mlb: MultiLabelBinarizer) -> Tuple:\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        genre_labels = mlb.fit_transform(df['genre'])\n",
    "        return train_test_split(\n",
    "            df['sinopsis'].values,\n",
    "            genre_labels,\n",
    "            test_size=Config.MODEL_PARAMS['TEST_SIZE'],\n",
    "            random_state=42,\n",
    "            stratify=genre_labels if len(genre_labels.shape) == 1 else None\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def create_weighted_sampler(genre_labels: np.ndarray) -> WeightedRandomSampler:\n",
    "        \"\"\"Create weighted sampler for balanced batch sampling\"\"\"\n",
    "        logging.info(\"Creating weighted sampler for balanced batch sampling...\")\n",
    "\n",
    "        sample_weights = np.zeros(len(genre_labels))\n",
    "        for i in range(genre_labels.shape[1]):\n",
    "            sample_weights += genre_labels[:, i] * (1.0 / np.sum(genre_labels[:, i]))\n",
    "\n",
    "        sample_weights = sample_weights / sample_weights.sum()\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Created sampler with {len(sample_weights)} weights\")\n",
    "        return sampler\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_class_weights(genre_labels: np.ndarray, mlb: MultiLabelBinarizer) -> torch.Tensor:\n",
    "        \"\"\"Calculate class weights for handling imbalanced data\"\"\"\n",
    "        class_weights = []\n",
    "        logging.info(\"\\nCalculating class weights for handling imbalanced data...\")\n",
    "\n",
    "        for i in range(genre_labels.shape[1]):\n",
    "            genre = mlb.classes_[i]\n",
    "            positive_samples = np.sum(genre_labels[:, i])\n",
    "            total_samples = len(genre_labels)\n",
    "\n",
    "            weights = compute_class_weight(\n",
    "                class_weight='balanced',\n",
    "                classes=np.array([0, 1]),\n",
    "                y=genre_labels[:, i]\n",
    "            )\n",
    "            class_weights.append(weights[1])\n",
    "\n",
    "            logging.info(f\"{genre}:\")\n",
    "            logging.info(f\"  Positive samples: {positive_samples}\")\n",
    "            logging.info(f\"  Negative samples: {total_samples - positive_samples}\")\n",
    "            logging.info(f\"  Weight: {weights[1]:.2f}\")\n",
    "\n",
    "        return torch.FloatTensor(class_weights).to(Config.DEVICE)\n",
    "\n",
    "class ModelSetup:\n",
    "    \"\"\"Class for handling model setup and data loaders\"\"\"\n",
    "    @staticmethod\n",
    "    def setup_model_and_tokenizer(num_labels: int) -> Tuple:\n",
    "        \"\"\"Setup model dan tokenizer\"\"\"\n",
    "        logging.info(\"Setting up model and tokenizer...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p1',\n",
    "            num_labels=num_labels,\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        ).to(Config.DEVICE)\n",
    "        logging.info(\"Model and tokenizer setup completed\")\n",
    "        return model, tokenizer\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_dataloaders(X_train: np.ndarray,\n",
    "                         X_test: np.ndarray,\n",
    "                         y_train: np.ndarray,\n",
    "                         y_test: np.ndarray,\n",
    "                         tokenizer,\n",
    "                         batch_size: int) -> Tuple:\n",
    "        \"\"\"Setup data loaders\"\"\"\n",
    "        logging.info(\"Setting up data loaders...\")\n",
    "        train_dataset = MovieDataset(X_train, y_train, tokenizer)\n",
    "        val_dataset = MovieDataset(X_test, y_test, tokenizer)\n",
    "        sampler = DataProcessor.create_weighted_sampler(y_train)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            num_workers=0,  # Set to 0 for Colab compatibility\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0,  # Set to 0 for Colab compatibility\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Created data loaders with batch size {batch_size}\")\n",
    "        return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19497acc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T21:42:23.091593Z",
     "iopub.status.busy": "2025-02-15T21:42:23.091357Z",
     "iopub.status.idle": "2025-02-15T21:42:23.117514Z",
     "shell.execute_reply": "2025-02-15T21:42:23.116869Z"
    },
    "papermill": {
     "duration": 0.031865,
     "end_time": "2025-02-15T21:42:23.118637",
     "exception": false,
     "start_time": "2025-02-15T21:42:23.086772",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAGIAN KETIGA - Loss Functions dan Training\n",
    "\n",
    "class LossFunctions:\n",
    "    \"\"\"Class untuk menangani berbagai loss functions\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def focal_loss(predictions: torch.Tensor,\n",
    "                  targets: torch.Tensor,\n",
    "                  gamma: float = 2.0,\n",
    "                  alpha: float = 0.25) -> torch.Tensor:\n",
    "        \"\"\"Calculate focal loss for multi-label classification\"\"\"\n",
    "        ce_loss = F.binary_cross_entropy_with_logits(predictions, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = alpha * (1-pt)**gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def label_smoothing_loss(outputs: torch.Tensor,\n",
    "                           targets: torch.Tensor,\n",
    "                           smoothing: float) -> torch.Tensor:\n",
    "        \"\"\"Calculate loss with label smoothing\"\"\"\n",
    "        log_probs = F.log_softmax(outputs, dim=-1)\n",
    "        targets = torch.clamp(targets * (1.0 - smoothing), min=smoothing / (targets.size(-1) - 1))\n",
    "        return torch.mean(torch.sum(-targets * log_probs, dim=-1))\n",
    "\n",
    "class DataAugmentation:\n",
    "    \"\"\"Class untuk menangani augmentasi data\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_mixup(batch: Dict[str, torch.Tensor], alpha: float = 0.2) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Apply mixup augmentation to batch\"\"\"\n",
    "        # Move tensors to device\n",
    "        input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "        labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        mixed_input_ids = lam * input_ids + (1 - lam) * input_ids.flip(0)\n",
    "        mixed_attention_mask = lam * attention_mask + (1 - lam) * attention_mask.flip(0)\n",
    "        mixed_labels = lam * labels + (1 - lam) * labels.flip(0)\n",
    "\n",
    "        return {\n",
    "            'input_ids': mixed_input_ids.long(),\n",
    "            'attention_mask': mixed_attention_mask.long(),\n",
    "            'labels': mixed_labels\n",
    "        }\n",
    "\n",
    "class Visualization:\n",
    "    \"\"\"Class untuk menangani visualisasi\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_confusion_matrices(predictions: np.ndarray,\n",
    "                              labels: np.ndarray,\n",
    "                              classes: List[str]) -> None:\n",
    "        \"\"\"Plot detailed confusion matrices for each genre\"\"\"\n",
    "        logging.info(\"Generating detailed confusion matrices for each genre...\")\n",
    "\n",
    "        # Pastikan input dalam format yang benar\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        if len(predictions.shape) == 1:\n",
    "            predictions = predictions.reshape(-1, 1)\n",
    "        if len(labels.shape) == 1:\n",
    "            labels = labels.reshape(-1, 1)\n",
    "\n",
    "        for i, genre in enumerate(classes):\n",
    "            try:\n",
    "                genre_preds = predictions[:, i]\n",
    "                genre_labels = labels[:, i]\n",
    "\n",
    "                # Calculate confusion matrix\n",
    "                cm = confusion_matrix(genre_labels, genre_preds)\n",
    "\n",
    "                # Extract values\n",
    "                TN, FP = cm[0]\n",
    "                FN, TP = cm[1]\n",
    "\n",
    "                # Calculate metrics\n",
    "                accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "                precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "                recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "                f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "                # Create plot\n",
    "                plt.figure(figsize=(12, 8))\n",
    "\n",
    "                # Main confusion matrix plot\n",
    "                main_ax = plt.subplot2grid((3, 3), (0, 0), rowspan=2, colspan=2)\n",
    "\n",
    "                # Plot heatmap\n",
    "                plot_labels = [f'Non-{genre}', genre]\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                          xticklabels=plot_labels,\n",
    "                          yticklabels=plot_labels,\n",
    "                          ax=main_ax)\n",
    "\n",
    "                main_ax.set_title(f'Confusion Matrix - {genre}')\n",
    "                main_ax.set_ylabel('True Label')\n",
    "                main_ax.set_xlabel('Predicted Label')\n",
    "\n",
    "                # Create text box for detailed metrics\n",
    "                plt.subplot2grid((3, 3), (0, 2), rowspan=3)\n",
    "                plt.axis('off')\n",
    "\n",
    "                metrics_text = [\n",
    "                    f'Detailed Metrics for {genre}:\\n',\n",
    "                    f'\\nConfusion Matrix Values:',\n",
    "                    f'True Negative (TN): {TN}',\n",
    "                    f'False Positive (FP): {FP}',\n",
    "                    f'False Negative (FN): {FN}',\n",
    "                    f'True Positive (TP): {TP}',\n",
    "                    f'\\nPerformance Metrics:',\n",
    "                    f'Accuracy: {accuracy:.3f}',\n",
    "                    f'Precision: {precision:.3f}',\n",
    "                    f'Recall: {recall:.3f}',\n",
    "                    f'F1 Score: {f1:.3f}',\n",
    "                    f'\\nAdditional Information:',\n",
    "                    f'Total Samples: {len(genre_labels)}',\n",
    "                    f'Positive Samples: {np.sum(genre_labels)}',\n",
    "                    f'Negative Samples: {len(genre_labels) - np.sum(genre_labels)}'\n",
    "                ]\n",
    "\n",
    "                plt.text(0, 0.95, '\\n'.join(metrics_text),\n",
    "                        fontsize=10,\n",
    "                        verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round,pad=1', facecolor='white', alpha=0.8))\n",
    "\n",
    "                # Add interpretation text\n",
    "                interpretation_ax = plt.subplot2grid((3, 3), (2, 0), colspan=2)\n",
    "                interpretation_ax.axis('off')\n",
    "\n",
    "                interpretation_text = [\n",
    "                    'Matrix Interpretation:',\n",
    "                    f'• Model correctly identified {TN} non-{genre} movies (True Negatives)',\n",
    "                    f'• Model correctly identified {TP} {genre} movies (True Positives)',\n",
    "                    f'• Model incorrectly classified {FP} non-{genre} movies as {genre} (False Positives)',\n",
    "                    f'• Model failed to identify {FN} {genre} movies (False Negatives)'\n",
    "                ]\n",
    "\n",
    "                interpretation_ax.text(0, 0.5, '\\n'.join(interpretation_text),\n",
    "                                    fontsize=9,\n",
    "                                    verticalalignment='center',\n",
    "                                    bbox=dict(boxstyle='round,pad=1', facecolor='lightyellow', alpha=0.3))\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plot_path = Config.CM_DIR / f'confusion_matrix_{genre}.png'\n",
    "                plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error plotting confusion matrix for genre {genre}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        logging.info(f\"Confusion matrices saved in: {Config.CM_DIR}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_training_history(history_data: Dict) -> None:\n",
    "        \"\"\"Plot and save training metrics\"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Plot Loss\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history_data['epochs'], history_data['training_loss'],\n",
    "                label='Training Loss', marker='o')\n",
    "        plt.plot(history_data['epochs'], history_data['validation_loss'],\n",
    "                label='Validation Loss', marker='o')\n",
    "        plt.title('Training History - Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Plot Accuracy\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(history_data['epochs'], history_data['accuracy'],\n",
    "                label='Accuracy', marker='o', color='green')\n",
    "        plt.title('Training History - Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Plot Loss Difference\n",
    "        plt.subplot(1, 3, 3)\n",
    "        loss_diff = np.array(history_data['training_loss']) - np.array(history_data['validation_loss'])\n",
    "        plt.plot(history_data['epochs'], loss_diff,\n",
    "                label='Loss Difference', marker='o', color='red')\n",
    "        plt.title('Learning Curve (Train-Val Loss)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Difference')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plot_path = Config.PLOTS_DIR / 'training_history.png'\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        logging.info(f\"Saved training history plots to {plot_path}\")\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Class untuk evaluasi model\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def evaluate_model(model: torch.nn.Module,\n",
    "                      val_loader: DataLoader,\n",
    "                      mlb: MultiLabelBinarizer,\n",
    "                      threshold_optimizer: DynamicThresholdOptimizer = None,\n",
    "                      performance_tracker: PerformanceTracker = None,\n",
    "                      epoch: int = None) -> Dict:\n",
    "        \"\"\"Evaluate model performance with dynamic thresholding\"\"\"\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        raw_predictions = []\n",
    "\n",
    "        logging.info(\"Starting model evaluation...\")\n",
    "        log_memory(\"evaluation start\")\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad(), tqdm(val_loader, desc=\"Evaluating\") as pbar:\n",
    "                for batch in pbar:\n",
    "                    input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                    attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                    labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    logits = outputs.logits\n",
    "                    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                    \n",
    "                    raw_predictions.extend(probs)\n",
    "                    all_labels.extend(labels)\n",
    "\n",
    "            raw_predictions = np.array(raw_predictions)\n",
    "            all_labels = np.array(all_labels)\n",
    "\n",
    "            # Apply dynamic thresholding if available\n",
    "            if threshold_optimizer is not None:\n",
    "                threshold_optimizer.optimize_thresholds(all_labels, raw_predictions, mlb.classes_)\n",
    "                all_preds = threshold_optimizer.apply_thresholds(raw_predictions)\n",
    "            else:\n",
    "                all_preds = (raw_predictions > 0.5).astype(int)\n",
    "\n",
    "            # Update performance tracker if available\n",
    "            if performance_tracker is not None and epoch is not None:\n",
    "                performance_tracker.update_metrics(all_labels, all_preds, epoch)\n",
    "\n",
    "            # Calculate all metrics\n",
    "            correct_predictions = np.sum(all_preds == all_labels)\n",
    "            total_predictions = all_labels.size\n",
    "            accuracy = correct_predictions / total_predictions\n",
    "\n",
    "            # Calculate per-genre metrics\n",
    "            genre_metrics = ModelEvaluator._calculate_genre_metrics(\n",
    "                all_preds, all_labels, mlb.classes_\n",
    "            )\n",
    "\n",
    "            # Calculate macro metrics\n",
    "            macro_metrics = ModelEvaluator._calculate_macro_metrics(genre_metrics)\n",
    "\n",
    "            # Save metrics\n",
    "            evaluation_metrics = {\n",
    "                'overall': macro_metrics,\n",
    "                'per_genre': genre_metrics\n",
    "            }\n",
    "\n",
    "            metrics_file = Config.METRICS_DIR / 'evaluation_metrics.json'\n",
    "            with open(metrics_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(evaluation_metrics, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            # Plot confusion matrices\n",
    "            Visualization.plot_confusion_matrices(all_preds, all_labels, mlb.classes_)\n",
    "\n",
    "            log_memory(\"evaluation end\")\n",
    "\n",
    "            return {\n",
    "                'accuracy': float(accuracy),\n",
    "                'macro_f1': float(macro_metrics['macro_f1']),\n",
    "                'genre_metrics': genre_metrics,\n",
    "                'raw_predictions': raw_predictions,\n",
    "                'true_labels': all_labels\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during model evaluation: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_macro_metrics(genre_metrics: Dict) -> Dict:\n",
    "        \"\"\"Calculate macro-averaged metrics\"\"\"\n",
    "        return {\n",
    "            'accuracy': np.mean([metrics['accuracy'] for metrics in genre_metrics.values()]),\n",
    "            'macro_f1': np.mean([metrics['f1_score'] for metrics in genre_metrics.values()]),\n",
    "            'macro_precision': np.mean([metrics['precision'] for metrics in genre_metrics.values()]),\n",
    "            'macro_recall': np.mean([metrics['recall'] for metrics in genre_metrics.values()])\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_genre_metrics(predictions: np.ndarray,\n",
    "                               labels: np.ndarray,\n",
    "                               classes: List[str]) -> Dict:\n",
    "        \"\"\"Calculate metrics for each genre\"\"\"\n",
    "        genre_metrics = {}\n",
    "        logging.info(\"\\nPer-genre Performance Metrics:\")\n",
    "\n",
    "        for i, genre in enumerate(classes):\n",
    "            genre_preds = predictions[:, i]\n",
    "            genre_labels = labels[:, i]\n",
    "\n",
    "            metrics = {\n",
    "                'accuracy': float(np.mean(genre_preds == genre_labels)),\n",
    "                'f1_score': float(f1_score(genre_labels, genre_preds, zero_division=0)),\n",
    "                'precision': float(precision_score(genre_labels, genre_preds, zero_division=0)),\n",
    "                'recall': float(recall_score(genre_labels, genre_preds, zero_division=0))\n",
    "            }\n",
    "\n",
    "            genre_metrics[genre] = metrics\n",
    "            logging.info(f\"\\nMetrics for {genre}:\")\n",
    "            for metric_name, value in metrics.items():\n",
    "                logging.info(f\"{metric_name.capitalize()}: {value:.4f}\")\n",
    "\n",
    "        return genre_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b109ac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-15T21:42:23.127611Z",
     "iopub.status.busy": "2025-02-15T21:42:23.127398Z",
     "iopub.status.idle": "2025-02-16T00:31:32.114884Z",
     "shell.execute_reply": "2025-02-16T00:31:32.113818Z"
    },
    "papermill": {
     "duration": 10148.994308,
     "end_time": "2025-02-16T00:31:32.116889",
     "exception": false,
     "start_time": "2025-02-15T21:42:23.122581",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files in dataset directory:\n",
      "- final_combined_movies_5genres.csv\n",
      "GPU tersedia: Tesla T4\n",
      "GPU Memory: 15.83 GB\n",
      "2025-02-15 21:42:23,178 - INFO - System Information:\n",
      "2025-02-15 21:42:23,179 - INFO - Python Version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "2025-02-15 21:42:23,180 - INFO - CPU Count: 4\n",
      "2025-02-15 21:42:23,182 - INFO - Initial Memory Usage: 635.80 MB\n",
      "2025-02-15 21:42:23,182 - INFO - GPU Device: Tesla T4\n",
      "2025-02-15 21:42:23,183 - INFO - GPU Memory Total: 15.83 GB\n",
      "2025-02-15 21:42:23,184 - INFO - CUDA Version: 12.1\n",
      "2025-02-15 21:42:23,185 - INFO - Starting movie genre classification with hyperparameter optimization\n",
      "2025-02-15 21:42:23,185 - INFO - Using device: cuda\n",
      "2025-02-15 21:42:23,187 - INFO - \n",
      "Initial Configuration:\n",
      "2025-02-15 21:42:23,187 - INFO - Sample Size: Full Dataset\n",
      "2025-02-15 21:42:23,188 - INFO - EPOCHS: 100\n",
      "2025-02-15 21:42:23,189 - INFO - BATCH_SIZE: 10\n",
      "2025-02-15 21:42:23,190 - INFO - LEARNING_RATE: 1e-05\n",
      "2025-02-15 21:42:23,190 - INFO - MAX_LENGTH: 512\n",
      "2025-02-15 21:42:23,192 - INFO - TEST_SIZE: 0.15\n",
      "2025-02-15 21:42:23,192 - INFO - WEIGHT_DECAY: 0.05\n",
      "2025-02-15 21:42:23,193 - INFO - MIXUP_PROB: 0.5\n",
      "2025-02-15 21:42:23,194 - INFO - PATIENCE: 5\n",
      "2025-02-15 21:42:23,195 - INFO - SMOOTHING: 0.2\n",
      "2025-02-15 21:42:23,196 - INFO - \n",
      "Loading and preprocessing data...\n",
      "2025-02-15 21:42:23,197 - INFO - Loading and preprocessing data...\n",
      "2025-02-15 21:42:23,199 - INFO - Memory usage after start: 635.80 MB\n",
      "2025-02-15 21:42:23,262 - INFO - Successfully loaded data using utf-8 encoding\n",
      "2025-02-15 21:42:23,264 - INFO - Memory usage after data loading: 637.89 MB\n",
      "2025-02-15 21:42:23,264 - INFO - Using full dataset with 1738 samples\n",
      "2025-02-15 21:42:23,265 - INFO - \n",
      "Sample data:\n",
      "2025-02-15 21:42:23,266 - INFO - \n",
      "Sample 1:\n",
      "2025-02-15 21:42:23,270 - INFO - Synopsis: Setelah kematian yang tampak, Siena mampu melihat tanda-tanda bahwa orang-orang akan meninggal. Namu...\n",
      "2025-02-15 21:42:23,271 - INFO - Genre: Horor\n",
      "2025-02-15 21:42:23,272 - INFO - \n",
      "Sample 2:\n",
      "2025-02-15 21:42:23,272 - INFO - Synopsis: Alfi (Al Ghazali) bertemu dengan Alana (Caitlin Halderman), seorang siswa baru di sekolahnya. Ternya...\n",
      "2025-02-15 21:42:23,273 - INFO - Genre: Drama\n",
      "2025-02-15 21:42:23,274 - INFO - \n",
      "Sample 3:\n",
      "2025-02-15 21:42:23,275 - INFO - Synopsis: Ketika gaji staf di sekolahnya dicuri, seorang guru baru yang enggan berusaha untuk mendapatkan kemb...\n",
      "2025-02-15 21:42:23,275 - INFO - Genre: Komedi\n",
      "2025-02-15 21:42:23,276 - INFO - \n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1738/1738 [00:00<00:00, 15232.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:42:23,408 - INFO - Memory usage after preprocessing: 639.64 MB\n",
      "2025-02-15 21:42:23,408 - INFO - \n",
      "Starting hyperparameter optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-02-15 21:42:23,410] A new study created in memory with name: no-name-b9af8e92-60c3-4f4b-a6dd-ad92d1fb8d69\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:42:23,410 - INFO - Starting hyperparameter optimization...\n",
      "2025-02-15 21:42:23,412 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 1e-05, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}\n",
      "2025-02-15 21:42:23,419 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15537d6779b348e79c38e28e2169c25f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f53fdde964144217818ef92a91885e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8b134088d944f89f18f3c2d9c7efed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853006c99fad4cb8bee5c686583a9b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3c8db21bc094fd28f6d226cb183df9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:42:44,286 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 21:42:44,287 - INFO - Setting up data loaders...\n",
      "2025-02-15 21:42:44,288 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 21:42:44,289 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 21:42:44,291 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:44:58,959 - INFO - Starting model evaluation...\n",
      "2025-02-15 21:44:58,961 - INFO - Memory usage after evaluation start: 1768.10 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:45:08,439 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 21:45:08,448 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 21:45:08,449 - INFO - Accuracy: 0.4598\n",
      "2025-02-15 21:45:08,450 - INFO - F1_score: 0.4835\n",
      "2025-02-15 21:45:08,450 - INFO - Precision: 0.3317\n",
      "2025-02-15 21:45:08,452 - INFO - Recall: 0.8919\n",
      "2025-02-15 21:45:08,457 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 21:45:08,458 - INFO - Accuracy: 0.7356\n",
      "2025-02-15 21:45:08,459 - INFO - F1_score: 0.5714\n",
      "2025-02-15 21:45:08,459 - INFO - Precision: 0.4423\n",
      "2025-02-15 21:45:08,460 - INFO - Recall: 0.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:45:08,466 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 21:45:08,468 - INFO - Accuracy: 0.5249\n",
      "2025-02-15 21:45:08,468 - INFO - F1_score: 0.4095\n",
      "2025-02-15 21:45:08,469 - INFO - Precision: 0.2829\n",
      "2025-02-15 21:45:08,470 - INFO - Recall: 0.7414\n",
      "2025-02-15 21:45:08,476 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 21:45:08,477 - INFO - Accuracy: 0.2490\n",
      "2025-02-15 21:45:08,478 - INFO - F1_score: 0.2632\n",
      "2025-02-15 21:45:08,479 - INFO - Precision: 0.1535\n",
      "2025-02-15 21:45:08,480 - INFO - Recall: 0.9211\n",
      "2025-02-15 21:45:08,486 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 21:45:08,487 - INFO - Accuracy: 0.7663\n",
      "2025-02-15 21:45:08,487 - INFO - F1_score: 0.3711\n",
      "2025-02-15 21:45:08,489 - INFO - Precision: 0.2857\n",
      "2025-02-15 21:45:08,490 - INFO - Recall: 0.5294\n",
      "2025-02-15 21:45:08,492 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 21:45:13,072 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 21:45:13,073 - INFO - Memory usage after evaluation end: 1807.55 MB\n",
      "2025-02-15 21:45:13,074 - INFO - Trial 0, Epoch 1: Loss = 1.5972, F1 = 0.4198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:47:48,441 - INFO - Starting model evaluation...\n",
      "2025-02-15 21:47:48,443 - INFO - Memory usage after evaluation start: 1807.68 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:47:57,911 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 21:47:57,917 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 21:47:57,918 - INFO - Accuracy: 0.6169\n",
      "2025-02-15 21:47:57,919 - INFO - F1_score: 0.5192\n",
      "2025-02-15 21:47:57,920 - INFO - Precision: 0.4030\n",
      "2025-02-15 21:47:57,921 - INFO - Recall: 0.7297\n",
      "2025-02-15 21:47:57,927 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 21:47:57,927 - INFO - Accuracy: 0.8238\n",
      "2025-02-15 21:47:57,928 - INFO - F1_score: 0.6933\n",
      "2025-02-15 21:47:57,928 - INFO - Precision: 0.5591\n",
      "2025-02-15 21:47:57,929 - INFO - Recall: 0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:47:57,937 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 21:47:57,937 - INFO - Accuracy: 0.5364\n",
      "2025-02-15 21:47:57,938 - INFO - F1_score: 0.4475\n",
      "2025-02-15 21:47:57,939 - INFO - Precision: 0.3043\n",
      "2025-02-15 21:47:57,940 - INFO - Recall: 0.8448\n",
      "2025-02-15 21:47:57,946 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 21:47:57,947 - INFO - Accuracy: 0.5249\n",
      "2025-02-15 21:47:57,947 - INFO - F1_score: 0.3111\n",
      "2025-02-15 21:47:57,948 - INFO - Precision: 0.1972\n",
      "2025-02-15 21:47:57,950 - INFO - Recall: 0.7368\n",
      "2025-02-15 21:47:57,955 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 21:47:57,956 - INFO - Accuracy: 0.5556\n",
      "2025-02-15 21:47:57,957 - INFO - F1_score: 0.3256\n",
      "2025-02-15 21:47:57,958 - INFO - Precision: 0.2029\n",
      "2025-02-15 21:47:57,959 - INFO - Recall: 0.8235\n",
      "2025-02-15 21:47:57,961 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 21:48:02,176 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 21:48:02,177 - INFO - Memory usage after evaluation end: 1837.09 MB\n",
      "2025-02-15 21:48:02,178 - INFO - Trial 0, Epoch 2: Loss = 1.4421, F1 = 0.4593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:50:37,580 - INFO - Starting model evaluation...\n",
      "2025-02-15 21:50:37,581 - INFO - Memory usage after evaluation start: 1837.09 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:50:47,132 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 21:50:47,138 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 21:50:47,138 - INFO - Accuracy: 0.5172\n",
      "2025-02-15 21:50:47,139 - INFO - F1_score: 0.5116\n",
      "2025-02-15 21:50:47,139 - INFO - Precision: 0.3587\n",
      "2025-02-15 21:50:47,140 - INFO - Recall: 0.8919\n",
      "2025-02-15 21:50:47,147 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 21:50:47,148 - INFO - Accuracy: 0.7931\n",
      "2025-02-15 21:50:47,148 - INFO - F1_score: 0.6667\n",
      "2025-02-15 21:50:47,149 - INFO - Precision: 0.5143\n",
      "2025-02-15 21:50:47,150 - INFO - Recall: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:50:47,158 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 21:50:47,158 - INFO - Accuracy: 0.3563\n",
      "2025-02-15 21:50:47,159 - INFO - F1_score: 0.4000\n",
      "2025-02-15 21:50:47,159 - INFO - Precision: 0.2523\n",
      "2025-02-15 21:50:47,161 - INFO - Recall: 0.9655\n",
      "2025-02-15 21:50:47,167 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 21:50:47,167 - INFO - Accuracy: 0.7931\n",
      "2025-02-15 21:50:47,168 - INFO - F1_score: 0.4130\n",
      "2025-02-15 21:50:47,169 - INFO - Precision: 0.3519\n",
      "2025-02-15 21:50:47,169 - INFO - Recall: 0.5000\n",
      "2025-02-15 21:50:47,176 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 21:50:47,177 - INFO - Accuracy: 0.6973\n",
      "2025-02-15 21:50:47,177 - INFO - F1_score: 0.3471\n",
      "2025-02-15 21:50:47,178 - INFO - Precision: 0.2414\n",
      "2025-02-15 21:50:47,180 - INFO - Recall: 0.6176\n",
      "2025-02-15 21:50:47,181 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 21:50:51,376 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 21:50:51,378 - INFO - Memory usage after evaluation end: 1862.51 MB\n",
      "2025-02-15 21:50:51,379 - INFO - Trial 0, Epoch 3: Loss = 1.3161, F1 = 0.4677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 21:50:52,475] Trial 0 finished with value: 0.46768909798416186 and parameters: {'batch_size': 16, 'learning_rate': 1e-05, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 0 with value: 0.46768909798416186.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:50:52,790 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 3e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}\n",
      "2025-02-15 21:50:52,795 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:50:53,821 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 21:50:53,822 - INFO - Setting up data loaders...\n",
      "2025-02-15 21:50:53,823 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 21:50:53,825 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 21:50:53,827 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:53:30,005 - INFO - Starting model evaluation...\n",
      "2025-02-15 21:53:30,007 - INFO - Memory usage after evaluation start: 1870.05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  3.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:53:38,914 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 21:53:38,921 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 21:53:38,922 - INFO - Accuracy: 0.6092\n",
      "2025-02-15 21:53:38,922 - INFO - F1_score: 0.5049\n",
      "2025-02-15 21:53:38,923 - INFO - Precision: 0.3939\n",
      "2025-02-15 21:53:38,924 - INFO - Recall: 0.7027\n",
      "2025-02-15 21:53:38,930 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 21:53:38,931 - INFO - Accuracy: 0.7739\n",
      "2025-02-15 21:53:38,931 - INFO - F1_score: 0.6467\n",
      "2025-02-15 21:53:38,932 - INFO - Precision: 0.4909\n",
      "2025-02-15 21:53:38,933 - INFO - Recall: 0.9474\n",
      "2025-02-15 21:53:38,939 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 21:53:38,940 - INFO - Accuracy: 0.4674\n",
      "2025-02-15 21:53:38,941 - INFO - F1_score: 0.4232\n",
      "2025-02-15 21:53:38,941 - INFO - Precision: 0.2787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:53:38,942 - INFO - Recall: 0.8793\n",
      "2025-02-15 21:53:38,950 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 21:53:38,950 - INFO - Accuracy: 0.6398\n",
      "2025-02-15 21:53:38,951 - INFO - F1_score: 0.3380\n",
      "2025-02-15 21:53:38,951 - INFO - Precision: 0.2308\n",
      "2025-02-15 21:53:38,952 - INFO - Recall: 0.6316\n",
      "2025-02-15 21:53:38,959 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 21:53:38,959 - INFO - Accuracy: 0.6782\n",
      "2025-02-15 21:53:38,960 - INFO - F1_score: 0.3913\n",
      "2025-02-15 21:53:38,961 - INFO - Precision: 0.2596\n",
      "2025-02-15 21:53:38,962 - INFO - Recall: 0.7941\n",
      "2025-02-15 21:53:38,964 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 21:53:43,108 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 21:53:43,109 - INFO - Memory usage after evaluation end: 1891.36 MB\n",
      "2025-02-15 21:53:43,110 - INFO - Trial 1, Epoch 1: Loss = 1.4934, F1 = 0.4608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:56:19,377 - INFO - Starting model evaluation...\n",
      "2025-02-15 21:56:19,379 - INFO - Memory usage after evaluation start: 1891.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:56:28,308 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 21:56:28,315 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 21:56:28,316 - INFO - Accuracy: 0.4483\n",
      "2025-02-15 21:56:28,316 - INFO - F1_score: 0.4894\n",
      "2025-02-15 21:56:28,317 - INFO - Precision: 0.3317\n",
      "2025-02-15 21:56:28,318 - INFO - Recall: 0.9324\n",
      "2025-02-15 21:56:28,324 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 21:56:28,325 - INFO - Accuracy: 0.8008\n",
      "2025-02-15 21:56:28,325 - INFO - F1_score: 0.6790\n",
      "2025-02-15 21:56:28,327 - INFO - Precision: 0.5238\n",
      "2025-02-15 21:56:28,328 - INFO - Recall: 0.9649\n",
      "2025-02-15 21:56:28,333 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 21:56:28,334 - INFO - Accuracy: 0.6207\n",
      "2025-02-15 21:56:28,335 - INFO - F1_score: 0.5075\n",
      "2025-02-15 21:56:28,336 - INFO - Precision: 0.3566\n",
      "2025-02-15 21:56:28,336 - INFO - Recall: 0.8793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:56:28,344 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 21:56:28,345 - INFO - Accuracy: 0.7510\n",
      "2025-02-15 21:56:28,346 - INFO - F1_score: 0.3925\n",
      "2025-02-15 21:56:28,347 - INFO - Precision: 0.3043\n",
      "2025-02-15 21:56:28,347 - INFO - Recall: 0.5526\n",
      "2025-02-15 21:56:28,355 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 21:56:28,356 - INFO - Accuracy: 0.8046\n",
      "2025-02-15 21:56:28,357 - INFO - F1_score: 0.3855\n",
      "2025-02-15 21:56:28,358 - INFO - Precision: 0.3265\n",
      "2025-02-15 21:56:28,359 - INFO - Recall: 0.4706\n",
      "2025-02-15 21:56:28,361 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 21:56:32,507 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 21:56:32,509 - INFO - Memory usage after evaluation end: 1920.10 MB\n",
      "2025-02-15 21:56:32,509 - INFO - Trial 1, Epoch 2: Loss = 1.2915, F1 = 0.4908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:59:09,004 - INFO - Starting model evaluation...\n",
      "2025-02-15 21:59:09,007 - INFO - Memory usage after evaluation start: 1920.10 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:59:17,951 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 21:59:17,958 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 21:59:17,958 - INFO - Accuracy: 0.5517\n",
      "2025-02-15 21:59:17,959 - INFO - F1_score: 0.5145\n",
      "2025-02-15 21:59:17,960 - INFO - Precision: 0.3713\n",
      "2025-02-15 21:59:17,961 - INFO - Recall: 0.8378\n",
      "2025-02-15 21:59:17,968 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 21:59:17,969 - INFO - Accuracy: 0.7548\n",
      "2025-02-15 21:59:17,969 - INFO - F1_score: 0.6279\n",
      "2025-02-15 21:59:17,970 - INFO - Precision: 0.4696\n",
      "2025-02-15 21:59:17,971 - INFO - Recall: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:59:17,981 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 21:59:17,982 - INFO - Accuracy: 0.6015\n",
      "2025-02-15 21:59:17,984 - INFO - F1_score: 0.4583\n",
      "2025-02-15 21:59:17,985 - INFO - Precision: 0.3284\n",
      "2025-02-15 21:59:17,985 - INFO - Recall: 0.7586\n",
      "2025-02-15 21:59:17,994 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 21:59:17,995 - INFO - Accuracy: 0.7510\n",
      "2025-02-15 21:59:17,996 - INFO - F1_score: 0.3434\n",
      "2025-02-15 21:59:17,997 - INFO - Precision: 0.2787\n",
      "2025-02-15 21:59:17,998 - INFO - Recall: 0.4474\n",
      "2025-02-15 21:59:18,007 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 21:59:18,009 - INFO - Accuracy: 0.7165\n",
      "2025-02-15 21:59:18,009 - INFO - F1_score: 0.3833\n",
      "2025-02-15 21:59:18,010 - INFO - Precision: 0.2674\n",
      "2025-02-15 21:59:18,010 - INFO - Recall: 0.6765\n",
      "2025-02-15 21:59:18,013 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 21:59:22,201 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 21:59:22,202 - INFO - Memory usage after evaluation end: 1949.96 MB\n",
      "2025-02-15 21:59:22,203 - INFO - Trial 1, Epoch 3: Loss = 1.1350, F1 = 0.4655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 21:59:23,439] Trial 1 finished with value: 0.49078045350690325 and parameters: {'batch_size': 8, 'learning_rate': 3e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}. Best is trial 1 with value: 0.49078045350690325.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:59:23,813 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-15 21:59:23,817 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 21:59:24,793 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 21:59:24,795 - INFO - Setting up data loaders...\n",
      "2025-02-15 21:59:24,796 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 21:59:24,797 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 21:59:24,799 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:01:59,840 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:01:59,842 - INFO - Memory usage after evaluation start: 1953.53 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:02:09,369 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:02:09,375 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:02:09,376 - INFO - Accuracy: 0.5249\n",
      "2025-02-15 22:02:09,376 - INFO - F1_score: 0.5040\n",
      "2025-02-15 22:02:09,377 - INFO - Precision: 0.3580\n",
      "2025-02-15 22:02:09,379 - INFO - Recall: 0.8514\n",
      "2025-02-15 22:02:09,384 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:02:09,385 - INFO - Accuracy: 0.8238\n",
      "2025-02-15 22:02:09,386 - INFO - F1_score: 0.7013\n",
      "2025-02-15 22:02:09,387 - INFO - Precision: 0.5567\n",
      "2025-02-15 22:02:09,388 - INFO - Recall: 0.9474\n",
      "2025-02-15 22:02:09,393 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:02:09,394 - INFO - Accuracy: 0.5211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:02:09,395 - INFO - F1_score: 0.4541\n",
      "2025-02-15 22:02:09,396 - INFO - Precision: 0.3041\n",
      "2025-02-15 22:02:09,396 - INFO - Recall: 0.8966\n",
      "2025-02-15 22:02:09,403 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:02:09,403 - INFO - Accuracy: 0.8008\n",
      "2025-02-15 22:02:09,404 - INFO - F1_score: 0.4468\n",
      "2025-02-15 22:02:09,404 - INFO - Precision: 0.3750\n",
      "2025-02-15 22:02:09,406 - INFO - Recall: 0.5526\n",
      "2025-02-15 22:02:09,412 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:02:09,412 - INFO - Accuracy: 0.5057\n",
      "2025-02-15 22:02:09,413 - INFO - F1_score: 0.3246\n",
      "2025-02-15 22:02:09,413 - INFO - Precision: 0.1975\n",
      "2025-02-15 22:02:09,414 - INFO - Recall: 0.9118\n",
      "2025-02-15 22:02:09,416 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:02:13,523 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:02:13,525 - INFO - Memory usage after evaluation end: 1976.34 MB\n",
      "2025-02-15 22:02:13,526 - INFO - Trial 2, Epoch 1: Loss = 1.5230, F1 = 0.4862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:04:49,140 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:04:49,142 - INFO - Memory usage after evaluation start: 1976.34 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:04:58,566 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:04:58,571 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:04:58,572 - INFO - Accuracy: 0.5364\n",
      "2025-02-15 22:04:58,572 - INFO - F1_score: 0.5141\n",
      "2025-02-15 22:04:58,574 - INFO - Precision: 0.3657\n",
      "2025-02-15 22:04:58,575 - INFO - Recall: 0.8649\n",
      "2025-02-15 22:04:58,580 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:04:58,581 - INFO - Accuracy: 0.7165\n",
      "2025-02-15 22:04:58,582 - INFO - F1_score: 0.5889\n",
      "2025-02-15 22:04:58,583 - INFO - Precision: 0.4309\n",
      "2025-02-15 22:04:58,584 - INFO - Recall: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:04:58,591 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:04:58,591 - INFO - Accuracy: 0.5824\n",
      "2025-02-15 22:04:58,592 - INFO - F1_score: 0.4785\n",
      "2025-02-15 22:04:58,592 - INFO - Precision: 0.3311\n",
      "2025-02-15 22:04:58,593 - INFO - Recall: 0.8621\n",
      "2025-02-15 22:04:58,599 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:04:58,599 - INFO - Accuracy: 0.7471\n",
      "2025-02-15 22:04:58,600 - INFO - F1_score: 0.4107\n",
      "2025-02-15 22:04:58,601 - INFO - Precision: 0.3108\n",
      "2025-02-15 22:04:58,601 - INFO - Recall: 0.6053\n",
      "2025-02-15 22:04:58,608 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:04:58,608 - INFO - Accuracy: 0.7395\n",
      "2025-02-15 22:04:58,609 - INFO - F1_score: 0.4138\n",
      "2025-02-15 22:04:58,609 - INFO - Precision: 0.2927\n",
      "2025-02-15 22:04:58,610 - INFO - Recall: 0.7059\n",
      "2025-02-15 22:04:58,612 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:05:02,771 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:05:02,773 - INFO - Memory usage after evaluation end: 2005.40 MB\n",
      "2025-02-15 22:05:02,773 - INFO - Trial 2, Epoch 2: Loss = 1.2777, F1 = 0.4812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:07:38,421 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:07:38,423 - INFO - Memory usage after evaluation start: 2005.65 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:07:47,970 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:07:47,978 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:07:47,979 - INFO - Accuracy: 0.6092\n",
      "2025-02-15 22:07:47,980 - INFO - F1_score: 0.5603\n",
      "2025-02-15 22:07:47,981 - INFO - Precision: 0.4114\n",
      "2025-02-15 22:07:47,982 - INFO - Recall: 0.8784\n",
      "2025-02-15 22:07:47,990 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:07:47,991 - INFO - Accuracy: 0.7050\n",
      "2025-02-15 22:07:47,993 - INFO - F1_score: 0.5792\n",
      "2025-02-15 22:07:47,994 - INFO - Precision: 0.4206\n",
      "2025-02-15 22:07:47,995 - INFO - Recall: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:07:48,003 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:07:48,004 - INFO - Accuracy: 0.5709\n",
      "2025-02-15 22:07:48,005 - INFO - F1_score: 0.4862\n",
      "2025-02-15 22:07:48,006 - INFO - Precision: 0.3312\n",
      "2025-02-15 22:07:48,007 - INFO - Recall: 0.9138\n",
      "2025-02-15 22:07:48,015 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:07:48,016 - INFO - Accuracy: 0.7893\n",
      "2025-02-15 22:07:48,017 - INFO - F1_score: 0.3678\n",
      "2025-02-15 22:07:48,018 - INFO - Precision: 0.3265\n",
      "2025-02-15 22:07:48,019 - INFO - Recall: 0.4211\n",
      "2025-02-15 22:07:48,026 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:07:48,027 - INFO - Accuracy: 0.7854\n",
      "2025-02-15 22:07:48,028 - INFO - F1_score: 0.4717\n",
      "2025-02-15 22:07:48,029 - INFO - Precision: 0.3472\n",
      "2025-02-15 22:07:48,030 - INFO - Recall: 0.7353\n",
      "2025-02-15 22:07:48,032 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:07:52,178 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:07:52,179 - INFO - Memory usage after evaluation end: 2030.21 MB\n",
      "2025-02-15 22:07:52,180 - INFO - Trial 2, Epoch 3: Loss = 1.1074, F1 = 0.4931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:07:53,634] Trial 2 finished with value: 0.4930665075070929 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}. Best is trial 2 with value: 0.4930665075070929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:07:54,057 - INFO - Trial parameter set: {'batch_size': 32, 'learning_rate': 3e-05, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}\n",
      "2025-02-15 22:07:54,061 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:07:55,286 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 22:07:55,287 - INFO - Setting up data loaders...\n",
      "2025-02-15 22:07:55,288 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 22:07:55,290 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 22:07:55,292 - INFO - Created data loaders with batch size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:10:30,471 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:10:30,472 - INFO - Memory usage after evaluation start: 2037.86 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:10:40,065 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:10:40,072 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:10:40,072 - INFO - Accuracy: 0.5249\n",
      "2025-02-15 22:10:40,073 - INFO - F1_score: 0.4959\n",
      "2025-02-15 22:10:40,073 - INFO - Precision: 0.3547\n",
      "2025-02-15 22:10:40,074 - INFO - Recall: 0.8243\n",
      "2025-02-15 22:10:40,081 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:10:40,081 - INFO - Accuracy: 0.7088\n",
      "2025-02-15 22:10:40,082 - INFO - F1_score: 0.5824\n",
      "2025-02-15 22:10:40,082 - INFO - Precision: 0.4240\n",
      "2025-02-15 22:10:40,083 - INFO - Recall: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:10:40,090 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:10:40,091 - INFO - Accuracy: 0.4559\n",
      "2025-02-15 22:10:40,092 - INFO - F1_score: 0.4228\n",
      "2025-02-15 22:10:40,093 - INFO - Precision: 0.2766\n",
      "2025-02-15 22:10:40,093 - INFO - Recall: 0.8966\n",
      "2025-02-15 22:10:40,099 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:10:40,099 - INFO - Accuracy: 0.6207\n",
      "2025-02-15 22:10:40,100 - INFO - F1_score: 0.3851\n",
      "2025-02-15 22:10:40,101 - INFO - Precision: 0.2520\n",
      "2025-02-15 22:10:40,102 - INFO - Recall: 0.8158\n",
      "2025-02-15 22:10:40,108 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:10:40,109 - INFO - Accuracy: 0.7088\n",
      "2025-02-15 22:10:40,109 - INFO - F1_score: 0.3667\n",
      "2025-02-15 22:10:40,110 - INFO - Precision: 0.2558\n",
      "2025-02-15 22:10:40,111 - INFO - Recall: 0.6471\n",
      "2025-02-15 22:10:40,113 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:10:44,219 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:10:44,220 - INFO - Memory usage after evaluation end: 2059.70 MB\n",
      "2025-02-15 22:10:44,221 - INFO - Trial 3, Epoch 1: Loss = 1.5449, F1 = 0.4506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:13:19,569 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:13:19,571 - INFO - Memory usage after evaluation start: 2059.70 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:13:29,174 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:13:29,180 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:13:29,181 - INFO - Accuracy: 0.3142\n",
      "2025-02-15 22:13:29,181 - INFO - F1_score: 0.4424\n",
      "2025-02-15 22:13:29,182 - INFO - Precision: 0.2874\n",
      "2025-02-15 22:13:29,183 - INFO - Recall: 0.9595\n",
      "2025-02-15 22:13:29,189 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:13:29,190 - INFO - Accuracy: 0.6667\n",
      "2025-02-15 22:13:29,191 - INFO - F1_score: 0.5538\n",
      "2025-02-15 22:13:29,192 - INFO - Precision: 0.3913\n",
      "2025-02-15 22:13:29,193 - INFO - Recall: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:13:29,200 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:13:29,201 - INFO - Accuracy: 0.6935\n",
      "2025-02-15 22:13:29,202 - INFO - F1_score: 0.5238\n",
      "2025-02-15 22:13:29,202 - INFO - Precision: 0.4000\n",
      "2025-02-15 22:13:29,203 - INFO - Recall: 0.7586\n",
      "2025-02-15 22:13:29,209 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:13:29,209 - INFO - Accuracy: 0.7586\n",
      "2025-02-15 22:13:29,210 - INFO - F1_score: 0.3505\n",
      "2025-02-15 22:13:29,211 - INFO - Precision: 0.2881\n",
      "2025-02-15 22:13:29,212 - INFO - Recall: 0.4474\n",
      "2025-02-15 22:13:29,218 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:13:29,219 - INFO - Accuracy: 0.5939\n",
      "2025-02-15 22:13:29,220 - INFO - F1_score: 0.3614\n",
      "2025-02-15 22:13:29,220 - INFO - Precision: 0.2273\n",
      "2025-02-15 22:13:29,221 - INFO - Recall: 0.8824\n",
      "2025-02-15 22:13:29,223 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:13:33,419 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:13:33,420 - INFO - Memory usage after evaluation end: 2088.70 MB\n",
      "2025-02-15 22:13:33,421 - INFO - Trial 3, Epoch 2: Loss = 1.3765, F1 = 0.4464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:16:09,041 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:16:09,043 - INFO - Memory usage after evaluation start: 2089.07 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:16:18,580 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:16:18,586 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:16:18,587 - INFO - Accuracy: 0.3755\n",
      "2025-02-15 22:16:18,587 - INFO - F1_score: 0.4585\n",
      "2025-02-15 22:16:18,588 - INFO - Precision: 0.3040\n",
      "2025-02-15 22:16:18,588 - INFO - Recall: 0.9324\n",
      "2025-02-15 22:16:18,595 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:16:18,595 - INFO - Accuracy: 0.6054\n",
      "2025-02-15 22:16:18,596 - INFO - F1_score: 0.5118\n",
      "2025-02-15 22:16:18,597 - INFO - Precision: 0.3506\n",
      "2025-02-15 22:16:18,598 - INFO - Recall: 0.9474\n",
      "2025-02-15 22:16:18,605 - INFO - \n",
      "Metrics for Komedi:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:16:18,605 - INFO - Accuracy: 0.5594\n",
      "2025-02-15 22:16:18,606 - INFO - F1_score: 0.4749\n",
      "2025-02-15 22:16:18,608 - INFO - Precision: 0.3230\n",
      "2025-02-15 22:16:18,608 - INFO - Recall: 0.8966\n",
      "2025-02-15 22:16:18,614 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:16:18,615 - INFO - Accuracy: 0.8084\n",
      "2025-02-15 22:16:18,615 - INFO - F1_score: 0.3590\n",
      "2025-02-15 22:16:18,616 - INFO - Precision: 0.3500\n",
      "2025-02-15 22:16:18,618 - INFO - Recall: 0.3684\n",
      "2025-02-15 22:16:18,623 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:16:18,624 - INFO - Accuracy: 0.8238\n",
      "2025-02-15 22:16:18,624 - INFO - F1_score: 0.4889\n",
      "2025-02-15 22:16:18,625 - INFO - Precision: 0.3929\n",
      "2025-02-15 22:16:18,626 - INFO - Recall: 0.6471\n",
      "2025-02-15 22:16:18,628 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:16:22,782 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:16:22,783 - INFO - Memory usage after evaluation end: 2113.49 MB\n",
      "2025-02-15 22:16:22,784 - INFO - Trial 3, Epoch 3: Loss = 1.2649, F1 = 0.4586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:16:24,351] Trial 3 finished with value: 0.45861383892833524 and parameters: {'batch_size': 32, 'learning_rate': 3e-05, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 2 with value: 0.4930665075070929.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:16:24,822 - INFO - Trial parameter set: {'batch_size': 32, 'learning_rate': 2e-05, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}\n",
      "2025-02-15 22:16:24,826 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:16:25,818 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 22:16:25,820 - INFO - Setting up data loaders...\n",
      "2025-02-15 22:16:25,821 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 22:16:25,823 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 22:16:25,824 - INFO - Created data loaders with batch size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:19:00,822 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:19:00,823 - INFO - Memory usage after evaluation start: 2150.29 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:19:10,347 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:19:10,353 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:19:10,354 - INFO - Accuracy: 0.6590\n",
      "2025-02-15 22:19:10,355 - INFO - F1_score: 0.4972\n",
      "2025-02-15 22:19:10,356 - INFO - Precision: 0.4272\n",
      "2025-02-15 22:19:10,357 - INFO - Recall: 0.5946\n",
      "2025-02-15 22:19:10,363 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:19:10,364 - INFO - Accuracy: 0.8123\n",
      "2025-02-15 22:19:10,365 - INFO - F1_score: 0.6711\n",
      "2025-02-15 22:19:10,366 - INFO - Precision: 0.5435\n",
      "2025-02-15 22:19:10,367 - INFO - Recall: 0.8772\n",
      "2025-02-15 22:19:10,372 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:19:10,373 - INFO - Accuracy: 0.5479\n",
      "2025-02-15 22:19:10,374 - INFO - F1_score: 0.4100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:19:10,375 - INFO - Precision: 0.2887\n",
      "2025-02-15 22:19:10,376 - INFO - Recall: 0.7069\n",
      "2025-02-15 22:19:10,382 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:19:10,383 - INFO - Accuracy: 0.5287\n",
      "2025-02-15 22:19:10,384 - INFO - F1_score: 0.3128\n",
      "2025-02-15 22:19:10,385 - INFO - Precision: 0.1986\n",
      "2025-02-15 22:19:10,385 - INFO - Recall: 0.7368\n",
      "2025-02-15 22:19:10,391 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:19:10,391 - INFO - Accuracy: 0.6207\n",
      "2025-02-15 22:19:10,392 - INFO - F1_score: 0.3356\n",
      "2025-02-15 22:19:10,394 - INFO - Precision: 0.2174\n",
      "2025-02-15 22:19:10,394 - INFO - Recall: 0.7353\n",
      "2025-02-15 22:19:10,396 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:19:14,476 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:19:14,477 - INFO - Memory usage after evaluation end: 2170.79 MB\n",
      "2025-02-15 22:19:14,478 - INFO - Trial 4, Epoch 1: Loss = 1.5581, F1 = 0.4453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:21:49,977 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:21:49,979 - INFO - Memory usage after evaluation start: 2170.79 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:21:59,523 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:21:59,529 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:21:59,530 - INFO - Accuracy: 0.6207\n",
      "2025-02-15 22:21:59,530 - INFO - F1_score: 0.4762\n",
      "2025-02-15 22:21:59,531 - INFO - Precision: 0.3913\n",
      "2025-02-15 22:21:59,532 - INFO - Recall: 0.6081\n",
      "2025-02-15 22:21:59,538 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:21:59,539 - INFO - Accuracy: 0.7778\n",
      "2025-02-15 22:21:59,540 - INFO - F1_score: 0.6506\n",
      "2025-02-15 22:21:59,540 - INFO - Precision: 0.4954\n",
      "2025-02-15 22:21:59,541 - INFO - Recall: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:21:59,548 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:21:59,549 - INFO - Accuracy: 0.4444\n",
      "2025-02-15 22:21:59,550 - INFO - F1_score: 0.4177\n",
      "2025-02-15 22:21:59,550 - INFO - Precision: 0.2723\n",
      "2025-02-15 22:21:59,551 - INFO - Recall: 0.8966\n",
      "2025-02-15 22:21:59,558 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:21:59,558 - INFO - Accuracy: 0.7739\n",
      "2025-02-15 22:21:59,559 - INFO - F1_score: 0.4040\n",
      "2025-02-15 22:21:59,559 - INFO - Precision: 0.3279\n",
      "2025-02-15 22:21:59,560 - INFO - Recall: 0.5263\n",
      "2025-02-15 22:21:59,568 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:21:59,568 - INFO - Accuracy: 0.7011\n",
      "2025-02-15 22:21:59,569 - INFO - F1_score: 0.3906\n",
      "2025-02-15 22:21:59,569 - INFO - Precision: 0.2660\n",
      "2025-02-15 22:21:59,570 - INFO - Recall: 0.7353\n",
      "2025-02-15 22:21:59,573 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:22:03,803 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:22:03,805 - INFO - Memory usage after evaluation end: 2172.02 MB\n",
      "2025-02-15 22:22:03,805 - INFO - Trial 4, Epoch 2: Loss = 1.3924, F1 = 0.4678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:24:39,253 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:24:39,255 - INFO - Memory usage after evaluation start: 2172.27 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:24:48,840 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:24:48,846 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:24:48,847 - INFO - Accuracy: 0.5747\n",
      "2025-02-15 22:24:48,847 - INFO - F1_score: 0.5067\n",
      "2025-02-15 22:24:48,848 - INFO - Precision: 0.3775\n",
      "2025-02-15 22:24:48,850 - INFO - Recall: 0.7703\n",
      "2025-02-15 22:24:48,856 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:24:48,856 - INFO - Accuracy: 0.8582\n",
      "2025-02-15 22:24:48,857 - INFO - F1_score: 0.7376\n",
      "2025-02-15 22:24:48,858 - INFO - Precision: 0.6190\n",
      "2025-02-15 22:24:48,859 - INFO - Recall: 0.9123\n",
      "2025-02-15 22:24:48,866 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:24:48,866 - INFO - Accuracy: 0.6092\n",
      "2025-02-15 22:24:48,867 - INFO - F1_score: 0.4796\n",
      "2025-02-15 22:24:48,867 - INFO - Precision: 0.3406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:24:48,868 - INFO - Recall: 0.8103\n",
      "2025-02-15 22:24:48,875 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:24:48,875 - INFO - Accuracy: 0.7126\n",
      "2025-02-15 22:24:48,876 - INFO - F1_score: 0.4000\n",
      "2025-02-15 22:24:48,877 - INFO - Precision: 0.2874\n",
      "2025-02-15 22:24:48,879 - INFO - Recall: 0.6579\n",
      "2025-02-15 22:24:48,884 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:24:48,884 - INFO - Accuracy: 0.6858\n",
      "2025-02-15 22:24:48,885 - INFO - F1_score: 0.4058\n",
      "2025-02-15 22:24:48,886 - INFO - Precision: 0.2692\n",
      "2025-02-15 22:24:48,887 - INFO - Recall: 0.8235\n",
      "2025-02-15 22:24:48,889 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:24:53,130 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:24:53,132 - INFO - Memory usage after evaluation end: 2196.78 MB\n",
      "2025-02-15 22:24:53,133 - INFO - Trial 4, Epoch 3: Loss = 1.2507, F1 = 0.5059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:24:54,849] Trial 4 finished with value: 0.5059288514665811 and parameters: {'batch_size': 32, 'learning_rate': 2e-05, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 4 with value: 0.5059288514665811.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:24:55,374 - INFO - Trial parameter set: {'batch_size': 32, 'learning_rate': 3e-05, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-15 22:24:55,378 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:24:56,531 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 22:24:56,532 - INFO - Setting up data loaders...\n",
      "2025-02-15 22:24:56,532 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 22:24:56,535 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 22:24:56,536 - INFO - Created data loaders with batch size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:27:31,923 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:27:31,925 - INFO - Memory usage after evaluation start: 2318.92 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:27:41,427 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:27:41,433 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:27:41,434 - INFO - Accuracy: 0.5134\n",
      "2025-02-15 22:27:41,434 - INFO - F1_score: 0.5058\n",
      "2025-02-15 22:27:41,435 - INFO - Precision: 0.3552\n",
      "2025-02-15 22:27:41,436 - INFO - Recall: 0.8784\n",
      "2025-02-15 22:27:41,442 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:27:41,442 - INFO - Accuracy: 0.8046\n",
      "2025-02-15 22:27:41,444 - INFO - F1_score: 0.6623\n",
      "2025-02-15 22:27:41,444 - INFO - Precision: 0.5319\n",
      "2025-02-15 22:27:41,445 - INFO - Recall: 0.8772\n",
      "2025-02-15 22:27:41,450 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:27:41,451 - INFO - Accuracy: 0.7241\n",
      "2025-02-15 22:27:41,451 - INFO - F1_score: 0.3333\n",
      "2025-02-15 22:27:41,452 - INFO - Precision: 0.3600\n",
      "2025-02-15 22:27:41,453 - INFO - Recall: 0.3103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:27:41,460 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:27:41,461 - INFO - Accuracy: 0.5939\n",
      "2025-02-15 22:27:41,461 - INFO - F1_score: 0.3375\n",
      "2025-02-15 22:27:41,462 - INFO - Precision: 0.2213\n",
      "2025-02-15 22:27:41,463 - INFO - Recall: 0.7105\n",
      "2025-02-15 22:27:41,469 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:27:41,469 - INFO - Accuracy: 0.4674\n",
      "2025-02-15 22:27:41,470 - INFO - F1_score: 0.2944\n",
      "2025-02-15 22:27:41,470 - INFO - Precision: 0.1779\n",
      "2025-02-15 22:27:41,472 - INFO - Recall: 0.8529\n",
      "2025-02-15 22:27:41,474 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:27:45,504 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:27:45,506 - INFO - Memory usage after evaluation end: 2321.60 MB\n",
      "2025-02-15 22:27:45,507 - INFO - Trial 5, Epoch 1: Loss = 1.5420, F1 = 0.4267\n",
      "2025-02-15 22:27:45,512 - ERROR - Error in trial training: \n",
      "2025-02-15 22:27:46,264 - ERROR - Error in optimization objective: \n",
      "2025-02-15 22:27:46,265 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:27:46,266] Trial 5 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:27:46,811 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 22:27:46,816 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:27:47,787 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 22:27:47,788 - INFO - Setting up data loaders...\n",
      "2025-02-15 22:27:47,789 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 22:27:47,792 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 22:27:47,793 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:30:22,980 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:30:22,982 - INFO - Memory usage after evaluation start: 2373.46 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:30:32,440 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:30:32,446 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:30:32,447 - INFO - Accuracy: 0.4943\n",
      "2025-02-15 22:30:32,447 - INFO - F1_score: 0.4884\n",
      "2025-02-15 22:30:32,448 - INFO - Precision: 0.3424\n",
      "2025-02-15 22:30:32,449 - INFO - Recall: 0.8514\n",
      "2025-02-15 22:30:32,455 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:30:32,456 - INFO - Accuracy: 0.7280\n",
      "2025-02-15 22:30:32,456 - INFO - F1_score: 0.6077\n",
      "2025-02-15 22:30:32,457 - INFO - Precision: 0.4435\n",
      "2025-02-15 22:30:32,457 - INFO - Recall: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:30:32,465 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:30:32,465 - INFO - Accuracy: 0.6360\n",
      "2025-02-15 22:30:32,466 - INFO - F1_score: 0.4379\n",
      "2025-02-15 22:30:32,467 - INFO - Precision: 0.3333\n",
      "2025-02-15 22:30:32,467 - INFO - Recall: 0.6379\n",
      "2025-02-15 22:30:32,474 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:30:32,474 - INFO - Accuracy: 0.7165\n",
      "2025-02-15 22:30:32,475 - INFO - F1_score: 0.3934\n",
      "2025-02-15 22:30:32,477 - INFO - Precision: 0.2857\n",
      "2025-02-15 22:30:32,477 - INFO - Recall: 0.6316\n",
      "2025-02-15 22:30:32,483 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:30:32,484 - INFO - Accuracy: 0.6513\n",
      "2025-02-15 22:30:32,485 - INFO - F1_score: 0.3546\n",
      "2025-02-15 22:30:32,485 - INFO - Precision: 0.2336\n",
      "2025-02-15 22:30:32,487 - INFO - Recall: 0.7353\n",
      "2025-02-15 22:30:32,489 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:30:36,305 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:30:36,306 - INFO - Memory usage after evaluation end: 2376.84 MB\n",
      "2025-02-15 22:30:36,307 - INFO - Trial 6, Epoch 1: Loss = 1.4682, F1 = 0.4564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:33:11,808 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:33:11,810 - INFO - Memory usage after evaluation start: 2376.84 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:33:21,357 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:33:21,363 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:33:21,364 - INFO - Accuracy: 0.4751\n",
      "2025-02-15 22:33:21,364 - INFO - F1_score: 0.4982\n",
      "2025-02-15 22:33:21,365 - INFO - Precision: 0.3417\n",
      "2025-02-15 22:33:21,366 - INFO - Recall: 0.9189\n",
      "2025-02-15 22:33:21,372 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:33:21,373 - INFO - Accuracy: 0.8046\n",
      "2025-02-15 22:33:21,373 - INFO - F1_score: 0.6752\n",
      "2025-02-15 22:33:21,374 - INFO - Precision: 0.5300\n",
      "2025-02-15 22:33:21,375 - INFO - Recall: 0.9298\n",
      "2025-02-15 22:33:21,381 - INFO - \n",
      "Metrics for Komedi:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:33:21,381 - INFO - Accuracy: 0.4598\n",
      "2025-02-15 22:33:21,382 - INFO - F1_score: 0.4471\n",
      "2025-02-15 22:33:21,383 - INFO - Precision: 0.2893\n",
      "2025-02-15 22:33:21,384 - INFO - Recall: 0.9828\n",
      "2025-02-15 22:33:21,390 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:33:21,390 - INFO - Accuracy: 0.7088\n",
      "2025-02-15 22:33:21,391 - INFO - F1_score: 0.3333\n",
      "2025-02-15 22:33:21,391 - INFO - Precision: 0.2500\n",
      "2025-02-15 22:33:21,392 - INFO - Recall: 0.5000\n",
      "2025-02-15 22:33:21,398 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:33:21,399 - INFO - Accuracy: 0.7816\n",
      "2025-02-15 22:33:21,399 - INFO - F1_score: 0.4466\n",
      "2025-02-15 22:33:21,401 - INFO - Precision: 0.3333\n",
      "2025-02-15 22:33:21,401 - INFO - Recall: 0.6765\n",
      "2025-02-15 22:33:21,403 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:33:25,227 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:33:25,228 - INFO - Memory usage after evaluation end: 2398.46 MB\n",
      "2025-02-15 22:33:25,230 - INFO - Trial 6, Epoch 2: Loss = 1.1929, F1 = 0.4801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:36:00,513 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:36:00,514 - INFO - Memory usage after evaluation start: 2398.59 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:36:10,069 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:36:10,075 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:36:10,076 - INFO - Accuracy: 0.5517\n",
      "2025-02-15 22:36:10,077 - INFO - F1_score: 0.5301\n",
      "2025-02-15 22:36:10,078 - INFO - Precision: 0.3771\n",
      "2025-02-15 22:36:10,079 - INFO - Recall: 0.8919\n",
      "2025-02-15 22:36:10,085 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:36:10,086 - INFO - Accuracy: 0.8506\n",
      "2025-02-15 22:36:10,087 - INFO - F1_score: 0.7194\n",
      "2025-02-15 22:36:10,087 - INFO - Precision: 0.6098\n",
      "2025-02-15 22:36:10,088 - INFO - Recall: 0.8772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:36:10,095 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:36:10,095 - INFO - Accuracy: 0.4981\n",
      "2025-02-15 22:36:10,096 - INFO - F1_score: 0.4609\n",
      "2025-02-15 22:36:10,096 - INFO - Precision: 0.3027\n",
      "2025-02-15 22:36:10,098 - INFO - Recall: 0.9655\n",
      "2025-02-15 22:36:10,104 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:36:10,104 - INFO - Accuracy: 0.6782\n",
      "2025-02-15 22:36:10,105 - INFO - F1_score: 0.3731\n",
      "2025-02-15 22:36:10,106 - INFO - Precision: 0.2604\n",
      "2025-02-15 22:36:10,106 - INFO - Recall: 0.6579\n",
      "2025-02-15 22:36:10,113 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:36:10,114 - INFO - Accuracy: 0.7816\n",
      "2025-02-15 22:36:10,114 - INFO - F1_score: 0.4571\n",
      "2025-02-15 22:36:10,115 - INFO - Precision: 0.3380\n",
      "2025-02-15 22:36:10,116 - INFO - Recall: 0.7059\n",
      "2025-02-15 22:36:10,118 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:36:13,941 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:36:13,943 - INFO - Memory usage after evaluation end: 2388.42 MB\n",
      "2025-02-15 22:36:13,944 - INFO - Trial 6, Epoch 3: Loss = 1.0429, F1 = 0.5081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:36:15,794] Trial 6 finished with value: 0.5081454955309341 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 6 with value: 0.5081454955309341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:36:16,360 - INFO - Trial parameter set: {'batch_size': 32, 'learning_rate': 2e-05, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 22:36:16,365 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:36:17,416 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 22:36:17,418 - INFO - Setting up data loaders...\n",
      "2025-02-15 22:36:17,419 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 22:36:17,420 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 22:36:17,422 - INFO - Created data loaders with batch size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:38:52,574 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:38:52,576 - INFO - Memory usage after evaluation start: 2389.67 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:39:02,075 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:39:02,082 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:39:02,082 - INFO - Accuracy: 0.5096\n",
      "2025-02-15 22:39:02,083 - INFO - F1_score: 0.5077\n",
      "2025-02-15 22:39:02,084 - INFO - Precision: 0.3548\n",
      "2025-02-15 22:39:02,084 - INFO - Recall: 0.8919\n",
      "2025-02-15 22:39:02,091 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:39:02,091 - INFO - Accuracy: 0.6130\n",
      "2025-02-15 22:39:02,092 - INFO - F1_score: 0.5213\n",
      "2025-02-15 22:39:02,093 - INFO - Precision: 0.3571\n",
      "2025-02-15 22:39:02,094 - INFO - Recall: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:39:02,102 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:39:02,103 - INFO - Accuracy: 0.5402\n",
      "2025-02-15 22:39:02,103 - INFO - F1_score: 0.4340\n",
      "2025-02-15 22:39:02,105 - INFO - Precision: 0.2987\n",
      "2025-02-15 22:39:02,105 - INFO - Recall: 0.7931\n",
      "2025-02-15 22:39:02,112 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:39:02,112 - INFO - Accuracy: 0.7050\n",
      "2025-02-15 22:39:02,113 - INFO - F1_score: 0.3937\n",
      "2025-02-15 22:39:02,114 - INFO - Precision: 0.2809\n",
      "2025-02-15 22:39:02,115 - INFO - Recall: 0.6579\n",
      "2025-02-15 22:39:02,121 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:39:02,122 - INFO - Accuracy: 0.6130\n",
      "2025-02-15 22:39:02,123 - INFO - F1_score: 0.3311\n",
      "2025-02-15 22:39:02,124 - INFO - Precision: 0.2137\n",
      "2025-02-15 22:39:02,124 - INFO - Recall: 0.7353\n",
      "2025-02-15 22:39:02,126 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:39:06,076 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:39:06,078 - INFO - Memory usage after evaluation end: 2408.62 MB\n",
      "2025-02-15 22:39:06,078 - INFO - Trial 7, Epoch 1: Loss = 1.5179, F1 = 0.4376\n",
      "2025-02-15 22:39:06,080 - ERROR - Error in trial training: \n",
      "2025-02-15 22:39:06,891 - ERROR - Error in optimization objective: \n",
      "2025-02-15 22:39:06,892 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:39:06,893] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:39:07,507 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 3e-05, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.15}\n",
      "2025-02-15 22:39:07,512 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:39:08,522 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 22:39:08,523 - INFO - Setting up data loaders...\n",
      "2025-02-15 22:39:08,523 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 22:39:08,525 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 22:39:08,527 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:41:44,977 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:41:44,980 - INFO - Memory usage after evaluation start: 2594.57 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:41:53,800 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:41:53,806 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:41:53,807 - INFO - Accuracy: 0.5862\n",
      "2025-02-15 22:41:53,808 - INFO - F1_score: 0.5345\n",
      "2025-02-15 22:41:53,809 - INFO - Precision: 0.3924\n",
      "2025-02-15 22:41:53,810 - INFO - Recall: 0.8378\n",
      "2025-02-15 22:41:53,815 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:41:53,816 - INFO - Accuracy: 0.8927\n",
      "2025-02-15 22:41:53,817 - INFO - F1_score: 0.7778\n",
      "2025-02-15 22:41:53,818 - INFO - Precision: 0.7101\n",
      "2025-02-15 22:41:53,819 - INFO - Recall: 0.8596\n",
      "2025-02-15 22:41:53,825 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:41:53,825 - INFO - Accuracy: 0.5939\n",
      "2025-02-15 22:41:53,826 - INFO - F1_score: 0.4804\n",
      "2025-02-15 22:41:53,827 - INFO - Precision: 0.3356\n",
      "2025-02-15 22:41:53,828 - INFO - Recall: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:41:53,835 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:41:53,835 - INFO - Accuracy: 0.6552\n",
      "2025-02-15 22:41:53,836 - INFO - F1_score: 0.3750\n",
      "2025-02-15 22:41:53,837 - INFO - Precision: 0.2547\n",
      "2025-02-15 22:41:53,839 - INFO - Recall: 0.7105\n",
      "2025-02-15 22:41:53,844 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:41:53,845 - INFO - Accuracy: 0.6897\n",
      "2025-02-15 22:41:53,845 - INFO - F1_score: 0.3520\n",
      "2025-02-15 22:41:53,846 - INFO - Precision: 0.2418\n",
      "2025-02-15 22:41:53,847 - INFO - Recall: 0.6471\n",
      "2025-02-15 22:41:53,849 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:41:57,642 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:41:57,643 - INFO - Memory usage after evaluation end: 2599.19 MB\n",
      "2025-02-15 22:41:57,644 - INFO - Trial 8, Epoch 1: Loss = 1.4480, F1 = 0.5039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:44:34,663 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:44:34,665 - INFO - Memory usage after evaluation start: 2599.19 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  3.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:44:43,615 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:44:43,621 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:44:43,621 - INFO - Accuracy: 0.6513\n",
      "2025-02-15 22:44:43,622 - INFO - F1_score: 0.5561\n",
      "2025-02-15 22:44:43,623 - INFO - Precision: 0.4351\n",
      "2025-02-15 22:44:43,624 - INFO - Recall: 0.7703\n",
      "2025-02-15 22:44:43,630 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:44:43,631 - INFO - Accuracy: 0.8199\n",
      "2025-02-15 22:44:43,631 - INFO - F1_score: 0.6803\n",
      "2025-02-15 22:44:43,632 - INFO - Precision: 0.5556\n",
      "2025-02-15 22:44:43,632 - INFO - Recall: 0.8772\n",
      "2025-02-15 22:44:43,639 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:44:43,640 - INFO - Accuracy: 0.7318\n",
      "2025-02-15 22:44:43,640 - INFO - F1_score: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:44:43,642 - INFO - Precision: 0.4268\n",
      "2025-02-15 22:44:43,642 - INFO - Recall: 0.6034\n",
      "2025-02-15 22:44:43,649 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:44:43,649 - INFO - Accuracy: 0.7816\n",
      "2025-02-15 22:44:43,650 - INFO - F1_score: 0.3736\n",
      "2025-02-15 22:44:43,652 - INFO - Precision: 0.3208\n",
      "2025-02-15 22:44:43,652 - INFO - Recall: 0.4474\n",
      "2025-02-15 22:44:43,658 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:44:43,658 - INFO - Accuracy: 0.6245\n",
      "2025-02-15 22:44:43,659 - INFO - F1_score: 0.3553\n",
      "2025-02-15 22:44:43,660 - INFO - Precision: 0.2288\n",
      "2025-02-15 22:44:43,660 - INFO - Recall: 0.7941\n",
      "2025-02-15 22:44:43,663 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:44:47,454 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:44:47,455 - INFO - Memory usage after evaluation end: 2604.69 MB\n",
      "2025-02-15 22:44:47,456 - INFO - Trial 8, Epoch 2: Loss = 1.2073, F1 = 0.4931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:47:24,561 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:47:24,563 - INFO - Memory usage after evaluation start: 2604.69 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:47:33,563 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:47:33,569 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:47:33,570 - INFO - Accuracy: 0.7280\n",
      "2025-02-15 22:47:33,571 - INFO - F1_score: 0.5359\n",
      "2025-02-15 22:47:33,572 - INFO - Precision: 0.5190\n",
      "2025-02-15 22:47:33,573 - INFO - Recall: 0.5541\n",
      "2025-02-15 22:47:33,579 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:47:33,579 - INFO - Accuracy: 0.7893\n",
      "2025-02-15 22:47:33,580 - INFO - F1_score: 0.6309\n",
      "2025-02-15 22:47:33,580 - INFO - Precision: 0.5109\n",
      "2025-02-15 22:47:33,581 - INFO - Recall: 0.8246\n",
      "2025-02-15 22:47:33,587 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:47:33,588 - INFO - Accuracy: 0.6513\n",
      "2025-02-15 22:47:33,588 - INFO - F1_score: 0.5185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:47:33,589 - INFO - Precision: 0.3740\n",
      "2025-02-15 22:47:33,590 - INFO - Recall: 0.8448\n",
      "2025-02-15 22:47:33,596 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:47:33,597 - INFO - Accuracy: 0.5977\n",
      "2025-02-15 22:47:33,597 - INFO - F1_score: 0.3478\n",
      "2025-02-15 22:47:33,598 - INFO - Precision: 0.2276\n",
      "2025-02-15 22:47:33,599 - INFO - Recall: 0.7368\n",
      "2025-02-15 22:47:33,605 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:47:33,605 - INFO - Accuracy: 0.8238\n",
      "2025-02-15 22:47:33,606 - INFO - F1_score: 0.4250\n",
      "2025-02-15 22:47:33,606 - INFO - Precision: 0.3696\n",
      "2025-02-15 22:47:33,608 - INFO - Recall: 0.5000\n",
      "2025-02-15 22:47:33,610 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:47:37,434 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:47:37,435 - INFO - Memory usage after evaluation end: 2610.32 MB\n",
      "2025-02-15 22:47:37,437 - INFO - Trial 8, Epoch 3: Loss = 1.0890, F1 = 0.4916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:47:39,468] Trial 8 finished with value: 0.5039305386522426 and parameters: {'batch_size': 8, 'learning_rate': 3e-05, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.15}. Best is trial 6 with value: 0.5081454955309341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:47:40,116 - INFO - Trial parameter set: {'batch_size': 32, 'learning_rate': 2e-05, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 22:47:40,120 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:47:41,208 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 22:47:41,209 - INFO - Setting up data loaders...\n",
      "2025-02-15 22:47:41,210 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 22:47:41,212 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 22:47:41,214 - INFO - Created data loaders with batch size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:50:16,351 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:50:16,353 - INFO - Memory usage after evaluation start: 2556.34 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:50:25,877 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:50:25,884 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:50:25,884 - INFO - Accuracy: 0.5632\n",
      "2025-02-15 22:50:25,885 - INFO - F1_score: 0.4956\n",
      "2025-02-15 22:50:25,886 - INFO - Precision: 0.3684\n",
      "2025-02-15 22:50:25,887 - INFO - Recall: 0.7568\n",
      "2025-02-15 22:50:25,893 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:50:25,894 - INFO - Accuracy: 0.8774\n",
      "2025-02-15 22:50:25,894 - INFO - F1_score: 0.7576\n",
      "2025-02-15 22:50:25,895 - INFO - Precision: 0.6667\n",
      "2025-02-15 22:50:25,897 - INFO - Recall: 0.8772\n",
      "2025-02-15 22:50:25,902 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:50:25,903 - INFO - Accuracy: 0.5402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:50:25,904 - INFO - F1_score: 0.4444\n",
      "2025-02-15 22:50:25,904 - INFO - Precision: 0.3038\n",
      "2025-02-15 22:50:25,905 - INFO - Recall: 0.8276\n",
      "2025-02-15 22:50:25,912 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:50:25,913 - INFO - Accuracy: 0.6667\n",
      "2025-02-15 22:50:25,913 - INFO - F1_score: 0.3741\n",
      "2025-02-15 22:50:25,914 - INFO - Precision: 0.2574\n",
      "2025-02-15 22:50:25,915 - INFO - Recall: 0.6842\n",
      "2025-02-15 22:50:25,921 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:50:25,922 - INFO - Accuracy: 0.4253\n",
      "2025-02-15 22:50:25,922 - INFO - F1_score: 0.2788\n",
      "2025-02-15 22:50:25,923 - INFO - Precision: 0.1667\n",
      "2025-02-15 22:50:25,924 - INFO - Recall: 0.8529\n",
      "2025-02-15 22:50:25,926 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:50:29,859 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:50:29,861 - INFO - Memory usage after evaluation end: 2560.05 MB\n",
      "2025-02-15 22:50:29,862 - INFO - Trial 9, Epoch 1: Loss = 1.4974, F1 = 0.4701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:53:05,824 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:53:05,825 - INFO - Memory usage after evaluation start: 2560.17 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:53:15,347 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:53:15,353 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:53:15,354 - INFO - Accuracy: 0.5785\n",
      "2025-02-15 22:53:15,354 - INFO - F1_score: 0.5259\n",
      "2025-02-15 22:53:15,355 - INFO - Precision: 0.3861\n",
      "2025-02-15 22:53:15,356 - INFO - Recall: 0.8243\n",
      "2025-02-15 22:53:15,362 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:53:15,363 - INFO - Accuracy: 0.7433\n",
      "2025-02-15 22:53:15,363 - INFO - F1_score: 0.6171\n",
      "2025-02-15 22:53:15,365 - INFO - Precision: 0.4576\n",
      "2025-02-15 22:53:15,366 - INFO - Recall: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:53:15,373 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:53:15,373 - INFO - Accuracy: 0.5977\n",
      "2025-02-15 22:53:15,374 - INFO - F1_score: 0.4670\n",
      "2025-02-15 22:53:15,374 - INFO - Precision: 0.3309\n",
      "2025-02-15 22:53:15,375 - INFO - Recall: 0.7931\n",
      "2025-02-15 22:53:15,381 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:53:15,382 - INFO - Accuracy: 0.6858\n",
      "2025-02-15 22:53:15,382 - INFO - F1_score: 0.4058\n",
      "2025-02-15 22:53:15,383 - INFO - Precision: 0.2800\n",
      "2025-02-15 22:53:15,384 - INFO - Recall: 0.7368\n",
      "2025-02-15 22:53:15,389 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:53:15,390 - INFO - Accuracy: 0.7816\n",
      "2025-02-15 22:53:15,392 - INFO - F1_score: 0.4242\n",
      "2025-02-15 22:53:15,393 - INFO - Precision: 0.3231\n",
      "2025-02-15 22:53:15,393 - INFO - Recall: 0.6176\n",
      "2025-02-15 22:53:15,395 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:53:19,374 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:53:19,376 - INFO - Memory usage after evaluation end: 2565.85 MB\n",
      "2025-02-15 22:53:19,377 - INFO - Trial 9, Epoch 2: Loss = 1.3575, F1 = 0.4880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:55:55,223 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:55:55,225 - INFO - Memory usage after evaluation start: 2565.85 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:56:04,794 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:56:04,800 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:56:04,800 - INFO - Accuracy: 0.3333\n",
      "2025-02-15 22:56:04,801 - INFO - F1_score: 0.4563\n",
      "2025-02-15 22:56:04,802 - INFO - Precision: 0.2967\n",
      "2025-02-15 22:56:04,803 - INFO - Recall: 0.9865\n",
      "2025-02-15 22:56:04,809 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:56:04,810 - INFO - Accuracy: 0.8199\n",
      "2025-02-15 22:56:04,810 - INFO - F1_score: 0.6846\n",
      "2025-02-15 22:56:04,811 - INFO - Precision: 0.5543\n",
      "2025-02-15 22:56:04,813 - INFO - Recall: 0.8947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:56:04,819 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:56:04,820 - INFO - Accuracy: 0.6820\n",
      "2025-02-15 22:56:04,821 - INFO - F1_score: 0.5202\n",
      "2025-02-15 22:56:04,822 - INFO - Precision: 0.3913\n",
      "2025-02-15 22:56:04,823 - INFO - Recall: 0.7759\n",
      "2025-02-15 22:56:04,829 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:56:04,830 - INFO - Accuracy: 0.6437\n",
      "2025-02-15 22:56:04,831 - INFO - F1_score: 0.3841\n",
      "2025-02-15 22:56:04,832 - INFO - Precision: 0.2566\n",
      "2025-02-15 22:56:04,833 - INFO - Recall: 0.7632\n",
      "2025-02-15 22:56:04,838 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:56:04,839 - INFO - Accuracy: 0.8429\n",
      "2025-02-15 22:56:04,840 - INFO - F1_score: 0.4938\n",
      "2025-02-15 22:56:04,841 - INFO - Precision: 0.4255\n",
      "2025-02-15 22:56:04,842 - INFO - Recall: 0.5882\n",
      "2025-02-15 22:56:04,844 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:56:08,776 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:56:08,777 - INFO - Memory usage after evaluation end: 2587.58 MB\n",
      "2025-02-15 22:56:08,778 - INFO - Trial 9, Epoch 3: Loss = 1.1473, F1 = 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 22:56:10,996] Trial 9 finished with value: 0.5077956186041643 and parameters: {'batch_size': 32, 'learning_rate': 2e-05, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 6 with value: 0.5081454955309341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:56:11,696 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 1e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 22:56:11,700 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:56:13,305 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 22:56:13,306 - INFO - Setting up data loaders...\n",
      "2025-02-15 22:56:13,307 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 22:56:13,309 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 22:56:13,310 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:58:48,417 - INFO - Starting model evaluation...\n",
      "2025-02-15 22:58:48,419 - INFO - Memory usage after evaluation start: 2574.05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:58:57,897 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 22:58:57,904 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 22:58:57,905 - INFO - Accuracy: 0.4713\n",
      "2025-02-15 22:58:57,906 - INFO - F1_score: 0.5036\n",
      "2025-02-15 22:58:57,906 - INFO - Precision: 0.3431\n",
      "2025-02-15 22:58:57,907 - INFO - Recall: 0.9459\n",
      "2025-02-15 22:58:57,914 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 22:58:57,914 - INFO - Accuracy: 0.7280\n",
      "2025-02-15 22:58:57,915 - INFO - F1_score: 0.6077\n",
      "2025-02-15 22:58:57,916 - INFO - Precision: 0.4435\n",
      "2025-02-15 22:58:57,917 - INFO - Recall: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 22:58:57,923 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 22:58:57,924 - INFO - Accuracy: 0.6360\n",
      "2025-02-15 22:58:57,926 - INFO - F1_score: 0.5226\n",
      "2025-02-15 22:58:57,926 - INFO - Precision: 0.3688\n",
      "2025-02-15 22:58:57,927 - INFO - Recall: 0.8966\n",
      "2025-02-15 22:58:57,934 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 22:58:57,934 - INFO - Accuracy: 0.5747\n",
      "2025-02-15 22:58:57,935 - INFO - F1_score: 0.3353\n",
      "2025-02-15 22:58:57,936 - INFO - Precision: 0.2171\n",
      "2025-02-15 22:58:57,936 - INFO - Recall: 0.7368\n",
      "2025-02-15 22:58:57,943 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 22:58:57,943 - INFO - Accuracy: 0.6705\n",
      "2025-02-15 22:58:57,945 - INFO - F1_score: 0.3582\n",
      "2025-02-15 22:58:57,946 - INFO - Precision: 0.2400\n",
      "2025-02-15 22:58:57,946 - INFO - Recall: 0.7059\n",
      "2025-02-15 22:58:57,948 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 22:59:01,917 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 22:59:01,918 - INFO - Memory usage after evaluation end: 2577.62 MB\n",
      "2025-02-15 22:59:01,919 - INFO - Trial 10, Epoch 1: Loss = 1.5146, F1 = 0.4655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:01:37,837 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:01:37,839 - INFO - Memory usage after evaluation start: 2577.62 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:01:47,387 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:01:47,393 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:01:47,393 - INFO - Accuracy: 0.4176\n",
      "2025-02-15 23:01:47,394 - INFO - F1_score: 0.4865\n",
      "2025-02-15 23:01:47,394 - INFO - Precision: 0.3243\n",
      "2025-02-15 23:01:47,396 - INFO - Recall: 0.9730\n",
      "2025-02-15 23:01:47,401 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:01:47,402 - INFO - Accuracy: 0.8046\n",
      "2025-02-15 23:01:47,403 - INFO - F1_score: 0.6792\n",
      "2025-02-15 23:01:47,403 - INFO - Precision: 0.5294\n",
      "2025-02-15 23:01:47,404 - INFO - Recall: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:01:47,411 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:01:47,412 - INFO - Accuracy: 0.5211\n",
      "2025-02-15 23:01:47,413 - INFO - F1_score: 0.4493\n",
      "2025-02-15 23:01:47,413 - INFO - Precision: 0.3018\n",
      "2025-02-15 23:01:47,415 - INFO - Recall: 0.8793\n",
      "2025-02-15 23:01:47,421 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:01:47,421 - INFO - Accuracy: 0.6437\n",
      "2025-02-15 23:01:47,422 - INFO - F1_score: 0.3841\n",
      "2025-02-15 23:01:47,423 - INFO - Precision: 0.2566\n",
      "2025-02-15 23:01:47,423 - INFO - Recall: 0.7632\n",
      "2025-02-15 23:01:47,429 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:01:47,430 - INFO - Accuracy: 0.7395\n",
      "2025-02-15 23:01:47,430 - INFO - F1_score: 0.4138\n",
      "2025-02-15 23:01:47,431 - INFO - Precision: 0.2927\n",
      "2025-02-15 23:01:47,431 - INFO - Recall: 0.7059\n",
      "2025-02-15 23:01:47,434 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:01:51,410 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:01:51,411 - INFO - Memory usage after evaluation end: 2594.12 MB\n",
      "2025-02-15 23:01:51,412 - INFO - Trial 10, Epoch 2: Loss = 1.3053, F1 = 0.4826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:04:27,453 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:04:27,455 - INFO - Memory usage after evaluation start: 2594.25 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:04:36,999 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:04:37,005 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:04:37,006 - INFO - Accuracy: 0.5249\n",
      "2025-02-15 23:04:37,006 - INFO - F1_score: 0.5231\n",
      "2025-02-15 23:04:37,007 - INFO - Precision: 0.3656\n",
      "2025-02-15 23:04:37,008 - INFO - Recall: 0.9189\n",
      "2025-02-15 23:04:37,014 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:04:37,015 - INFO - Accuracy: 0.8429\n",
      "2025-02-15 23:04:37,015 - INFO - F1_score: 0.7248\n",
      "2025-02-15 23:04:37,016 - INFO - Precision: 0.5870\n",
      "2025-02-15 23:04:37,017 - INFO - Recall: 0.9474\n",
      "2025-02-15 23:04:37,023 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:04:37,024 - INFO - Accuracy: 0.5326\n",
      "2025-02-15 23:04:37,024 - INFO - F1_score: 0.4554\n",
      "2025-02-15 23:04:37,025 - INFO - Precision: 0.3072\n",
      "2025-02-15 23:04:37,026 - INFO - Recall: 0.8793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:04:37,033 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:04:37,033 - INFO - Accuracy: 0.6897\n",
      "2025-02-15 23:04:37,034 - INFO - F1_score: 0.3721\n",
      "2025-02-15 23:04:37,034 - INFO - Precision: 0.2637\n",
      "2025-02-15 23:04:37,035 - INFO - Recall: 0.6316\n",
      "2025-02-15 23:04:37,041 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:04:37,042 - INFO - Accuracy: 0.6284\n",
      "2025-02-15 23:04:37,043 - INFO - F1_score: 0.3742\n",
      "2025-02-15 23:04:37,043 - INFO - Precision: 0.2397\n",
      "2025-02-15 23:04:37,045 - INFO - Recall: 0.8529\n",
      "2025-02-15 23:04:37,047 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:04:41,068 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:04:41,069 - INFO - Memory usage after evaluation end: 2618.24 MB\n",
      "2025-02-15 23:04:41,070 - INFO - Trial 10, Epoch 3: Loss = 1.1449, F1 = 0.4899\n",
      "2025-02-15 23:04:41,072 - ERROR - Error in trial training: \n",
      "2025-02-15 23:04:41,924 - ERROR - Error in optimization objective: \n",
      "2025-02-15 23:04:41,925 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 23:04:41,926] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:04:42,673 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 23:04:42,678 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:04:43,659 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 23:04:43,660 - INFO - Setting up data loaders...\n",
      "2025-02-15 23:04:43,661 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 23:04:43,663 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 23:04:43,664 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:07:18,302 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:07:18,304 - INFO - Memory usage after evaluation start: 2918.68 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:07:27,761 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:07:27,767 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:07:27,767 - INFO - Accuracy: 0.5824\n",
      "2025-02-15 23:07:27,768 - INFO - F1_score: 0.5068\n",
      "2025-02-15 23:07:27,769 - INFO - Precision: 0.3810\n",
      "2025-02-15 23:07:27,769 - INFO - Recall: 0.7568\n",
      "2025-02-15 23:07:27,775 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:07:27,776 - INFO - Accuracy: 0.6513\n",
      "2025-02-15 23:07:27,777 - INFO - F1_score: 0.5473\n",
      "2025-02-15 23:07:27,777 - INFO - Precision: 0.3819\n",
      "2025-02-15 23:07:27,778 - INFO - Recall: 0.9649\n",
      "2025-02-15 23:07:27,784 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:07:27,784 - INFO - Accuracy: 0.7663\n",
      "2025-02-15 23:07:27,785 - INFO - F1_score: 0.4874\n",
      "2025-02-15 23:07:27,785 - INFO - Precision: 0.4754\n",
      "2025-02-15 23:07:27,786 - INFO - Recall: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:07:27,793 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:07:27,794 - INFO - Accuracy: 0.7471\n",
      "2025-02-15 23:07:27,794 - INFO - F1_score: 0.4000\n",
      "2025-02-15 23:07:27,795 - INFO - Precision: 0.3056\n",
      "2025-02-15 23:07:27,796 - INFO - Recall: 0.5789\n",
      "2025-02-15 23:07:27,802 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:07:27,803 - INFO - Accuracy: 0.7203\n",
      "2025-02-15 23:07:27,803 - INFO - F1_score: 0.3652\n",
      "2025-02-15 23:07:27,804 - INFO - Precision: 0.2593\n",
      "2025-02-15 23:07:27,804 - INFO - Recall: 0.6176\n",
      "2025-02-15 23:07:27,807 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:07:31,667 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:07:31,669 - INFO - Memory usage after evaluation end: 2923.30 MB\n",
      "2025-02-15 23:07:31,669 - INFO - Trial 11, Epoch 1: Loss = 1.4508, F1 = 0.4613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:10:07,418 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:10:07,421 - INFO - Memory usage after evaluation start: 2923.43 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:10:16,979 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:10:16,984 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:10:16,985 - INFO - Accuracy: 0.5402\n",
      "2025-02-15 23:10:16,985 - INFO - F1_score: 0.5122\n",
      "2025-02-15 23:10:16,986 - INFO - Precision: 0.3663\n",
      "2025-02-15 23:10:16,987 - INFO - Recall: 0.8514\n",
      "2025-02-15 23:10:16,993 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:10:16,994 - INFO - Accuracy: 0.8238\n",
      "2025-02-15 23:10:16,994 - INFO - F1_score: 0.6974\n",
      "2025-02-15 23:10:16,995 - INFO - Precision: 0.5579\n",
      "2025-02-15 23:10:16,995 - INFO - Recall: 0.9298\n",
      "2025-02-15 23:10:17,002 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:10:17,002 - INFO - Accuracy: 0.6054\n",
      "2025-02-15 23:10:17,003 - INFO - F1_score: 0.4824\n",
      "2025-02-15 23:10:17,004 - INFO - Precision: 0.3404\n",
      "2025-02-15 23:10:17,005 - INFO - Recall: 0.8276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:10:17,011 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:10:17,011 - INFO - Accuracy: 0.7586\n",
      "2025-02-15 23:10:17,012 - INFO - F1_score: 0.3368\n",
      "2025-02-15 23:10:17,013 - INFO - Precision: 0.2807\n",
      "2025-02-15 23:10:17,014 - INFO - Recall: 0.4211\n",
      "2025-02-15 23:10:17,020 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:10:17,020 - INFO - Accuracy: 0.7395\n",
      "2025-02-15 23:10:17,021 - INFO - F1_score: 0.4237\n",
      "2025-02-15 23:10:17,022 - INFO - Precision: 0.2976\n",
      "2025-02-15 23:10:17,023 - INFO - Recall: 0.7353\n",
      "2025-02-15 23:10:17,024 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:10:20,828 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:10:20,830 - INFO - Memory usage after evaluation end: 2929.18 MB\n",
      "2025-02-15 23:10:20,831 - INFO - Trial 11, Epoch 2: Loss = 1.2584, F1 = 0.4905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:12:56,686 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:12:56,689 - INFO - Memory usage after evaluation start: 2929.18 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:13:06,242 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:13:06,247 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:13:06,248 - INFO - Accuracy: 0.6322\n",
      "2025-02-15 23:13:06,248 - INFO - F1_score: 0.5152\n",
      "2025-02-15 23:13:06,250 - INFO - Precision: 0.4113\n",
      "2025-02-15 23:13:06,251 - INFO - Recall: 0.6892\n",
      "2025-02-15 23:13:06,256 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:13:06,257 - INFO - Accuracy: 0.7586\n",
      "2025-02-15 23:13:06,257 - INFO - F1_score: 0.6228\n",
      "2025-02-15 23:13:06,258 - INFO - Precision: 0.4727\n",
      "2025-02-15 23:13:06,259 - INFO - Recall: 0.9123\n",
      "2025-02-15 23:13:06,265 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:13:06,266 - INFO - Accuracy: 0.5134\n",
      "2025-02-15 23:13:06,266 - INFO - F1_score: 0.4730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:13:06,267 - INFO - Precision: 0.3115\n",
      "2025-02-15 23:13:06,269 - INFO - Recall: 0.9828\n",
      "2025-02-15 23:13:06,275 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:13:06,275 - INFO - Accuracy: 0.6935\n",
      "2025-02-15 23:13:06,276 - INFO - F1_score: 0.3651\n",
      "2025-02-15 23:13:06,276 - INFO - Precision: 0.2614\n",
      "2025-02-15 23:13:06,277 - INFO - Recall: 0.6053\n",
      "2025-02-15 23:13:06,283 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:13:06,283 - INFO - Accuracy: 0.8774\n",
      "2025-02-15 23:13:06,284 - INFO - F1_score: 0.5556\n",
      "2025-02-15 23:13:06,285 - INFO - Precision: 0.5263\n",
      "2025-02-15 23:13:06,285 - INFO - Recall: 0.5882\n",
      "2025-02-15 23:13:06,287 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:13:10,054 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:13:10,056 - INFO - Memory usage after evaluation end: 2934.80 MB\n",
      "2025-02-15 23:13:10,057 - INFO - Trial 11, Epoch 3: Loss = 1.0463, F1 = 0.5063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 23:13:12,614] Trial 11 finished with value: 0.5063139944895106 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 6 with value: 0.5081454955309341.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:13:13,414 - INFO - Trial parameter set: {'batch_size': 32, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 23:13:13,419 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:13:14,509 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 23:13:14,510 - INFO - Setting up data loaders...\n",
      "2025-02-15 23:13:14,511 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 23:13:14,513 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 23:13:14,514 - INFO - Created data loaders with batch size 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:15:49,681 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:15:49,683 - INFO - Memory usage after evaluation start: 3157.71 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 9/9 [00:09<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:15:59,215 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:15:59,222 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:15:59,222 - INFO - Accuracy: 0.5785\n",
      "2025-02-15 23:15:59,223 - INFO - F1_score: 0.5175\n",
      "2025-02-15 23:15:59,224 - INFO - Precision: 0.3831\n",
      "2025-02-15 23:15:59,225 - INFO - Recall: 0.7973\n",
      "2025-02-15 23:15:59,230 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:15:59,231 - INFO - Accuracy: 0.5249\n",
      "2025-02-15 23:15:59,232 - INFO - F1_score: 0.4746\n",
      "2025-02-15 23:15:59,233 - INFO - Precision: 0.3128\n",
      "2025-02-15 23:15:59,234 - INFO - Recall: 0.9825\n",
      "2025-02-15 23:15:59,239 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:15:59,240 - INFO - Accuracy: 0.4598\n",
      "2025-02-15 23:15:59,240 - INFO - F1_score: 0.4245\n",
      "2025-02-15 23:15:59,241 - INFO - Precision: 0.2781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:15:59,242 - INFO - Recall: 0.8966\n",
      "2025-02-15 23:15:59,248 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:15:59,249 - INFO - Accuracy: 0.6667\n",
      "2025-02-15 23:15:59,249 - INFO - F1_score: 0.3650\n",
      "2025-02-15 23:15:59,250 - INFO - Precision: 0.2525\n",
      "2025-02-15 23:15:59,251 - INFO - Recall: 0.6579\n",
      "2025-02-15 23:15:59,257 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:15:59,258 - INFO - Accuracy: 0.7356\n",
      "2025-02-15 23:15:59,258 - INFO - F1_score: 0.4202\n",
      "2025-02-15 23:15:59,259 - INFO - Precision: 0.2941\n",
      "2025-02-15 23:15:59,259 - INFO - Recall: 0.7353\n",
      "2025-02-15 23:15:59,262 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:16:03,055 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:16:03,057 - INFO - Memory usage after evaluation end: 3161.34 MB\n",
      "2025-02-15 23:16:03,058 - INFO - Trial 12, Epoch 1: Loss = 1.4936, F1 = 0.4403\n",
      "2025-02-15 23:16:03,060 - ERROR - Error in trial training: \n",
      "2025-02-15 23:16:04,088 - ERROR - Error in optimization objective: \n",
      "2025-02-15 23:16:04,089 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 23:16:04,090] Trial 12 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:16:04,904 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 23:16:04,929 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:16:06,084 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 23:16:06,085 - INFO - Setting up data loaders...\n",
      "2025-02-15 23:16:06,085 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 23:16:06,088 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 23:16:06,089 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:18:41,240 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:18:41,242 - INFO - Memory usage after evaluation start: 3176.10 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:18:50,785 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:18:50,791 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:18:50,792 - INFO - Accuracy: 0.6858\n",
      "2025-02-15 23:18:50,792 - INFO - F1_score: 0.5495\n",
      "2025-02-15 23:18:50,793 - INFO - Precision: 0.4630\n",
      "2025-02-15 23:18:50,795 - INFO - Recall: 0.6757\n",
      "2025-02-15 23:18:50,800 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:18:50,801 - INFO - Accuracy: 0.7318\n",
      "2025-02-15 23:18:50,801 - INFO - F1_score: 0.6111\n",
      "2025-02-15 23:18:50,802 - INFO - Precision: 0.4472\n",
      "2025-02-15 23:18:50,803 - INFO - Recall: 0.9649\n",
      "2025-02-15 23:18:50,808 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:18:50,809 - INFO - Accuracy: 0.6782\n",
      "2025-02-15 23:18:50,810 - INFO - F1_score: 0.4615\n",
      "2025-02-15 23:18:50,810 - INFO - Precision: 0.3673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:18:50,811 - INFO - Recall: 0.6207\n",
      "2025-02-15 23:18:50,818 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:18:50,819 - INFO - Accuracy: 0.4215\n",
      "2025-02-15 23:18:50,819 - INFO - F1_score: 0.2977\n",
      "2025-02-15 23:18:50,820 - INFO - Precision: 0.1808\n",
      "2025-02-15 23:18:50,822 - INFO - Recall: 0.8421\n",
      "2025-02-15 23:18:50,826 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:18:50,827 - INFO - Accuracy: 0.8467\n",
      "2025-02-15 23:18:50,828 - INFO - F1_score: 0.4118\n",
      "2025-02-15 23:18:50,828 - INFO - Precision: 0.4118\n",
      "2025-02-15 23:18:50,829 - INFO - Recall: 0.4118\n",
      "2025-02-15 23:18:50,832 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:18:54,621 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:18:54,622 - INFO - Memory usage after evaluation end: 3180.73 MB\n",
      "2025-02-15 23:18:54,624 - INFO - Trial 13, Epoch 1: Loss = 1.4764, F1 = 0.4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:21:30,474 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:21:30,476 - INFO - Memory usage after evaluation start: 3180.85 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:21:40,026 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:21:40,032 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:21:40,033 - INFO - Accuracy: 0.4176\n",
      "2025-02-15 23:21:40,034 - INFO - F1_score: 0.4648\n",
      "2025-02-15 23:21:40,034 - INFO - Precision: 0.3143\n",
      "2025-02-15 23:21:40,035 - INFO - Recall: 0.8919\n",
      "2025-02-15 23:21:40,042 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:21:40,042 - INFO - Accuracy: 0.7893\n",
      "2025-02-15 23:21:40,043 - INFO - F1_score: 0.6541\n",
      "2025-02-15 23:21:40,044 - INFO - Precision: 0.5098\n",
      "2025-02-15 23:21:40,045 - INFO - Recall: 0.9123\n",
      "2025-02-15 23:21:40,051 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:21:40,052 - INFO - Accuracy: 0.7165\n",
      "2025-02-15 23:21:40,052 - INFO - F1_score: 0.5316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:21:40,053 - INFO - Precision: 0.4200\n",
      "2025-02-15 23:21:40,054 - INFO - Recall: 0.7241\n",
      "2025-02-15 23:21:40,060 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:21:40,061 - INFO - Accuracy: 0.7778\n",
      "2025-02-15 23:21:40,062 - INFO - F1_score: 0.4200\n",
      "2025-02-15 23:21:40,063 - INFO - Precision: 0.3387\n",
      "2025-02-15 23:21:40,064 - INFO - Recall: 0.5526\n",
      "2025-02-15 23:21:40,070 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:21:40,070 - INFO - Accuracy: 0.8506\n",
      "2025-02-15 23:21:40,071 - INFO - F1_score: 0.5063\n",
      "2025-02-15 23:21:40,072 - INFO - Precision: 0.4444\n",
      "2025-02-15 23:21:40,072 - INFO - Recall: 0.5882\n",
      "2025-02-15 23:21:40,075 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:21:43,865 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:21:43,866 - INFO - Memory usage after evaluation end: 3186.60 MB\n",
      "2025-02-15 23:21:43,867 - INFO - Trial 13, Epoch 2: Loss = 1.2556, F1 = 0.5154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:24:19,760 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:24:19,761 - INFO - Memory usage after evaluation start: 3186.60 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:24:29,312 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:24:29,317 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:24:29,318 - INFO - Accuracy: 0.5594\n",
      "2025-02-15 23:24:29,318 - INFO - F1_score: 0.5148\n",
      "2025-02-15 23:24:29,320 - INFO - Precision: 0.3742\n",
      "2025-02-15 23:24:29,321 - INFO - Recall: 0.8243\n",
      "2025-02-15 23:24:29,326 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:24:29,327 - INFO - Accuracy: 0.8046\n",
      "2025-02-15 23:24:29,327 - INFO - F1_score: 0.6710\n",
      "2025-02-15 23:24:29,328 - INFO - Precision: 0.5306\n",
      "2025-02-15 23:24:29,329 - INFO - Recall: 0.9123\n",
      "2025-02-15 23:24:29,335 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:24:29,335 - INFO - Accuracy: 0.6935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:24:29,336 - INFO - F1_score: 0.5000\n",
      "2025-02-15 23:24:29,337 - INFO - Precision: 0.3922\n",
      "2025-02-15 23:24:29,338 - INFO - Recall: 0.6897\n",
      "2025-02-15 23:24:29,344 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:24:29,345 - INFO - Accuracy: 0.7088\n",
      "2025-02-15 23:24:29,345 - INFO - F1_score: 0.3770\n",
      "2025-02-15 23:24:29,346 - INFO - Precision: 0.2738\n",
      "2025-02-15 23:24:29,346 - INFO - Recall: 0.6053\n",
      "2025-02-15 23:24:29,353 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:24:29,353 - INFO - Accuracy: 0.7241\n",
      "2025-02-15 23:24:29,354 - INFO - F1_score: 0.4098\n",
      "2025-02-15 23:24:29,354 - INFO - Precision: 0.2841\n",
      "2025-02-15 23:24:29,355 - INFO - Recall: 0.7353\n",
      "2025-02-15 23:24:29,357 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:24:33,153 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:24:33,154 - INFO - Memory usage after evaluation end: 3192.23 MB\n",
      "2025-02-15 23:24:33,155 - INFO - Trial 13, Epoch 3: Loss = 1.0058, F1 = 0.4945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 23:24:35,831] Trial 13 finished with value: 0.515370293250627 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 13 with value: 0.515370293250627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:24:36,675 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 23:24:36,678 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:24:38,220 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 23:24:38,221 - INFO - Setting up data loaders...\n",
      "2025-02-15 23:24:38,222 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 23:24:38,225 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 23:24:38,226 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:27:13,401 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:27:13,403 - INFO - Memory usage after evaluation start: 3261.97 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:27:22,950 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:27:22,957 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:27:22,958 - INFO - Accuracy: 0.5824\n",
      "2025-02-15 23:27:22,958 - INFO - F1_score: 0.5281\n",
      "2025-02-15 23:27:22,960 - INFO - Precision: 0.3885\n",
      "2025-02-15 23:27:22,961 - INFO - Recall: 0.8243\n",
      "2025-02-15 23:27:22,966 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:27:22,966 - INFO - Accuracy: 0.8736\n",
      "2025-02-15 23:27:22,967 - INFO - F1_score: 0.7130\n",
      "2025-02-15 23:27:22,969 - INFO - Precision: 0.7069\n",
      "2025-02-15 23:27:22,969 - INFO - Recall: 0.7193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:27:22,976 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:27:22,979 - INFO - Accuracy: 0.4636\n",
      "2025-02-15 23:27:22,982 - INFO - F1_score: 0.4355\n",
      "2025-02-15 23:27:22,984 - INFO - Precision: 0.2842\n",
      "2025-02-15 23:27:22,985 - INFO - Recall: 0.9310\n",
      "2025-02-15 23:27:22,993 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:27:22,993 - INFO - Accuracy: 0.6322\n",
      "2025-02-15 23:27:22,994 - INFO - F1_score: 0.3514\n",
      "2025-02-15 23:27:22,995 - INFO - Precision: 0.2364\n",
      "2025-02-15 23:27:22,996 - INFO - Recall: 0.6842\n",
      "2025-02-15 23:27:23,002 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:27:23,002 - INFO - Accuracy: 0.6820\n",
      "2025-02-15 23:27:23,003 - INFO - F1_score: 0.3566\n",
      "2025-02-15 23:27:23,004 - INFO - Precision: 0.2421\n",
      "2025-02-15 23:27:23,005 - INFO - Recall: 0.6765\n",
      "2025-02-15 23:27:23,007 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:27:26,823 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:27:26,824 - INFO - Memory usage after evaluation end: 3265.72 MB\n",
      "2025-02-15 23:27:26,825 - INFO - Trial 14, Epoch 1: Loss = 1.5339, F1 = 0.4769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:30:02,545 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:30:02,547 - INFO - Memory usage after evaluation start: 3265.84 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:30:12,120 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:30:12,126 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:30:12,127 - INFO - Accuracy: 0.6284\n",
      "2025-02-15 23:30:12,128 - INFO - F1_score: 0.5530\n",
      "2025-02-15 23:30:12,128 - INFO - Precision: 0.4196\n",
      "2025-02-15 23:30:12,129 - INFO - Recall: 0.8108\n",
      "2025-02-15 23:30:12,135 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:30:12,135 - INFO - Accuracy: 0.7778\n",
      "2025-02-15 23:30:12,136 - INFO - F1_score: 0.6506\n",
      "2025-02-15 23:30:12,136 - INFO - Precision: 0.4954\n",
      "2025-02-15 23:30:12,137 - INFO - Recall: 0.9474\n",
      "2025-02-15 23:30:12,143 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:30:12,144 - INFO - Accuracy: 0.5517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:30:12,145 - INFO - F1_score: 0.4706\n",
      "2025-02-15 23:30:12,146 - INFO - Precision: 0.3190\n",
      "2025-02-15 23:30:12,146 - INFO - Recall: 0.8966\n",
      "2025-02-15 23:30:12,152 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:30:12,153 - INFO - Accuracy: 0.7778\n",
      "2025-02-15 23:30:12,154 - INFO - F1_score: 0.4423\n",
      "2025-02-15 23:30:12,154 - INFO - Precision: 0.3485\n",
      "2025-02-15 23:30:12,155 - INFO - Recall: 0.6053\n",
      "2025-02-15 23:30:12,161 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:30:12,162 - INFO - Accuracy: 0.7126\n",
      "2025-02-15 23:30:12,162 - INFO - F1_score: 0.4186\n",
      "2025-02-15 23:30:12,163 - INFO - Precision: 0.2842\n",
      "2025-02-15 23:30:12,164 - INFO - Recall: 0.7941\n",
      "2025-02-15 23:30:12,166 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:30:15,916 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:30:15,917 - INFO - Memory usage after evaluation end: 3271.47 MB\n",
      "2025-02-15 23:30:15,918 - INFO - Trial 14, Epoch 2: Loss = 1.2657, F1 = 0.5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:32:52,142 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:32:52,143 - INFO - Memory usage after evaluation start: 3271.59 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:33:01,698 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:33:01,704 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:33:01,705 - INFO - Accuracy: 0.4483\n",
      "2025-02-15 23:33:01,705 - INFO - F1_score: 0.4820\n",
      "2025-02-15 23:33:01,706 - INFO - Precision: 0.3284\n",
      "2025-02-15 23:33:01,708 - INFO - Recall: 0.9054\n",
      "2025-02-15 23:33:01,713 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:33:01,714 - INFO - Accuracy: 0.8467\n",
      "2025-02-15 23:33:01,714 - INFO - F1_score: 0.7222\n",
      "2025-02-15 23:33:01,715 - INFO - Precision: 0.5977\n",
      "2025-02-15 23:33:01,716 - INFO - Recall: 0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:33:01,723 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:33:01,724 - INFO - Accuracy: 0.5211\n",
      "2025-02-15 23:33:01,724 - INFO - F1_score: 0.4589\n",
      "2025-02-15 23:33:01,725 - INFO - Precision: 0.3064\n",
      "2025-02-15 23:33:01,727 - INFO - Recall: 0.9138\n",
      "2025-02-15 23:33:01,732 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:33:01,733 - INFO - Accuracy: 0.7854\n",
      "2025-02-15 23:33:01,733 - INFO - F1_score: 0.4043\n",
      "2025-02-15 23:33:01,734 - INFO - Precision: 0.3393\n",
      "2025-02-15 23:33:01,735 - INFO - Recall: 0.5000\n",
      "2025-02-15 23:33:01,741 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:33:01,742 - INFO - Accuracy: 0.7241\n",
      "2025-02-15 23:33:01,742 - INFO - F1_score: 0.4098\n",
      "2025-02-15 23:33:01,743 - INFO - Precision: 0.2841\n",
      "2025-02-15 23:33:01,744 - INFO - Recall: 0.7353\n",
      "2025-02-15 23:33:01,746 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:33:05,556 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:33:05,557 - INFO - Memory usage after evaluation end: 3277.34 MB\n",
      "2025-02-15 23:33:05,558 - INFO - Trial 14, Epoch 3: Loss = 1.0974, F1 = 0.4954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 23:33:08,458] Trial 14 finished with value: 0.5070196760216448 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 13 with value: 0.515370293250627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:33:09,356 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 23:33:09,360 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:33:10,543 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 23:33:10,544 - INFO - Setting up data loaders...\n",
      "2025-02-15 23:33:10,547 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 23:33:10,549 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 23:33:10,550 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:35:45,782 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:35:45,784 - INFO - Memory usage after evaluation start: 3342.07 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:35:55,242 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:35:55,248 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:35:55,248 - INFO - Accuracy: 0.6207\n",
      "2025-02-15 23:35:55,249 - INFO - F1_score: 0.5263\n",
      "2025-02-15 23:35:55,250 - INFO - Precision: 0.4074\n",
      "2025-02-15 23:35:55,251 - INFO - Recall: 0.7432\n",
      "2025-02-15 23:35:55,257 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:35:55,257 - INFO - Accuracy: 0.6552\n",
      "2025-02-15 23:35:55,258 - INFO - F1_score: 0.5500\n",
      "2025-02-15 23:35:55,259 - INFO - Precision: 0.3846\n",
      "2025-02-15 23:35:55,259 - INFO - Recall: 0.9649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:35:55,267 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:35:55,268 - INFO - Accuracy: 0.5249\n",
      "2025-02-15 23:35:55,269 - INFO - F1_score: 0.4464\n",
      "2025-02-15 23:35:55,269 - INFO - Precision: 0.3012\n",
      "2025-02-15 23:35:55,270 - INFO - Recall: 0.8621\n",
      "2025-02-15 23:35:55,276 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:35:55,276 - INFO - Accuracy: 0.7395\n",
      "2025-02-15 23:35:55,277 - INFO - F1_score: 0.4237\n",
      "2025-02-15 23:35:55,278 - INFO - Precision: 0.3125\n",
      "2025-02-15 23:35:55,279 - INFO - Recall: 0.6579\n",
      "2025-02-15 23:35:55,284 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:35:55,285 - INFO - Accuracy: 0.8238\n",
      "2025-02-15 23:35:55,285 - INFO - F1_score: 0.4103\n",
      "2025-02-15 23:35:55,286 - INFO - Precision: 0.3636\n",
      "2025-02-15 23:35:55,287 - INFO - Recall: 0.4706\n",
      "2025-02-15 23:35:55,289 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:35:59,085 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:35:59,087 - INFO - Memory usage after evaluation end: 3346.82 MB\n",
      "2025-02-15 23:35:59,088 - INFO - Trial 15, Epoch 1: Loss = 1.4693, F1 = 0.4713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:38:35,139 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:38:35,141 - INFO - Memory usage after evaluation start: 3346.95 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:38:44,683 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:38:44,689 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:38:44,690 - INFO - Accuracy: 0.4521\n",
      "2025-02-15 23:38:44,690 - INFO - F1_score: 0.4838\n",
      "2025-02-15 23:38:44,691 - INFO - Precision: 0.3300\n",
      "2025-02-15 23:38:44,692 - INFO - Recall: 0.9054\n",
      "2025-02-15 23:38:44,698 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:38:44,699 - INFO - Accuracy: 0.8429\n",
      "2025-02-15 23:38:44,700 - INFO - F1_score: 0.7172\n",
      "2025-02-15 23:38:44,701 - INFO - Precision: 0.5909\n",
      "2025-02-15 23:38:44,701 - INFO - Recall: 0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:38:44,708 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:38:44,709 - INFO - Accuracy: 0.6169\n",
      "2025-02-15 23:38:44,709 - INFO - F1_score: 0.4898\n",
      "2025-02-15 23:38:44,710 - INFO - Precision: 0.3478\n",
      "2025-02-15 23:38:44,711 - INFO - Recall: 0.8276\n",
      "2025-02-15 23:38:44,717 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:38:44,717 - INFO - Accuracy: 0.6705\n",
      "2025-02-15 23:38:44,718 - INFO - F1_score: 0.3676\n",
      "2025-02-15 23:38:44,718 - INFO - Precision: 0.2551\n",
      "2025-02-15 23:38:44,720 - INFO - Recall: 0.6579\n",
      "2025-02-15 23:38:44,725 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:38:44,726 - INFO - Accuracy: 0.7893\n",
      "2025-02-15 23:38:44,726 - INFO - F1_score: 0.4086\n",
      "2025-02-15 23:38:44,727 - INFO - Precision: 0.3220\n",
      "2025-02-15 23:38:44,728 - INFO - Recall: 0.5588\n",
      "2025-02-15 23:38:44,730 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:38:48,534 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:38:48,535 - INFO - Memory usage after evaluation end: 3352.57 MB\n",
      "2025-02-15 23:38:48,536 - INFO - Trial 15, Epoch 2: Loss = 1.2418, F1 = 0.4934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:41:24,584 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:41:24,586 - INFO - Memory usage after evaluation start: 3352.57 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:41:34,119 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:41:34,125 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:41:34,126 - INFO - Accuracy: 0.5785\n",
      "2025-02-15 23:41:34,127 - INFO - F1_score: 0.5299\n",
      "2025-02-15 23:41:34,128 - INFO - Precision: 0.3875\n",
      "2025-02-15 23:41:34,129 - INFO - Recall: 0.8378\n",
      "2025-02-15 23:41:34,134 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:41:34,135 - INFO - Accuracy: 0.8123\n",
      "2025-02-15 23:41:34,135 - INFO - F1_score: 0.6755\n",
      "2025-02-15 23:41:34,137 - INFO - Precision: 0.5426\n",
      "2025-02-15 23:41:34,137 - INFO - Recall: 0.8947\n",
      "2025-02-15 23:41:34,143 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:41:34,144 - INFO - Accuracy: 0.4981\n",
      "2025-02-15 23:41:34,144 - INFO - F1_score: 0.4426\n",
      "2025-02-15 23:41:34,146 - INFO - Precision: 0.2938\n",
      "2025-02-15 23:41:34,146 - INFO - Recall: 0.8966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:41:34,153 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:41:34,154 - INFO - Accuracy: 0.7893\n",
      "2025-02-15 23:41:34,154 - INFO - F1_score: 0.4086\n",
      "2025-02-15 23:41:34,155 - INFO - Precision: 0.3455\n",
      "2025-02-15 23:41:34,156 - INFO - Recall: 0.5000\n",
      "2025-02-15 23:41:34,162 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:41:34,162 - INFO - Accuracy: 0.7318\n",
      "2025-02-15 23:41:34,163 - INFO - F1_score: 0.4167\n",
      "2025-02-15 23:41:34,165 - INFO - Precision: 0.2907\n",
      "2025-02-15 23:41:34,165 - INFO - Recall: 0.7353\n",
      "2025-02-15 23:41:34,167 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:41:38,065 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:41:38,066 - INFO - Memory usage after evaluation end: 3358.32 MB\n",
      "2025-02-15 23:41:38,068 - INFO - Trial 15, Epoch 3: Loss = 1.0570, F1 = 0.4946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 23:41:41,116] Trial 15 finished with value: 0.4946466454699829 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 13 with value: 0.515370293250627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:41:42,054 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 1e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 23:41:42,058 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:41:43,211 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 23:41:43,212 - INFO - Setting up data loaders...\n",
      "2025-02-15 23:41:43,214 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 23:41:43,215 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 23:41:43,217 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:44:18,190 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:44:18,192 - INFO - Memory usage after evaluation start: 3428.14 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:44:27,607 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:44:27,614 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:44:27,615 - INFO - Accuracy: 0.3333\n",
      "2025-02-15 23:44:27,615 - INFO - F1_score: 0.4563\n",
      "2025-02-15 23:44:27,616 - INFO - Precision: 0.2967\n",
      "2025-02-15 23:44:27,617 - INFO - Recall: 0.9865\n",
      "2025-02-15 23:44:27,623 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:44:27,623 - INFO - Accuracy: 0.6590\n",
      "2025-02-15 23:44:27,625 - INFO - F1_score: 0.5389\n",
      "2025-02-15 23:44:27,625 - INFO - Precision: 0.3824\n",
      "2025-02-15 23:44:27,626 - INFO - Recall: 0.9123\n",
      "2025-02-15 23:44:27,632 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:44:27,633 - INFO - Accuracy: 0.6130\n",
      "2025-02-15 23:44:27,634 - INFO - F1_score: 0.4599\n",
      "2025-02-15 23:44:27,635 - INFO - Precision: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:44:27,635 - INFO - Recall: 0.7414\n",
      "2025-02-15 23:44:27,642 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:44:27,643 - INFO - Accuracy: 0.5019\n",
      "2025-02-15 23:44:27,643 - INFO - F1_score: 0.3011\n",
      "2025-02-15 23:44:27,644 - INFO - Precision: 0.1892\n",
      "2025-02-15 23:44:27,646 - INFO - Recall: 0.7368\n",
      "2025-02-15 23:44:27,651 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:44:27,651 - INFO - Accuracy: 0.5785\n",
      "2025-02-15 23:44:27,652 - INFO - F1_score: 0.3373\n",
      "2025-02-15 23:44:27,653 - INFO - Precision: 0.2121\n",
      "2025-02-15 23:44:27,653 - INFO - Recall: 0.8235\n",
      "2025-02-15 23:44:27,656 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:44:31,457 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:44:31,458 - INFO - Memory usage after evaluation end: 3431.77 MB\n",
      "2025-02-15 23:44:31,459 - INFO - Trial 16, Epoch 1: Loss = 1.5209, F1 = 0.4187\n",
      "2025-02-15 23:44:31,461 - ERROR - Error in trial training: \n",
      "2025-02-15 23:44:32,640 - ERROR - Error in optimization objective: \n",
      "2025-02-15 23:44:32,642 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 23:44:32,643] Trial 16 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:44:33,605 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 23:44:33,646 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:44:34,606 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 23:44:34,607 - INFO - Setting up data loaders...\n",
      "2025-02-15 23:44:34,609 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 23:44:34,610 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 23:44:34,612 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:47:09,407 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:47:09,409 - INFO - Memory usage after evaluation start: 3305.88 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:47:18,814 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:47:18,821 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:47:18,822 - INFO - Accuracy: 0.6284\n",
      "2025-02-15 23:47:18,823 - INFO - F1_score: 0.5126\n",
      "2025-02-15 23:47:18,824 - INFO - Precision: 0.4080\n",
      "2025-02-15 23:47:18,824 - INFO - Recall: 0.6892\n",
      "2025-02-15 23:47:18,832 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:47:18,832 - INFO - Accuracy: 0.8238\n",
      "2025-02-15 23:47:18,833 - INFO - F1_score: 0.6933\n",
      "2025-02-15 23:47:18,833 - INFO - Precision: 0.5591\n",
      "2025-02-15 23:47:18,834 - INFO - Recall: 0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:47:18,843 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:47:18,843 - INFO - Accuracy: 0.6207\n",
      "2025-02-15 23:47:18,844 - INFO - F1_score: 0.4817\n",
      "2025-02-15 23:47:18,845 - INFO - Precision: 0.3459\n",
      "2025-02-15 23:47:18,845 - INFO - Recall: 0.7931\n",
      "2025-02-15 23:47:18,853 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:47:18,854 - INFO - Accuracy: 0.6130\n",
      "2025-02-15 23:47:18,854 - INFO - F1_score: 0.3804\n",
      "2025-02-15 23:47:18,855 - INFO - Precision: 0.2480\n",
      "2025-02-15 23:47:18,857 - INFO - Recall: 0.8158\n",
      "2025-02-15 23:47:18,864 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:47:18,864 - INFO - Accuracy: 0.5632\n",
      "2025-02-15 23:47:18,865 - INFO - F1_score: 0.3294\n",
      "2025-02-15 23:47:18,867 - INFO - Precision: 0.2059\n",
      "2025-02-15 23:47:18,868 - INFO - Recall: 0.8235\n",
      "2025-02-15 23:47:18,870 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:47:22,772 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:47:22,773 - INFO - Memory usage after evaluation end: 3310.50 MB\n",
      "2025-02-15 23:47:22,774 - INFO - Trial 17, Epoch 1: Loss = 1.4762, F1 = 0.4795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:49:58,802 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:49:58,804 - INFO - Memory usage after evaluation start: 3310.50 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:50:08,289 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:50:08,295 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:50:08,296 - INFO - Accuracy: 0.4789\n",
      "2025-02-15 23:50:08,297 - INFO - F1_score: 0.5000\n",
      "2025-02-15 23:50:08,297 - INFO - Precision: 0.3434\n",
      "2025-02-15 23:50:08,298 - INFO - Recall: 0.9189\n",
      "2025-02-15 23:50:08,304 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:50:08,304 - INFO - Accuracy: 0.8008\n",
      "2025-02-15 23:50:08,305 - INFO - F1_score: 0.6750\n",
      "2025-02-15 23:50:08,305 - INFO - Precision: 0.5243\n",
      "2025-02-15 23:50:08,306 - INFO - Recall: 0.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:50:08,313 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:50:08,314 - INFO - Accuracy: 0.5556\n",
      "2025-02-15 23:50:08,315 - INFO - F1_score: 0.4821\n",
      "2025-02-15 23:50:08,316 - INFO - Precision: 0.3253\n",
      "2025-02-15 23:50:08,317 - INFO - Recall: 0.9310\n",
      "2025-02-15 23:50:08,322 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:50:08,323 - INFO - Accuracy: 0.7280\n",
      "2025-02-15 23:50:08,323 - INFO - F1_score: 0.3932\n",
      "2025-02-15 23:50:08,325 - INFO - Precision: 0.2911\n",
      "2025-02-15 23:50:08,325 - INFO - Recall: 0.6053\n",
      "2025-02-15 23:50:08,331 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:50:08,331 - INFO - Accuracy: 0.7854\n",
      "2025-02-15 23:50:08,332 - INFO - F1_score: 0.4286\n",
      "2025-02-15 23:50:08,334 - INFO - Precision: 0.3281\n",
      "2025-02-15 23:50:08,334 - INFO - Recall: 0.6176\n",
      "2025-02-15 23:50:08,336 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:50:12,150 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:50:12,151 - INFO - Memory usage after evaluation end: 3316.13 MB\n",
      "2025-02-15 23:50:12,153 - INFO - Trial 17, Epoch 2: Loss = 1.2404, F1 = 0.4958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:52:48,205 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:52:48,208 - INFO - Memory usage after evaluation start: 3316.13 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:52:57,769 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:52:57,774 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:52:57,775 - INFO - Accuracy: 0.4253\n",
      "2025-02-15 23:52:57,776 - INFO - F1_score: 0.4718\n",
      "2025-02-15 23:52:57,777 - INFO - Precision: 0.3190\n",
      "2025-02-15 23:52:57,777 - INFO - Recall: 0.9054\n",
      "2025-02-15 23:52:57,784 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:52:57,784 - INFO - Accuracy: 0.8582\n",
      "2025-02-15 23:52:57,785 - INFO - F1_score: 0.7338\n",
      "2025-02-15 23:52:57,786 - INFO - Precision: 0.6220\n",
      "2025-02-15 23:52:57,786 - INFO - Recall: 0.8947\n",
      "2025-02-15 23:52:57,792 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:52:57,793 - INFO - Accuracy: 0.7050\n",
      "2025-02-15 23:52:57,794 - INFO - F1_score: 0.5600\n",
      "2025-02-15 23:52:57,794 - INFO - Precision: 0.4188\n",
      "2025-02-15 23:52:57,796 - INFO - Recall: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:52:57,803 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:52:57,803 - INFO - Accuracy: 0.6130\n",
      "2025-02-15 23:52:57,804 - INFO - F1_score: 0.3567\n",
      "2025-02-15 23:52:57,805 - INFO - Precision: 0.2353\n",
      "2025-02-15 23:52:57,806 - INFO - Recall: 0.7368\n",
      "2025-02-15 23:52:57,812 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:52:57,813 - INFO - Accuracy: 0.7241\n",
      "2025-02-15 23:52:57,814 - INFO - F1_score: 0.4098\n",
      "2025-02-15 23:52:57,815 - INFO - Precision: 0.2841\n",
      "2025-02-15 23:52:57,816 - INFO - Recall: 0.7353\n",
      "2025-02-15 23:52:57,818 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:53:01,612 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:53:01,614 - INFO - Memory usage after evaluation end: 3321.88 MB\n",
      "2025-02-15 23:53:01,615 - INFO - Trial 17, Epoch 3: Loss = 1.1103, F1 = 0.5064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 23:53:04,827] Trial 17 finished with value: 0.5064335798437446 and parameters: {'batch_size': 16, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 13 with value: 0.515370293250627.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:53:05,830 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 2e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 23:53:05,834 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:53:07,002 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 23:53:07,003 - INFO - Setting up data loaders...\n",
      "2025-02-15 23:53:07,004 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 23:53:07,006 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 23:53:07,008 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:55:43,408 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:55:43,410 - INFO - Memory usage after evaluation start: 3545.16 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  3.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:55:52,333 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:55:52,339 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:55:52,340 - INFO - Accuracy: 0.3870\n",
      "2025-02-15 23:55:52,341 - INFO - F1_score: 0.4737\n",
      "2025-02-15 23:55:52,341 - INFO - Precision: 0.3130\n",
      "2025-02-15 23:55:52,343 - INFO - Recall: 0.9730\n",
      "2025-02-15 23:55:52,349 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:55:52,349 - INFO - Accuracy: 0.8008\n",
      "2025-02-15 23:55:52,350 - INFO - F1_score: 0.6709\n",
      "2025-02-15 23:55:52,351 - INFO - Precision: 0.5248\n",
      "2025-02-15 23:55:52,352 - INFO - Recall: 0.9298\n",
      "2025-02-15 23:55:52,357 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:55:52,358 - INFO - Accuracy: 0.4330\n",
      "2025-02-15 23:55:52,359 - INFO - F1_score: 0.4127\n",
      "2025-02-15 23:55:52,359 - INFO - Precision: 0.2680\n",
      "2025-02-15 23:55:52,360 - INFO - Recall: 0.8966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:55:52,367 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:55:52,368 - INFO - Accuracy: 0.6897\n",
      "2025-02-15 23:55:52,368 - INFO - F1_score: 0.3910\n",
      "2025-02-15 23:55:52,370 - INFO - Precision: 0.2737\n",
      "2025-02-15 23:55:52,370 - INFO - Recall: 0.6842\n",
      "2025-02-15 23:55:52,376 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:55:52,377 - INFO - Accuracy: 0.7126\n",
      "2025-02-15 23:55:52,377 - INFO - F1_score: 0.4000\n",
      "2025-02-15 23:55:52,378 - INFO - Precision: 0.2747\n",
      "2025-02-15 23:55:52,380 - INFO - Recall: 0.7353\n",
      "2025-02-15 23:55:52,381 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:55:56,153 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:55:56,155 - INFO - Memory usage after evaluation end: 3548.79 MB\n",
      "2025-02-15 23:55:56,156 - INFO - Trial 18, Epoch 1: Loss = 1.4260, F1 = 0.4696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:58:33,237 - INFO - Starting model evaluation...\n",
      "2025-02-15 23:58:33,240 - INFO - Memory usage after evaluation start: 3548.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:08<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:58:42,109 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-15 23:58:42,114 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-15 23:58:42,115 - INFO - Accuracy: 0.5670\n",
      "2025-02-15 23:58:42,116 - INFO - F1_score: 0.5311\n",
      "2025-02-15 23:58:42,117 - INFO - Precision: 0.3832\n",
      "2025-02-15 23:58:42,118 - INFO - Recall: 0.8649\n",
      "2025-02-15 23:58:42,124 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-15 23:58:42,124 - INFO - Accuracy: 0.7893\n",
      "2025-02-15 23:58:42,125 - INFO - F1_score: 0.6584\n",
      "2025-02-15 23:58:42,126 - INFO - Precision: 0.5096\n",
      "2025-02-15 23:58:42,127 - INFO - Recall: 0.9298\n",
      "2025-02-15 23:58:42,133 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-15 23:58:42,133 - INFO - Accuracy: 0.4598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:58:42,134 - INFO - F1_score: 0.4337\n",
      "2025-02-15 23:58:42,135 - INFO - Precision: 0.2827\n",
      "2025-02-15 23:58:42,136 - INFO - Recall: 0.9310\n",
      "2025-02-15 23:58:42,142 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-15 23:58:42,143 - INFO - Accuracy: 0.6973\n",
      "2025-02-15 23:58:42,144 - INFO - F1_score: 0.3780\n",
      "2025-02-15 23:58:42,144 - INFO - Precision: 0.2697\n",
      "2025-02-15 23:58:42,145 - INFO - Recall: 0.6316\n",
      "2025-02-15 23:58:42,152 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-15 23:58:42,152 - INFO - Accuracy: 0.7969\n",
      "2025-02-15 23:58:42,153 - INFO - F1_score: 0.4301\n",
      "2025-02-15 23:58:42,154 - INFO - Precision: 0.3390\n",
      "2025-02-15 23:58:42,155 - INFO - Recall: 0.5882\n",
      "2025-02-15 23:58:42,157 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-15 23:58:45,905 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-15 23:58:45,906 - INFO - Memory usage after evaluation end: 3554.79 MB\n",
      "2025-02-15 23:58:45,907 - INFO - Trial 18, Epoch 2: Loss = 1.1961, F1 = 0.4863\n",
      "2025-02-15 23:58:45,909 - ERROR - Error in trial training: \n",
      "2025-02-15 23:58:46,981 - ERROR - Error in optimization objective: \n",
      "2025-02-15 23:58:46,982 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-15 23:58:46,983] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:58:48,064 - INFO - Trial parameter set: {'batch_size': 16, 'learning_rate': 1e-05, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-15 23:58:48,068 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-15 23:58:49,222 - INFO - Model and tokenizer setup completed\n",
      "2025-02-15 23:58:49,223 - INFO - Setting up data loaders...\n",
      "2025-02-15 23:58:49,224 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-15 23:58:49,226 - INFO - Created sampler with 1477 weights\n",
      "2025-02-15 23:58:49,227 - INFO - Created data loaders with batch size 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:01:24,368 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:01:24,370 - INFO - Memory usage after evaluation start: 3604.32 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 17/17 [00:09<00:00,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:01:33,825 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:01:33,831 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:01:33,832 - INFO - Accuracy: 0.6973\n",
      "2025-02-16 00:01:33,833 - INFO - F1_score: 0.4903\n",
      "2025-02-16 00:01:33,834 - INFO - Precision: 0.4691\n",
      "2025-02-16 00:01:33,835 - INFO - Recall: 0.5135\n",
      "2025-02-16 00:01:33,841 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:01:33,841 - INFO - Accuracy: 0.6590\n",
      "2025-02-16 00:01:33,842 - INFO - F1_score: 0.5137\n",
      "2025-02-16 00:01:33,843 - INFO - Precision: 0.3730\n",
      "2025-02-16 00:01:33,844 - INFO - Recall: 0.8246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:01:33,851 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:01:33,852 - INFO - Accuracy: 0.6245\n",
      "2025-02-16 00:01:33,852 - INFO - F1_score: 0.4235\n",
      "2025-02-16 00:01:33,853 - INFO - Precision: 0.3214\n",
      "2025-02-16 00:01:33,854 - INFO - Recall: 0.6207\n",
      "2025-02-16 00:01:33,861 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:01:33,861 - INFO - Accuracy: 0.7280\n",
      "2025-02-16 00:01:33,863 - INFO - F1_score: 0.3486\n",
      "2025-02-16 00:01:33,863 - INFO - Precision: 0.2676\n",
      "2025-02-16 00:01:33,864 - INFO - Recall: 0.5000\n",
      "2025-02-16 00:01:33,870 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:01:33,871 - INFO - Accuracy: 0.6284\n",
      "2025-02-16 00:01:33,871 - INFO - F1_score: 0.3490\n",
      "2025-02-16 00:01:33,880 - INFO - Precision: 0.2261\n",
      "2025-02-16 00:01:33,881 - INFO - Recall: 0.7647\n",
      "2025-02-16 00:01:33,882 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 00:01:37,657 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:01:37,658 - INFO - Memory usage after evaluation end: 3606.82 MB\n",
      "2025-02-16 00:01:37,659 - INFO - Trial 19, Epoch 1: Loss = 1.5434, F1 = 0.4250\n",
      "2025-02-16 00:01:37,661 - ERROR - Error in trial training: \n",
      "2025-02-16 00:01:38,950 - ERROR - Error in optimization objective: \n",
      "2025-02-16 00:01:38,951 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 00:01:38,953] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:01:40,022 - INFO - \n",
      "Hyperparameter Optimization Results:\n",
      "2025-02-16 00:01:40,027 - INFO - Best trial number: 13\n",
      "2025-02-16 00:01:40,028 - INFO - Best F1-score: 0.5154\n",
      "2025-02-16 00:01:40,029 - INFO - \n",
      "Best hyperparameters:\n",
      "2025-02-16 00:01:40,030 - INFO - batch_size: 16\n",
      "2025-02-16 00:01:40,031 - INFO - learning_rate: 2e-05\n",
      "2025-02-16 00:01:40,031 - INFO - weight_decay: 0.01\n",
      "2025-02-16 00:01:40,032 - INFO - mixup_prob: 0.2\n",
      "2025-02-16 00:01:40,033 - INFO - smoothing: 0.1\n",
      "2025-02-16 00:01:40,942 - WARNING - Could not create optimization plots: \n",
      "Image export using the \"kaleido\" engine requires the kaleido package,\n",
      "which can be installed using pip:\n",
      "    $ pip install -U kaleido\n",
      "\n",
      "2025-02-16 00:01:42,089 - INFO - \n",
      "Best Hyperparameters found:\n",
      "2025-02-16 00:01:42,091 - INFO - batch_size: 16\n",
      "2025-02-16 00:01:42,092 - INFO - learning_rate: 2e-05\n",
      "2025-02-16 00:01:42,093 - INFO - weight_decay: 0.01\n",
      "2025-02-16 00:01:42,094 - INFO - mixup_prob: 0.2\n",
      "2025-02-16 00:01:42,094 - INFO - smoothing: 0.1\n",
      "2025-02-16 00:01:42,095 - INFO - \n",
      "Training final model with optimized parameters...\n",
      "2025-02-16 00:01:42,097 - INFO - Starting model training\n",
      "2025-02-16 00:01:42,098 - INFO - Memory usage after training start: 3594.02 MB\n",
      "2025-02-16 00:01:42,119 - INFO - Loading and preprocessing data...\n",
      "2025-02-16 00:01:42,120 - INFO - Memory usage after start: 3594.02 MB\n",
      "2025-02-16 00:01:42,133 - INFO - Successfully loaded data using utf-8 encoding\n",
      "2025-02-16 00:01:42,134 - INFO - Memory usage after data loading: 3594.14 MB\n",
      "2025-02-16 00:01:42,135 - INFO - Using full dataset with 1738 samples\n",
      "2025-02-16 00:01:42,136 - INFO - \n",
      "Sample data:\n",
      "2025-02-16 00:01:42,137 - INFO - \n",
      "Sample 1:\n",
      "2025-02-16 00:01:42,138 - INFO - Synopsis: Setelah kematian yang tampak, Siena mampu melihat tanda-tanda bahwa orang-orang akan meninggal. Namu...\n",
      "2025-02-16 00:01:42,139 - INFO - Genre: Horor\n",
      "2025-02-16 00:01:42,139 - INFO - \n",
      "Sample 2:\n",
      "2025-02-16 00:01:42,141 - INFO - Synopsis: Alfi (Al Ghazali) bertemu dengan Alana (Caitlin Halderman), seorang siswa baru di sekolahnya. Ternya...\n",
      "2025-02-16 00:01:42,142 - INFO - Genre: Drama\n",
      "2025-02-16 00:01:42,142 - INFO - \n",
      "Sample 3:\n",
      "2025-02-16 00:01:42,143 - INFO - Synopsis: Ketika gaji staf di sekolahnya dicuri, seorang guru baru yang enggan berusaha untuk mendapatkan kemb...\n",
      "2025-02-16 00:01:42,144 - INFO - Genre: Komedi\n",
      "2025-02-16 00:01:42,145 - INFO - \n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1738/1738 [00:00<00:00, 14551.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:01:42,272 - INFO - Memory usage after preprocessing: 3594.89 MB\n",
      "2025-02-16 00:01:42,273 - INFO - \n",
      "Dataset statistics:\n",
      "2025-02-16 00:01:42,274 - INFO - Total samples after preprocessing: 1738\n",
      "2025-02-16 00:01:42,279 - INFO - Genre 'Drama': 510 samples\n",
      "2025-02-16 00:01:42,279 - INFO - Genre 'Horor': 349 samples\n",
      "2025-02-16 00:01:42,280 - INFO - Genre 'Komedi': 374 samples\n",
      "2025-02-16 00:01:42,280 - INFO - Genre 'Laga': 297 samples\n",
      "2025-02-16 00:01:42,282 - INFO - Genre 'Romantis': 208 samples\n",
      "2025-02-16 00:01:42,283 - INFO - \n",
      "Training set size: 1477\n",
      "2025-02-16 00:01:42,284 - INFO - Testing set size: 261\n",
      "2025-02-16 00:01:42,284 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:01:43,407 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 00:01:43,408 - INFO - Setting up data loaders...\n",
      "2025-02-16 00:01:43,409 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 00:01:43,412 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 00:01:43,413 - INFO - Created data loaders with batch size 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=1.6268]\u001b[A\n",
      "Epoch 1:   1%|          | 1/148 [00:01<02:55,  1.20s/it, training_loss=1.6268]\u001b[A\n",
      "Epoch 1:   1%|          | 1/148 [00:02<02:55,  1.20s/it, training_loss=1.6441]\u001b[A\n",
      "Epoch 1:   1%|▏         | 2/148 [00:02<02:38,  1.09s/it, training_loss=1.6441]\u001b[A\n",
      "Epoch 1:   1%|▏         | 2/148 [00:03<02:38,  1.09s/it, training_loss=1.7695]\u001b[A\n",
      "Epoch 1:   2%|▏         | 3/148 [00:03<02:32,  1.05s/it, training_loss=1.7695]\u001b[A\n",
      "Epoch 1:   2%|▏         | 3/148 [00:04<02:32,  1.05s/it, training_loss=1.7077]\u001b[A\n",
      "Epoch 1:   3%|▎         | 4/148 [00:04<02:29,  1.04s/it, training_loss=1.7077]\u001b[A\n",
      "Epoch 1:   3%|▎         | 4/148 [00:05<02:29,  1.04s/it, training_loss=1.5704]\u001b[A\n",
      "Epoch 1:   3%|▎         | 5/148 [00:05<02:28,  1.04s/it, training_loss=1.5704]\u001b[A\n",
      "Epoch 1:   3%|▎         | 5/148 [00:06<02:28,  1.04s/it, training_loss=1.5620]\u001b[A\n",
      "Epoch 1:   4%|▍         | 6/148 [00:06<02:27,  1.04s/it, training_loss=1.5620]\u001b[A\n",
      "Epoch 1:   4%|▍         | 6/148 [00:07<02:27,  1.04s/it, training_loss=1.5456]\u001b[A\n",
      "Epoch 1:   5%|▍         | 7/148 [00:07<02:25,  1.03s/it, training_loss=1.5456]\u001b[A\n",
      "Epoch 1:   5%|▍         | 7/148 [00:08<02:25,  1.03s/it, training_loss=1.6036]\u001b[A\n",
      "Epoch 1:   5%|▌         | 8/148 [00:08<02:24,  1.03s/it, training_loss=1.6036]\u001b[A\n",
      "Epoch 1:   5%|▌         | 8/148 [00:09<02:24,  1.03s/it, training_loss=1.6047]\u001b[A\n",
      "Epoch 1:   6%|▌         | 9/148 [00:09<02:23,  1.03s/it, training_loss=1.6047]\u001b[A\n",
      "Epoch 1:   6%|▌         | 9/148 [00:10<02:23,  1.03s/it, training_loss=1.7539]\u001b[A\n",
      "Epoch 1:   7%|▋         | 10/148 [00:10<02:22,  1.03s/it, training_loss=1.7539]\u001b[A\n",
      "Epoch 1:   7%|▋         | 10/148 [00:11<02:22,  1.03s/it, training_loss=1.5768]\u001b[A\n",
      "Epoch 1:   7%|▋         | 11/148 [00:11<02:20,  1.03s/it, training_loss=1.5768]\u001b[A\n",
      "Epoch 1:   7%|▋         | 11/148 [00:12<02:20,  1.03s/it, training_loss=1.5469]\u001b[A\n",
      "Epoch 1:   8%|▊         | 12/148 [00:12<02:20,  1.03s/it, training_loss=1.5469]\u001b[A\n",
      "Epoch 1:   8%|▊         | 12/148 [00:13<02:20,  1.03s/it, training_loss=1.4726]\u001b[A\n",
      "Epoch 1:   9%|▉         | 13/148 [00:13<02:19,  1.03s/it, training_loss=1.4726]\u001b[A\n",
      "Epoch 1:   9%|▉         | 13/148 [00:14<02:19,  1.03s/it, training_loss=1.6042]\u001b[A\n",
      "Epoch 1:   9%|▉         | 14/148 [00:14<02:19,  1.04s/it, training_loss=1.6042]\u001b[A\n",
      "Epoch 1:   9%|▉         | 14/148 [00:15<02:19,  1.04s/it, training_loss=1.6174]\u001b[A\n",
      "Epoch 1:  10%|█         | 15/148 [00:15<02:18,  1.04s/it, training_loss=1.6174]\u001b[A\n",
      "Epoch 1:  10%|█         | 15/148 [00:16<02:18,  1.04s/it, training_loss=1.5215]\u001b[A\n",
      "Epoch 1:  11%|█         | 16/148 [00:16<02:18,  1.05s/it, training_loss=1.5215]\u001b[A\n",
      "Epoch 1:  11%|█         | 16/148 [00:17<02:18,  1.05s/it, training_loss=1.6244]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 17/148 [00:17<02:17,  1.05s/it, training_loss=1.6244]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 17/148 [00:18<02:17,  1.05s/it, training_loss=1.7608]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 18/148 [00:18<02:16,  1.05s/it, training_loss=1.7608]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 18/148 [00:19<02:16,  1.05s/it, training_loss=1.6861]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 19/148 [00:19<02:16,  1.05s/it, training_loss=1.6861]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 19/148 [00:20<02:16,  1.05s/it, training_loss=1.4471]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 20/148 [00:20<02:15,  1.06s/it, training_loss=1.4471]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 20/148 [00:21<02:15,  1.06s/it, training_loss=1.5839]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 21/148 [00:21<02:15,  1.06s/it, training_loss=1.5839]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 21/148 [00:23<02:15,  1.06s/it, training_loss=1.4838]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 22/148 [00:23<02:15,  1.07s/it, training_loss=1.4838]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 22/148 [00:24<02:15,  1.07s/it, training_loss=1.5869]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 23/148 [00:24<02:14,  1.08s/it, training_loss=1.5869]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 23/148 [00:25<02:14,  1.08s/it, training_loss=1.6504]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 24/148 [00:25<02:13,  1.07s/it, training_loss=1.6504]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 24/148 [00:26<02:13,  1.07s/it, training_loss=1.6032]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 25/148 [00:26<02:12,  1.08s/it, training_loss=1.6032]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 25/148 [00:27<02:12,  1.08s/it, training_loss=1.5804]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 26/148 [00:27<02:11,  1.08s/it, training_loss=1.5804]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 26/148 [00:28<02:11,  1.08s/it, training_loss=1.6719]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 27/148 [00:28<02:10,  1.08s/it, training_loss=1.6719]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 27/148 [00:29<02:10,  1.08s/it, training_loss=1.5974]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 28/148 [00:29<02:10,  1.08s/it, training_loss=1.5974]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 28/148 [00:30<02:10,  1.08s/it, training_loss=1.5982]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 29/148 [00:30<02:09,  1.09s/it, training_loss=1.5982]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 29/148 [00:31<02:09,  1.09s/it, training_loss=1.5925]\u001b[A\n",
      "Epoch 1:  20%|██        | 30/148 [00:31<02:08,  1.09s/it, training_loss=1.5925]\u001b[A\n",
      "Epoch 1:  20%|██        | 30/148 [00:32<02:08,  1.09s/it, training_loss=1.6860]\u001b[A\n",
      "Epoch 1:  21%|██        | 31/148 [00:32<02:07,  1.09s/it, training_loss=1.6860]\u001b[A\n",
      "Epoch 1:  21%|██        | 31/148 [00:33<02:07,  1.09s/it, training_loss=1.6171]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 32/148 [00:33<02:06,  1.09s/it, training_loss=1.6171]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 32/148 [00:35<02:06,  1.09s/it, training_loss=1.5912]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 33/148 [00:35<02:05,  1.09s/it, training_loss=1.5912]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 33/148 [00:36<02:05,  1.09s/it, training_loss=1.5179]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 34/148 [00:36<02:04,  1.10s/it, training_loss=1.5179]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 34/148 [00:37<02:04,  1.10s/it, training_loss=1.5679]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 35/148 [00:37<02:03,  1.10s/it, training_loss=1.5679]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 35/148 [00:38<02:03,  1.10s/it, training_loss=1.5634]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 36/148 [00:38<02:02,  1.09s/it, training_loss=1.5634]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 36/148 [00:39<02:02,  1.09s/it, training_loss=1.6090]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 37/148 [00:39<02:01,  1.10s/it, training_loss=1.6090]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 37/148 [00:40<02:01,  1.10s/it, training_loss=1.6409]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 38/148 [00:40<02:00,  1.10s/it, training_loss=1.6409]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 38/148 [00:41<02:00,  1.10s/it, training_loss=1.4829]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 39/148 [00:41<01:59,  1.09s/it, training_loss=1.4829]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 39/148 [00:42<01:59,  1.09s/it, training_loss=1.4816]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 40/148 [00:42<01:57,  1.09s/it, training_loss=1.4816]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 40/148 [00:43<01:57,  1.09s/it, training_loss=1.6646]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 41/148 [00:43<01:56,  1.09s/it, training_loss=1.6646]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 41/148 [00:44<01:56,  1.09s/it, training_loss=1.7417]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 42/148 [00:44<01:54,  1.08s/it, training_loss=1.7417]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 42/148 [00:45<01:54,  1.08s/it, training_loss=1.6440]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 43/148 [00:45<01:53,  1.09s/it, training_loss=1.6440]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 43/148 [00:47<01:53,  1.09s/it, training_loss=1.7102]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 44/148 [00:47<01:52,  1.08s/it, training_loss=1.7102]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 44/148 [00:48<01:52,  1.08s/it, training_loss=1.6371]\u001b[A\n",
      "Epoch 1:  30%|███       | 45/148 [00:48<01:50,  1.08s/it, training_loss=1.6371]\u001b[A\n",
      "Epoch 1:  30%|███       | 45/148 [00:49<01:50,  1.08s/it, training_loss=1.6566]\u001b[A\n",
      "Epoch 1:  31%|███       | 46/148 [00:49<01:49,  1.07s/it, training_loss=1.6566]\u001b[A\n",
      "Epoch 1:  31%|███       | 46/148 [00:50<01:49,  1.07s/it, training_loss=1.5920]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 47/148 [00:50<01:47,  1.07s/it, training_loss=1.5920]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 47/148 [00:51<01:47,  1.07s/it, training_loss=1.6455]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 48/148 [00:51<01:46,  1.06s/it, training_loss=1.6455]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 48/148 [00:52<01:46,  1.06s/it, training_loss=1.6139]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 49/148 [00:52<01:44,  1.06s/it, training_loss=1.6139]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 49/148 [00:53<01:44,  1.06s/it, training_loss=1.5814]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 50/148 [00:53<01:43,  1.06s/it, training_loss=1.5814]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 50/148 [00:54<01:43,  1.06s/it, training_loss=1.5484]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 51/148 [00:54<01:42,  1.06s/it, training_loss=1.5484]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 51/148 [00:55<01:42,  1.06s/it, training_loss=1.6857]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 52/148 [00:55<01:41,  1.06s/it, training_loss=1.6857]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 52/148 [00:56<01:41,  1.06s/it, training_loss=1.6370]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 53/148 [00:56<01:39,  1.05s/it, training_loss=1.6370]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 53/148 [00:57<01:39,  1.05s/it, training_loss=1.4780]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 54/148 [00:57<01:38,  1.05s/it, training_loss=1.4780]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 54/148 [00:58<01:38,  1.05s/it, training_loss=1.6584]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 55/148 [00:58<01:37,  1.04s/it, training_loss=1.6584]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 55/148 [00:59<01:37,  1.04s/it, training_loss=1.5796]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 56/148 [00:59<01:35,  1.04s/it, training_loss=1.5796]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 56/148 [01:00<01:35,  1.04s/it, training_loss=1.5284]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 57/148 [01:00<01:34,  1.04s/it, training_loss=1.5284]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 57/148 [01:01<01:34,  1.04s/it, training_loss=1.5162]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 58/148 [01:01<01:33,  1.04s/it, training_loss=1.5162]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 58/148 [01:02<01:33,  1.04s/it, training_loss=1.6192]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 59/148 [01:02<01:32,  1.04s/it, training_loss=1.6192]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 59/148 [01:03<01:32,  1.04s/it, training_loss=1.5388]\u001b[A\n",
      "Epoch 1:  41%|████      | 60/148 [01:03<01:31,  1.03s/it, training_loss=1.5388]\u001b[A\n",
      "Epoch 1:  41%|████      | 60/148 [01:04<01:31,  1.03s/it, training_loss=1.5328]\u001b[A\n",
      "Epoch 1:  41%|████      | 61/148 [01:04<01:29,  1.03s/it, training_loss=1.5328]\u001b[A\n",
      "Epoch 1:  41%|████      | 61/148 [01:05<01:29,  1.03s/it, training_loss=1.5579]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 62/148 [01:05<01:29,  1.04s/it, training_loss=1.5579]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 62/148 [01:06<01:29,  1.04s/it, training_loss=1.6147]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 63/148 [01:06<01:27,  1.03s/it, training_loss=1.6147]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 63/148 [01:07<01:27,  1.03s/it, training_loss=1.5084]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 64/148 [01:07<01:27,  1.04s/it, training_loss=1.5084]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 64/148 [01:08<01:27,  1.04s/it, training_loss=1.5642]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 65/148 [01:08<01:25,  1.03s/it, training_loss=1.5642]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 65/148 [01:09<01:25,  1.03s/it, training_loss=1.5152]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 66/148 [01:09<01:24,  1.03s/it, training_loss=1.5152]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 66/148 [01:11<01:24,  1.03s/it, training_loss=1.5326]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 67/148 [01:11<01:23,  1.03s/it, training_loss=1.5326]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 67/148 [01:12<01:23,  1.03s/it, training_loss=1.4701]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 68/148 [01:12<01:22,  1.03s/it, training_loss=1.4701]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 68/148 [01:13<01:22,  1.03s/it, training_loss=1.5535]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 69/148 [01:13<01:21,  1.03s/it, training_loss=1.5535]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 69/148 [01:14<01:21,  1.03s/it, training_loss=1.5590]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 70/148 [01:14<01:20,  1.03s/it, training_loss=1.5590]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 70/148 [01:15<01:20,  1.03s/it, training_loss=1.6313]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 71/148 [01:15<01:19,  1.03s/it, training_loss=1.6313]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 71/148 [01:16<01:19,  1.03s/it, training_loss=1.5619]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 72/148 [01:16<01:18,  1.03s/it, training_loss=1.5619]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 72/148 [01:17<01:18,  1.03s/it, training_loss=1.5112]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 73/148 [01:17<01:16,  1.02s/it, training_loss=1.5112]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 73/148 [01:18<01:16,  1.02s/it, training_loss=1.6140]\u001b[A\n",
      "Epoch 1:  50%|█████     | 74/148 [01:18<01:15,  1.02s/it, training_loss=1.6140]\u001b[A\n",
      "Epoch 1:  50%|█████     | 74/148 [01:19<01:15,  1.02s/it, training_loss=1.4499]\u001b[A\n",
      "Epoch 1:  51%|█████     | 75/148 [01:19<01:14,  1.02s/it, training_loss=1.4499]\u001b[A\n",
      "Epoch 1:  51%|█████     | 75/148 [01:20<01:14,  1.02s/it, training_loss=1.6493]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 76/148 [01:20<01:13,  1.02s/it, training_loss=1.6493]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 76/148 [01:21<01:13,  1.02s/it, training_loss=1.6966]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 77/148 [01:21<01:12,  1.03s/it, training_loss=1.6966]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 77/148 [01:22<01:12,  1.03s/it, training_loss=1.5399]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 78/148 [01:22<01:11,  1.03s/it, training_loss=1.5399]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 78/148 [01:23<01:11,  1.03s/it, training_loss=1.5446]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 79/148 [01:23<01:10,  1.02s/it, training_loss=1.5446]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 79/148 [01:24<01:10,  1.02s/it, training_loss=1.6643]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 80/148 [01:24<01:09,  1.03s/it, training_loss=1.6643]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 80/148 [01:25<01:09,  1.03s/it, training_loss=1.5349]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 81/148 [01:25<01:08,  1.03s/it, training_loss=1.5349]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 81/148 [01:26<01:08,  1.03s/it, training_loss=1.5005]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 82/148 [01:26<01:08,  1.03s/it, training_loss=1.5005]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 82/148 [01:27<01:08,  1.03s/it, training_loss=1.5317]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 83/148 [01:27<01:07,  1.03s/it, training_loss=1.5317]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 83/148 [01:28<01:07,  1.03s/it, training_loss=1.4409]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 84/148 [01:28<01:06,  1.04s/it, training_loss=1.4409]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 84/148 [01:29<01:06,  1.04s/it, training_loss=1.6505]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 85/148 [01:29<01:05,  1.04s/it, training_loss=1.6505]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 85/148 [01:30<01:05,  1.04s/it, training_loss=1.5348]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 86/148 [01:30<01:04,  1.04s/it, training_loss=1.5348]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 86/148 [01:31<01:04,  1.04s/it, training_loss=1.5033]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 87/148 [01:31<01:03,  1.05s/it, training_loss=1.5033]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 87/148 [01:32<01:03,  1.05s/it, training_loss=1.5495]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 88/148 [01:32<01:02,  1.04s/it, training_loss=1.5495]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 88/148 [01:33<01:02,  1.04s/it, training_loss=1.8245]\u001b[A\n",
      "Epoch 1:  60%|██████    | 89/148 [01:33<01:01,  1.04s/it, training_loss=1.8245]\u001b[A\n",
      "Epoch 1:  60%|██████    | 89/148 [01:34<01:01,  1.04s/it, training_loss=1.6549]\u001b[A\n",
      "Epoch 1:  61%|██████    | 90/148 [01:34<01:00,  1.04s/it, training_loss=1.6549]\u001b[A\n",
      "Epoch 1:  61%|██████    | 90/148 [01:35<01:00,  1.04s/it, training_loss=1.5003]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 91/148 [01:35<00:59,  1.04s/it, training_loss=1.5003]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 91/148 [01:36<00:59,  1.04s/it, training_loss=1.6206]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 92/148 [01:36<00:58,  1.04s/it, training_loss=1.6206]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 92/148 [01:37<00:58,  1.04s/it, training_loss=1.6041]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 93/148 [01:37<00:57,  1.05s/it, training_loss=1.6041]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 93/148 [01:38<00:57,  1.05s/it, training_loss=1.7374]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 94/148 [01:38<00:56,  1.05s/it, training_loss=1.7374]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 94/148 [01:40<00:56,  1.05s/it, training_loss=1.5298]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 95/148 [01:40<00:55,  1.05s/it, training_loss=1.5298]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 95/148 [01:41<00:55,  1.05s/it, training_loss=1.3963]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 96/148 [01:41<00:54,  1.05s/it, training_loss=1.3963]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 96/148 [01:42<00:54,  1.05s/it, training_loss=1.6066]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 97/148 [01:42<00:53,  1.05s/it, training_loss=1.6066]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 97/148 [01:43<00:53,  1.05s/it, training_loss=1.4718]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 98/148 [01:43<00:52,  1.06s/it, training_loss=1.4718]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 98/148 [01:44<00:52,  1.06s/it, training_loss=1.6247]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 99/148 [01:44<00:51,  1.06s/it, training_loss=1.6247]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 99/148 [01:45<00:51,  1.06s/it, training_loss=1.4357]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 100/148 [01:45<00:50,  1.06s/it, training_loss=1.4357]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 100/148 [01:46<00:50,  1.06s/it, training_loss=1.5915]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 101/148 [01:46<00:49,  1.06s/it, training_loss=1.5915]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 101/148 [01:47<00:49,  1.06s/it, training_loss=1.4699]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 102/148 [01:47<00:48,  1.06s/it, training_loss=1.4699]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 102/148 [01:48<00:48,  1.06s/it, training_loss=1.5418]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 103/148 [01:48<00:47,  1.05s/it, training_loss=1.5418]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 103/148 [01:49<00:47,  1.05s/it, training_loss=1.6168]\u001b[A\n",
      "Epoch 1:  70%|███████   | 104/148 [01:49<00:46,  1.06s/it, training_loss=1.6168]\u001b[A\n",
      "Epoch 1:  70%|███████   | 104/148 [01:50<00:46,  1.06s/it, training_loss=1.3397]\u001b[A\n",
      "Epoch 1:  71%|███████   | 105/148 [01:50<00:45,  1.06s/it, training_loss=1.3397]\u001b[A\n",
      "Epoch 1:  71%|███████   | 105/148 [01:51<00:45,  1.06s/it, training_loss=1.5490]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 106/148 [01:51<00:44,  1.06s/it, training_loss=1.5490]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 106/148 [01:52<00:44,  1.06s/it, training_loss=1.6090]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 107/148 [01:52<00:43,  1.06s/it, training_loss=1.6090]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 107/148 [01:53<00:43,  1.06s/it, training_loss=1.7029]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 108/148 [01:53<00:42,  1.06s/it, training_loss=1.7029]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 108/148 [01:54<00:42,  1.06s/it, training_loss=1.6077]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 109/148 [01:54<00:41,  1.06s/it, training_loss=1.6077]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 109/148 [01:55<00:41,  1.06s/it, training_loss=1.6344]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 110/148 [01:55<00:40,  1.06s/it, training_loss=1.6344]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 110/148 [01:56<00:40,  1.06s/it, training_loss=1.4995]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 111/148 [01:56<00:39,  1.06s/it, training_loss=1.4995]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 111/148 [01:58<00:39,  1.06s/it, training_loss=1.5596]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 112/148 [01:58<00:38,  1.06s/it, training_loss=1.5596]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 112/148 [01:59<00:38,  1.06s/it, training_loss=1.5591]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 113/148 [01:59<00:37,  1.06s/it, training_loss=1.5591]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 113/148 [02:00<00:37,  1.06s/it, training_loss=1.6973]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 114/148 [02:00<00:36,  1.06s/it, training_loss=1.6973]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 114/148 [02:01<00:36,  1.06s/it, training_loss=1.4326]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 115/148 [02:01<00:34,  1.06s/it, training_loss=1.4326]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 115/148 [02:02<00:34,  1.06s/it, training_loss=1.5443]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 116/148 [02:02<00:33,  1.06s/it, training_loss=1.5443]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 116/148 [02:03<00:33,  1.06s/it, training_loss=1.5573]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 117/148 [02:03<00:32,  1.05s/it, training_loss=1.5573]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 117/148 [02:04<00:32,  1.05s/it, training_loss=1.3567]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 118/148 [02:04<00:31,  1.06s/it, training_loss=1.3567]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 118/148 [02:05<00:31,  1.06s/it, training_loss=1.5273]\u001b[A\n",
      "Epoch 1:  80%|████████  | 119/148 [02:05<00:30,  1.06s/it, training_loss=1.5273]\u001b[A\n",
      "Epoch 1:  80%|████████  | 119/148 [02:06<00:30,  1.06s/it, training_loss=1.6252]\u001b[A\n",
      "Epoch 1:  81%|████████  | 120/148 [02:06<00:29,  1.06s/it, training_loss=1.6252]\u001b[A\n",
      "Epoch 1:  81%|████████  | 120/148 [02:07<00:29,  1.06s/it, training_loss=1.6663]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 121/148 [02:07<00:28,  1.06s/it, training_loss=1.6663]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 121/148 [02:08<00:28,  1.06s/it, training_loss=1.3618]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 122/148 [02:08<00:27,  1.06s/it, training_loss=1.3618]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 122/148 [02:09<00:27,  1.06s/it, training_loss=1.4266]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 123/148 [02:09<00:26,  1.06s/it, training_loss=1.4266]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 123/148 [02:10<00:26,  1.06s/it, training_loss=1.6744]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 124/148 [02:10<00:25,  1.05s/it, training_loss=1.6744]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 124/148 [02:11<00:25,  1.05s/it, training_loss=1.6598]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 125/148 [02:11<00:24,  1.06s/it, training_loss=1.6598]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 125/148 [02:12<00:24,  1.06s/it, training_loss=1.4495]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 126/148 [02:12<00:23,  1.06s/it, training_loss=1.4495]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 126/148 [02:13<00:23,  1.06s/it, training_loss=1.5469]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 127/148 [02:13<00:22,  1.05s/it, training_loss=1.5469]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 127/148 [02:14<00:22,  1.05s/it, training_loss=1.5467]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 128/148 [02:14<00:21,  1.05s/it, training_loss=1.5467]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 128/148 [02:15<00:21,  1.05s/it, training_loss=1.5552]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 129/148 [02:15<00:19,  1.05s/it, training_loss=1.5552]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 129/148 [02:17<00:19,  1.05s/it, training_loss=1.6191]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 130/148 [02:17<00:18,  1.05s/it, training_loss=1.6191]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 130/148 [02:18<00:18,  1.05s/it, training_loss=1.4561]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 131/148 [02:18<00:17,  1.05s/it, training_loss=1.4561]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 131/148 [02:19<00:17,  1.05s/it, training_loss=1.7400]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 132/148 [02:19<00:16,  1.04s/it, training_loss=1.7400]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 132/148 [02:20<00:16,  1.04s/it, training_loss=1.3485]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 133/148 [02:20<00:15,  1.05s/it, training_loss=1.3485]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 133/148 [02:21<00:15,  1.05s/it, training_loss=1.5977]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 134/148 [02:21<00:14,  1.04s/it, training_loss=1.5977]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 134/148 [02:22<00:14,  1.04s/it, training_loss=1.6273]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 135/148 [02:22<00:13,  1.05s/it, training_loss=1.6273]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 135/148 [02:23<00:13,  1.05s/it, training_loss=1.6113]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 136/148 [02:23<00:12,  1.04s/it, training_loss=1.6113]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 136/148 [02:24<00:12,  1.04s/it, training_loss=1.5783]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 137/148 [02:24<00:11,  1.04s/it, training_loss=1.5783]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 137/148 [02:25<00:11,  1.04s/it, training_loss=1.8174]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 138/148 [02:25<00:10,  1.04s/it, training_loss=1.8174]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 138/148 [02:26<00:10,  1.04s/it, training_loss=1.5646]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 139/148 [02:26<00:09,  1.04s/it, training_loss=1.5646]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 139/148 [02:27<00:09,  1.04s/it, training_loss=1.6449]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 140/148 [02:27<00:08,  1.04s/it, training_loss=1.6449]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 140/148 [02:28<00:08,  1.04s/it, training_loss=1.4774]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 141/148 [02:28<00:07,  1.04s/it, training_loss=1.4774]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 141/148 [02:29<00:07,  1.04s/it, training_loss=1.5241]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 142/148 [02:29<00:06,  1.04s/it, training_loss=1.5241]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 142/148 [02:30<00:06,  1.04s/it, training_loss=1.3803]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 143/148 [02:30<00:05,  1.04s/it, training_loss=1.3803]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 143/148 [02:31<00:05,  1.04s/it, training_loss=1.4576]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 144/148 [02:31<00:04,  1.04s/it, training_loss=1.4576]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 144/148 [02:32<00:04,  1.04s/it, training_loss=1.6302]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 145/148 [02:32<00:03,  1.04s/it, training_loss=1.6302]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 145/148 [02:33<00:03,  1.04s/it, training_loss=1.6389]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 146/148 [02:33<00:02,  1.04s/it, training_loss=1.6389]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 146/148 [02:34<00:02,  1.04s/it, training_loss=1.4711]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 147/148 [02:34<00:01,  1.04s/it, training_loss=1.4711]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 147/148 [02:35<00:01,  1.04s/it, training_loss=1.2778]\u001b[A\n",
      "Epoch 1: 100%|██████████| 148/148 [02:35<00:00,  1.04it/s, training_loss=1.2778]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:04:18,942 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:04:18,944 - INFO - Memory usage after evaluation start: 3653.98 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:08,  3.07it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:08,  3.01it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:08,  2.98it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:07,  2.95it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:07,  2.95it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:02<00:07,  2.94it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:06,  2.93it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:06,  2.94it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:03<00:06,  2.95it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:05,  2.95it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:05,  2.94it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:04<00:05,  2.93it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:04<00:04,  2.93it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:04,  2.93it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:05<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:05<00:03,  2.92it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:03,  2.92it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:06<00:03,  2.92it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:06<00:02,  2.92it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:07<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:07<00:01,  2.92it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:08<00:01,  2.92it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:08<00:00,  2.91it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:08<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:04:27,874 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 00:04:27,892 - INFO - Class 'Drama': Optimal threshold = 0.650, F1 Score = 0.530\n",
      "2025-02-16 00:04:27,908 - INFO - Class 'Horor': Optimal threshold = 0.600, F1 Score = 0.632\n",
      "2025-02-16 00:04:27,922 - INFO - Class 'Komedi': Optimal threshold = 0.450, F1 Score = 0.415\n",
      "2025-02-16 00:04:27,938 - INFO - Class 'Laga': Optimal threshold = 0.650, F1 Score = 0.337\n",
      "2025-02-16 00:04:27,952 - INFO - Class 'Romantis': Optimal threshold = 0.500, F1 Score = 0.385\n",
      "2025-02-16 00:04:27,979 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:04:27,987 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:04:27,988 - INFO - Accuracy: 0.6743\n",
      "2025-02-16 00:04:27,989 - INFO - F1_score: 0.5304\n",
      "2025-02-16 00:04:27,990 - INFO - Precision: 0.4486\n",
      "2025-02-16 00:04:27,992 - INFO - Recall: 0.6486\n",
      "2025-02-16 00:04:27,998 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:04:27,999 - INFO - Accuracy: 0.8352\n",
      "2025-02-16 00:04:28,000 - INFO - F1_score: 0.6325\n",
      "2025-02-16 00:04:28,001 - INFO - Precision: 0.6167\n",
      "2025-02-16 00:04:28,003 - INFO - Recall: 0.6491\n",
      "2025-02-16 00:04:28,011 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:04:28,012 - INFO - Accuracy: 0.3946\n",
      "2025-02-16 00:04:28,013 - INFO - F1_score: 0.4148\n",
      "2025-02-16 00:04:28,016 - INFO - Precision: 0.2642\n",
      "2025-02-16 00:04:28,018 - INFO - Recall: 0.9655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:04:28,028 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:04:28,029 - INFO - Accuracy: 0.7433\n",
      "2025-02-16 00:04:28,030 - INFO - F1_score: 0.3366\n",
      "2025-02-16 00:04:28,031 - INFO - Precision: 0.2698\n",
      "2025-02-16 00:04:28,032 - INFO - Recall: 0.4474\n",
      "2025-02-16 00:04:28,040 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:04:28,040 - INFO - Accuracy: 0.6820\n",
      "2025-02-16 00:04:28,042 - INFO - F1_score: 0.3852\n",
      "2025-02-16 00:04:28,042 - INFO - Precision: 0.2574\n",
      "2025-02-16 00:04:28,043 - INFO - Recall: 0.7647\n",
      "2025-02-16 00:04:28,045 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 00:04:31,844 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:04:31,845 - INFO - Memory usage after evaluation end: 3658.73 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [02:57<?, ?it/s, Train Loss=1.5752, Val Loss=0.0573, Accuracy=0.6659]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:04:40,699 - INFO - New best accuracy: 0.6659\n",
      "2025-02-16 00:04:41,630 - INFO - New best loss: 0.0573\n",
      "2025-02-16 00:04:42,547 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 1/100 [02:59<4:55:33, 179.13s/it, Train Loss=1.5752, Val Loss=0.0573, Accuracy=0.6659]\n",
      "Epoch 2:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=1.6912]\u001b[A\n",
      "Epoch 2:   1%|          | 1/148 [00:01<02:32,  1.04s/it, training_loss=1.6912]\u001b[A\n",
      "Epoch 2:   1%|          | 1/148 [00:02<02:32,  1.04s/it, training_loss=1.7170]\u001b[A\n",
      "Epoch 2:   1%|▏         | 2/148 [00:02<02:30,  1.03s/it, training_loss=1.7170]\u001b[A\n",
      "Epoch 2:   1%|▏         | 2/148 [00:03<02:30,  1.03s/it, training_loss=1.5352]\u001b[A\n",
      "Epoch 2:   2%|▏         | 3/148 [00:03<02:30,  1.04s/it, training_loss=1.5352]\u001b[A\n",
      "Epoch 2:   2%|▏         | 3/148 [00:04<02:30,  1.04s/it, training_loss=1.4469]\u001b[A\n",
      "Epoch 2:   3%|▎         | 4/148 [00:04<02:30,  1.04s/it, training_loss=1.4469]\u001b[A\n",
      "Epoch 2:   3%|▎         | 4/148 [00:05<02:30,  1.04s/it, training_loss=1.4622]\u001b[A\n",
      "Epoch 2:   3%|▎         | 5/148 [00:05<02:29,  1.04s/it, training_loss=1.4622]\u001b[A\n",
      "Epoch 2:   3%|▎         | 5/148 [00:06<02:29,  1.04s/it, training_loss=1.5972]\u001b[A\n",
      "Epoch 2:   4%|▍         | 6/148 [00:06<02:28,  1.05s/it, training_loss=1.5972]\u001b[A\n",
      "Epoch 2:   4%|▍         | 6/148 [00:07<02:28,  1.05s/it, training_loss=1.4968]\u001b[A\n",
      "Epoch 2:   5%|▍         | 7/148 [00:07<02:27,  1.05s/it, training_loss=1.4968]\u001b[A\n",
      "Epoch 2:   5%|▍         | 7/148 [00:08<02:27,  1.05s/it, training_loss=1.3797]\u001b[A\n",
      "Epoch 2:   5%|▌         | 8/148 [00:08<02:26,  1.05s/it, training_loss=1.3797]\u001b[A\n",
      "Epoch 2:   5%|▌         | 8/148 [00:09<02:26,  1.05s/it, training_loss=1.4433]\u001b[A\n",
      "Epoch 2:   6%|▌         | 9/148 [00:09<02:26,  1.05s/it, training_loss=1.4433]\u001b[A\n",
      "Epoch 2:   6%|▌         | 9/148 [00:10<02:26,  1.05s/it, training_loss=1.6356]\u001b[A\n",
      "Epoch 2:   7%|▋         | 10/148 [00:10<02:25,  1.05s/it, training_loss=1.6356]\u001b[A\n",
      "Epoch 2:   7%|▋         | 10/148 [00:11<02:25,  1.05s/it, training_loss=1.4852]\u001b[A\n",
      "Epoch 2:   7%|▋         | 11/148 [00:11<02:24,  1.06s/it, training_loss=1.4852]\u001b[A\n",
      "Epoch 2:   7%|▋         | 11/148 [00:12<02:24,  1.06s/it, training_loss=1.5289]\u001b[A\n",
      "Epoch 2:   8%|▊         | 12/148 [00:12<02:23,  1.06s/it, training_loss=1.5289]\u001b[A\n",
      "Epoch 2:   8%|▊         | 12/148 [00:13<02:23,  1.06s/it, training_loss=1.4934]\u001b[A\n",
      "Epoch 2:   9%|▉         | 13/148 [00:13<02:23,  1.06s/it, training_loss=1.4934]\u001b[A\n",
      "Epoch 2:   9%|▉         | 13/148 [00:14<02:23,  1.06s/it, training_loss=1.4199]\u001b[A\n",
      "Epoch 2:   9%|▉         | 14/148 [00:14<02:22,  1.07s/it, training_loss=1.4199]\u001b[A\n",
      "Epoch 2:   9%|▉         | 14/148 [00:15<02:22,  1.07s/it, training_loss=1.5349]\u001b[A\n",
      "Epoch 2:  10%|█         | 15/148 [00:15<02:21,  1.07s/it, training_loss=1.5349]\u001b[A\n",
      "Epoch 2:  10%|█         | 15/148 [00:16<02:21,  1.07s/it, training_loss=1.6708]\u001b[A\n",
      "Epoch 2:  11%|█         | 16/148 [00:16<02:21,  1.07s/it, training_loss=1.6708]\u001b[A\n",
      "Epoch 2:  11%|█         | 16/148 [00:17<02:21,  1.07s/it, training_loss=1.4326]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 17/148 [00:17<02:20,  1.07s/it, training_loss=1.4326]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 17/148 [00:19<02:20,  1.07s/it, training_loss=1.5848]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 18/148 [00:19<02:19,  1.07s/it, training_loss=1.5848]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 18/148 [00:20<02:19,  1.07s/it, training_loss=1.3938]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 19/148 [00:20<02:18,  1.08s/it, training_loss=1.3938]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 19/148 [00:21<02:18,  1.08s/it, training_loss=1.7085]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 20/148 [00:21<02:17,  1.07s/it, training_loss=1.7085]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 20/148 [00:22<02:17,  1.07s/it, training_loss=1.6387]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 21/148 [00:22<02:16,  1.07s/it, training_loss=1.6387]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 21/148 [00:23<02:16,  1.07s/it, training_loss=1.4209]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 22/148 [00:23<02:15,  1.07s/it, training_loss=1.4209]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 22/148 [00:24<02:15,  1.07s/it, training_loss=1.6870]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 23/148 [00:24<02:14,  1.08s/it, training_loss=1.6870]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 23/148 [00:25<02:14,  1.08s/it, training_loss=1.4458]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 24/148 [00:25<02:13,  1.08s/it, training_loss=1.4458]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 24/148 [00:26<02:13,  1.08s/it, training_loss=1.3936]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 25/148 [00:26<02:12,  1.08s/it, training_loss=1.3936]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 25/148 [00:27<02:12,  1.08s/it, training_loss=1.2970]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 26/148 [00:27<02:11,  1.08s/it, training_loss=1.2970]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 26/148 [00:28<02:11,  1.08s/it, training_loss=1.4311]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 27/148 [00:28<02:10,  1.08s/it, training_loss=1.4311]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 27/148 [00:29<02:10,  1.08s/it, training_loss=1.5189]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 28/148 [00:29<02:09,  1.08s/it, training_loss=1.5189]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 28/148 [00:30<02:09,  1.08s/it, training_loss=1.6738]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 29/148 [00:30<02:07,  1.07s/it, training_loss=1.6738]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 29/148 [00:31<02:07,  1.07s/it, training_loss=1.5538]\u001b[A\n",
      "Epoch 2:  20%|██        | 30/148 [00:31<02:06,  1.07s/it, training_loss=1.5538]\u001b[A\n",
      "Epoch 2:  20%|██        | 30/148 [00:32<02:06,  1.07s/it, training_loss=1.5861]\u001b[A\n",
      "Epoch 2:  21%|██        | 31/148 [00:33<02:05,  1.07s/it, training_loss=1.5861]\u001b[A\n",
      "Epoch 2:  21%|██        | 31/148 [00:34<02:05,  1.07s/it, training_loss=1.5113]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 32/148 [00:34<02:04,  1.07s/it, training_loss=1.5113]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 32/148 [00:35<02:04,  1.07s/it, training_loss=1.5670]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 33/148 [00:35<02:02,  1.06s/it, training_loss=1.5670]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 33/148 [00:36<02:02,  1.06s/it, training_loss=1.4919]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 34/148 [00:36<02:01,  1.06s/it, training_loss=1.4919]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 34/148 [00:37<02:01,  1.06s/it, training_loss=1.5447]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 35/148 [00:37<01:59,  1.06s/it, training_loss=1.5447]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 35/148 [00:38<01:59,  1.06s/it, training_loss=1.6876]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 36/148 [00:38<01:59,  1.06s/it, training_loss=1.6876]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 36/148 [00:39<01:59,  1.06s/it, training_loss=1.5561]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 37/148 [00:39<01:57,  1.06s/it, training_loss=1.5561]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 37/148 [00:40<01:57,  1.06s/it, training_loss=1.4699]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 38/148 [00:40<01:56,  1.06s/it, training_loss=1.4699]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 38/148 [00:41<01:56,  1.06s/it, training_loss=1.6679]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 39/148 [00:41<01:55,  1.06s/it, training_loss=1.6679]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 39/148 [00:42<01:55,  1.06s/it, training_loss=1.5676]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 40/148 [00:42<01:53,  1.05s/it, training_loss=1.5676]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 40/148 [00:43<01:53,  1.05s/it, training_loss=1.5170]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 41/148 [00:43<01:52,  1.05s/it, training_loss=1.5170]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 41/148 [00:44<01:52,  1.05s/it, training_loss=1.5613]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 42/148 [00:44<01:51,  1.05s/it, training_loss=1.5613]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 42/148 [00:45<01:51,  1.05s/it, training_loss=1.5939]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 43/148 [00:45<01:49,  1.05s/it, training_loss=1.5939]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 43/148 [00:46<01:49,  1.05s/it, training_loss=1.5206]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 44/148 [00:46<01:48,  1.04s/it, training_loss=1.5206]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 44/148 [00:47<01:48,  1.04s/it, training_loss=1.3558]\u001b[A\n",
      "Epoch 2:  30%|███       | 45/148 [00:47<01:47,  1.04s/it, training_loss=1.3558]\u001b[A\n",
      "Epoch 2:  30%|███       | 45/148 [00:48<01:47,  1.04s/it, training_loss=1.6188]\u001b[A\n",
      "Epoch 2:  31%|███       | 46/148 [00:48<01:46,  1.04s/it, training_loss=1.6188]\u001b[A\n",
      "Epoch 2:  31%|███       | 46/148 [00:49<01:46,  1.04s/it, training_loss=1.2772]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 47/148 [00:49<01:45,  1.05s/it, training_loss=1.2772]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 47/148 [00:50<01:45,  1.05s/it, training_loss=1.6864]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 48/148 [00:50<01:44,  1.04s/it, training_loss=1.6864]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 48/148 [00:51<01:44,  1.04s/it, training_loss=1.5553]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 49/148 [00:51<01:42,  1.04s/it, training_loss=1.5553]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 49/148 [00:52<01:42,  1.04s/it, training_loss=1.4772]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 50/148 [00:52<01:41,  1.04s/it, training_loss=1.4772]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 50/148 [00:53<01:41,  1.04s/it, training_loss=1.4106]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 51/148 [00:53<01:40,  1.04s/it, training_loss=1.4106]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 51/148 [00:55<01:40,  1.04s/it, training_loss=1.4398]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 52/148 [00:55<01:40,  1.04s/it, training_loss=1.4398]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 52/148 [00:56<01:40,  1.04s/it, training_loss=1.5015]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 53/148 [00:56<01:38,  1.04s/it, training_loss=1.5015]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 53/148 [00:57<01:38,  1.04s/it, training_loss=1.4195]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 54/148 [00:57<01:37,  1.04s/it, training_loss=1.4195]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 54/148 [00:58<01:37,  1.04s/it, training_loss=1.5552]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 55/148 [00:58<01:36,  1.04s/it, training_loss=1.5552]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 55/148 [00:59<01:36,  1.04s/it, training_loss=1.4194]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 56/148 [00:59<01:35,  1.04s/it, training_loss=1.4194]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 56/148 [01:00<01:35,  1.04s/it, training_loss=1.3442]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 57/148 [01:00<01:34,  1.04s/it, training_loss=1.3442]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 57/148 [01:01<01:34,  1.04s/it, training_loss=1.3142]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 58/148 [01:01<01:34,  1.04s/it, training_loss=1.3142]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 58/148 [01:02<01:34,  1.04s/it, training_loss=1.5391]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 59/148 [01:02<01:32,  1.04s/it, training_loss=1.5391]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 59/148 [01:03<01:32,  1.04s/it, training_loss=1.5775]\u001b[A\n",
      "Epoch 2:  41%|████      | 60/148 [01:03<01:31,  1.04s/it, training_loss=1.5775]\u001b[A\n",
      "Epoch 2:  41%|████      | 60/148 [01:04<01:31,  1.04s/it, training_loss=1.5740]\u001b[A\n",
      "Epoch 2:  41%|████      | 61/148 [01:04<01:30,  1.04s/it, training_loss=1.5740]\u001b[A\n",
      "Epoch 2:  41%|████      | 61/148 [01:05<01:30,  1.04s/it, training_loss=1.3637]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 62/148 [01:05<01:29,  1.04s/it, training_loss=1.3637]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 62/148 [01:06<01:29,  1.04s/it, training_loss=1.3399]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 63/148 [01:06<01:28,  1.04s/it, training_loss=1.3399]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 63/148 [01:07<01:28,  1.04s/it, training_loss=1.3539]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 64/148 [01:07<01:27,  1.05s/it, training_loss=1.3539]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 64/148 [01:08<01:27,  1.05s/it, training_loss=1.5975]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 65/148 [01:08<01:26,  1.04s/it, training_loss=1.5975]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 65/148 [01:09<01:26,  1.04s/it, training_loss=1.4082]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 66/148 [01:09<01:25,  1.04s/it, training_loss=1.4082]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 66/148 [01:10<01:25,  1.04s/it, training_loss=1.3891]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 67/148 [01:10<01:24,  1.04s/it, training_loss=1.3891]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 67/148 [01:11<01:24,  1.04s/it, training_loss=1.4828]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 68/148 [01:11<01:22,  1.04s/it, training_loss=1.4828]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 68/148 [01:12<01:22,  1.04s/it, training_loss=1.5449]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 69/148 [01:12<01:21,  1.04s/it, training_loss=1.5449]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 69/148 [01:13<01:21,  1.04s/it, training_loss=1.5834]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 70/148 [01:13<01:20,  1.03s/it, training_loss=1.5834]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 70/148 [01:14<01:20,  1.03s/it, training_loss=1.5488]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 71/148 [01:14<01:19,  1.03s/it, training_loss=1.5488]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 71/148 [01:15<01:19,  1.03s/it, training_loss=1.5077]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 72/148 [01:15<01:18,  1.03s/it, training_loss=1.5077]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 72/148 [01:16<01:18,  1.03s/it, training_loss=1.4177]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 73/148 [01:16<01:17,  1.04s/it, training_loss=1.4177]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 73/148 [01:17<01:17,  1.04s/it, training_loss=1.4602]\u001b[A\n",
      "Epoch 2:  50%|█████     | 74/148 [01:17<01:16,  1.04s/it, training_loss=1.4602]\u001b[A\n",
      "Epoch 2:  50%|█████     | 74/148 [01:18<01:16,  1.04s/it, training_loss=1.3497]\u001b[A\n",
      "Epoch 2:  51%|█████     | 75/148 [01:18<01:15,  1.04s/it, training_loss=1.3497]\u001b[A\n",
      "Epoch 2:  51%|█████     | 75/148 [01:19<01:15,  1.04s/it, training_loss=1.2855]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 76/148 [01:19<01:15,  1.04s/it, training_loss=1.2855]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 76/148 [01:20<01:15,  1.04s/it, training_loss=1.4904]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 77/148 [01:20<01:13,  1.04s/it, training_loss=1.4904]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 77/148 [01:22<01:13,  1.04s/it, training_loss=1.4897]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 78/148 [01:22<01:12,  1.04s/it, training_loss=1.4897]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 78/148 [01:23<01:12,  1.04s/it, training_loss=1.4756]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 79/148 [01:23<01:11,  1.04s/it, training_loss=1.4756]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 79/148 [01:24<01:11,  1.04s/it, training_loss=1.5354]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 80/148 [01:24<01:10,  1.04s/it, training_loss=1.5354]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 80/148 [01:25<01:10,  1.04s/it, training_loss=1.3845]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 81/148 [01:25<01:10,  1.04s/it, training_loss=1.3845]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 81/148 [01:26<01:10,  1.04s/it, training_loss=1.6667]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 82/148 [01:26<01:08,  1.04s/it, training_loss=1.6667]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 82/148 [01:27<01:08,  1.04s/it, training_loss=1.3902]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 83/148 [01:27<01:07,  1.05s/it, training_loss=1.3902]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 83/148 [01:28<01:07,  1.05s/it, training_loss=1.2767]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 84/148 [01:28<01:07,  1.05s/it, training_loss=1.2767]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 84/148 [01:29<01:07,  1.05s/it, training_loss=1.2908]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 85/148 [01:29<01:06,  1.05s/it, training_loss=1.2908]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 85/148 [01:30<01:06,  1.05s/it, training_loss=1.7430]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 86/148 [01:30<01:05,  1.05s/it, training_loss=1.7430]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 86/148 [01:31<01:05,  1.05s/it, training_loss=1.4214]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 87/148 [01:31<01:04,  1.05s/it, training_loss=1.4214]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 87/148 [01:32<01:04,  1.05s/it, training_loss=1.5926]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 88/148 [01:32<01:03,  1.05s/it, training_loss=1.5926]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 88/148 [01:33<01:03,  1.05s/it, training_loss=1.5689]\u001b[A\n",
      "Epoch 2:  60%|██████    | 89/148 [01:33<01:01,  1.05s/it, training_loss=1.5689]\u001b[A\n",
      "Epoch 2:  60%|██████    | 89/148 [01:34<01:01,  1.05s/it, training_loss=1.3758]\u001b[A\n",
      "Epoch 2:  61%|██████    | 90/148 [01:34<01:00,  1.05s/it, training_loss=1.3758]\u001b[A\n",
      "Epoch 2:  61%|██████    | 90/148 [01:35<01:00,  1.05s/it, training_loss=1.4562]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 91/148 [01:35<00:59,  1.05s/it, training_loss=1.4562]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 91/148 [01:36<00:59,  1.05s/it, training_loss=1.4598]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 92/148 [01:36<00:58,  1.05s/it, training_loss=1.4598]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 92/148 [01:37<00:58,  1.05s/it, training_loss=1.1544]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 93/148 [01:37<00:57,  1.05s/it, training_loss=1.1544]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 93/148 [01:38<00:57,  1.05s/it, training_loss=1.4436]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 94/148 [01:38<00:56,  1.05s/it, training_loss=1.4436]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 94/148 [01:39<00:56,  1.05s/it, training_loss=1.5983]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 95/148 [01:39<00:55,  1.06s/it, training_loss=1.5983]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 95/148 [01:40<00:55,  1.06s/it, training_loss=1.5751]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 96/148 [01:40<00:54,  1.06s/it, training_loss=1.5751]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 96/148 [01:42<00:54,  1.06s/it, training_loss=1.2445]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 97/148 [01:42<00:53,  1.06s/it, training_loss=1.2445]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 97/148 [01:43<00:53,  1.06s/it, training_loss=1.3788]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 98/148 [01:43<00:53,  1.06s/it, training_loss=1.3788]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 98/148 [01:44<00:53,  1.06s/it, training_loss=1.5652]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 99/148 [01:44<00:51,  1.06s/it, training_loss=1.5652]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 99/148 [01:45<00:51,  1.06s/it, training_loss=1.3243]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 100/148 [01:45<00:50,  1.06s/it, training_loss=1.3243]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 100/148 [01:46<00:50,  1.06s/it, training_loss=1.5089]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 101/148 [01:46<00:49,  1.06s/it, training_loss=1.5089]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 101/148 [01:47<00:49,  1.06s/it, training_loss=1.6635]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 102/148 [01:47<00:48,  1.06s/it, training_loss=1.6635]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 102/148 [01:48<00:48,  1.06s/it, training_loss=1.4840]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 103/148 [01:48<00:47,  1.06s/it, training_loss=1.4840]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 103/148 [01:49<00:47,  1.06s/it, training_loss=1.2094]\u001b[A\n",
      "Epoch 2:  70%|███████   | 104/148 [01:49<00:46,  1.06s/it, training_loss=1.2094]\u001b[A\n",
      "Epoch 2:  70%|███████   | 104/148 [01:50<00:46,  1.06s/it, training_loss=1.6497]\u001b[A\n",
      "Epoch 2:  71%|███████   | 105/148 [01:50<00:45,  1.06s/it, training_loss=1.6497]\u001b[A\n",
      "Epoch 2:  71%|███████   | 105/148 [01:51<00:45,  1.06s/it, training_loss=1.4140]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 106/148 [01:51<00:44,  1.06s/it, training_loss=1.4140]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 106/148 [01:52<00:44,  1.06s/it, training_loss=1.6058]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 107/148 [01:52<00:43,  1.06s/it, training_loss=1.6058]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 107/148 [01:53<00:43,  1.06s/it, training_loss=1.3020]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 108/148 [01:53<00:42,  1.06s/it, training_loss=1.3020]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 108/148 [01:54<00:42,  1.06s/it, training_loss=1.4456]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 109/148 [01:54<00:41,  1.06s/it, training_loss=1.4456]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 109/148 [01:55<00:41,  1.06s/it, training_loss=1.6053]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 110/148 [01:55<00:40,  1.06s/it, training_loss=1.6053]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 110/148 [01:56<00:40,  1.06s/it, training_loss=1.2733]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 111/148 [01:56<00:39,  1.06s/it, training_loss=1.2733]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 111/148 [01:57<00:39,  1.06s/it, training_loss=1.6579]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 112/148 [01:57<00:38,  1.06s/it, training_loss=1.6579]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 112/148 [01:58<00:38,  1.06s/it, training_loss=1.5179]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 113/148 [01:58<00:37,  1.06s/it, training_loss=1.5179]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 113/148 [02:00<00:37,  1.06s/it, training_loss=1.2769]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 114/148 [02:00<00:36,  1.06s/it, training_loss=1.2769]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 114/148 [02:01<00:36,  1.06s/it, training_loss=1.4897]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 115/148 [02:01<00:34,  1.06s/it, training_loss=1.4897]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 115/148 [02:02<00:34,  1.06s/it, training_loss=1.6509]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 116/148 [02:02<00:33,  1.05s/it, training_loss=1.6509]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 116/148 [02:03<00:33,  1.05s/it, training_loss=1.2917]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 117/148 [02:03<00:32,  1.06s/it, training_loss=1.2917]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 117/148 [02:04<00:32,  1.06s/it, training_loss=1.5980]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 118/148 [02:04<00:31,  1.06s/it, training_loss=1.5980]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 118/148 [02:05<00:31,  1.06s/it, training_loss=1.3572]\u001b[A\n",
      "Epoch 2:  80%|████████  | 119/148 [02:05<00:30,  1.05s/it, training_loss=1.3572]\u001b[A\n",
      "Epoch 2:  80%|████████  | 119/148 [02:06<00:30,  1.05s/it, training_loss=1.2663]\u001b[A\n",
      "Epoch 2:  81%|████████  | 120/148 [02:06<00:29,  1.06s/it, training_loss=1.2663]\u001b[A\n",
      "Epoch 2:  81%|████████  | 120/148 [02:07<00:29,  1.06s/it, training_loss=1.3777]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 121/148 [02:07<00:28,  1.06s/it, training_loss=1.3777]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 121/148 [02:08<00:28,  1.06s/it, training_loss=1.3451]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 122/148 [02:08<00:27,  1.06s/it, training_loss=1.3451]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 122/148 [02:09<00:27,  1.06s/it, training_loss=1.3493]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 123/148 [02:09<00:26,  1.05s/it, training_loss=1.3493]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 123/148 [02:10<00:26,  1.05s/it, training_loss=1.6452]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 124/148 [02:10<00:25,  1.05s/it, training_loss=1.6452]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 124/148 [02:11<00:25,  1.05s/it, training_loss=1.2488]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 125/148 [02:11<00:24,  1.06s/it, training_loss=1.2488]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 125/148 [02:12<00:24,  1.06s/it, training_loss=1.4979]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 126/148 [02:12<00:23,  1.05s/it, training_loss=1.4979]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 126/148 [02:13<00:23,  1.05s/it, training_loss=1.6177]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 127/148 [02:13<00:22,  1.05s/it, training_loss=1.6177]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 127/148 [02:14<00:22,  1.05s/it, training_loss=1.5295]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 128/148 [02:14<00:21,  1.06s/it, training_loss=1.5295]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 128/148 [02:15<00:21,  1.06s/it, training_loss=1.2622]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 129/148 [02:15<00:20,  1.05s/it, training_loss=1.2622]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 129/148 [02:16<00:20,  1.05s/it, training_loss=1.5829]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 130/148 [02:16<00:18,  1.05s/it, training_loss=1.5829]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 130/148 [02:17<00:18,  1.05s/it, training_loss=1.5509]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 131/148 [02:17<00:17,  1.05s/it, training_loss=1.5509]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 131/148 [02:18<00:17,  1.05s/it, training_loss=1.2916]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 132/148 [02:18<00:16,  1.05s/it, training_loss=1.2916]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 132/148 [02:20<00:16,  1.05s/it, training_loss=1.5764]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 133/148 [02:20<00:15,  1.05s/it, training_loss=1.5764]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 133/148 [02:21<00:15,  1.05s/it, training_loss=1.7294]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 134/148 [02:21<00:14,  1.05s/it, training_loss=1.7294]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 134/148 [02:22<00:14,  1.05s/it, training_loss=1.4093]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 135/148 [02:22<00:13,  1.05s/it, training_loss=1.4093]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 135/148 [02:23<00:13,  1.05s/it, training_loss=1.5936]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 136/148 [02:23<00:12,  1.05s/it, training_loss=1.5936]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 136/148 [02:24<00:12,  1.05s/it, training_loss=1.5223]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 137/148 [02:24<00:11,  1.05s/it, training_loss=1.5223]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 137/148 [02:25<00:11,  1.05s/it, training_loss=1.6425]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 138/148 [02:25<00:10,  1.05s/it, training_loss=1.6425]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 138/148 [02:26<00:10,  1.05s/it, training_loss=1.4063]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 139/148 [02:26<00:09,  1.05s/it, training_loss=1.4063]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 139/148 [02:27<00:09,  1.05s/it, training_loss=1.1409]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 140/148 [02:27<00:08,  1.05s/it, training_loss=1.1409]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 140/148 [02:28<00:08,  1.05s/it, training_loss=1.5448]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 141/148 [02:28<00:07,  1.05s/it, training_loss=1.5448]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 141/148 [02:29<00:07,  1.05s/it, training_loss=1.6074]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 142/148 [02:29<00:06,  1.04s/it, training_loss=1.6074]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 142/148 [02:30<00:06,  1.04s/it, training_loss=1.3397]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 143/148 [02:30<00:05,  1.04s/it, training_loss=1.3397]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 143/148 [02:31<00:05,  1.04s/it, training_loss=1.2200]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 144/148 [02:31<00:04,  1.05s/it, training_loss=1.2200]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 144/148 [02:32<00:04,  1.05s/it, training_loss=1.6099]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 145/148 [02:32<00:03,  1.05s/it, training_loss=1.6099]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 145/148 [02:33<00:03,  1.05s/it, training_loss=1.6210]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 146/148 [02:33<00:02,  1.04s/it, training_loss=1.6210]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 146/148 [02:34<00:02,  1.04s/it, training_loss=1.2337]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 147/148 [02:34<00:01,  1.04s/it, training_loss=1.2337]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 147/148 [02:35<00:01,  1.04s/it, training_loss=1.2883]\u001b[A\n",
      "Epoch 2: 100%|██████████| 148/148 [02:35<00:00,  1.04it/s, training_loss=1.2883]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:07:17,968 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:07:17,969 - INFO - Memory usage after evaluation start: 3661.33 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:08,  2.98it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:08,  2.94it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:08,  2.94it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:07,  2.95it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:07,  2.95it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:02<00:07,  2.94it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:06,  2.93it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:06,  2.93it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:03<00:06,  2.92it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:05,  2.92it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:04<00:05,  2.92it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:04<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:05<00:04,  2.93it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:05<00:03,  2.95it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:03,  2.94it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:06<00:03,  2.94it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:06<00:02,  2.93it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:06<00:02,  2.92it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:07<00:02,  2.92it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:07<00:01,  2.92it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:07<00:01,  2.93it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:08<00:01,  2.94it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:08<00:00,  2.94it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:08<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:07:26,887 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 00:07:26,901 - INFO - Class 'Drama': Optimal threshold = 0.500, F1 Score = 0.541\n",
      "2025-02-16 00:07:26,916 - INFO - Class 'Horor': Optimal threshold = 0.550, F1 Score = 0.748\n",
      "2025-02-16 00:07:26,930 - INFO - Class 'Komedi': Optimal threshold = 0.600, F1 Score = 0.497\n",
      "2025-02-16 00:07:26,944 - INFO - Class 'Laga': Optimal threshold = 0.750, F1 Score = 0.395\n",
      "2025-02-16 00:07:26,958 - INFO - Class 'Romantis': Optimal threshold = 0.750, F1 Score = 0.431\n",
      "2025-02-16 00:07:26,979 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:07:26,985 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:07:26,985 - INFO - Accuracy: 0.6552\n",
      "2025-02-16 00:07:26,986 - INFO - F1_score: 0.5408\n",
      "2025-02-16 00:07:26,988 - INFO - Precision: 0.4344\n",
      "2025-02-16 00:07:26,988 - INFO - Recall: 0.7162\n",
      "2025-02-16 00:07:26,994 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:07:26,994 - INFO - Accuracy: 0.8659\n",
      "2025-02-16 00:07:26,995 - INFO - F1_score: 0.7482\n",
      "2025-02-16 00:07:26,996 - INFO - Precision: 0.6341\n",
      "2025-02-16 00:07:26,998 - INFO - Recall: 0.9123\n",
      "2025-02-16 00:07:27,003 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:07:27,003 - INFO - Accuracy: 0.6897\n",
      "2025-02-16 00:07:27,004 - INFO - F1_score: 0.4969\n",
      "2025-02-16 00:07:27,004 - INFO - Precision: 0.3883\n",
      "2025-02-16 00:07:27,005 - INFO - Recall: 0.6897\n",
      "2025-02-16 00:07:27,012 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:07:27,012 - INFO - Accuracy: 0.8123\n",
      "2025-02-16 00:07:27,013 - INFO - F1_score: 0.3951\n",
      "2025-02-16 00:07:27,014 - INFO - Precision: 0.3721\n",
      "2025-02-16 00:07:27,016 - INFO - Recall: 0.4211\n",
      "2025-02-16 00:07:27,021 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:07:27,021 - INFO - Accuracy: 0.8582\n",
      "2025-02-16 00:07:27,022 - INFO - F1_score: 0.4308\n",
      "2025-02-16 00:07:27,023 - INFO - Precision: 0.4516\n",
      "2025-02-16 00:07:27,023 - INFO - Recall: 0.4118\n",
      "2025-02-16 00:07:27,025 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:07:30,858 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:07:30,860 - INFO - Memory usage after evaluation end: 3682.70 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 1/100 [05:56<4:55:33, 179.13s/it, Train Loss=1.4812, Val Loss=0.0531, Accuracy=0.7762]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:07:39,590 - INFO - New best accuracy: 0.7762\n",
      "2025-02-16 00:07:40,981 - INFO - New best loss: 0.0531\n",
      "2025-02-16 00:07:42,395 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 2/100 [05:58<4:53:16, 179.55s/it, Train Loss=1.4812, Val Loss=0.0531, Accuracy=0.7762]\n",
      "Epoch 3:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=1.5329]\u001b[A\n",
      "Epoch 3:   1%|          | 1/148 [00:01<02:36,  1.06s/it, training_loss=1.5329]\u001b[A\n",
      "Epoch 3:   1%|          | 1/148 [00:02<02:36,  1.06s/it, training_loss=1.4829]\u001b[A\n",
      "Epoch 3:   1%|▏         | 2/148 [00:02<02:32,  1.04s/it, training_loss=1.4829]\u001b[A\n",
      "Epoch 3:   1%|▏         | 2/148 [00:03<02:32,  1.04s/it, training_loss=1.6148]\u001b[A\n",
      "Epoch 3:   2%|▏         | 3/148 [00:03<02:30,  1.04s/it, training_loss=1.6148]\u001b[A\n",
      "Epoch 3:   2%|▏         | 3/148 [00:04<02:30,  1.04s/it, training_loss=1.6529]\u001b[A\n",
      "Epoch 3:   3%|▎         | 4/148 [00:04<02:28,  1.03s/it, training_loss=1.6529]\u001b[A\n",
      "Epoch 3:   3%|▎         | 4/148 [00:05<02:28,  1.03s/it, training_loss=1.6230]\u001b[A\n",
      "Epoch 3:   3%|▎         | 5/148 [00:05<02:27,  1.03s/it, training_loss=1.6230]\u001b[A\n",
      "Epoch 3:   3%|▎         | 5/148 [00:06<02:27,  1.03s/it, training_loss=1.5305]\u001b[A\n",
      "Epoch 3:   4%|▍         | 6/148 [00:06<02:26,  1.03s/it, training_loss=1.5305]\u001b[A\n",
      "Epoch 3:   4%|▍         | 6/148 [00:07<02:26,  1.03s/it, training_loss=1.3923]\u001b[A\n",
      "Epoch 3:   5%|▍         | 7/148 [00:07<02:26,  1.04s/it, training_loss=1.3923]\u001b[A\n",
      "Epoch 3:   5%|▍         | 7/148 [00:08<02:26,  1.04s/it, training_loss=1.2051]\u001b[A\n",
      "Epoch 3:   5%|▌         | 8/148 [00:08<02:26,  1.04s/it, training_loss=1.2051]\u001b[A\n",
      "Epoch 3:   5%|▌         | 8/148 [00:09<02:26,  1.04s/it, training_loss=1.2040]\u001b[A\n",
      "Epoch 3:   6%|▌         | 9/148 [00:09<02:25,  1.05s/it, training_loss=1.2040]\u001b[A\n",
      "Epoch 3:   6%|▌         | 9/148 [00:10<02:25,  1.05s/it, training_loss=1.0599]\u001b[A\n",
      "Epoch 3:   7%|▋         | 10/148 [00:10<02:24,  1.05s/it, training_loss=1.0599]\u001b[A\n",
      "Epoch 3:   7%|▋         | 10/148 [00:11<02:24,  1.05s/it, training_loss=1.7463]\u001b[A\n",
      "Epoch 3:   7%|▋         | 11/148 [00:11<02:24,  1.05s/it, training_loss=1.7463]\u001b[A\n",
      "Epoch 3:   7%|▋         | 11/148 [00:12<02:24,  1.05s/it, training_loss=1.6219]\u001b[A\n",
      "Epoch 3:   8%|▊         | 12/148 [00:12<02:23,  1.06s/it, training_loss=1.6219]\u001b[A\n",
      "Epoch 3:   8%|▊         | 12/148 [00:13<02:23,  1.06s/it, training_loss=1.2557]\u001b[A\n",
      "Epoch 3:   9%|▉         | 13/148 [00:13<02:23,  1.06s/it, training_loss=1.2557]\u001b[A\n",
      "Epoch 3:   9%|▉         | 13/148 [00:14<02:23,  1.06s/it, training_loss=1.4347]\u001b[A\n",
      "Epoch 3:   9%|▉         | 14/148 [00:14<02:22,  1.06s/it, training_loss=1.4347]\u001b[A\n",
      "Epoch 3:   9%|▉         | 14/148 [00:15<02:22,  1.06s/it, training_loss=1.3152]\u001b[A\n",
      "Epoch 3:  10%|█         | 15/148 [00:15<02:21,  1.07s/it, training_loss=1.3152]\u001b[A\n",
      "Epoch 3:  10%|█         | 15/148 [00:16<02:21,  1.07s/it, training_loss=1.5118]\u001b[A\n",
      "Epoch 3:  11%|█         | 16/148 [00:16<02:20,  1.07s/it, training_loss=1.5118]\u001b[A\n",
      "Epoch 3:  11%|█         | 16/148 [00:17<02:20,  1.07s/it, training_loss=1.2908]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 17/148 [00:17<02:20,  1.07s/it, training_loss=1.2908]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 17/148 [00:18<02:20,  1.07s/it, training_loss=1.3532]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 18/148 [00:18<02:19,  1.07s/it, training_loss=1.3532]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 18/148 [00:20<02:19,  1.07s/it, training_loss=1.6736]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 19/148 [00:20<02:18,  1.07s/it, training_loss=1.6736]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 19/148 [00:21<02:18,  1.07s/it, training_loss=1.2625]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 20/148 [00:21<02:17,  1.07s/it, training_loss=1.2625]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 20/148 [00:22<02:17,  1.07s/it, training_loss=1.3797]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 21/148 [00:22<02:17,  1.08s/it, training_loss=1.3797]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 21/148 [00:23<02:17,  1.08s/it, training_loss=1.2093]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 22/148 [00:23<02:16,  1.08s/it, training_loss=1.2093]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 22/148 [00:24<02:16,  1.08s/it, training_loss=1.6221]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 23/148 [00:24<02:14,  1.08s/it, training_loss=1.6221]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 23/148 [00:25<02:14,  1.08s/it, training_loss=1.1992]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 24/148 [00:25<02:13,  1.08s/it, training_loss=1.1992]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 24/148 [00:26<02:13,  1.08s/it, training_loss=1.4949]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 25/148 [00:26<02:12,  1.08s/it, training_loss=1.4949]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 25/148 [00:27<02:12,  1.08s/it, training_loss=1.5045]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 26/148 [00:27<02:11,  1.08s/it, training_loss=1.5045]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 26/148 [00:28<02:11,  1.08s/it, training_loss=1.4043]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 27/148 [00:28<02:10,  1.08s/it, training_loss=1.4043]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 27/148 [00:29<02:10,  1.08s/it, training_loss=1.2281]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 28/148 [00:29<02:08,  1.07s/it, training_loss=1.2281]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 28/148 [00:30<02:08,  1.07s/it, training_loss=1.5834]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 29/148 [00:30<02:07,  1.07s/it, training_loss=1.5834]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 29/148 [00:31<02:07,  1.07s/it, training_loss=1.4203]\u001b[A\n",
      "Epoch 3:  20%|██        | 30/148 [00:31<02:05,  1.07s/it, training_loss=1.4203]\u001b[A\n",
      "Epoch 3:  20%|██        | 30/148 [00:32<02:05,  1.07s/it, training_loss=1.7485]\u001b[A\n",
      "Epoch 3:  21%|██        | 31/148 [00:32<02:04,  1.06s/it, training_loss=1.7485]\u001b[A\n",
      "Epoch 3:  21%|██        | 31/148 [00:34<02:04,  1.06s/it, training_loss=1.6177]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 32/148 [00:34<02:03,  1.06s/it, training_loss=1.6177]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 32/148 [00:35<02:03,  1.06s/it, training_loss=1.6118]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 33/148 [00:35<02:02,  1.06s/it, training_loss=1.6118]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 33/148 [00:36<02:02,  1.06s/it, training_loss=1.4277]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 34/148 [00:36<02:01,  1.06s/it, training_loss=1.4277]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 34/148 [00:37<02:01,  1.06s/it, training_loss=1.1726]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 35/148 [00:37<01:59,  1.06s/it, training_loss=1.1726]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 35/148 [00:38<01:59,  1.06s/it, training_loss=1.5978]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 36/148 [00:38<01:58,  1.05s/it, training_loss=1.5978]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 36/148 [00:39<01:58,  1.05s/it, training_loss=1.6192]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 37/148 [00:39<01:56,  1.05s/it, training_loss=1.6192]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 37/148 [00:40<01:56,  1.05s/it, training_loss=1.4508]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 38/148 [00:40<01:55,  1.05s/it, training_loss=1.4508]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 38/148 [00:41<01:55,  1.05s/it, training_loss=1.4704]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 39/148 [00:41<01:54,  1.05s/it, training_loss=1.4704]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 39/148 [00:42<01:54,  1.05s/it, training_loss=1.2377]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 40/148 [00:42<01:53,  1.05s/it, training_loss=1.2377]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 40/148 [00:43<01:53,  1.05s/it, training_loss=1.2188]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 41/148 [00:43<01:52,  1.05s/it, training_loss=1.2188]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 41/148 [00:44<01:52,  1.05s/it, training_loss=1.5642]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 42/148 [00:44<01:51,  1.05s/it, training_loss=1.5642]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 42/148 [00:45<01:51,  1.05s/it, training_loss=1.5320]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 43/148 [00:45<01:50,  1.05s/it, training_loss=1.5320]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 43/148 [00:46<01:50,  1.05s/it, training_loss=1.6763]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 44/148 [00:46<01:49,  1.05s/it, training_loss=1.6763]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 44/148 [00:47<01:49,  1.05s/it, training_loss=1.2620]\u001b[A\n",
      "Epoch 3:  30%|███       | 45/148 [00:47<01:48,  1.05s/it, training_loss=1.2620]\u001b[A\n",
      "Epoch 3:  30%|███       | 45/148 [00:48<01:48,  1.05s/it, training_loss=1.2654]\u001b[A\n",
      "Epoch 3:  31%|███       | 46/148 [00:48<01:47,  1.05s/it, training_loss=1.2654]\u001b[A\n",
      "Epoch 3:  31%|███       | 46/148 [00:49<01:47,  1.05s/it, training_loss=1.2614]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 47/148 [00:49<01:45,  1.05s/it, training_loss=1.2614]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 47/148 [00:50<01:45,  1.05s/it, training_loss=1.5696]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 48/148 [00:50<01:44,  1.05s/it, training_loss=1.5696]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 48/148 [00:51<01:44,  1.05s/it, training_loss=1.6473]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 49/148 [00:51<01:43,  1.04s/it, training_loss=1.6473]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 49/148 [00:52<01:43,  1.04s/it, training_loss=1.2020]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 50/148 [00:52<01:42,  1.04s/it, training_loss=1.2020]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 50/148 [00:53<01:42,  1.04s/it, training_loss=1.0916]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 51/148 [00:53<01:41,  1.05s/it, training_loss=1.0916]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 51/148 [00:54<01:41,  1.05s/it, training_loss=1.1625]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 52/148 [00:54<01:40,  1.05s/it, training_loss=1.1625]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 52/148 [00:56<01:40,  1.05s/it, training_loss=1.2736]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 53/148 [00:56<01:39,  1.04s/it, training_loss=1.2736]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 53/148 [00:57<01:39,  1.04s/it, training_loss=1.5242]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 54/148 [00:57<01:38,  1.04s/it, training_loss=1.5242]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 54/148 [00:58<01:38,  1.04s/it, training_loss=1.6525]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 55/148 [00:58<01:36,  1.04s/it, training_loss=1.6525]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 55/148 [00:59<01:36,  1.04s/it, training_loss=1.2391]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 56/148 [00:59<01:35,  1.04s/it, training_loss=1.2391]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 56/148 [01:00<01:35,  1.04s/it, training_loss=1.7213]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 57/148 [01:00<01:34,  1.04s/it, training_loss=1.7213]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 57/148 [01:01<01:34,  1.04s/it, training_loss=1.7556]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 58/148 [01:01<01:33,  1.04s/it, training_loss=1.7556]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 58/148 [01:02<01:33,  1.04s/it, training_loss=1.2833]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 59/148 [01:02<01:32,  1.04s/it, training_loss=1.2833]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 59/148 [01:03<01:32,  1.04s/it, training_loss=1.5310]\u001b[A\n",
      "Epoch 3:  41%|████      | 60/148 [01:03<01:31,  1.04s/it, training_loss=1.5310]\u001b[A\n",
      "Epoch 3:  41%|████      | 60/148 [01:04<01:31,  1.04s/it, training_loss=1.1824]\u001b[A\n",
      "Epoch 3:  41%|████      | 61/148 [01:04<01:30,  1.04s/it, training_loss=1.1824]\u001b[A\n",
      "Epoch 3:  41%|████      | 61/148 [01:05<01:30,  1.04s/it, training_loss=1.5474]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 62/148 [01:05<01:29,  1.04s/it, training_loss=1.5474]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 62/148 [01:06<01:29,  1.04s/it, training_loss=1.2529]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 63/148 [01:06<01:28,  1.04s/it, training_loss=1.2529]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 63/148 [01:07<01:28,  1.04s/it, training_loss=1.6810]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 64/148 [01:07<01:27,  1.04s/it, training_loss=1.6810]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 64/148 [01:08<01:27,  1.04s/it, training_loss=1.4941]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 65/148 [01:08<01:26,  1.04s/it, training_loss=1.4941]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 65/148 [01:09<01:26,  1.04s/it, training_loss=1.1727]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 66/148 [01:09<01:25,  1.05s/it, training_loss=1.1727]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 66/148 [01:10<01:25,  1.05s/it, training_loss=1.1328]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 67/148 [01:10<01:24,  1.05s/it, training_loss=1.1328]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 67/148 [01:11<01:24,  1.05s/it, training_loss=1.6422]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 68/148 [01:11<01:23,  1.05s/it, training_loss=1.6422]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 68/148 [01:12<01:23,  1.05s/it, training_loss=1.0068]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 69/148 [01:12<01:22,  1.04s/it, training_loss=1.0068]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 69/148 [01:13<01:22,  1.04s/it, training_loss=1.1200]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 70/148 [01:13<01:22,  1.05s/it, training_loss=1.1200]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 70/148 [01:14<01:22,  1.05s/it, training_loss=1.1438]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 71/148 [01:14<01:20,  1.05s/it, training_loss=1.1438]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 71/148 [01:15<01:20,  1.05s/it, training_loss=1.4773]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 72/148 [01:15<01:19,  1.05s/it, training_loss=1.4773]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 72/148 [01:16<01:19,  1.05s/it, training_loss=1.7119]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 73/148 [01:16<01:18,  1.05s/it, training_loss=1.7119]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 73/148 [01:17<01:18,  1.05s/it, training_loss=1.4047]\u001b[A\n",
      "Epoch 3:  50%|█████     | 74/148 [01:17<01:17,  1.05s/it, training_loss=1.4047]\u001b[A\n",
      "Epoch 3:  50%|█████     | 74/148 [01:19<01:17,  1.05s/it, training_loss=1.2187]\u001b[A\n",
      "Epoch 3:  51%|█████     | 75/148 [01:19<01:16,  1.05s/it, training_loss=1.2187]\u001b[A\n",
      "Epoch 3:  51%|█████     | 75/148 [01:20<01:16,  1.05s/it, training_loss=1.4590]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 76/148 [01:20<01:15,  1.04s/it, training_loss=1.4590]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 76/148 [01:21<01:15,  1.04s/it, training_loss=1.6197]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 77/148 [01:21<01:14,  1.04s/it, training_loss=1.6197]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 77/148 [01:22<01:14,  1.04s/it, training_loss=1.4311]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 78/148 [01:22<01:13,  1.04s/it, training_loss=1.4311]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 78/148 [01:23<01:13,  1.04s/it, training_loss=1.2303]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 79/148 [01:23<01:12,  1.05s/it, training_loss=1.2303]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 79/148 [01:24<01:12,  1.05s/it, training_loss=1.3443]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 80/148 [01:24<01:11,  1.05s/it, training_loss=1.3443]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 80/148 [01:25<01:11,  1.05s/it, training_loss=1.5892]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 81/148 [01:25<01:10,  1.05s/it, training_loss=1.5892]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 81/148 [01:26<01:10,  1.05s/it, training_loss=0.9890]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 82/148 [01:26<01:09,  1.05s/it, training_loss=0.9890]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 82/148 [01:27<01:09,  1.05s/it, training_loss=1.4785]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 83/148 [01:27<01:08,  1.05s/it, training_loss=1.4785]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 83/148 [01:28<01:08,  1.05s/it, training_loss=1.5117]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 84/148 [01:28<01:06,  1.05s/it, training_loss=1.5117]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 84/148 [01:29<01:06,  1.05s/it, training_loss=1.6362]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 85/148 [01:29<01:05,  1.04s/it, training_loss=1.6362]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 85/148 [01:30<01:05,  1.04s/it, training_loss=1.5757]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 86/148 [01:30<01:04,  1.04s/it, training_loss=1.5757]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 86/148 [01:31<01:04,  1.04s/it, training_loss=1.6251]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 87/148 [01:31<01:03,  1.05s/it, training_loss=1.6251]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 87/148 [01:32<01:03,  1.05s/it, training_loss=1.3206]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 88/148 [01:32<01:02,  1.04s/it, training_loss=1.3206]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 88/148 [01:33<01:02,  1.04s/it, training_loss=1.5348]\u001b[A\n",
      "Epoch 3:  60%|██████    | 89/148 [01:33<01:01,  1.05s/it, training_loss=1.5348]\u001b[A\n",
      "Epoch 3:  60%|██████    | 89/148 [01:34<01:01,  1.05s/it, training_loss=1.5709]\u001b[A\n",
      "Epoch 3:  61%|██████    | 90/148 [01:34<01:00,  1.04s/it, training_loss=1.5709]\u001b[A\n",
      "Epoch 3:  61%|██████    | 90/148 [01:35<01:00,  1.04s/it, training_loss=1.1878]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 91/148 [01:35<00:59,  1.05s/it, training_loss=1.1878]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 91/148 [01:36<00:59,  1.05s/it, training_loss=1.0532]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 92/148 [01:36<00:58,  1.05s/it, training_loss=1.0532]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 92/148 [01:37<00:58,  1.05s/it, training_loss=1.1640]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 93/148 [01:37<00:57,  1.05s/it, training_loss=1.1640]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 93/148 [01:38<00:57,  1.05s/it, training_loss=1.6104]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 94/148 [01:38<00:56,  1.04s/it, training_loss=1.6104]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 94/148 [01:39<00:56,  1.04s/it, training_loss=1.3359]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 95/148 [01:39<00:55,  1.05s/it, training_loss=1.3359]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 95/148 [01:40<00:55,  1.05s/it, training_loss=1.4948]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 96/148 [01:40<00:54,  1.05s/it, training_loss=1.4948]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 96/148 [01:42<00:54,  1.05s/it, training_loss=1.5221]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 97/148 [01:42<00:53,  1.04s/it, training_loss=1.5221]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 97/148 [01:43<00:53,  1.04s/it, training_loss=1.5621]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 98/148 [01:43<00:52,  1.04s/it, training_loss=1.5621]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 98/148 [01:44<00:52,  1.04s/it, training_loss=1.6531]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 99/148 [01:44<00:51,  1.04s/it, training_loss=1.6531]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 99/148 [01:45<00:51,  1.04s/it, training_loss=1.6486]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 100/148 [01:45<00:50,  1.04s/it, training_loss=1.6486]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 100/148 [01:46<00:50,  1.04s/it, training_loss=1.5709]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 101/148 [01:46<00:48,  1.04s/it, training_loss=1.5709]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 101/148 [01:47<00:48,  1.04s/it, training_loss=0.8948]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 102/148 [01:47<00:48,  1.05s/it, training_loss=0.8948]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 102/148 [01:48<00:48,  1.05s/it, training_loss=1.1567]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 103/148 [01:48<00:47,  1.05s/it, training_loss=1.1567]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 103/148 [01:49<00:47,  1.05s/it, training_loss=1.1958]\u001b[A\n",
      "Epoch 3:  70%|███████   | 104/148 [01:49<00:46,  1.05s/it, training_loss=1.1958]\u001b[A\n",
      "Epoch 3:  70%|███████   | 104/148 [01:50<00:46,  1.05s/it, training_loss=1.4152]\u001b[A\n",
      "Epoch 3:  71%|███████   | 105/148 [01:50<00:45,  1.05s/it, training_loss=1.4152]\u001b[A\n",
      "Epoch 3:  71%|███████   | 105/148 [01:51<00:45,  1.05s/it, training_loss=1.5221]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 106/148 [01:51<00:44,  1.05s/it, training_loss=1.5221]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 106/148 [01:52<00:44,  1.05s/it, training_loss=1.6282]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 107/148 [01:52<00:42,  1.05s/it, training_loss=1.6282]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 107/148 [01:53<00:42,  1.05s/it, training_loss=1.7183]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 108/148 [01:53<00:41,  1.05s/it, training_loss=1.7183]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 108/148 [01:54<00:41,  1.05s/it, training_loss=1.5754]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 109/148 [01:54<00:40,  1.05s/it, training_loss=1.5754]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 109/148 [01:55<00:40,  1.05s/it, training_loss=1.6012]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 110/148 [01:55<00:39,  1.05s/it, training_loss=1.6012]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 110/148 [01:56<00:39,  1.05s/it, training_loss=1.3136]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 111/148 [01:56<00:39,  1.06s/it, training_loss=1.3136]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 111/148 [01:57<00:39,  1.06s/it, training_loss=1.5741]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 112/148 [01:57<00:37,  1.05s/it, training_loss=1.5741]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 112/148 [01:58<00:37,  1.05s/it, training_loss=1.4502]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 113/148 [01:58<00:36,  1.05s/it, training_loss=1.4502]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 113/148 [01:59<00:36,  1.05s/it, training_loss=1.2129]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 114/148 [01:59<00:35,  1.05s/it, training_loss=1.2129]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 114/148 [02:00<00:35,  1.05s/it, training_loss=1.5145]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 115/148 [02:00<00:34,  1.05s/it, training_loss=1.5145]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 115/148 [02:01<00:34,  1.05s/it, training_loss=1.1503]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 116/148 [02:01<00:33,  1.06s/it, training_loss=1.1503]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 116/148 [02:03<00:33,  1.06s/it, training_loss=1.2288]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 117/148 [02:03<00:32,  1.06s/it, training_loss=1.2288]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 117/148 [02:04<00:32,  1.06s/it, training_loss=1.2144]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 118/148 [02:04<00:31,  1.06s/it, training_loss=1.2144]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 118/148 [02:05<00:31,  1.06s/it, training_loss=1.6128]\u001b[A\n",
      "Epoch 3:  80%|████████  | 119/148 [02:05<00:30,  1.06s/it, training_loss=1.6128]\u001b[A\n",
      "Epoch 3:  80%|████████  | 119/148 [02:06<00:30,  1.06s/it, training_loss=1.5433]\u001b[A\n",
      "Epoch 3:  81%|████████  | 120/148 [02:06<00:29,  1.06s/it, training_loss=1.5433]\u001b[A\n",
      "Epoch 3:  81%|████████  | 120/148 [02:07<00:29,  1.06s/it, training_loss=1.2222]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 121/148 [02:07<00:28,  1.06s/it, training_loss=1.2222]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 121/148 [02:08<00:28,  1.06s/it, training_loss=1.6212]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 122/148 [02:08<00:27,  1.06s/it, training_loss=1.6212]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 122/148 [02:09<00:27,  1.06s/it, training_loss=1.5745]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 123/148 [02:09<00:26,  1.06s/it, training_loss=1.5745]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 123/148 [02:10<00:26,  1.06s/it, training_loss=1.5248]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 124/148 [02:10<00:25,  1.05s/it, training_loss=1.5248]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 124/148 [02:11<00:25,  1.05s/it, training_loss=1.6012]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 125/148 [02:11<00:24,  1.05s/it, training_loss=1.6012]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 125/148 [02:12<00:24,  1.05s/it, training_loss=1.5413]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 126/148 [02:12<00:23,  1.05s/it, training_loss=1.5413]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 126/148 [02:13<00:23,  1.05s/it, training_loss=1.7135]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 127/148 [02:13<00:22,  1.05s/it, training_loss=1.7135]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 127/148 [02:14<00:22,  1.05s/it, training_loss=1.0552]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 128/148 [02:14<00:21,  1.05s/it, training_loss=1.0552]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 128/148 [02:15<00:21,  1.05s/it, training_loss=1.6882]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 129/148 [02:15<00:19,  1.05s/it, training_loss=1.6882]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 129/148 [02:16<00:19,  1.05s/it, training_loss=1.6935]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 130/148 [02:16<00:18,  1.05s/it, training_loss=1.6935]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 130/148 [02:17<00:18,  1.05s/it, training_loss=1.5368]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 131/148 [02:17<00:17,  1.05s/it, training_loss=1.5368]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 131/148 [02:18<00:17,  1.05s/it, training_loss=1.5594]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 132/148 [02:18<00:16,  1.05s/it, training_loss=1.5594]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 132/148 [02:19<00:16,  1.05s/it, training_loss=1.5206]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 133/148 [02:19<00:15,  1.05s/it, training_loss=1.5206]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 133/148 [02:20<00:15,  1.05s/it, training_loss=1.7583]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 134/148 [02:20<00:14,  1.06s/it, training_loss=1.7583]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 134/148 [02:22<00:14,  1.06s/it, training_loss=1.5679]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 135/148 [02:22<00:13,  1.05s/it, training_loss=1.5679]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 135/148 [02:23<00:13,  1.05s/it, training_loss=1.5677]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 136/148 [02:23<00:12,  1.06s/it, training_loss=1.5677]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 136/148 [02:24<00:12,  1.06s/it, training_loss=1.3321]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 137/148 [02:24<00:11,  1.06s/it, training_loss=1.3321]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 137/148 [02:25<00:11,  1.06s/it, training_loss=1.7082]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 138/148 [02:25<00:10,  1.05s/it, training_loss=1.7082]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 138/148 [02:26<00:10,  1.05s/it, training_loss=1.4926]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 139/148 [02:26<00:09,  1.05s/it, training_loss=1.4926]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 139/148 [02:27<00:09,  1.05s/it, training_loss=1.1455]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 140/148 [02:27<00:08,  1.06s/it, training_loss=1.1455]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 140/148 [02:28<00:08,  1.06s/it, training_loss=1.5367]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 141/148 [02:28<00:07,  1.05s/it, training_loss=1.5367]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 141/148 [02:29<00:07,  1.05s/it, training_loss=1.1607]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 142/148 [02:29<00:06,  1.06s/it, training_loss=1.1607]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 142/148 [02:30<00:06,  1.06s/it, training_loss=1.6341]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 143/148 [02:30<00:05,  1.05s/it, training_loss=1.6341]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 143/148 [02:31<00:05,  1.05s/it, training_loss=1.2909]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 144/148 [02:31<00:04,  1.05s/it, training_loss=1.2909]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 144/148 [02:32<00:04,  1.05s/it, training_loss=1.0597]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 145/148 [02:32<00:03,  1.05s/it, training_loss=1.0597]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 145/148 [02:33<00:03,  1.05s/it, training_loss=1.5787]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 146/148 [02:33<00:02,  1.06s/it, training_loss=1.5787]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 146/148 [02:34<00:02,  1.06s/it, training_loss=1.3752]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 147/148 [02:34<00:01,  1.06s/it, training_loss=1.3752]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 147/148 [02:35<00:01,  1.06s/it, training_loss=1.0897]\u001b[A\n",
      "Epoch 3: 100%|██████████| 148/148 [02:35<00:00,  1.03it/s, training_loss=1.0897]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:10:17,870 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:10:17,872 - INFO - Memory usage after evaluation start: 3667.06 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:08,  3.04it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:08,  2.97it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:08,  2.94it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:02<00:07,  2.91it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:06,  2.92it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:03<00:06,  2.92it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:04<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:04<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:05<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:03,  2.92it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:06<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:06<00:02,  2.92it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:07<00:02,  2.92it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:07<00:01,  2.92it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:08<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:08<00:00,  2.91it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:08<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:10:26,831 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 00:10:26,846 - INFO - Class 'Drama': Optimal threshold = 0.550, F1 Score = 0.528\n",
      "2025-02-16 00:10:26,860 - INFO - Class 'Horor': Optimal threshold = 0.750, F1 Score = 0.773\n",
      "2025-02-16 00:10:26,874 - INFO - Class 'Komedi': Optimal threshold = 0.600, F1 Score = 0.480\n",
      "2025-02-16 00:10:26,888 - INFO - Class 'Laga': Optimal threshold = 0.550, F1 Score = 0.400\n",
      "2025-02-16 00:10:26,901 - INFO - Class 'Romantis': Optimal threshold = 0.550, F1 Score = 0.500\n",
      "2025-02-16 00:10:26,924 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:10:26,930 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:10:26,930 - INFO - Accuracy: 0.6437\n",
      "2025-02-16 00:10:26,931 - INFO - F1_score: 0.5279\n",
      "2025-02-16 00:10:26,932 - INFO - Precision: 0.4228\n",
      "2025-02-16 00:10:26,932 - INFO - Recall: 0.7027\n",
      "2025-02-16 00:10:26,939 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:10:26,939 - INFO - Accuracy: 0.8966\n",
      "2025-02-16 00:10:26,940 - INFO - F1_score: 0.7731\n",
      "2025-02-16 00:10:26,940 - INFO - Precision: 0.7419\n",
      "2025-02-16 00:10:26,942 - INFO - Recall: 0.8070\n",
      "2025-02-16 00:10:26,948 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:10:26,948 - INFO - Accuracy: 0.6590\n",
      "2025-02-16 00:10:26,949 - INFO - F1_score: 0.4795\n",
      "2025-02-16 00:10:26,950 - INFO - Precision: 0.3628\n",
      "2025-02-16 00:10:26,951 - INFO - Recall: 0.7069\n",
      "2025-02-16 00:10:26,957 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:10:26,957 - INFO - Accuracy: 0.6667\n",
      "2025-02-16 00:10:26,958 - INFO - F1_score: 0.4000\n",
      "2025-02-16 00:10:26,958 - INFO - Precision: 0.2710\n",
      "2025-02-16 00:10:26,959 - INFO - Recall: 0.7632\n",
      "2025-02-16 00:10:26,965 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:10:26,965 - INFO - Accuracy: 0.8314\n",
      "2025-02-16 00:10:26,966 - INFO - F1_score: 0.5000\n",
      "2025-02-16 00:10:26,968 - INFO - Precision: 0.4074\n",
      "2025-02-16 00:10:26,968 - INFO - Recall: 0.6471\n",
      "2025-02-16 00:10:26,970 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:10:30,913 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:10:30,915 - INFO - Memory usage after evaluation end: 3688.31 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 2/100 [08:56<4:53:16, 179.55s/it, Train Loss=1.4309, Val Loss=0.0533, Accuracy=0.7395]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:10:39,773 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [08:56<4:48:40, 178.56s/it, Train Loss=1.4309, Val Loss=0.0533, Accuracy=0.7395]\n",
      "Epoch 4:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=1.6027]\u001b[A\n",
      "Epoch 4:   1%|          | 1/148 [00:01<02:32,  1.04s/it, training_loss=1.6027]\u001b[A\n",
      "Epoch 4:   1%|          | 1/148 [00:02<02:32,  1.04s/it, training_loss=1.1488]\u001b[A\n",
      "Epoch 4:   1%|▏         | 2/148 [00:02<02:32,  1.05s/it, training_loss=1.1488]\u001b[A\n",
      "Epoch 4:   1%|▏         | 2/148 [00:03<02:32,  1.05s/it, training_loss=1.1876]\u001b[A\n",
      "Epoch 4:   2%|▏         | 3/148 [00:03<02:31,  1.05s/it, training_loss=1.1876]\u001b[A\n",
      "Epoch 4:   2%|▏         | 3/148 [00:04<02:31,  1.05s/it, training_loss=1.1445]\u001b[A\n",
      "Epoch 4:   3%|▎         | 4/148 [00:04<02:30,  1.05s/it, training_loss=1.1445]\u001b[A\n",
      "Epoch 4:   3%|▎         | 4/148 [00:05<02:30,  1.05s/it, training_loss=1.7833]\u001b[A\n",
      "Epoch 4:   3%|▎         | 5/148 [00:05<02:29,  1.05s/it, training_loss=1.7833]\u001b[A\n",
      "Epoch 4:   3%|▎         | 5/148 [00:06<02:29,  1.05s/it, training_loss=1.4460]\u001b[A\n",
      "Epoch 4:   4%|▍         | 6/148 [00:06<02:28,  1.04s/it, training_loss=1.4460]\u001b[A\n",
      "Epoch 4:   4%|▍         | 6/148 [00:07<02:28,  1.04s/it, training_loss=1.5261]\u001b[A\n",
      "Epoch 4:   5%|▍         | 7/148 [00:07<02:27,  1.05s/it, training_loss=1.5261]\u001b[A\n",
      "Epoch 4:   5%|▍         | 7/148 [00:08<02:27,  1.05s/it, training_loss=1.2915]\u001b[A\n",
      "Epoch 4:   5%|▌         | 8/148 [00:08<02:26,  1.05s/it, training_loss=1.2915]\u001b[A\n",
      "Epoch 4:   5%|▌         | 8/148 [00:09<02:26,  1.05s/it, training_loss=1.1018]\u001b[A\n",
      "Epoch 4:   6%|▌         | 9/148 [00:09<02:26,  1.05s/it, training_loss=1.1018]\u001b[A\n",
      "Epoch 4:   6%|▌         | 9/148 [00:10<02:26,  1.05s/it, training_loss=1.5149]\u001b[A\n",
      "Epoch 4:   7%|▋         | 10/148 [00:10<02:25,  1.05s/it, training_loss=1.5149]\u001b[A\n",
      "Epoch 4:   7%|▋         | 10/148 [00:11<02:25,  1.05s/it, training_loss=1.7518]\u001b[A\n",
      "Epoch 4:   7%|▋         | 11/148 [00:11<02:24,  1.05s/it, training_loss=1.7518]\u001b[A\n",
      "Epoch 4:   7%|▋         | 11/148 [00:12<02:24,  1.05s/it, training_loss=1.0439]\u001b[A\n",
      "Epoch 4:   8%|▊         | 12/148 [00:12<02:23,  1.05s/it, training_loss=1.0439]\u001b[A\n",
      "Epoch 4:   8%|▊         | 12/148 [00:13<02:23,  1.05s/it, training_loss=1.5344]\u001b[A\n",
      "Epoch 4:   9%|▉         | 13/148 [00:13<02:22,  1.05s/it, training_loss=1.5344]\u001b[A\n",
      "Epoch 4:   9%|▉         | 13/148 [00:14<02:22,  1.05s/it, training_loss=1.6537]\u001b[A\n",
      "Epoch 4:   9%|▉         | 14/148 [00:14<02:20,  1.05s/it, training_loss=1.6537]\u001b[A\n",
      "Epoch 4:   9%|▉         | 14/148 [00:15<02:20,  1.05s/it, training_loss=1.0651]\u001b[A\n",
      "Epoch 4:  10%|█         | 15/148 [00:15<02:20,  1.06s/it, training_loss=1.0651]\u001b[A\n",
      "Epoch 4:  10%|█         | 15/148 [00:16<02:20,  1.06s/it, training_loss=1.2660]\u001b[A\n",
      "Epoch 4:  11%|█         | 16/148 [00:16<02:19,  1.06s/it, training_loss=1.2660]\u001b[A\n",
      "Epoch 4:  11%|█         | 16/148 [00:17<02:19,  1.06s/it, training_loss=1.6772]\u001b[A\n",
      "Epoch 4:  11%|█▏        | 17/148 [00:17<02:18,  1.05s/it, training_loss=1.6772]\u001b[A\n",
      "Epoch 4:  11%|█▏        | 17/148 [00:18<02:18,  1.05s/it, training_loss=1.3103]\u001b[A\n",
      "Epoch 4:  12%|█▏        | 18/148 [00:18<02:17,  1.06s/it, training_loss=1.3103]\u001b[A\n",
      "Epoch 4:  12%|█▏        | 18/148 [00:20<02:17,  1.06s/it, training_loss=1.2491]\u001b[A\n",
      "Epoch 4:  13%|█▎        | 19/148 [00:20<02:16,  1.06s/it, training_loss=1.2491]\u001b[A\n",
      "Epoch 4:  13%|█▎        | 19/148 [00:21<02:16,  1.06s/it, training_loss=1.6182]\u001b[A\n",
      "Epoch 4:  14%|█▎        | 20/148 [00:21<02:15,  1.06s/it, training_loss=1.6182]\u001b[A\n",
      "Epoch 4:  14%|█▎        | 20/148 [00:22<02:15,  1.06s/it, training_loss=1.5717]\u001b[A\n",
      "Epoch 4:  14%|█▍        | 21/148 [00:22<02:14,  1.06s/it, training_loss=1.5717]\u001b[A\n",
      "Epoch 4:  14%|█▍        | 21/148 [00:23<02:14,  1.06s/it, training_loss=1.0417]\u001b[A\n",
      "Epoch 4:  15%|█▍        | 22/148 [00:23<02:13,  1.06s/it, training_loss=1.0417]\u001b[A\n",
      "Epoch 4:  15%|█▍        | 22/148 [00:24<02:13,  1.06s/it, training_loss=1.5903]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 23/148 [00:24<02:12,  1.06s/it, training_loss=1.5903]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 23/148 [00:25<02:12,  1.06s/it, training_loss=1.3752]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 24/148 [00:25<02:11,  1.06s/it, training_loss=1.3752]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 24/148 [00:26<02:11,  1.06s/it, training_loss=1.4978]\u001b[A\n",
      "Epoch 4:  17%|█▋        | 25/148 [00:26<02:10,  1.06s/it, training_loss=1.4978]\u001b[A\n",
      "Epoch 4:  17%|█▋        | 25/148 [00:27<02:10,  1.06s/it, training_loss=1.5852]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 26/148 [00:27<02:08,  1.06s/it, training_loss=1.5852]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 26/148 [00:28<02:08,  1.06s/it, training_loss=1.6014]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 27/148 [00:28<02:07,  1.06s/it, training_loss=1.6014]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 27/148 [00:29<02:07,  1.06s/it, training_loss=1.1307]\u001b[A\n",
      "Epoch 4:  19%|█▉        | 28/148 [00:29<02:06,  1.06s/it, training_loss=1.1307]\u001b[A\n",
      "Epoch 4:  19%|█▉        | 28/148 [00:30<02:06,  1.06s/it, training_loss=1.2034]\u001b[A\n",
      "Epoch 4:  20%|█▉        | 29/148 [00:30<02:06,  1.06s/it, training_loss=1.2034]\u001b[A\n",
      "Epoch 4:  20%|█▉        | 29/148 [00:31<02:06,  1.06s/it, training_loss=1.6160]\u001b[A\n",
      "Epoch 4:  20%|██        | 30/148 [00:31<02:04,  1.06s/it, training_loss=1.6160]\u001b[A\n",
      "Epoch 4:  20%|██        | 30/148 [00:32<02:04,  1.06s/it, training_loss=1.6476]\u001b[A\n",
      "Epoch 4:  21%|██        | 31/148 [00:32<02:03,  1.06s/it, training_loss=1.6476]\u001b[A\n",
      "Epoch 4:  21%|██        | 31/148 [00:33<02:03,  1.06s/it, training_loss=1.2961]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 32/148 [00:33<02:03,  1.06s/it, training_loss=1.2961]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 32/148 [00:34<02:03,  1.06s/it, training_loss=1.7247]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 33/148 [00:34<02:02,  1.06s/it, training_loss=1.7247]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 33/148 [00:35<02:02,  1.06s/it, training_loss=1.2339]\u001b[A\n",
      "Epoch 4:  23%|██▎       | 34/148 [00:35<02:00,  1.06s/it, training_loss=1.2339]\u001b[A\n",
      "Epoch 4:  23%|██▎       | 34/148 [00:36<02:00,  1.06s/it, training_loss=1.4789]\u001b[A\n",
      "Epoch 4:  24%|██▎       | 35/148 [00:36<01:59,  1.06s/it, training_loss=1.4789]\u001b[A\n",
      "Epoch 4:  24%|██▎       | 35/148 [00:38<01:59,  1.06s/it, training_loss=1.5833]\u001b[A\n",
      "Epoch 4:  24%|██▍       | 36/148 [00:38<01:58,  1.06s/it, training_loss=1.5833]\u001b[A\n",
      "Epoch 4:  24%|██▍       | 36/148 [00:39<01:58,  1.06s/it, training_loss=1.0699]\u001b[A\n",
      "Epoch 4:  25%|██▌       | 37/148 [00:39<01:58,  1.06s/it, training_loss=1.0699]\u001b[A\n",
      "Epoch 4:  25%|██▌       | 37/148 [00:40<01:58,  1.06s/it, training_loss=1.5766]\u001b[A\n",
      "Epoch 4:  26%|██▌       | 38/148 [00:40<01:56,  1.06s/it, training_loss=1.5766]\u001b[A\n",
      "Epoch 4:  26%|██▌       | 38/148 [00:41<01:56,  1.06s/it, training_loss=1.6155]\u001b[A\n",
      "Epoch 4:  26%|██▋       | 39/148 [00:41<01:54,  1.05s/it, training_loss=1.6155]\u001b[A\n",
      "Epoch 4:  26%|██▋       | 39/148 [00:42<01:54,  1.05s/it, training_loss=1.0647]\u001b[A\n",
      "Epoch 4:  27%|██▋       | 40/148 [00:42<01:53,  1.05s/it, training_loss=1.0647]\u001b[A\n",
      "Epoch 4:  27%|██▋       | 40/148 [00:43<01:53,  1.05s/it, training_loss=1.4484]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 41/148 [00:43<01:52,  1.05s/it, training_loss=1.4484]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 41/148 [00:44<01:52,  1.05s/it, training_loss=1.6559]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 42/148 [00:44<01:51,  1.05s/it, training_loss=1.6559]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 42/148 [00:45<01:51,  1.05s/it, training_loss=1.3723]\u001b[A\n",
      "Epoch 4:  29%|██▉       | 43/148 [00:45<01:49,  1.05s/it, training_loss=1.3723]\u001b[A\n",
      "Epoch 4:  29%|██▉       | 43/148 [00:46<01:49,  1.05s/it, training_loss=1.6909]\u001b[A\n",
      "Epoch 4:  30%|██▉       | 44/148 [00:46<01:48,  1.04s/it, training_loss=1.6909]\u001b[A\n",
      "Epoch 4:  30%|██▉       | 44/148 [00:47<01:48,  1.04s/it, training_loss=1.2157]\u001b[A\n",
      "Epoch 4:  30%|███       | 45/148 [00:47<01:47,  1.04s/it, training_loss=1.2157]\u001b[A\n",
      "Epoch 4:  30%|███       | 45/148 [00:48<01:47,  1.04s/it, training_loss=1.2831]\u001b[A\n",
      "Epoch 4:  31%|███       | 46/148 [00:48<01:46,  1.04s/it, training_loss=1.2831]\u001b[A\n",
      "Epoch 4:  31%|███       | 46/148 [00:49<01:46,  1.04s/it, training_loss=1.5847]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 47/148 [00:49<01:45,  1.05s/it, training_loss=1.5847]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 47/148 [00:50<01:45,  1.05s/it, training_loss=1.5193]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 48/148 [00:50<01:44,  1.05s/it, training_loss=1.5193]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 48/148 [00:51<01:44,  1.05s/it, training_loss=1.4737]\u001b[A\n",
      "Epoch 4:  33%|███▎      | 49/148 [00:51<01:43,  1.05s/it, training_loss=1.4737]\u001b[A\n",
      "Epoch 4:  33%|███▎      | 49/148 [00:52<01:43,  1.05s/it, training_loss=1.5539]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 50/148 [00:52<01:42,  1.04s/it, training_loss=1.5539]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 50/148 [00:53<01:42,  1.04s/it, training_loss=1.1644]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 51/148 [00:53<01:41,  1.04s/it, training_loss=1.1644]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 51/148 [00:54<01:41,  1.04s/it, training_loss=1.3018]\u001b[A\n",
      "Epoch 4:  35%|███▌      | 52/148 [00:54<01:40,  1.05s/it, training_loss=1.3018]\u001b[A\n",
      "Epoch 4:  35%|███▌      | 52/148 [00:55<01:40,  1.05s/it, training_loss=1.5882]\u001b[A\n",
      "Epoch 4:  36%|███▌      | 53/148 [00:55<01:39,  1.05s/it, training_loss=1.5882]\u001b[A\n",
      "Epoch 4:  36%|███▌      | 53/148 [00:56<01:39,  1.05s/it, training_loss=1.5986]\u001b[A\n",
      "Epoch 4:  36%|███▋      | 54/148 [00:56<01:38,  1.04s/it, training_loss=1.5986]\u001b[A\n",
      "Epoch 4:  36%|███▋      | 54/148 [00:57<01:38,  1.04s/it, training_loss=1.5574]\u001b[A\n",
      "Epoch 4:  37%|███▋      | 55/148 [00:57<01:36,  1.04s/it, training_loss=1.5574]\u001b[A\n",
      "Epoch 4:  37%|███▋      | 55/148 [00:58<01:36,  1.04s/it, training_loss=1.2774]\u001b[A\n",
      "Epoch 4:  38%|███▊      | 56/148 [00:58<01:35,  1.04s/it, training_loss=1.2774]\u001b[A\n",
      "Epoch 4:  38%|███▊      | 56/148 [00:59<01:35,  1.04s/it, training_loss=1.5828]\u001b[A\n",
      "Epoch 4:  39%|███▊      | 57/148 [00:59<01:34,  1.04s/it, training_loss=1.5828]\u001b[A\n",
      "Epoch 4:  39%|███▊      | 57/148 [01:00<01:34,  1.04s/it, training_loss=1.5790]\u001b[A\n",
      "Epoch 4:  39%|███▉      | 58/148 [01:00<01:33,  1.04s/it, training_loss=1.5790]\u001b[A\n",
      "Epoch 4:  39%|███▉      | 58/148 [01:02<01:33,  1.04s/it, training_loss=1.6417]\u001b[A\n",
      "Epoch 4:  40%|███▉      | 59/148 [01:02<01:31,  1.03s/it, training_loss=1.6417]\u001b[A\n",
      "Epoch 4:  40%|███▉      | 59/148 [01:03<01:31,  1.03s/it, training_loss=1.3330]\u001b[A\n",
      "Epoch 4:  41%|████      | 60/148 [01:03<01:31,  1.03s/it, training_loss=1.3330]\u001b[A\n",
      "Epoch 4:  41%|████      | 60/148 [01:04<01:31,  1.03s/it, training_loss=1.5142]\u001b[A\n",
      "Epoch 4:  41%|████      | 61/148 [01:04<01:30,  1.04s/it, training_loss=1.5142]\u001b[A\n",
      "Epoch 4:  41%|████      | 61/148 [01:05<01:30,  1.04s/it, training_loss=1.4847]\u001b[A\n",
      "Epoch 4:  42%|████▏     | 62/148 [01:05<01:29,  1.04s/it, training_loss=1.4847]\u001b[A\n",
      "Epoch 4:  42%|████▏     | 62/148 [01:06<01:29,  1.04s/it, training_loss=1.6094]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 63/148 [01:06<01:27,  1.04s/it, training_loss=1.6094]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 63/148 [01:07<01:27,  1.04s/it, training_loss=1.2496]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 64/148 [01:07<01:27,  1.04s/it, training_loss=1.2496]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 64/148 [01:08<01:27,  1.04s/it, training_loss=1.2058]\u001b[A\n",
      "Epoch 4:  44%|████▍     | 65/148 [01:08<01:26,  1.04s/it, training_loss=1.2058]\u001b[A\n",
      "Epoch 4:  44%|████▍     | 65/148 [01:09<01:26,  1.04s/it, training_loss=1.3028]\u001b[A\n",
      "Epoch 4:  45%|████▍     | 66/148 [01:09<01:25,  1.05s/it, training_loss=1.3028]\u001b[A\n",
      "Epoch 4:  45%|████▍     | 66/148 [01:10<01:25,  1.05s/it, training_loss=1.2275]\u001b[A\n",
      "Epoch 4:  45%|████▌     | 67/148 [01:10<01:24,  1.04s/it, training_loss=1.2275]\u001b[A\n",
      "Epoch 4:  45%|████▌     | 67/148 [01:11<01:24,  1.04s/it, training_loss=1.5112]\u001b[A\n",
      "Epoch 4:  46%|████▌     | 68/148 [01:11<01:23,  1.04s/it, training_loss=1.5112]\u001b[A\n",
      "Epoch 4:  46%|████▌     | 68/148 [01:12<01:23,  1.04s/it, training_loss=1.3422]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 69/148 [01:12<01:22,  1.04s/it, training_loss=1.3422]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 69/148 [01:13<01:22,  1.04s/it, training_loss=1.0666]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 70/148 [01:13<01:21,  1.05s/it, training_loss=1.0666]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 70/148 [01:14<01:21,  1.05s/it, training_loss=1.0937]\u001b[A\n",
      "Epoch 4:  48%|████▊     | 71/148 [01:14<01:20,  1.05s/it, training_loss=1.0937]\u001b[A\n",
      "Epoch 4:  48%|████▊     | 71/148 [01:15<01:20,  1.05s/it, training_loss=1.5899]\u001b[A\n",
      "Epoch 4:  49%|████▊     | 72/148 [01:15<01:19,  1.05s/it, training_loss=1.5899]\u001b[A\n",
      "Epoch 4:  49%|████▊     | 72/148 [01:16<01:19,  1.05s/it, training_loss=1.2641]\u001b[A\n",
      "Epoch 4:  49%|████▉     | 73/148 [01:16<01:18,  1.05s/it, training_loss=1.2641]\u001b[A\n",
      "Epoch 4:  49%|████▉     | 73/148 [01:17<01:18,  1.05s/it, training_loss=1.1191]\u001b[A\n",
      "Epoch 4:  50%|█████     | 74/148 [01:17<01:17,  1.05s/it, training_loss=1.1191]\u001b[A\n",
      "Epoch 4:  50%|█████     | 74/148 [01:18<01:17,  1.05s/it, training_loss=1.1781]\u001b[A\n",
      "Epoch 4:  51%|█████     | 75/148 [01:18<01:16,  1.05s/it, training_loss=1.1781]\u001b[A\n",
      "Epoch 4:  51%|█████     | 75/148 [01:19<01:16,  1.05s/it, training_loss=1.4719]\u001b[A\n",
      "Epoch 4:  51%|█████▏    | 76/148 [01:19<01:15,  1.05s/it, training_loss=1.4719]\u001b[A\n",
      "Epoch 4:  51%|█████▏    | 76/148 [01:20<01:15,  1.05s/it, training_loss=1.1140]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 77/148 [01:20<01:14,  1.05s/it, training_loss=1.1140]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 77/148 [01:21<01:14,  1.05s/it, training_loss=1.4946]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 78/148 [01:21<01:13,  1.05s/it, training_loss=1.4946]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 78/148 [01:22<01:13,  1.05s/it, training_loss=1.2600]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 79/148 [01:22<01:12,  1.05s/it, training_loss=1.2600]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 79/148 [01:23<01:12,  1.05s/it, training_loss=1.7490]\u001b[A\n",
      "Epoch 4:  54%|█████▍    | 80/148 [01:23<01:11,  1.05s/it, training_loss=1.7490]\u001b[A\n",
      "Epoch 4:  54%|█████▍    | 80/148 [01:25<01:11,  1.05s/it, training_loss=1.3190]\u001b[A\n",
      "Epoch 4:  55%|█████▍    | 81/148 [01:25<01:10,  1.04s/it, training_loss=1.3190]\u001b[A\n",
      "Epoch 4:  55%|█████▍    | 81/148 [01:26<01:10,  1.04s/it, training_loss=1.7931]\u001b[A\n",
      "Epoch 4:  55%|█████▌    | 82/148 [01:26<01:09,  1.05s/it, training_loss=1.7931]\u001b[A\n",
      "Epoch 4:  55%|█████▌    | 82/148 [01:27<01:09,  1.05s/it, training_loss=1.6831]\u001b[A\n",
      "Epoch 4:  56%|█████▌    | 83/148 [01:27<01:07,  1.04s/it, training_loss=1.6831]\u001b[A\n",
      "Epoch 4:  56%|█████▌    | 83/148 [01:28<01:07,  1.04s/it, training_loss=1.5765]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 84/148 [01:28<01:06,  1.04s/it, training_loss=1.5765]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 84/148 [01:29<01:06,  1.04s/it, training_loss=0.9783]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 85/148 [01:29<01:05,  1.05s/it, training_loss=0.9783]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 85/148 [01:30<01:05,  1.05s/it, training_loss=1.3651]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 86/148 [01:30<01:05,  1.05s/it, training_loss=1.3651]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 86/148 [01:31<01:05,  1.05s/it, training_loss=1.1945]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 87/148 [01:31<01:04,  1.05s/it, training_loss=1.1945]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 87/148 [01:32<01:04,  1.05s/it, training_loss=1.2653]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 88/148 [01:32<01:03,  1.05s/it, training_loss=1.2653]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 88/148 [01:33<01:03,  1.05s/it, training_loss=1.5409]\u001b[A\n",
      "Epoch 4:  60%|██████    | 89/148 [01:33<01:01,  1.05s/it, training_loss=1.5409]\u001b[A\n",
      "Epoch 4:  60%|██████    | 89/148 [01:34<01:01,  1.05s/it, training_loss=1.1102]\u001b[A\n",
      "Epoch 4:  61%|██████    | 90/148 [01:34<01:01,  1.06s/it, training_loss=1.1102]\u001b[A\n",
      "Epoch 4:  61%|██████    | 90/148 [01:35<01:01,  1.06s/it, training_loss=1.6889]\u001b[A\n",
      "Epoch 4:  61%|██████▏   | 91/148 [01:35<00:59,  1.05s/it, training_loss=1.6889]\u001b[A\n",
      "Epoch 4:  61%|██████▏   | 91/148 [01:36<00:59,  1.05s/it, training_loss=1.6071]\u001b[A\n",
      "Epoch 4:  62%|██████▏   | 92/148 [01:36<00:58,  1.05s/it, training_loss=1.6071]\u001b[A\n",
      "Epoch 4:  62%|██████▏   | 92/148 [01:37<00:58,  1.05s/it, training_loss=1.5965]\u001b[A\n",
      "Epoch 4:  63%|██████▎   | 93/148 [01:37<00:57,  1.05s/it, training_loss=1.5965]\u001b[A\n",
      "Epoch 4:  63%|██████▎   | 93/148 [01:38<00:57,  1.05s/it, training_loss=1.1816]\u001b[A\n",
      "Epoch 4:  64%|██████▎   | 94/148 [01:38<00:56,  1.05s/it, training_loss=1.1816]\u001b[A\n",
      "Epoch 4:  64%|██████▎   | 94/148 [01:39<00:56,  1.05s/it, training_loss=1.1111]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 95/148 [01:39<00:55,  1.05s/it, training_loss=1.1111]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 95/148 [01:40<00:55,  1.05s/it, training_loss=1.5283]\u001b[A\n",
      "Epoch 4:  65%|██████▍   | 96/148 [01:40<00:54,  1.05s/it, training_loss=1.5283]\u001b[A\n",
      "Epoch 4:  65%|██████▍   | 96/148 [01:41<00:54,  1.05s/it, training_loss=1.6125]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 97/148 [01:41<00:53,  1.05s/it, training_loss=1.6125]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 97/148 [01:42<00:53,  1.05s/it, training_loss=1.6335]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 98/148 [01:42<00:52,  1.05s/it, training_loss=1.6335]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 98/148 [01:43<00:52,  1.05s/it, training_loss=1.5641]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 99/148 [01:43<00:51,  1.05s/it, training_loss=1.5641]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 99/148 [01:44<00:51,  1.05s/it, training_loss=1.0306]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 100/148 [01:44<00:50,  1.06s/it, training_loss=1.0306]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 100/148 [01:46<00:50,  1.06s/it, training_loss=1.5917]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 101/148 [01:46<00:49,  1.05s/it, training_loss=1.5917]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 101/148 [01:47<00:49,  1.05s/it, training_loss=1.6378]\u001b[A\n",
      "Epoch 4:  69%|██████▉   | 102/148 [01:47<00:48,  1.05s/it, training_loss=1.6378]\u001b[A\n",
      "Epoch 4:  69%|██████▉   | 102/148 [01:48<00:48,  1.05s/it, training_loss=1.2591]\u001b[A\n",
      "Epoch 4:  70%|██████▉   | 103/148 [01:48<00:47,  1.05s/it, training_loss=1.2591]\u001b[A\n",
      "Epoch 4:  70%|██████▉   | 103/148 [01:49<00:47,  1.05s/it, training_loss=1.5659]\u001b[A\n",
      "Epoch 4:  70%|███████   | 104/148 [01:49<00:46,  1.05s/it, training_loss=1.5659]\u001b[A\n",
      "Epoch 4:  70%|███████   | 104/148 [01:50<00:46,  1.05s/it, training_loss=1.2850]\u001b[A\n",
      "Epoch 4:  71%|███████   | 105/148 [01:50<00:45,  1.05s/it, training_loss=1.2850]\u001b[A\n",
      "Epoch 4:  71%|███████   | 105/148 [01:51<00:45,  1.05s/it, training_loss=1.5537]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 106/148 [01:51<00:44,  1.05s/it, training_loss=1.5537]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 106/148 [01:52<00:44,  1.05s/it, training_loss=1.6061]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 107/148 [01:52<00:43,  1.05s/it, training_loss=1.6061]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 107/148 [01:53<00:43,  1.05s/it, training_loss=1.3456]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 108/148 [01:53<00:42,  1.05s/it, training_loss=1.3456]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 108/148 [01:54<00:42,  1.05s/it, training_loss=1.4178]\u001b[A\n",
      "Epoch 4:  74%|███████▎  | 109/148 [01:54<00:41,  1.05s/it, training_loss=1.4178]\u001b[A\n",
      "Epoch 4:  74%|███████▎  | 109/148 [01:55<00:41,  1.05s/it, training_loss=1.5628]\u001b[A\n",
      "Epoch 4:  74%|███████▍  | 110/148 [01:55<00:39,  1.05s/it, training_loss=1.5628]\u001b[A\n",
      "Epoch 4:  74%|███████▍  | 110/148 [01:56<00:39,  1.05s/it, training_loss=1.4753]\u001b[A\n",
      "Epoch 4:  75%|███████▌  | 111/148 [01:56<00:38,  1.05s/it, training_loss=1.4753]\u001b[A\n",
      "Epoch 4:  75%|███████▌  | 111/148 [01:57<00:38,  1.05s/it, training_loss=1.1101]\u001b[A\n",
      "Epoch 4:  76%|███████▌  | 112/148 [01:57<00:38,  1.06s/it, training_loss=1.1101]\u001b[A\n",
      "Epoch 4:  76%|███████▌  | 112/148 [01:58<00:38,  1.06s/it, training_loss=1.6309]\u001b[A\n",
      "Epoch 4:  76%|███████▋  | 113/148 [01:58<00:36,  1.06s/it, training_loss=1.6309]\u001b[A\n",
      "Epoch 4:  76%|███████▋  | 113/148 [01:59<00:36,  1.06s/it, training_loss=1.5420]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 114/148 [01:59<00:35,  1.05s/it, training_loss=1.5420]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 114/148 [02:00<00:35,  1.05s/it, training_loss=1.6605]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 115/148 [02:00<00:34,  1.05s/it, training_loss=1.6605]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 115/148 [02:01<00:34,  1.05s/it, training_loss=1.0951]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 116/148 [02:01<00:33,  1.06s/it, training_loss=1.0951]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 116/148 [02:02<00:33,  1.06s/it, training_loss=1.5916]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 117/148 [02:02<00:32,  1.06s/it, training_loss=1.5916]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 117/148 [02:03<00:32,  1.06s/it, training_loss=1.1747]\u001b[A\n",
      "Epoch 4:  80%|███████▉  | 118/148 [02:03<00:31,  1.06s/it, training_loss=1.1747]\u001b[A\n",
      "Epoch 4:  80%|███████▉  | 118/148 [02:05<00:31,  1.06s/it, training_loss=1.6102]\u001b[A\n",
      "Epoch 4:  80%|████████  | 119/148 [02:05<00:30,  1.06s/it, training_loss=1.6102]\u001b[A\n",
      "Epoch 4:  80%|████████  | 119/148 [02:06<00:30,  1.06s/it, training_loss=1.6559]\u001b[A\n",
      "Epoch 4:  81%|████████  | 120/148 [02:06<00:29,  1.06s/it, training_loss=1.6559]\u001b[A\n",
      "Epoch 4:  81%|████████  | 120/148 [02:07<00:29,  1.06s/it, training_loss=1.6477]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 121/148 [02:07<00:28,  1.06s/it, training_loss=1.6477]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 121/148 [02:08<00:28,  1.06s/it, training_loss=1.5269]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 122/148 [02:08<00:27,  1.06s/it, training_loss=1.5269]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 122/148 [02:09<00:27,  1.06s/it, training_loss=1.2236]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 123/148 [02:09<00:26,  1.05s/it, training_loss=1.2236]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 123/148 [02:10<00:26,  1.05s/it, training_loss=1.2418]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 124/148 [02:10<00:25,  1.05s/it, training_loss=1.2418]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 124/148 [02:11<00:25,  1.05s/it, training_loss=1.5584]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 125/148 [02:11<00:24,  1.05s/it, training_loss=1.5584]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 125/148 [02:12<00:24,  1.05s/it, training_loss=1.1662]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 126/148 [02:12<00:23,  1.05s/it, training_loss=1.1662]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 126/148 [02:13<00:23,  1.05s/it, training_loss=1.3744]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 127/148 [02:13<00:22,  1.05s/it, training_loss=1.3744]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 127/148 [02:14<00:22,  1.05s/it, training_loss=1.5736]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 128/148 [02:14<00:21,  1.05s/it, training_loss=1.5736]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 128/148 [02:15<00:21,  1.05s/it, training_loss=1.6415]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 129/148 [02:15<00:20,  1.05s/it, training_loss=1.6415]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 129/148 [02:16<00:20,  1.05s/it, training_loss=1.6244]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 130/148 [02:16<00:18,  1.05s/it, training_loss=1.6244]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 130/148 [02:17<00:18,  1.05s/it, training_loss=1.0337]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 131/148 [02:17<00:17,  1.05s/it, training_loss=1.0337]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 131/148 [02:18<00:17,  1.05s/it, training_loss=1.5466]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 132/148 [02:18<00:16,  1.05s/it, training_loss=1.5466]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 132/148 [02:19<00:16,  1.05s/it, training_loss=1.1540]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 133/148 [02:19<00:15,  1.05s/it, training_loss=1.1540]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 133/148 [02:20<00:15,  1.05s/it, training_loss=1.1238]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 134/148 [02:20<00:14,  1.06s/it, training_loss=1.1238]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 134/148 [02:21<00:14,  1.06s/it, training_loss=1.5477]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 135/148 [02:21<00:13,  1.06s/it, training_loss=1.5477]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 135/148 [02:22<00:13,  1.06s/it, training_loss=1.5624]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 136/148 [02:22<00:12,  1.05s/it, training_loss=1.5624]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 136/148 [02:23<00:12,  1.05s/it, training_loss=0.9183]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 137/148 [02:23<00:11,  1.06s/it, training_loss=0.9183]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 137/148 [02:25<00:11,  1.06s/it, training_loss=1.5924]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 138/148 [02:25<00:10,  1.06s/it, training_loss=1.5924]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 138/148 [02:26<00:10,  1.06s/it, training_loss=1.1162]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 139/148 [02:26<00:09,  1.06s/it, training_loss=1.1162]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 139/148 [02:27<00:09,  1.06s/it, training_loss=1.1614]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 140/148 [02:27<00:08,  1.06s/it, training_loss=1.1614]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 140/148 [02:28<00:08,  1.06s/it, training_loss=1.3646]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 141/148 [02:28<00:07,  1.05s/it, training_loss=1.3646]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 141/148 [02:29<00:07,  1.05s/it, training_loss=1.5286]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 142/148 [02:29<00:06,  1.06s/it, training_loss=1.5286]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 142/148 [02:30<00:06,  1.06s/it, training_loss=1.3070]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 143/148 [02:30<00:05,  1.06s/it, training_loss=1.3070]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 143/148 [02:31<00:05,  1.06s/it, training_loss=1.6534]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 144/148 [02:31<00:04,  1.05s/it, training_loss=1.6534]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 144/148 [02:32<00:04,  1.05s/it, training_loss=0.8641]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 145/148 [02:32<00:03,  1.06s/it, training_loss=0.8641]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 145/148 [02:33<00:03,  1.06s/it, training_loss=1.5418]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 146/148 [02:33<00:02,  1.05s/it, training_loss=1.5418]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 146/148 [02:34<00:02,  1.05s/it, training_loss=1.0967]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 147/148 [02:34<00:01,  1.06s/it, training_loss=1.0967]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 147/148 [02:35<00:01,  1.06s/it, training_loss=1.2874]\u001b[A\n",
      "Epoch 4: 100%|██████████| 148/148 [02:35<00:00,  1.03it/s, training_loss=1.2874]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:13:15,102 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:13:15,105 - INFO - Memory usage after evaluation start: 3688.43 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:08,  3.00it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:08,  2.94it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:08,  2.93it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:02<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:06,  2.92it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:03<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:05,  2.92it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:04<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:04<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:05<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:05<00:03,  2.92it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:06<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:07<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:08<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:08<00:00,  2.90it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:08<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:13:24,071 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 00:13:24,086 - INFO - Class 'Drama': Optimal threshold = 0.650, F1 Score = 0.533\n",
      "2025-02-16 00:13:24,100 - INFO - Class 'Horor': Optimal threshold = 0.650, F1 Score = 0.785\n",
      "2025-02-16 00:13:24,113 - INFO - Class 'Komedi': Optimal threshold = 0.600, F1 Score = 0.595\n",
      "2025-02-16 00:13:24,127 - INFO - Class 'Laga': Optimal threshold = 0.650, F1 Score = 0.396\n",
      "2025-02-16 00:13:24,140 - INFO - Class 'Romantis': Optimal threshold = 0.750, F1 Score = 0.535\n",
      "2025-02-16 00:13:24,161 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:13:24,166 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:13:24,167 - INFO - Accuracy: 0.7586\n",
      "2025-02-16 00:13:24,168 - INFO - F1_score: 0.5333\n",
      "2025-02-16 00:13:24,169 - INFO - Precision: 0.5902\n",
      "2025-02-16 00:13:24,170 - INFO - Recall: 0.4865\n",
      "2025-02-16 00:13:24,176 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:13:24,177 - INFO - Accuracy: 0.8889\n",
      "2025-02-16 00:13:24,178 - INFO - F1_score: 0.7852\n",
      "2025-02-16 00:13:24,178 - INFO - Precision: 0.6795\n",
      "2025-02-16 00:13:24,180 - INFO - Recall: 0.9298\n",
      "2025-02-16 00:13:24,185 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:13:24,186 - INFO - Accuracy: 0.7701\n",
      "2025-02-16 00:13:24,186 - INFO - F1_score: 0.5946\n",
      "2025-02-16 00:13:24,187 - INFO - Precision: 0.4889\n",
      "2025-02-16 00:13:24,188 - INFO - Recall: 0.7586\n",
      "2025-02-16 00:13:24,193 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:13:24,194 - INFO - Accuracy: 0.7778\n",
      "2025-02-16 00:13:24,194 - INFO - F1_score: 0.3958\n",
      "2025-02-16 00:13:24,195 - INFO - Precision: 0.3276\n",
      "2025-02-16 00:13:24,195 - INFO - Recall: 0.5000\n",
      "2025-02-16 00:13:24,201 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:13:24,202 - INFO - Accuracy: 0.8736\n",
      "2025-02-16 00:13:24,202 - INFO - F1_score: 0.5352\n",
      "2025-02-16 00:13:24,203 - INFO - Precision: 0.5135\n",
      "2025-02-16 00:13:24,204 - INFO - Recall: 0.5588\n",
      "2025-02-16 00:13:24,206 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:13:28,032 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:13:28,034 - INFO - Memory usage after evaluation end: 3694.18 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [11:53<4:48:40, 178.56s/it, Train Loss=1.4083, Val Loss=0.0527, Accuracy=0.8138]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:13:36,876 - INFO - New best accuracy: 0.8138\n",
      "2025-02-16 00:13:38,308 - INFO - New best loss: 0.0527\n",
      "2025-02-16 00:13:39,794 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 4/100 [11:56<4:46:37, 179.14s/it, Train Loss=1.4083, Val Loss=0.0527, Accuracy=0.8138]\n",
      "Epoch 5:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=1.5687]\u001b[A\n",
      "Epoch 5:   1%|          | 1/148 [00:01<02:38,  1.08s/it, training_loss=1.5687]\u001b[A\n",
      "Epoch 5:   1%|          | 1/148 [00:02<02:38,  1.08s/it, training_loss=1.5795]\u001b[A\n",
      "Epoch 5:   1%|▏         | 2/148 [00:02<02:33,  1.05s/it, training_loss=1.5795]\u001b[A\n",
      "Epoch 5:   1%|▏         | 2/148 [00:03<02:33,  1.05s/it, training_loss=1.2761]\u001b[A\n",
      "Epoch 5:   2%|▏         | 3/148 [00:03<02:32,  1.05s/it, training_loss=1.2761]\u001b[A\n",
      "Epoch 5:   2%|▏         | 3/148 [00:04<02:32,  1.05s/it, training_loss=1.1138]\u001b[A\n",
      "Epoch 5:   3%|▎         | 4/148 [00:04<02:32,  1.06s/it, training_loss=1.1138]\u001b[A\n",
      "Epoch 5:   3%|▎         | 4/148 [00:05<02:32,  1.06s/it, training_loss=1.3345]\u001b[A\n",
      "Epoch 5:   3%|▎         | 5/148 [00:05<02:31,  1.06s/it, training_loss=1.3345]\u001b[A\n",
      "Epoch 5:   3%|▎         | 5/148 [00:06<02:31,  1.06s/it, training_loss=1.1786]\u001b[A\n",
      "Epoch 5:   4%|▍         | 6/148 [00:06<02:30,  1.06s/it, training_loss=1.1786]\u001b[A\n",
      "Epoch 5:   4%|▍         | 6/148 [00:07<02:30,  1.06s/it, training_loss=1.3609]\u001b[A\n",
      "Epoch 5:   5%|▍         | 7/148 [00:07<02:28,  1.05s/it, training_loss=1.3609]\u001b[A\n",
      "Epoch 5:   5%|▍         | 7/148 [00:08<02:28,  1.05s/it, training_loss=1.6388]\u001b[A\n",
      "Epoch 5:   5%|▌         | 8/148 [00:08<02:27,  1.05s/it, training_loss=1.6388]\u001b[A\n",
      "Epoch 5:   5%|▌         | 8/148 [00:09<02:27,  1.05s/it, training_loss=1.1739]\u001b[A\n",
      "Epoch 5:   6%|▌         | 9/148 [00:09<02:26,  1.06s/it, training_loss=1.1739]\u001b[A\n",
      "Epoch 5:   6%|▌         | 9/148 [00:10<02:26,  1.06s/it, training_loss=1.5822]\u001b[A\n",
      "Epoch 5:   7%|▋         | 10/148 [00:10<02:25,  1.05s/it, training_loss=1.5822]\u001b[A\n",
      "Epoch 5:   7%|▋         | 10/148 [00:11<02:25,  1.05s/it, training_loss=0.9903]\u001b[A\n",
      "Epoch 5:   7%|▋         | 11/148 [00:11<02:24,  1.05s/it, training_loss=0.9903]\u001b[A\n",
      "Epoch 5:   7%|▋         | 11/148 [00:12<02:24,  1.05s/it, training_loss=1.0112]\u001b[A\n",
      "Epoch 5:   8%|▊         | 12/148 [00:12<02:23,  1.06s/it, training_loss=1.0112]\u001b[A\n",
      "Epoch 5:   8%|▊         | 12/148 [00:13<02:23,  1.06s/it, training_loss=1.4268]\u001b[A\n",
      "Epoch 5:   9%|▉         | 13/148 [00:13<02:23,  1.06s/it, training_loss=1.4268]\u001b[A\n",
      "Epoch 5:   9%|▉         | 13/148 [00:14<02:23,  1.06s/it, training_loss=1.5113]\u001b[A\n",
      "Epoch 5:   9%|▉         | 14/148 [00:14<02:22,  1.06s/it, training_loss=1.5113]\u001b[A\n",
      "Epoch 5:   9%|▉         | 14/148 [00:15<02:22,  1.06s/it, training_loss=0.8966]\u001b[A\n",
      "Epoch 5:  10%|█         | 15/148 [00:15<02:21,  1.07s/it, training_loss=0.8966]\u001b[A\n",
      "Epoch 5:  10%|█         | 15/148 [00:16<02:21,  1.07s/it, training_loss=1.1878]\u001b[A\n",
      "Epoch 5:  11%|█         | 16/148 [00:16<02:20,  1.07s/it, training_loss=1.1878]\u001b[A\n",
      "Epoch 5:  11%|█         | 16/148 [00:18<02:20,  1.07s/it, training_loss=1.1372]\u001b[A\n",
      "Epoch 5:  11%|█▏        | 17/148 [00:18<02:19,  1.07s/it, training_loss=1.1372]\u001b[A\n",
      "Epoch 5:  11%|█▏        | 17/148 [00:19<02:19,  1.07s/it, training_loss=1.5489]\u001b[A\n",
      "Epoch 5:  12%|█▏        | 18/148 [00:19<02:18,  1.07s/it, training_loss=1.5489]\u001b[A\n",
      "Epoch 5:  12%|█▏        | 18/148 [00:20<02:18,  1.07s/it, training_loss=1.6318]\u001b[A\n",
      "Epoch 5:  13%|█▎        | 19/148 [00:20<02:17,  1.07s/it, training_loss=1.6318]\u001b[A\n",
      "Epoch 5:  13%|█▎        | 19/148 [00:21<02:17,  1.07s/it, training_loss=1.5005]\u001b[A\n",
      "Epoch 5:  14%|█▎        | 20/148 [00:21<02:16,  1.06s/it, training_loss=1.5005]\u001b[A\n",
      "Epoch 5:  14%|█▎        | 20/148 [00:22<02:16,  1.06s/it, training_loss=1.5067]\u001b[A\n",
      "Epoch 5:  14%|█▍        | 21/148 [00:22<02:15,  1.06s/it, training_loss=1.5067]\u001b[A\n",
      "Epoch 5:  14%|█▍        | 21/148 [00:23<02:15,  1.06s/it, training_loss=1.4600]\u001b[A\n",
      "Epoch 5:  15%|█▍        | 22/148 [00:23<02:13,  1.06s/it, training_loss=1.4600]\u001b[A\n",
      "Epoch 5:  15%|█▍        | 22/148 [00:24<02:13,  1.06s/it, training_loss=1.4530]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 23/148 [00:24<02:12,  1.06s/it, training_loss=1.4530]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 23/148 [00:25<02:12,  1.06s/it, training_loss=1.6440]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 24/148 [00:25<02:11,  1.06s/it, training_loss=1.6440]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 24/148 [00:26<02:11,  1.06s/it, training_loss=0.9736]\u001b[A\n",
      "Epoch 5:  17%|█▋        | 25/148 [00:26<02:10,  1.06s/it, training_loss=0.9736]\u001b[A\n",
      "Epoch 5:  17%|█▋        | 25/148 [00:27<02:10,  1.06s/it, training_loss=0.9701]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 26/148 [00:27<02:09,  1.06s/it, training_loss=0.9701]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 26/148 [00:28<02:09,  1.06s/it, training_loss=1.7031]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 27/148 [00:28<02:08,  1.06s/it, training_loss=1.7031]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 27/148 [00:29<02:08,  1.06s/it, training_loss=1.5038]\u001b[A\n",
      "Epoch 5:  19%|█▉        | 28/148 [00:29<02:07,  1.06s/it, training_loss=1.5038]\u001b[A\n",
      "Epoch 5:  19%|█▉        | 28/148 [00:30<02:07,  1.06s/it, training_loss=1.4858]\u001b[A\n",
      "Epoch 5:  20%|█▉        | 29/148 [00:30<02:06,  1.06s/it, training_loss=1.4858]\u001b[A\n",
      "Epoch 5:  20%|█▉        | 29/148 [00:31<02:06,  1.06s/it, training_loss=1.5743]\u001b[A\n",
      "Epoch 5:  20%|██        | 30/148 [00:31<02:05,  1.06s/it, training_loss=1.5743]\u001b[A\n",
      "Epoch 5:  20%|██        | 30/148 [00:32<02:05,  1.06s/it, training_loss=1.4179]\u001b[A\n",
      "Epoch 5:  21%|██        | 31/148 [00:32<02:04,  1.07s/it, training_loss=1.4179]\u001b[A\n",
      "Epoch 5:  21%|██        | 31/148 [00:33<02:04,  1.07s/it, training_loss=1.4100]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 32/148 [00:33<02:03,  1.07s/it, training_loss=1.4100]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 32/148 [00:35<02:03,  1.07s/it, training_loss=1.5609]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 33/148 [00:35<02:02,  1.06s/it, training_loss=1.5609]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 33/148 [00:36<02:02,  1.06s/it, training_loss=1.3496]\u001b[A\n",
      "Epoch 5:  23%|██▎       | 34/148 [00:36<02:01,  1.06s/it, training_loss=1.3496]\u001b[A\n",
      "Epoch 5:  23%|██▎       | 34/148 [00:37<02:01,  1.06s/it, training_loss=1.6097]\u001b[A\n",
      "Epoch 5:  24%|██▎       | 35/148 [00:37<01:59,  1.06s/it, training_loss=1.6097]\u001b[A\n",
      "Epoch 5:  24%|██▎       | 35/148 [00:38<01:59,  1.06s/it, training_loss=1.0536]\u001b[A\n",
      "Epoch 5:  24%|██▍       | 36/148 [00:38<01:59,  1.07s/it, training_loss=1.0536]\u001b[A\n",
      "Epoch 5:  24%|██▍       | 36/148 [00:39<01:59,  1.07s/it, training_loss=1.1153]\u001b[A\n",
      "Epoch 5:  25%|██▌       | 37/148 [00:39<01:58,  1.07s/it, training_loss=1.1153]\u001b[A\n",
      "Epoch 5:  25%|██▌       | 37/148 [00:40<01:58,  1.07s/it, training_loss=1.5671]\u001b[A\n",
      "Epoch 5:  26%|██▌       | 38/148 [00:40<01:57,  1.07s/it, training_loss=1.5671]\u001b[A\n",
      "Epoch 5:  26%|██▌       | 38/148 [00:41<01:57,  1.07s/it, training_loss=0.9469]\u001b[A\n",
      "Epoch 5:  26%|██▋       | 39/148 [00:41<01:56,  1.07s/it, training_loss=0.9469]\u001b[A\n",
      "Epoch 5:  26%|██▋       | 39/148 [00:42<01:56,  1.07s/it, training_loss=0.8855]\u001b[A\n",
      "Epoch 5:  27%|██▋       | 40/148 [00:42<01:55,  1.07s/it, training_loss=0.8855]\u001b[A\n",
      "Epoch 5:  27%|██▋       | 40/148 [00:43<01:55,  1.07s/it, training_loss=1.5381]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 41/148 [00:43<01:53,  1.06s/it, training_loss=1.5381]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 41/148 [00:44<01:53,  1.06s/it, training_loss=1.0852]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 42/148 [00:44<01:51,  1.06s/it, training_loss=1.0852]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 42/148 [00:45<01:51,  1.06s/it, training_loss=1.5297]\u001b[A\n",
      "Epoch 5:  29%|██▉       | 43/148 [00:45<01:50,  1.06s/it, training_loss=1.5297]\u001b[A\n",
      "Epoch 5:  29%|██▉       | 43/148 [00:46<01:50,  1.06s/it, training_loss=1.4697]\u001b[A\n",
      "Epoch 5:  30%|██▉       | 44/148 [00:46<01:49,  1.05s/it, training_loss=1.4697]\u001b[A\n",
      "Epoch 5:  30%|██▉       | 44/148 [00:47<01:49,  1.05s/it, training_loss=1.0538]\u001b[A\n",
      "Epoch 5:  30%|███       | 45/148 [00:47<01:48,  1.05s/it, training_loss=1.0538]\u001b[A\n",
      "Epoch 5:  30%|███       | 45/148 [00:48<01:48,  1.05s/it, training_loss=1.6603]\u001b[A\n",
      "Epoch 5:  31%|███       | 46/148 [00:48<01:47,  1.05s/it, training_loss=1.6603]\u001b[A\n",
      "Epoch 5:  31%|███       | 46/148 [00:49<01:47,  1.05s/it, training_loss=1.6277]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 47/148 [00:49<01:46,  1.05s/it, training_loss=1.6277]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 47/148 [00:50<01:46,  1.05s/it, training_loss=1.4073]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 48/148 [00:50<01:45,  1.05s/it, training_loss=1.4073]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 48/148 [00:51<01:45,  1.05s/it, training_loss=1.2606]\u001b[A\n",
      "Epoch 5:  33%|███▎      | 49/148 [00:51<01:44,  1.05s/it, training_loss=1.2606]\u001b[A\n",
      "Epoch 5:  33%|███▎      | 49/148 [00:53<01:44,  1.05s/it, training_loss=1.5559]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 50/148 [00:53<01:42,  1.05s/it, training_loss=1.5559]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 50/148 [00:54<01:42,  1.05s/it, training_loss=1.6766]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 51/148 [00:54<01:41,  1.05s/it, training_loss=1.6766]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 51/148 [00:55<01:41,  1.05s/it, training_loss=1.7994]\u001b[A\n",
      "Epoch 5:  35%|███▌      | 52/148 [00:55<01:40,  1.05s/it, training_loss=1.7994]\u001b[A\n",
      "Epoch 5:  35%|███▌      | 52/148 [00:56<01:40,  1.05s/it, training_loss=1.6320]\u001b[A\n",
      "Epoch 5:  36%|███▌      | 53/148 [00:56<01:38,  1.04s/it, training_loss=1.6320]\u001b[A\n",
      "Epoch 5:  36%|███▌      | 53/148 [00:57<01:38,  1.04s/it, training_loss=1.1016]\u001b[A\n",
      "Epoch 5:  36%|███▋      | 54/148 [00:57<01:38,  1.04s/it, training_loss=1.1016]\u001b[A\n",
      "Epoch 5:  36%|███▋      | 54/148 [00:58<01:38,  1.04s/it, training_loss=1.5614]\u001b[A\n",
      "Epoch 5:  37%|███▋      | 55/148 [00:58<01:36,  1.04s/it, training_loss=1.5614]\u001b[A\n",
      "Epoch 5:  37%|███▋      | 55/148 [00:59<01:36,  1.04s/it, training_loss=1.0667]\u001b[A\n",
      "Epoch 5:  38%|███▊      | 56/148 [00:59<01:35,  1.04s/it, training_loss=1.0667]\u001b[A\n",
      "Epoch 5:  38%|███▊      | 56/148 [01:00<01:35,  1.04s/it, training_loss=1.0260]\u001b[A\n",
      "Epoch 5:  39%|███▊      | 57/148 [01:00<01:34,  1.04s/it, training_loss=1.0260]\u001b[A\n",
      "Epoch 5:  39%|███▊      | 57/148 [01:01<01:34,  1.04s/it, training_loss=1.7135]\u001b[A\n",
      "Epoch 5:  39%|███▉      | 58/148 [01:01<01:33,  1.04s/it, training_loss=1.7135]\u001b[A\n",
      "Epoch 5:  39%|███▉      | 58/148 [01:02<01:33,  1.04s/it, training_loss=1.6925]\u001b[A\n",
      "Epoch 5:  40%|███▉      | 59/148 [01:02<01:32,  1.04s/it, training_loss=1.6925]\u001b[A\n",
      "Epoch 5:  40%|███▉      | 59/148 [01:03<01:32,  1.04s/it, training_loss=1.1291]\u001b[A\n",
      "Epoch 5:  41%|████      | 60/148 [01:03<01:31,  1.04s/it, training_loss=1.1291]\u001b[A\n",
      "Epoch 5:  41%|████      | 60/148 [01:04<01:31,  1.04s/it, training_loss=1.5576]\u001b[A\n",
      "Epoch 5:  41%|████      | 61/148 [01:04<01:30,  1.04s/it, training_loss=1.5576]\u001b[A\n",
      "Epoch 5:  41%|████      | 61/148 [01:05<01:30,  1.04s/it, training_loss=0.9642]\u001b[A\n",
      "Epoch 5:  42%|████▏     | 62/148 [01:05<01:30,  1.05s/it, training_loss=0.9642]\u001b[A\n",
      "Epoch 5:  42%|████▏     | 62/148 [01:06<01:30,  1.05s/it, training_loss=0.8818]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 63/148 [01:06<01:28,  1.05s/it, training_loss=0.8818]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 63/148 [01:07<01:28,  1.05s/it, training_loss=1.1489]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 64/148 [01:07<01:27,  1.04s/it, training_loss=1.1489]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 64/148 [01:08<01:27,  1.04s/it, training_loss=1.6515]\u001b[A\n",
      "Epoch 5:  44%|████▍     | 65/148 [01:08<01:26,  1.04s/it, training_loss=1.6515]\u001b[A\n",
      "Epoch 5:  44%|████▍     | 65/148 [01:09<01:26,  1.04s/it, training_loss=0.9309]\u001b[A\n",
      "Epoch 5:  45%|████▍     | 66/148 [01:09<01:25,  1.04s/it, training_loss=0.9309]\u001b[A\n",
      "Epoch 5:  45%|████▍     | 66/148 [01:10<01:25,  1.04s/it, training_loss=1.1681]\u001b[A\n",
      "Epoch 5:  45%|████▌     | 67/148 [01:10<01:24,  1.04s/it, training_loss=1.1681]\u001b[A\n",
      "Epoch 5:  45%|████▌     | 67/148 [01:11<01:24,  1.04s/it, training_loss=0.9074]\u001b[A\n",
      "Epoch 5:  46%|████▌     | 68/148 [01:11<01:23,  1.04s/it, training_loss=0.9074]\u001b[A\n",
      "Epoch 5:  46%|████▌     | 68/148 [01:12<01:23,  1.04s/it, training_loss=1.5079]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 69/148 [01:12<01:22,  1.04s/it, training_loss=1.5079]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 69/148 [01:13<01:22,  1.04s/it, training_loss=1.6011]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 70/148 [01:13<01:21,  1.04s/it, training_loss=1.6011]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 70/148 [01:14<01:21,  1.04s/it, training_loss=1.7464]\u001b[A\n",
      "Epoch 5:  48%|████▊     | 71/148 [01:14<01:20,  1.04s/it, training_loss=1.7464]\u001b[A\n",
      "Epoch 5:  48%|████▊     | 71/148 [01:15<01:20,  1.04s/it, training_loss=1.2888]\u001b[A\n",
      "Epoch 5:  49%|████▊     | 72/148 [01:15<01:19,  1.04s/it, training_loss=1.2888]\u001b[A\n",
      "Epoch 5:  49%|████▊     | 72/148 [01:16<01:19,  1.04s/it, training_loss=0.9597]\u001b[A\n",
      "Epoch 5:  49%|████▉     | 73/148 [01:16<01:18,  1.04s/it, training_loss=0.9597]\u001b[A\n",
      "Epoch 5:  49%|████▉     | 73/148 [01:18<01:18,  1.04s/it, training_loss=0.8811]\u001b[A\n",
      "Epoch 5:  50%|█████     | 74/148 [01:18<01:17,  1.05s/it, training_loss=0.8811]\u001b[A\n",
      "Epoch 5:  50%|█████     | 74/148 [01:19<01:17,  1.05s/it, training_loss=1.6676]\u001b[A\n",
      "Epoch 5:  51%|█████     | 75/148 [01:19<01:16,  1.05s/it, training_loss=1.6676]\u001b[A\n",
      "Epoch 5:  51%|█████     | 75/148 [01:20<01:16,  1.05s/it, training_loss=1.4577]\u001b[A\n",
      "Epoch 5:  51%|█████▏    | 76/148 [01:20<01:15,  1.05s/it, training_loss=1.4577]\u001b[A\n",
      "Epoch 5:  51%|█████▏    | 76/148 [01:21<01:15,  1.05s/it, training_loss=1.5252]\u001b[A\n",
      "Epoch 5:  52%|█████▏    | 77/148 [01:21<01:14,  1.04s/it, training_loss=1.5252]\u001b[A\n",
      "Epoch 5:  52%|█████▏    | 77/148 [01:22<01:14,  1.04s/it, training_loss=1.6030]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 78/148 [01:22<01:12,  1.04s/it, training_loss=1.6030]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 78/148 [01:23<01:12,  1.04s/it, training_loss=1.0039]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 79/148 [01:23<01:11,  1.04s/it, training_loss=1.0039]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 79/148 [01:24<01:11,  1.04s/it, training_loss=1.5142]\u001b[A\n",
      "Epoch 5:  54%|█████▍    | 80/148 [01:24<01:10,  1.04s/it, training_loss=1.5142]\u001b[A\n",
      "Epoch 5:  54%|█████▍    | 80/148 [01:25<01:10,  1.04s/it, training_loss=1.5325]\u001b[A\n",
      "Epoch 5:  55%|█████▍    | 81/148 [01:25<01:09,  1.04s/it, training_loss=1.5325]\u001b[A\n",
      "Epoch 5:  55%|█████▍    | 81/148 [01:26<01:09,  1.04s/it, training_loss=1.6118]\u001b[A\n",
      "Epoch 5:  55%|█████▌    | 82/148 [01:26<01:08,  1.04s/it, training_loss=1.6118]\u001b[A\n",
      "Epoch 5:  55%|█████▌    | 82/148 [01:27<01:08,  1.04s/it, training_loss=1.5316]\u001b[A\n",
      "Epoch 5:  56%|█████▌    | 83/148 [01:27<01:07,  1.04s/it, training_loss=1.5316]\u001b[A\n",
      "Epoch 5:  56%|█████▌    | 83/148 [01:28<01:07,  1.04s/it, training_loss=1.0194]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 84/148 [01:28<01:06,  1.04s/it, training_loss=1.0194]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 84/148 [01:29<01:06,  1.04s/it, training_loss=1.3479]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 85/148 [01:29<01:05,  1.04s/it, training_loss=1.3479]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 85/148 [01:30<01:05,  1.04s/it, training_loss=1.5507]\u001b[A\n",
      "Epoch 5:  58%|█████▊    | 86/148 [01:30<01:04,  1.04s/it, training_loss=1.5507]\u001b[A\n",
      "Epoch 5:  58%|█████▊    | 86/148 [01:31<01:04,  1.04s/it, training_loss=1.5494]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 87/148 [01:31<01:03,  1.04s/it, training_loss=1.5494]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 87/148 [01:32<01:03,  1.04s/it, training_loss=1.2594]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 88/148 [01:32<01:02,  1.05s/it, training_loss=1.2594]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 88/148 [01:33<01:02,  1.05s/it, training_loss=1.6884]\u001b[A\n",
      "Epoch 5:  60%|██████    | 89/148 [01:33<01:01,  1.04s/it, training_loss=1.6884]\u001b[A\n",
      "Epoch 5:  60%|██████    | 89/148 [01:34<01:01,  1.04s/it, training_loss=1.6207]\u001b[A\n",
      "Epoch 5:  61%|██████    | 90/148 [01:34<01:00,  1.04s/it, training_loss=1.6207]\u001b[A\n",
      "Epoch 5:  61%|██████    | 90/148 [01:35<01:00,  1.04s/it, training_loss=1.6029]\u001b[A\n",
      "Epoch 5:  61%|██████▏   | 91/148 [01:35<00:59,  1.04s/it, training_loss=1.6029]\u001b[A\n",
      "Epoch 5:  61%|██████▏   | 91/148 [01:36<00:59,  1.04s/it, training_loss=1.5017]\u001b[A\n",
      "Epoch 5:  62%|██████▏   | 92/148 [01:36<00:58,  1.05s/it, training_loss=1.5017]\u001b[A\n",
      "Epoch 5:  62%|██████▏   | 92/148 [01:37<00:58,  1.05s/it, training_loss=1.5267]\u001b[A\n",
      "Epoch 5:  63%|██████▎   | 93/148 [01:37<00:57,  1.04s/it, training_loss=1.5267]\u001b[A\n",
      "Epoch 5:  63%|██████▎   | 93/148 [01:38<00:57,  1.04s/it, training_loss=1.6113]\u001b[A\n",
      "Epoch 5:  64%|██████▎   | 94/148 [01:38<00:56,  1.04s/it, training_loss=1.6113]\u001b[A\n",
      "Epoch 5:  64%|██████▎   | 94/148 [01:39<00:56,  1.04s/it, training_loss=1.6034]\u001b[A\n",
      "Epoch 5:  64%|██████▍   | 95/148 [01:39<00:55,  1.04s/it, training_loss=1.6034]\u001b[A\n",
      "Epoch 5:  64%|██████▍   | 95/148 [01:40<00:55,  1.04s/it, training_loss=1.3249]\u001b[A\n",
      "Epoch 5:  65%|██████▍   | 96/148 [01:40<00:54,  1.05s/it, training_loss=1.3249]\u001b[A\n",
      "Epoch 5:  65%|██████▍   | 96/148 [01:42<00:54,  1.05s/it, training_loss=1.2432]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 97/148 [01:42<00:53,  1.05s/it, training_loss=1.2432]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 97/148 [01:43<00:53,  1.05s/it, training_loss=1.5959]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 98/148 [01:43<00:52,  1.05s/it, training_loss=1.5959]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 98/148 [01:44<00:52,  1.05s/it, training_loss=1.2215]\u001b[A\n",
      "Epoch 5:  67%|██████▋   | 99/148 [01:44<00:51,  1.05s/it, training_loss=1.2215]\u001b[A\n",
      "Epoch 5:  67%|██████▋   | 99/148 [01:45<00:51,  1.05s/it, training_loss=1.5331]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 100/148 [01:45<00:50,  1.05s/it, training_loss=1.5331]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 100/148 [01:46<00:50,  1.05s/it, training_loss=0.9842]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 101/148 [01:46<00:49,  1.05s/it, training_loss=0.9842]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 101/148 [01:47<00:49,  1.05s/it, training_loss=1.0562]\u001b[A\n",
      "Epoch 5:  69%|██████▉   | 102/148 [01:47<00:48,  1.05s/it, training_loss=1.0562]\u001b[A\n",
      "Epoch 5:  69%|██████▉   | 102/148 [01:48<00:48,  1.05s/it, training_loss=1.1641]\u001b[A\n",
      "Epoch 5:  70%|██████▉   | 103/148 [01:48<00:47,  1.05s/it, training_loss=1.1641]\u001b[A\n",
      "Epoch 5:  70%|██████▉   | 103/148 [01:49<00:47,  1.05s/it, training_loss=1.5630]\u001b[A\n",
      "Epoch 5:  70%|███████   | 104/148 [01:49<00:46,  1.05s/it, training_loss=1.5630]\u001b[A\n",
      "Epoch 5:  70%|███████   | 104/148 [01:50<00:46,  1.05s/it, training_loss=1.6124]\u001b[A\n",
      "Epoch 5:  71%|███████   | 105/148 [01:50<00:44,  1.05s/it, training_loss=1.6124]\u001b[A\n",
      "Epoch 5:  71%|███████   | 105/148 [01:51<00:44,  1.05s/it, training_loss=1.6848]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 106/148 [01:51<00:43,  1.04s/it, training_loss=1.6848]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 106/148 [01:52<00:43,  1.04s/it, training_loss=1.1627]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 107/148 [01:52<00:42,  1.05s/it, training_loss=1.1627]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 107/148 [01:53<00:42,  1.05s/it, training_loss=1.2490]\u001b[A\n",
      "Epoch 5:  73%|███████▎  | 108/148 [01:53<00:41,  1.05s/it, training_loss=1.2490]\u001b[A\n",
      "Epoch 5:  73%|███████▎  | 108/148 [01:54<00:41,  1.05s/it, training_loss=1.3344]\u001b[A\n",
      "Epoch 5:  74%|███████▎  | 109/148 [01:54<00:41,  1.05s/it, training_loss=1.3344]\u001b[A\n",
      "Epoch 5:  74%|███████▎  | 109/148 [01:55<00:41,  1.05s/it, training_loss=1.4255]\u001b[A\n",
      "Epoch 5:  74%|███████▍  | 110/148 [01:55<00:39,  1.05s/it, training_loss=1.4255]\u001b[A\n",
      "Epoch 5:  74%|███████▍  | 110/148 [01:56<00:39,  1.05s/it, training_loss=1.7056]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 111/148 [01:56<00:38,  1.05s/it, training_loss=1.7056]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 111/148 [01:57<00:38,  1.05s/it, training_loss=1.2135]\u001b[A\n",
      "Epoch 5:  76%|███████▌  | 112/148 [01:57<00:37,  1.05s/it, training_loss=1.2135]\u001b[A\n",
      "Epoch 5:  76%|███████▌  | 112/148 [01:58<00:37,  1.05s/it, training_loss=1.2420]\u001b[A\n",
      "Epoch 5:  76%|███████▋  | 113/148 [01:58<00:36,  1.05s/it, training_loss=1.2420]\u001b[A\n",
      "Epoch 5:  76%|███████▋  | 113/148 [01:59<00:36,  1.05s/it, training_loss=1.2250]\u001b[A\n",
      "Epoch 5:  77%|███████▋  | 114/148 [01:59<00:35,  1.06s/it, training_loss=1.2250]\u001b[A\n",
      "Epoch 5:  77%|███████▋  | 114/148 [02:00<00:35,  1.06s/it, training_loss=1.5796]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 115/148 [02:00<00:34,  1.05s/it, training_loss=1.5796]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 115/148 [02:01<00:34,  1.05s/it, training_loss=1.1249]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 116/148 [02:01<00:33,  1.05s/it, training_loss=1.1249]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 116/148 [02:03<00:33,  1.05s/it, training_loss=1.2704]\u001b[A\n",
      "Epoch 5:  79%|███████▉  | 117/148 [02:03<00:32,  1.05s/it, training_loss=1.2704]\u001b[A\n",
      "Epoch 5:  79%|███████▉  | 117/148 [02:04<00:32,  1.05s/it, training_loss=1.6809]\u001b[A\n",
      "Epoch 5:  80%|███████▉  | 118/148 [02:04<00:31,  1.05s/it, training_loss=1.6809]\u001b[A\n",
      "Epoch 5:  80%|███████▉  | 118/148 [02:05<00:31,  1.05s/it, training_loss=1.3340]\u001b[A\n",
      "Epoch 5:  80%|████████  | 119/148 [02:05<00:30,  1.06s/it, training_loss=1.3340]\u001b[A\n",
      "Epoch 5:  80%|████████  | 119/148 [02:06<00:30,  1.06s/it, training_loss=1.5320]\u001b[A\n",
      "Epoch 5:  81%|████████  | 120/148 [02:06<00:29,  1.05s/it, training_loss=1.5320]\u001b[A\n",
      "Epoch 5:  81%|████████  | 120/148 [02:07<00:29,  1.05s/it, training_loss=1.6330]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 121/148 [02:07<00:28,  1.05s/it, training_loss=1.6330]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 121/148 [02:08<00:28,  1.05s/it, training_loss=1.1390]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 122/148 [02:08<00:27,  1.05s/it, training_loss=1.1390]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 122/148 [02:09<00:27,  1.05s/it, training_loss=1.5285]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 123/148 [02:09<00:26,  1.05s/it, training_loss=1.5285]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 123/148 [02:10<00:26,  1.05s/it, training_loss=1.1209]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 124/148 [02:10<00:25,  1.05s/it, training_loss=1.1209]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 124/148 [02:11<00:25,  1.05s/it, training_loss=1.3344]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 125/148 [02:11<00:24,  1.05s/it, training_loss=1.3344]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 125/148 [02:12<00:24,  1.05s/it, training_loss=1.2601]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 126/148 [02:12<00:23,  1.05s/it, training_loss=1.2601]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 126/148 [02:13<00:23,  1.05s/it, training_loss=1.6083]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 127/148 [02:13<00:22,  1.05s/it, training_loss=1.6083]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 127/148 [02:14<00:22,  1.05s/it, training_loss=0.9643]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 128/148 [02:14<00:20,  1.05s/it, training_loss=0.9643]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 128/148 [02:15<00:20,  1.05s/it, training_loss=1.4613]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 129/148 [02:15<00:19,  1.05s/it, training_loss=1.4613]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 129/148 [02:16<00:19,  1.05s/it, training_loss=1.6403]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 130/148 [02:16<00:18,  1.05s/it, training_loss=1.6403]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 130/148 [02:17<00:18,  1.05s/it, training_loss=1.1307]\u001b[A\n",
      "Epoch 5:  89%|████████▊ | 131/148 [02:17<00:17,  1.05s/it, training_loss=1.1307]\u001b[A\n",
      "Epoch 5:  89%|████████▊ | 131/148 [02:18<00:17,  1.05s/it, training_loss=1.4927]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 132/148 [02:18<00:16,  1.06s/it, training_loss=1.4927]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 132/148 [02:19<00:16,  1.06s/it, training_loss=1.0505]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 133/148 [02:19<00:15,  1.06s/it, training_loss=1.0505]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 133/148 [02:20<00:15,  1.06s/it, training_loss=1.5600]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 134/148 [02:20<00:14,  1.05s/it, training_loss=1.5600]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 134/148 [02:21<00:14,  1.05s/it, training_loss=1.6062]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 135/148 [02:21<00:13,  1.05s/it, training_loss=1.6062]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 135/148 [02:22<00:13,  1.05s/it, training_loss=1.0656]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 136/148 [02:22<00:12,  1.05s/it, training_loss=1.0656]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 136/148 [02:24<00:12,  1.05s/it, training_loss=1.4872]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 137/148 [02:24<00:11,  1.05s/it, training_loss=1.4872]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 137/148 [02:25<00:11,  1.05s/it, training_loss=1.4891]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 138/148 [02:25<00:10,  1.05s/it, training_loss=1.4891]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 138/148 [02:26<00:10,  1.05s/it, training_loss=1.2247]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 139/148 [02:26<00:09,  1.05s/it, training_loss=1.2247]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 139/148 [02:27<00:09,  1.05s/it, training_loss=1.2128]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 140/148 [02:27<00:08,  1.05s/it, training_loss=1.2128]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 140/148 [02:28<00:08,  1.05s/it, training_loss=1.0161]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 141/148 [02:28<00:07,  1.05s/it, training_loss=1.0161]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 141/148 [02:29<00:07,  1.05s/it, training_loss=1.5945]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 142/148 [02:29<00:06,  1.05s/it, training_loss=1.5945]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 142/148 [02:30<00:06,  1.05s/it, training_loss=1.1177]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 143/148 [02:30<00:05,  1.05s/it, training_loss=1.1177]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 143/148 [02:31<00:05,  1.05s/it, training_loss=1.5357]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 144/148 [02:31<00:04,  1.05s/it, training_loss=1.5357]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 144/148 [02:32<00:04,  1.05s/it, training_loss=1.2828]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 145/148 [02:32<00:03,  1.05s/it, training_loss=1.2828]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 145/148 [02:33<00:03,  1.05s/it, training_loss=1.5447]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 146/148 [02:33<00:02,  1.05s/it, training_loss=1.5447]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 146/148 [02:34<00:02,  1.05s/it, training_loss=1.5734]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 147/148 [02:34<00:01,  1.04s/it, training_loss=1.5734]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 147/148 [02:35<00:01,  1.04s/it, training_loss=1.0517]\u001b[A\n",
      "Epoch 5: 100%|██████████| 148/148 [02:35<00:00,  1.04it/s, training_loss=1.0517]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:16:15,085 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:16:15,087 - INFO - Memory usage after evaluation start: 3678.82 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:08,  3.06it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:08,  2.98it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:08,  2.95it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:07,  2.93it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:07,  2.93it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:02<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:03<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:05,  2.92it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:04<00:05,  2.92it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:04<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:05<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:06<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:07<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:08<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:08<00:00,  2.91it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:08<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:16:24,049 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 00:16:24,064 - INFO - Class 'Drama': Optimal threshold = 0.550, F1 Score = 0.533\n",
      "2025-02-16 00:16:24,077 - INFO - Class 'Horor': Optimal threshold = 0.600, F1 Score = 0.788\n",
      "2025-02-16 00:16:24,091 - INFO - Class 'Komedi': Optimal threshold = 0.700, F1 Score = 0.576\n",
      "2025-02-16 00:16:24,104 - INFO - Class 'Laga': Optimal threshold = 0.650, F1 Score = 0.415\n",
      "2025-02-16 00:16:24,117 - INFO - Class 'Romantis': Optimal threshold = 0.700, F1 Score = 0.528\n",
      "2025-02-16 00:16:24,138 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:16:24,143 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:16:24,144 - INFO - Accuracy: 0.7050\n",
      "2025-02-16 00:16:24,144 - INFO - F1_score: 0.5333\n",
      "2025-02-16 00:16:24,145 - INFO - Precision: 0.4835\n",
      "2025-02-16 00:16:24,146 - INFO - Recall: 0.5946\n",
      "2025-02-16 00:16:24,152 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:16:24,153 - INFO - Accuracy: 0.8927\n",
      "2025-02-16 00:16:24,153 - INFO - F1_score: 0.7879\n",
      "2025-02-16 00:16:24,154 - INFO - Precision: 0.6933\n",
      "2025-02-16 00:16:24,154 - INFO - Recall: 0.9123\n",
      "2025-02-16 00:16:24,160 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:16:24,161 - INFO - Accuracy: 0.7969\n",
      "2025-02-16 00:16:24,161 - INFO - F1_score: 0.5760\n",
      "2025-02-16 00:16:24,162 - INFO - Precision: 0.5373\n",
      "2025-02-16 00:16:24,164 - INFO - Recall: 0.6207\n",
      "2025-02-16 00:16:24,169 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:16:24,169 - INFO - Accuracy: 0.7625\n",
      "2025-02-16 00:16:24,170 - INFO - F1_score: 0.4151\n",
      "2025-02-16 00:16:24,170 - INFO - Precision: 0.3235\n",
      "2025-02-16 00:16:24,171 - INFO - Recall: 0.5789\n",
      "2025-02-16 00:16:24,177 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:16:24,178 - INFO - Accuracy: 0.8697\n",
      "2025-02-16 00:16:24,178 - INFO - F1_score: 0.5278\n",
      "2025-02-16 00:16:24,179 - INFO - Precision: 0.5000\n",
      "2025-02-16 00:16:24,179 - INFO - Recall: 0.5588\n",
      "2025-02-16 00:16:24,182 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:16:27,980 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:16:27,982 - INFO - Memory usage after evaluation end: 3700.20 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 4/100 [14:53<4:46:37, 179.14s/it, Train Loss=1.3699, Val Loss=0.0521, Accuracy=0.8054]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:16:36,823 - INFO - New best loss: 0.0521\n",
      "2025-02-16 00:16:38,251 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   5%|▌         | 5/100 [14:56<4:44:00, 179.37s/it, Train Loss=1.3699, Val Loss=0.0521, Accuracy=0.8054]\n",
      "Epoch 6:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=1.6178]\u001b[A\n",
      "Epoch 6:   1%|          | 1/148 [00:01<02:33,  1.04s/it, training_loss=1.6178]\u001b[A\n",
      "Epoch 6:   1%|          | 1/148 [00:02<02:33,  1.04s/it, training_loss=1.6454]\u001b[A\n",
      "Epoch 6:   1%|▏         | 2/148 [00:02<02:32,  1.04s/it, training_loss=1.6454]\u001b[A\n",
      "Epoch 6:   1%|▏         | 2/148 [00:03<02:32,  1.04s/it, training_loss=1.2963]\u001b[A\n",
      "Epoch 6:   2%|▏         | 3/148 [00:03<02:30,  1.04s/it, training_loss=1.2963]\u001b[A\n",
      "Epoch 6:   2%|▏         | 3/148 [00:04<02:30,  1.04s/it, training_loss=1.2091]\u001b[A\n",
      "Epoch 6:   3%|▎         | 4/148 [00:04<02:31,  1.05s/it, training_loss=1.2091]\u001b[A\n",
      "Epoch 6:   3%|▎         | 4/148 [00:05<02:31,  1.05s/it, training_loss=1.5970]\u001b[A\n",
      "Epoch 6:   3%|▎         | 5/148 [00:05<02:30,  1.05s/it, training_loss=1.5970]\u001b[A\n",
      "Epoch 6:   3%|▎         | 5/148 [00:06<02:30,  1.05s/it, training_loss=1.2813]\u001b[A\n",
      "Epoch 6:   4%|▍         | 6/148 [00:06<02:29,  1.05s/it, training_loss=1.2813]\u001b[A\n",
      "Epoch 6:   4%|▍         | 6/148 [00:07<02:29,  1.05s/it, training_loss=1.0313]\u001b[A\n",
      "Epoch 6:   5%|▍         | 7/148 [00:07<02:28,  1.05s/it, training_loss=1.0313]\u001b[A\n",
      "Epoch 6:   5%|▍         | 7/148 [00:08<02:28,  1.05s/it, training_loss=1.1896]\u001b[A\n",
      "Epoch 6:   5%|▌         | 8/148 [00:08<02:27,  1.06s/it, training_loss=1.1896]\u001b[A\n",
      "Epoch 6:   5%|▌         | 8/148 [00:09<02:27,  1.06s/it, training_loss=1.1142]\u001b[A\n",
      "Epoch 6:   6%|▌         | 9/148 [00:09<02:27,  1.06s/it, training_loss=1.1142]\u001b[A\n",
      "Epoch 6:   6%|▌         | 9/148 [00:10<02:27,  1.06s/it, training_loss=1.0517]\u001b[A\n",
      "Epoch 6:   7%|▋         | 10/148 [00:10<02:26,  1.06s/it, training_loss=1.0517]\u001b[A\n",
      "Epoch 6:   7%|▋         | 10/148 [00:11<02:26,  1.06s/it, training_loss=1.5746]\u001b[A\n",
      "Epoch 6:   7%|▋         | 11/148 [00:11<02:25,  1.06s/it, training_loss=1.5746]\u001b[A\n",
      "Epoch 6:   7%|▋         | 11/148 [00:12<02:25,  1.06s/it, training_loss=1.1268]\u001b[A\n",
      "Epoch 6:   8%|▊         | 12/148 [00:12<02:24,  1.06s/it, training_loss=1.1268]\u001b[A\n",
      "Epoch 6:   8%|▊         | 12/148 [00:13<02:24,  1.06s/it, training_loss=0.9753]\u001b[A\n",
      "Epoch 6:   9%|▉         | 13/148 [00:13<02:23,  1.07s/it, training_loss=0.9753]\u001b[A\n",
      "Epoch 6:   9%|▉         | 13/148 [00:14<02:23,  1.07s/it, training_loss=1.1916]\u001b[A\n",
      "Epoch 6:   9%|▉         | 14/148 [00:14<02:23,  1.07s/it, training_loss=1.1916]\u001b[A\n",
      "Epoch 6:   9%|▉         | 14/148 [00:15<02:23,  1.07s/it, training_loss=1.5147]\u001b[A\n",
      "Epoch 6:  10%|█         | 15/148 [00:15<02:21,  1.07s/it, training_loss=1.5147]\u001b[A\n",
      "Epoch 6:  10%|█         | 15/148 [00:16<02:21,  1.07s/it, training_loss=1.5149]\u001b[A\n",
      "Epoch 6:  11%|█         | 16/148 [00:16<02:21,  1.07s/it, training_loss=1.5149]\u001b[A\n",
      "Epoch 6:  11%|█         | 16/148 [00:18<02:21,  1.07s/it, training_loss=1.6077]\u001b[A\n",
      "Epoch 6:  11%|█▏        | 17/148 [00:18<02:20,  1.07s/it, training_loss=1.6077]\u001b[A\n",
      "Epoch 6:  11%|█▏        | 17/148 [00:19<02:20,  1.07s/it, training_loss=1.5091]\u001b[A\n",
      "Epoch 6:  12%|█▏        | 18/148 [00:19<02:19,  1.07s/it, training_loss=1.5091]\u001b[A\n",
      "Epoch 6:  12%|█▏        | 18/148 [00:20<02:19,  1.07s/it, training_loss=1.5095]\u001b[A\n",
      "Epoch 6:  13%|█▎        | 19/148 [00:20<02:18,  1.07s/it, training_loss=1.5095]\u001b[A\n",
      "Epoch 6:  13%|█▎        | 19/148 [00:21<02:18,  1.07s/it, training_loss=1.5585]\u001b[A\n",
      "Epoch 6:  14%|█▎        | 20/148 [00:21<02:17,  1.07s/it, training_loss=1.5585]\u001b[A\n",
      "Epoch 6:  14%|█▎        | 20/148 [00:22<02:17,  1.07s/it, training_loss=0.9709]\u001b[A\n",
      "Epoch 6:  14%|█▍        | 21/148 [00:22<02:16,  1.07s/it, training_loss=0.9709]\u001b[A\n",
      "Epoch 6:  14%|█▍        | 21/148 [00:23<02:16,  1.07s/it, training_loss=1.0540]\u001b[A\n",
      "Epoch 6:  15%|█▍        | 22/148 [00:23<02:14,  1.07s/it, training_loss=1.0540]\u001b[A\n",
      "Epoch 6:  15%|█▍        | 22/148 [00:24<02:14,  1.07s/it, training_loss=1.5233]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 23/148 [00:24<02:13,  1.07s/it, training_loss=1.5233]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 23/148 [00:25<02:13,  1.07s/it, training_loss=1.0175]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 24/148 [00:25<02:13,  1.07s/it, training_loss=1.0175]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 24/148 [00:26<02:13,  1.07s/it, training_loss=1.6350]\u001b[A\n",
      "Epoch 6:  17%|█▋        | 25/148 [00:26<02:11,  1.07s/it, training_loss=1.6350]\u001b[A\n",
      "Epoch 6:  17%|█▋        | 25/148 [00:27<02:11,  1.07s/it, training_loss=1.6710]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 26/148 [00:27<02:10,  1.07s/it, training_loss=1.6710]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 26/148 [00:28<02:10,  1.07s/it, training_loss=1.1253]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 27/148 [00:28<02:09,  1.07s/it, training_loss=1.1253]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 27/148 [00:29<02:09,  1.07s/it, training_loss=1.5565]\u001b[A\n",
      "Epoch 6:  19%|█▉        | 28/148 [00:29<02:08,  1.07s/it, training_loss=1.5565]\u001b[A\n",
      "Epoch 6:  19%|█▉        | 28/148 [00:30<02:08,  1.07s/it, training_loss=1.5449]\u001b[A\n",
      "Epoch 6:  20%|█▉        | 29/148 [00:30<02:06,  1.06s/it, training_loss=1.5449]\u001b[A\n",
      "Epoch 6:  20%|█▉        | 29/148 [00:31<02:06,  1.06s/it, training_loss=1.5043]\u001b[A\n",
      "Epoch 6:  20%|██        | 30/148 [00:31<02:05,  1.06s/it, training_loss=1.5043]\u001b[A\n",
      "Epoch 6:  20%|██        | 30/148 [00:32<02:05,  1.06s/it, training_loss=1.5746]\u001b[A\n",
      "Epoch 6:  21%|██        | 31/148 [00:32<02:03,  1.06s/it, training_loss=1.5746]\u001b[A\n",
      "Epoch 6:  21%|██        | 31/148 [00:34<02:03,  1.06s/it, training_loss=1.0229]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 32/148 [00:34<02:02,  1.05s/it, training_loss=1.0229]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 32/148 [00:35<02:02,  1.05s/it, training_loss=1.6360]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 33/148 [00:35<02:01,  1.05s/it, training_loss=1.6360]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 33/148 [00:36<02:01,  1.05s/it, training_loss=1.0881]\u001b[A\n",
      "Epoch 6:  23%|██▎       | 34/148 [00:36<02:00,  1.06s/it, training_loss=1.0881]\u001b[A\n",
      "Epoch 6:  23%|██▎       | 34/148 [00:37<02:00,  1.06s/it, training_loss=1.5737]\u001b[A\n",
      "Epoch 6:  24%|██▎       | 35/148 [00:37<01:59,  1.05s/it, training_loss=1.5737]\u001b[A\n",
      "Epoch 6:  24%|██▎       | 35/148 [00:38<01:59,  1.05s/it, training_loss=0.9800]\u001b[A\n",
      "Epoch 6:  24%|██▍       | 36/148 [00:38<01:58,  1.06s/it, training_loss=0.9800]\u001b[A\n",
      "Epoch 6:  24%|██▍       | 36/148 [00:39<01:58,  1.06s/it, training_loss=1.5598]\u001b[A\n",
      "Epoch 6:  25%|██▌       | 37/148 [00:39<01:56,  1.05s/it, training_loss=1.5598]\u001b[A\n",
      "Epoch 6:  25%|██▌       | 37/148 [00:40<01:56,  1.05s/it, training_loss=1.5297]\u001b[A\n",
      "Epoch 6:  26%|██▌       | 38/148 [00:40<01:55,  1.05s/it, training_loss=1.5297]\u001b[A\n",
      "Epoch 6:  26%|██▌       | 38/148 [00:41<01:55,  1.05s/it, training_loss=1.5971]\u001b[A\n",
      "Epoch 6:  26%|██▋       | 39/148 [00:41<01:54,  1.05s/it, training_loss=1.5971]\u001b[A\n",
      "Epoch 6:  26%|██▋       | 39/148 [00:42<01:54,  1.05s/it, training_loss=1.5334]\u001b[A\n",
      "Epoch 6:  27%|██▋       | 40/148 [00:42<01:53,  1.05s/it, training_loss=1.5334]\u001b[A\n",
      "Epoch 6:  27%|██▋       | 40/148 [00:43<01:53,  1.05s/it, training_loss=1.2375]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 41/148 [00:43<01:51,  1.05s/it, training_loss=1.2375]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 41/148 [00:44<01:51,  1.05s/it, training_loss=1.1543]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 42/148 [00:44<01:51,  1.05s/it, training_loss=1.1543]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 42/148 [00:45<01:51,  1.05s/it, training_loss=0.9418]\u001b[A\n",
      "Epoch 6:  29%|██▉       | 43/148 [00:45<01:50,  1.05s/it, training_loss=0.9418]\u001b[A\n",
      "Epoch 6:  29%|██▉       | 43/148 [00:46<01:50,  1.05s/it, training_loss=1.3112]\u001b[A\n",
      "Epoch 6:  30%|██▉       | 44/148 [00:46<01:49,  1.05s/it, training_loss=1.3112]\u001b[A\n",
      "Epoch 6:  30%|██▉       | 44/148 [00:47<01:49,  1.05s/it, training_loss=1.7425]\u001b[A\n",
      "Epoch 6:  30%|███       | 45/148 [00:47<01:47,  1.05s/it, training_loss=1.7425]\u001b[A\n",
      "Epoch 6:  30%|███       | 45/148 [00:48<01:47,  1.05s/it, training_loss=1.0017]\u001b[A\n",
      "Epoch 6:  31%|███       | 46/148 [00:48<01:46,  1.04s/it, training_loss=1.0017]\u001b[A\n",
      "Epoch 6:  31%|███       | 46/148 [00:49<01:46,  1.04s/it, training_loss=1.9102]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 47/148 [00:49<01:45,  1.04s/it, training_loss=1.9102]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 47/148 [00:50<01:45,  1.04s/it, training_loss=1.6467]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 48/148 [00:50<01:44,  1.04s/it, training_loss=1.6467]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 48/148 [00:51<01:44,  1.04s/it, training_loss=1.1177]\u001b[A\n",
      "Epoch 6:  33%|███▎      | 49/148 [00:51<01:43,  1.05s/it, training_loss=1.1177]\u001b[A\n",
      "Epoch 6:  33%|███▎      | 49/148 [00:52<01:43,  1.05s/it, training_loss=1.0686]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 50/148 [00:52<01:42,  1.05s/it, training_loss=1.0686]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 50/148 [00:53<01:42,  1.05s/it, training_loss=1.0477]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 51/148 [00:53<01:41,  1.05s/it, training_loss=1.0477]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 51/148 [00:54<01:41,  1.05s/it, training_loss=1.7253]\u001b[A\n",
      "Epoch 6:  35%|███▌      | 52/148 [00:54<01:40,  1.05s/it, training_loss=1.7253]\u001b[A\n",
      "Epoch 6:  35%|███▌      | 52/148 [00:56<01:40,  1.05s/it, training_loss=1.2292]\u001b[A\n",
      "Epoch 6:  36%|███▌      | 53/148 [00:56<01:39,  1.05s/it, training_loss=1.2292]\u001b[A\n",
      "Epoch 6:  36%|███▌      | 53/148 [00:57<01:39,  1.05s/it, training_loss=1.4862]\u001b[A\n",
      "Epoch 6:  36%|███▋      | 54/148 [00:57<01:38,  1.04s/it, training_loss=1.4862]\u001b[A\n",
      "Epoch 6:  36%|███▋      | 54/148 [00:58<01:38,  1.04s/it, training_loss=1.6448]\u001b[A\n",
      "Epoch 6:  37%|███▋      | 55/148 [00:58<01:36,  1.04s/it, training_loss=1.6448]\u001b[A\n",
      "Epoch 6:  37%|███▋      | 55/148 [00:59<01:36,  1.04s/it, training_loss=0.8459]\u001b[A\n",
      "Epoch 6:  38%|███▊      | 56/148 [00:59<01:36,  1.04s/it, training_loss=0.8459]\u001b[A\n",
      "Epoch 6:  38%|███▊      | 56/148 [01:00<01:36,  1.04s/it, training_loss=1.0458]\u001b[A\n",
      "Epoch 6:  39%|███▊      | 57/148 [01:00<01:35,  1.05s/it, training_loss=1.0458]\u001b[A\n",
      "Epoch 6:  39%|███▊      | 57/148 [01:01<01:35,  1.05s/it, training_loss=1.2145]\u001b[A\n",
      "Epoch 6:  39%|███▉      | 58/148 [01:01<01:34,  1.05s/it, training_loss=1.2145]\u001b[A\n",
      "Epoch 6:  39%|███▉      | 58/148 [01:02<01:34,  1.05s/it, training_loss=1.0748]\u001b[A\n",
      "Epoch 6:  40%|███▉      | 59/148 [01:02<01:33,  1.05s/it, training_loss=1.0748]\u001b[A\n",
      "Epoch 6:  40%|███▉      | 59/148 [01:03<01:33,  1.05s/it, training_loss=1.5822]\u001b[A\n",
      "Epoch 6:  41%|████      | 60/148 [01:03<01:32,  1.05s/it, training_loss=1.5822]\u001b[A\n",
      "Epoch 6:  41%|████      | 60/148 [01:04<01:32,  1.05s/it, training_loss=1.0519]\u001b[A\n",
      "Epoch 6:  41%|████      | 61/148 [01:04<01:31,  1.05s/it, training_loss=1.0519]\u001b[A\n",
      "Epoch 6:  41%|████      | 61/148 [01:05<01:31,  1.05s/it, training_loss=1.6317]\u001b[A\n",
      "Epoch 6:  42%|████▏     | 62/148 [01:05<01:29,  1.04s/it, training_loss=1.6317]\u001b[A\n",
      "Epoch 6:  42%|████▏     | 62/148 [01:06<01:29,  1.04s/it, training_loss=1.1075]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 63/148 [01:06<01:28,  1.04s/it, training_loss=1.1075]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 63/148 [01:07<01:28,  1.04s/it, training_loss=1.1140]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 64/148 [01:07<01:27,  1.04s/it, training_loss=1.1140]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 64/148 [01:08<01:27,  1.04s/it, training_loss=1.0284]\u001b[A\n",
      "Epoch 6:  44%|████▍     | 65/148 [01:08<01:26,  1.05s/it, training_loss=1.0284]\u001b[A\n",
      "Epoch 6:  44%|████▍     | 65/148 [01:09<01:26,  1.05s/it, training_loss=1.5176]\u001b[A\n",
      "Epoch 6:  45%|████▍     | 66/148 [01:09<01:25,  1.04s/it, training_loss=1.5176]\u001b[A\n",
      "Epoch 6:  45%|████▍     | 66/148 [01:10<01:25,  1.04s/it, training_loss=1.6044]\u001b[A\n",
      "Epoch 6:  45%|████▌     | 67/148 [01:10<01:24,  1.05s/it, training_loss=1.6044]\u001b[A\n",
      "Epoch 6:  45%|████▌     | 67/148 [01:11<01:24,  1.05s/it, training_loss=1.2094]\u001b[A\n",
      "Epoch 6:  46%|████▌     | 68/148 [01:11<01:23,  1.05s/it, training_loss=1.2094]\u001b[A\n",
      "Epoch 6:  46%|████▌     | 68/148 [01:12<01:23,  1.05s/it, training_loss=1.1589]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 69/148 [01:12<01:22,  1.05s/it, training_loss=1.1589]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 69/148 [01:13<01:22,  1.05s/it, training_loss=1.1300]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 70/148 [01:13<01:21,  1.05s/it, training_loss=1.1300]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 70/148 [01:14<01:21,  1.05s/it, training_loss=1.0862]\u001b[A\n",
      "Epoch 6:  48%|████▊     | 71/148 [01:14<01:20,  1.05s/it, training_loss=1.0862]\u001b[A\n",
      "Epoch 6:  48%|████▊     | 71/148 [01:15<01:20,  1.05s/it, training_loss=0.8772]\u001b[A\n",
      "Epoch 6:  49%|████▊     | 72/148 [01:15<01:19,  1.05s/it, training_loss=0.8772]\u001b[A\n",
      "Epoch 6:  49%|████▊     | 72/148 [01:16<01:19,  1.05s/it, training_loss=1.6785]\u001b[A\n",
      "Epoch 6:  49%|████▉     | 73/148 [01:16<01:18,  1.04s/it, training_loss=1.6785]\u001b[A\n",
      "Epoch 6:  49%|████▉     | 73/148 [01:17<01:18,  1.04s/it, training_loss=1.5879]\u001b[A\n",
      "Epoch 6:  50%|█████     | 74/148 [01:17<01:17,  1.04s/it, training_loss=1.5879]\u001b[A\n",
      "Epoch 6:  50%|█████     | 74/148 [01:19<01:17,  1.04s/it, training_loss=1.2035]\u001b[A\n",
      "Epoch 6:  51%|█████     | 75/148 [01:19<01:16,  1.05s/it, training_loss=1.2035]\u001b[A\n",
      "Epoch 6:  51%|█████     | 75/148 [01:20<01:16,  1.05s/it, training_loss=1.5209]\u001b[A\n",
      "Epoch 6:  51%|█████▏    | 76/148 [01:20<01:15,  1.05s/it, training_loss=1.5209]\u001b[A\n",
      "Epoch 6:  51%|█████▏    | 76/148 [01:21<01:15,  1.05s/it, training_loss=1.7038]\u001b[A\n",
      "Epoch 6:  52%|█████▏    | 77/148 [01:21<01:14,  1.05s/it, training_loss=1.7038]\u001b[A\n",
      "Epoch 6:  52%|█████▏    | 77/148 [01:22<01:14,  1.05s/it, training_loss=1.5158]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 78/148 [01:22<01:13,  1.04s/it, training_loss=1.5158]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 78/148 [01:23<01:13,  1.04s/it, training_loss=1.1223]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 79/148 [01:23<01:12,  1.05s/it, training_loss=1.1223]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 79/148 [01:24<01:12,  1.05s/it, training_loss=1.6011]\u001b[A\n",
      "Epoch 6:  54%|█████▍    | 80/148 [01:24<01:10,  1.04s/it, training_loss=1.6011]\u001b[A\n",
      "Epoch 6:  54%|█████▍    | 80/148 [01:25<01:10,  1.04s/it, training_loss=1.4708]\u001b[A\n",
      "Epoch 6:  55%|█████▍    | 81/148 [01:25<01:10,  1.05s/it, training_loss=1.4708]\u001b[A\n",
      "Epoch 6:  55%|█████▍    | 81/148 [01:26<01:10,  1.05s/it, training_loss=1.0022]\u001b[A\n",
      "Epoch 6:  55%|█████▌    | 82/148 [01:26<01:09,  1.05s/it, training_loss=1.0022]\u001b[A\n",
      "Epoch 6:  55%|█████▌    | 82/148 [01:27<01:09,  1.05s/it, training_loss=1.6260]\u001b[A\n",
      "Epoch 6:  56%|█████▌    | 83/148 [01:27<01:08,  1.05s/it, training_loss=1.6260]\u001b[A\n",
      "Epoch 6:  56%|█████▌    | 83/148 [01:28<01:08,  1.05s/it, training_loss=0.9481]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 84/148 [01:28<01:06,  1.05s/it, training_loss=0.9481]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 84/148 [01:29<01:06,  1.05s/it, training_loss=1.1941]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 85/148 [01:29<01:06,  1.05s/it, training_loss=1.1941]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 85/148 [01:30<01:06,  1.05s/it, training_loss=1.5255]\u001b[A\n",
      "Epoch 6:  58%|█████▊    | 86/148 [01:30<01:04,  1.05s/it, training_loss=1.5255]\u001b[A\n",
      "Epoch 6:  58%|█████▊    | 86/148 [01:31<01:04,  1.05s/it, training_loss=1.6604]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 87/148 [01:31<01:03,  1.04s/it, training_loss=1.6604]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 87/148 [01:32<01:03,  1.04s/it, training_loss=1.7002]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 88/148 [01:32<01:02,  1.04s/it, training_loss=1.7002]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 88/148 [01:33<01:02,  1.04s/it, training_loss=1.0638]\u001b[A\n",
      "Epoch 6:  60%|██████    | 89/148 [01:33<01:01,  1.05s/it, training_loss=1.0638]\u001b[A\n",
      "Epoch 6:  60%|██████    | 89/148 [01:34<01:01,  1.05s/it, training_loss=1.6614]\u001b[A\n",
      "Epoch 6:  61%|██████    | 90/148 [01:34<01:00,  1.05s/it, training_loss=1.6614]\u001b[A\n",
      "Epoch 6:  61%|██████    | 90/148 [01:35<01:00,  1.05s/it, training_loss=0.9951]\u001b[A\n",
      "Epoch 6:  61%|██████▏   | 91/148 [01:35<00:59,  1.05s/it, training_loss=0.9951]\u001b[A\n",
      "Epoch 6:  61%|██████▏   | 91/148 [01:36<00:59,  1.05s/it, training_loss=1.0575]\u001b[A\n",
      "Epoch 6:  62%|██████▏   | 92/148 [01:36<00:58,  1.05s/it, training_loss=1.0575]\u001b[A\n",
      "Epoch 6:  62%|██████▏   | 92/148 [01:37<00:58,  1.05s/it, training_loss=0.9262]\u001b[A\n",
      "Epoch 6:  63%|██████▎   | 93/148 [01:37<00:57,  1.05s/it, training_loss=0.9262]\u001b[A\n",
      "Epoch 6:  63%|██████▎   | 93/148 [01:38<00:57,  1.05s/it, training_loss=1.4670]\u001b[A\n",
      "Epoch 6:  64%|██████▎   | 94/148 [01:38<00:56,  1.05s/it, training_loss=1.4670]\u001b[A\n",
      "Epoch 6:  64%|██████▎   | 94/148 [01:39<00:56,  1.05s/it, training_loss=1.7048]\u001b[A\n",
      "Epoch 6:  64%|██████▍   | 95/148 [01:39<00:55,  1.05s/it, training_loss=1.7048]\u001b[A\n",
      "Epoch 6:  64%|██████▍   | 95/148 [01:41<00:55,  1.05s/it, training_loss=1.5737]\u001b[A\n",
      "Epoch 6:  65%|██████▍   | 96/148 [01:41<00:54,  1.05s/it, training_loss=1.5737]\u001b[A\n",
      "Epoch 6:  65%|██████▍   | 96/148 [01:42<00:54,  1.05s/it, training_loss=1.4901]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 97/148 [01:42<00:53,  1.05s/it, training_loss=1.4901]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 97/148 [01:43<00:53,  1.05s/it, training_loss=1.3356]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 98/148 [01:43<00:52,  1.05s/it, training_loss=1.3356]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 98/148 [01:44<00:52,  1.05s/it, training_loss=1.6106]\u001b[A\n",
      "Epoch 6:  67%|██████▋   | 99/148 [01:44<00:51,  1.05s/it, training_loss=1.6106]\u001b[A\n",
      "Epoch 6:  67%|██████▋   | 99/148 [01:45<00:51,  1.05s/it, training_loss=1.6152]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 100/148 [01:45<00:50,  1.05s/it, training_loss=1.6152]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 100/148 [01:46<00:50,  1.05s/it, training_loss=1.0916]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 101/148 [01:46<00:49,  1.05s/it, training_loss=1.0916]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 101/148 [01:47<00:49,  1.05s/it, training_loss=0.8221]\u001b[A\n",
      "Epoch 6:  69%|██████▉   | 102/148 [01:47<00:48,  1.05s/it, training_loss=0.8221]\u001b[A\n",
      "Epoch 6:  69%|██████▉   | 102/148 [01:48<00:48,  1.05s/it, training_loss=1.5692]\u001b[A\n",
      "Epoch 6:  70%|██████▉   | 103/148 [01:48<00:47,  1.05s/it, training_loss=1.5692]\u001b[A\n",
      "Epoch 6:  70%|██████▉   | 103/148 [01:49<00:47,  1.05s/it, training_loss=1.5917]\u001b[A\n",
      "Epoch 6:  70%|███████   | 104/148 [01:49<00:46,  1.05s/it, training_loss=1.5917]\u001b[A\n",
      "Epoch 6:  70%|███████   | 104/148 [01:50<00:46,  1.05s/it, training_loss=1.5876]\u001b[A\n",
      "Epoch 6:  71%|███████   | 105/148 [01:50<00:45,  1.05s/it, training_loss=1.5876]\u001b[A\n",
      "Epoch 6:  71%|███████   | 105/148 [01:51<00:45,  1.05s/it, training_loss=1.7330]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 106/148 [01:51<00:44,  1.05s/it, training_loss=1.7330]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 106/148 [01:52<00:44,  1.05s/it, training_loss=1.1665]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 107/148 [01:52<00:43,  1.05s/it, training_loss=1.1665]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 107/148 [01:53<00:43,  1.05s/it, training_loss=1.5679]\u001b[A\n",
      "Epoch 6:  73%|███████▎  | 108/148 [01:53<00:42,  1.05s/it, training_loss=1.5679]\u001b[A\n",
      "Epoch 6:  73%|███████▎  | 108/148 [01:54<00:42,  1.05s/it, training_loss=1.6524]\u001b[A\n",
      "Epoch 6:  74%|███████▎  | 109/148 [01:54<00:40,  1.05s/it, training_loss=1.6524]\u001b[A\n",
      "Epoch 6:  74%|███████▎  | 109/148 [01:55<00:40,  1.05s/it, training_loss=1.0057]\u001b[A\n",
      "Epoch 6:  74%|███████▍  | 110/148 [01:55<00:40,  1.05s/it, training_loss=1.0057]\u001b[A\n",
      "Epoch 6:  74%|███████▍  | 110/148 [01:56<00:40,  1.05s/it, training_loss=0.9940]\u001b[A\n",
      "Epoch 6:  75%|███████▌  | 111/148 [01:56<00:39,  1.06s/it, training_loss=0.9940]\u001b[A\n",
      "Epoch 6:  75%|███████▌  | 111/148 [01:57<00:39,  1.06s/it, training_loss=1.5485]\u001b[A\n",
      "Epoch 6:  76%|███████▌  | 112/148 [01:57<00:37,  1.05s/it, training_loss=1.5485]\u001b[A\n",
      "Epoch 6:  76%|███████▌  | 112/148 [01:58<00:37,  1.05s/it, training_loss=1.6732]\u001b[A\n",
      "Epoch 6:  76%|███████▋  | 113/148 [01:58<00:36,  1.05s/it, training_loss=1.6732]\u001b[A\n",
      "Epoch 6:  76%|███████▋  | 113/148 [01:59<00:36,  1.05s/it, training_loss=1.0923]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 114/148 [01:59<00:35,  1.05s/it, training_loss=1.0923]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 114/148 [02:01<00:35,  1.05s/it, training_loss=1.6037]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 115/148 [02:01<00:34,  1.05s/it, training_loss=1.6037]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 115/148 [02:02<00:34,  1.05s/it, training_loss=0.9306]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 116/148 [02:02<00:33,  1.06s/it, training_loss=0.9306]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 116/148 [02:03<00:33,  1.06s/it, training_loss=1.4853]\u001b[A\n",
      "Epoch 6:  79%|███████▉  | 117/148 [02:03<00:32,  1.05s/it, training_loss=1.4853]\u001b[A\n",
      "Epoch 6:  79%|███████▉  | 117/148 [02:04<00:32,  1.05s/it, training_loss=1.4312]\u001b[A\n",
      "Epoch 6:  80%|███████▉  | 118/148 [02:04<00:31,  1.06s/it, training_loss=1.4312]\u001b[A\n",
      "Epoch 6:  80%|███████▉  | 118/148 [02:05<00:31,  1.06s/it, training_loss=1.5191]\u001b[A\n",
      "Epoch 6:  80%|████████  | 119/148 [02:05<00:30,  1.05s/it, training_loss=1.5191]\u001b[A\n",
      "Epoch 6:  80%|████████  | 119/148 [02:06<00:30,  1.05s/it, training_loss=1.2006]\u001b[A\n",
      "Epoch 6:  81%|████████  | 120/148 [02:06<00:29,  1.06s/it, training_loss=1.2006]\u001b[A\n",
      "Epoch 6:  81%|████████  | 120/148 [02:07<00:29,  1.06s/it, training_loss=1.5126]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 121/148 [02:07<00:28,  1.06s/it, training_loss=1.5126]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 121/148 [02:08<00:28,  1.06s/it, training_loss=1.5878]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 122/148 [02:08<00:27,  1.06s/it, training_loss=1.5878]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 122/148 [02:09<00:27,  1.06s/it, training_loss=1.0197]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 123/148 [02:09<00:26,  1.06s/it, training_loss=1.0197]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 123/148 [02:10<00:26,  1.06s/it, training_loss=0.9374]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 124/148 [02:10<00:25,  1.06s/it, training_loss=0.9374]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 124/148 [02:11<00:25,  1.06s/it, training_loss=1.6215]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 125/148 [02:11<00:24,  1.06s/it, training_loss=1.6215]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 125/148 [02:12<00:24,  1.06s/it, training_loss=1.2699]\u001b[A\n",
      "Epoch 6:  85%|████████▌ | 126/148 [02:12<00:23,  1.06s/it, training_loss=1.2699]\u001b[A\n",
      "Epoch 6:  85%|████████▌ | 126/148 [02:13<00:23,  1.06s/it, training_loss=1.5896]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 127/148 [02:13<00:22,  1.06s/it, training_loss=1.5896]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 127/148 [02:14<00:22,  1.06s/it, training_loss=0.9369]\u001b[A\n",
      "Epoch 6:  86%|████████▋ | 128/148 [02:14<00:21,  1.07s/it, training_loss=0.9369]\u001b[A\n",
      "Epoch 6:  86%|████████▋ | 128/148 [02:15<00:21,  1.07s/it, training_loss=0.9554]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 129/148 [02:15<00:20,  1.06s/it, training_loss=0.9554]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 129/148 [02:16<00:20,  1.06s/it, training_loss=1.0621]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 130/148 [02:16<00:19,  1.06s/it, training_loss=1.0621]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 130/148 [02:17<00:19,  1.06s/it, training_loss=1.1080]\u001b[A\n",
      "Epoch 6:  89%|████████▊ | 131/148 [02:17<00:18,  1.06s/it, training_loss=1.1080]\u001b[A\n",
      "Epoch 6:  89%|████████▊ | 131/148 [02:19<00:18,  1.06s/it, training_loss=1.4195]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 132/148 [02:19<00:16,  1.06s/it, training_loss=1.4195]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 132/148 [02:20<00:16,  1.06s/it, training_loss=1.3845]\u001b[A\n",
      "Epoch 6:  90%|████████▉ | 133/148 [02:20<00:15,  1.05s/it, training_loss=1.3845]\u001b[A\n",
      "Epoch 6:  90%|████████▉ | 133/148 [02:21<00:15,  1.05s/it, training_loss=1.5163]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 134/148 [02:21<00:14,  1.05s/it, training_loss=1.5163]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 134/148 [02:22<00:14,  1.05s/it, training_loss=1.5976]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 135/148 [02:22<00:13,  1.05s/it, training_loss=1.5976]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 135/148 [02:23<00:13,  1.05s/it, training_loss=1.0299]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 136/148 [02:23<00:12,  1.05s/it, training_loss=1.0299]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 136/148 [02:24<00:12,  1.05s/it, training_loss=0.9368]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 137/148 [02:24<00:11,  1.06s/it, training_loss=0.9368]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 137/148 [02:25<00:11,  1.06s/it, training_loss=0.9121]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 138/148 [02:25<00:10,  1.06s/it, training_loss=0.9121]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 138/148 [02:26<00:10,  1.06s/it, training_loss=1.0477]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 139/148 [02:26<00:09,  1.06s/it, training_loss=1.0477]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 139/148 [02:27<00:09,  1.06s/it, training_loss=1.5923]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 140/148 [02:27<00:08,  1.05s/it, training_loss=1.5923]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 140/148 [02:28<00:08,  1.05s/it, training_loss=1.1529]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 141/148 [02:28<00:07,  1.05s/it, training_loss=1.1529]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 141/148 [02:29<00:07,  1.05s/it, training_loss=0.8246]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 142/148 [02:29<00:06,  1.05s/it, training_loss=0.8246]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 142/148 [02:30<00:06,  1.05s/it, training_loss=1.5036]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 143/148 [02:30<00:05,  1.05s/it, training_loss=1.5036]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 143/148 [02:31<00:05,  1.05s/it, training_loss=1.1576]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 144/148 [02:31<00:04,  1.05s/it, training_loss=1.1576]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 144/148 [02:32<00:04,  1.05s/it, training_loss=1.4473]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 145/148 [02:32<00:03,  1.05s/it, training_loss=1.4473]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 145/148 [02:33<00:03,  1.05s/it, training_loss=1.5561]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 146/148 [02:33<00:02,  1.04s/it, training_loss=1.5561]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 146/148 [02:34<00:02,  1.04s/it, training_loss=1.5432]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 147/148 [02:34<00:01,  1.04s/it, training_loss=1.5432]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 147/148 [02:35<00:01,  1.04s/it, training_loss=1.4766]\u001b[A\n",
      "Epoch 6: 100%|██████████| 148/148 [02:35<00:00,  1.04it/s, training_loss=1.4766]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:19:15,120 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:19:15,122 - INFO - Memory usage after evaluation start: 3684.64 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:08,  3.05it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:08,  2.97it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:08,  2.95it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:07,  2.93it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:07,  2.93it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:02<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:06,  2.92it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:06,  2.92it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:03<00:06,  2.92it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:05,  2.92it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:04<00:05,  2.92it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:04<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:05<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:05<00:03,  2.92it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:06<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:07<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:08<00:01,  2.92it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:08<00:00,  2.91it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:08<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:19:24,079 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 00:19:24,095 - INFO - Class 'Drama': Optimal threshold = 0.650, F1 Score = 0.556\n",
      "2025-02-16 00:19:24,109 - INFO - Class 'Horor': Optimal threshold = 0.700, F1 Score = 0.791\n",
      "2025-02-16 00:19:24,123 - INFO - Class 'Komedi': Optimal threshold = 0.600, F1 Score = 0.556\n",
      "2025-02-16 00:19:24,137 - INFO - Class 'Laga': Optimal threshold = 0.650, F1 Score = 0.351\n",
      "2025-02-16 00:19:24,150 - INFO - Class 'Romantis': Optimal threshold = 0.750, F1 Score = 0.535\n",
      "2025-02-16 00:19:24,172 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:19:24,177 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:19:24,178 - INFO - Accuracy: 0.6935\n",
      "2025-02-16 00:19:24,179 - INFO - F1_score: 0.5556\n",
      "2025-02-16 00:19:24,179 - INFO - Precision: 0.4717\n",
      "2025-02-16 00:19:24,180 - INFO - Recall: 0.6757\n",
      "2025-02-16 00:19:24,187 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:19:24,187 - INFO - Accuracy: 0.8966\n",
      "2025-02-16 00:19:24,188 - INFO - F1_score: 0.7907\n",
      "2025-02-16 00:19:24,189 - INFO - Precision: 0.7083\n",
      "2025-02-16 00:19:24,189 - INFO - Recall: 0.8947\n",
      "2025-02-16 00:19:24,195 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:19:24,196 - INFO - Accuracy: 0.7854\n",
      "2025-02-16 00:19:24,197 - INFO - F1_score: 0.5556\n",
      "2025-02-16 00:19:24,198 - INFO - Precision: 0.5147\n",
      "2025-02-16 00:19:24,199 - INFO - Recall: 0.6034\n",
      "2025-02-16 00:19:24,204 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:19:24,205 - INFO - Accuracy: 0.8161\n",
      "2025-02-16 00:19:24,205 - INFO - F1_score: 0.3514\n",
      "2025-02-16 00:19:24,206 - INFO - Precision: 0.3611\n",
      "2025-02-16 00:19:24,208 - INFO - Recall: 0.3421\n",
      "2025-02-16 00:19:24,213 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:19:24,214 - INFO - Accuracy: 0.8736\n",
      "2025-02-16 00:19:24,215 - INFO - F1_score: 0.5352\n",
      "2025-02-16 00:19:24,215 - INFO - Precision: 0.5135\n",
      "2025-02-16 00:19:24,217 - INFO - Recall: 0.5588\n",
      "2025-02-16 00:19:24,219 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:19:28,160 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:19:28,162 - INFO - Memory usage after evaluation end: 3705.64 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   5%|▌         | 5/100 [17:53<4:44:00, 179.37s/it, Train Loss=1.3371, Val Loss=0.0543, Accuracy=0.8130]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:19:36,949 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 6/100 [17:53<4:39:56, 178.69s/it, Train Loss=1.3371, Val Loss=0.0543, Accuracy=0.8130]\n",
      "Epoch 7:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=0.9535]\u001b[A\n",
      "Epoch 7:   1%|          | 1/148 [00:01<02:34,  1.05s/it, training_loss=0.9535]\u001b[A\n",
      "Epoch 7:   1%|          | 1/148 [00:02<02:34,  1.05s/it, training_loss=1.0906]\u001b[A\n",
      "Epoch 7:   1%|▏         | 2/148 [00:02<02:33,  1.05s/it, training_loss=1.0906]\u001b[A\n",
      "Epoch 7:   1%|▏         | 2/148 [00:03<02:33,  1.05s/it, training_loss=1.0887]\u001b[A\n",
      "Epoch 7:   2%|▏         | 3/148 [00:03<02:31,  1.05s/it, training_loss=1.0887]\u001b[A\n",
      "Epoch 7:   2%|▏         | 3/148 [00:04<02:31,  1.05s/it, training_loss=1.5097]\u001b[A\n",
      "Epoch 7:   3%|▎         | 4/148 [00:04<02:30,  1.04s/it, training_loss=1.5097]\u001b[A\n",
      "Epoch 7:   3%|▎         | 4/148 [00:05<02:30,  1.04s/it, training_loss=1.1199]\u001b[A\n",
      "Epoch 7:   3%|▎         | 5/148 [00:05<02:30,  1.05s/it, training_loss=1.1199]\u001b[A\n",
      "Epoch 7:   3%|▎         | 5/148 [00:06<02:30,  1.05s/it, training_loss=1.1892]\u001b[A\n",
      "Epoch 7:   4%|▍         | 6/148 [00:06<02:29,  1.05s/it, training_loss=1.1892]\u001b[A\n",
      "Epoch 7:   4%|▍         | 6/148 [00:07<02:29,  1.05s/it, training_loss=1.4225]\u001b[A\n",
      "Epoch 7:   5%|▍         | 7/148 [00:07<02:27,  1.05s/it, training_loss=1.4225]\u001b[A\n",
      "Epoch 7:   5%|▍         | 7/148 [00:08<02:27,  1.05s/it, training_loss=1.3281]\u001b[A\n",
      "Epoch 7:   5%|▌         | 8/148 [00:08<02:26,  1.05s/it, training_loss=1.3281]\u001b[A\n",
      "Epoch 7:   5%|▌         | 8/148 [00:09<02:26,  1.05s/it, training_loss=1.2604]\u001b[A\n",
      "Epoch 7:   6%|▌         | 9/148 [00:09<02:26,  1.06s/it, training_loss=1.2604]\u001b[A\n",
      "Epoch 7:   6%|▌         | 9/148 [00:10<02:26,  1.06s/it, training_loss=1.5859]\u001b[A\n",
      "Epoch 7:   7%|▋         | 10/148 [00:10<02:25,  1.05s/it, training_loss=1.5859]\u001b[A\n",
      "Epoch 7:   7%|▋         | 10/148 [00:11<02:25,  1.05s/it, training_loss=1.3157]\u001b[A\n",
      "Epoch 7:   7%|▋         | 11/148 [00:11<02:24,  1.06s/it, training_loss=1.3157]\u001b[A\n",
      "Epoch 7:   7%|▋         | 11/148 [00:12<02:24,  1.06s/it, training_loss=1.0544]\u001b[A\n",
      "Epoch 7:   8%|▊         | 12/148 [00:12<02:24,  1.06s/it, training_loss=1.0544]\u001b[A\n",
      "Epoch 7:   8%|▊         | 12/148 [00:13<02:24,  1.06s/it, training_loss=1.0635]\u001b[A\n",
      "Epoch 7:   9%|▉         | 13/148 [00:13<02:23,  1.06s/it, training_loss=1.0635]\u001b[A\n",
      "Epoch 7:   9%|▉         | 13/148 [00:14<02:23,  1.06s/it, training_loss=1.2083]\u001b[A\n",
      "Epoch 7:   9%|▉         | 14/148 [00:14<02:22,  1.06s/it, training_loss=1.2083]\u001b[A\n",
      "Epoch 7:   9%|▉         | 14/148 [00:15<02:22,  1.06s/it, training_loss=0.8930]\u001b[A\n",
      "Epoch 7:  10%|█         | 15/148 [00:15<02:21,  1.06s/it, training_loss=0.8930]\u001b[A\n",
      "Epoch 7:  10%|█         | 15/148 [00:16<02:21,  1.06s/it, training_loss=1.0190]\u001b[A\n",
      "Epoch 7:  11%|█         | 16/148 [00:16<02:20,  1.07s/it, training_loss=1.0190]\u001b[A\n",
      "Epoch 7:  11%|█         | 16/148 [00:17<02:20,  1.07s/it, training_loss=1.1717]\u001b[A\n",
      "Epoch 7:  11%|█▏        | 17/148 [00:17<02:19,  1.07s/it, training_loss=1.1717]\u001b[A\n",
      "Epoch 7:  11%|█▏        | 17/148 [00:19<02:19,  1.07s/it, training_loss=0.9588]\u001b[A\n",
      "Epoch 7:  12%|█▏        | 18/148 [00:19<02:18,  1.07s/it, training_loss=0.9588]\u001b[A\n",
      "Epoch 7:  12%|█▏        | 18/148 [00:20<02:18,  1.07s/it, training_loss=1.2014]\u001b[A\n",
      "Epoch 7:  13%|█▎        | 19/148 [00:20<02:17,  1.07s/it, training_loss=1.2014]\u001b[A\n",
      "Epoch 7:  13%|█▎        | 19/148 [00:21<02:17,  1.07s/it, training_loss=0.9666]\u001b[A\n",
      "Epoch 7:  14%|█▎        | 20/148 [00:21<02:17,  1.07s/it, training_loss=0.9666]\u001b[A\n",
      "Epoch 7:  14%|█▎        | 20/148 [00:22<02:17,  1.07s/it, training_loss=1.5085]\u001b[A\n",
      "Epoch 7:  14%|█▍        | 21/148 [00:22<02:15,  1.07s/it, training_loss=1.5085]\u001b[A\n",
      "Epoch 7:  14%|█▍        | 21/148 [00:23<02:15,  1.07s/it, training_loss=1.1890]\u001b[A\n",
      "Epoch 7:  15%|█▍        | 22/148 [00:23<02:14,  1.07s/it, training_loss=1.1890]\u001b[A\n",
      "Epoch 7:  15%|█▍        | 22/148 [00:24<02:14,  1.07s/it, training_loss=0.8740]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 23/148 [00:24<02:13,  1.07s/it, training_loss=0.8740]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 23/148 [00:25<02:13,  1.07s/it, training_loss=1.5708]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 24/148 [00:25<02:12,  1.06s/it, training_loss=1.5708]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 24/148 [00:26<02:12,  1.06s/it, training_loss=1.6571]\u001b[A\n",
      "Epoch 7:  17%|█▋        | 25/148 [00:26<02:10,  1.06s/it, training_loss=1.6571]\u001b[A\n",
      "Epoch 7:  17%|█▋        | 25/148 [00:27<02:10,  1.06s/it, training_loss=1.5574]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 26/148 [00:27<02:09,  1.06s/it, training_loss=1.5574]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 26/148 [00:28<02:09,  1.06s/it, training_loss=1.6105]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 27/148 [00:28<02:07,  1.06s/it, training_loss=1.6105]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 27/148 [00:29<02:07,  1.06s/it, training_loss=1.5125]\u001b[A\n",
      "Epoch 7:  19%|█▉        | 28/148 [00:29<02:06,  1.06s/it, training_loss=1.5125]\u001b[A\n",
      "Epoch 7:  19%|█▉        | 28/148 [00:30<02:06,  1.06s/it, training_loss=0.9967]\u001b[A\n",
      "Epoch 7:  20%|█▉        | 29/148 [00:30<02:05,  1.06s/it, training_loss=0.9967]\u001b[A\n",
      "Epoch 7:  20%|█▉        | 29/148 [00:31<02:05,  1.06s/it, training_loss=0.8760]\u001b[A\n",
      "Epoch 7:  20%|██        | 30/148 [00:31<02:04,  1.06s/it, training_loss=0.8760]\u001b[A\n",
      "Epoch 7:  20%|██        | 30/148 [00:32<02:04,  1.06s/it, training_loss=1.0495]\u001b[A\n",
      "Epoch 7:  21%|██        | 31/148 [00:32<02:04,  1.06s/it, training_loss=1.0495]\u001b[A\n",
      "Epoch 7:  21%|██        | 31/148 [00:33<02:04,  1.06s/it, training_loss=1.6324]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 32/148 [00:33<02:02,  1.06s/it, training_loss=1.6324]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 32/148 [00:34<02:02,  1.06s/it, training_loss=1.6478]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 33/148 [00:34<02:00,  1.05s/it, training_loss=1.6478]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 33/148 [00:35<02:00,  1.05s/it, training_loss=1.0438]\u001b[A\n",
      "Epoch 7:  23%|██▎       | 34/148 [00:35<01:59,  1.05s/it, training_loss=1.0438]\u001b[A\n",
      "Epoch 7:  23%|██▎       | 34/148 [00:37<01:59,  1.05s/it, training_loss=0.9292]\u001b[A\n",
      "Epoch 7:  24%|██▎       | 35/148 [00:37<01:59,  1.05s/it, training_loss=0.9292]\u001b[A\n",
      "Epoch 7:  24%|██▎       | 35/148 [00:38<01:59,  1.05s/it, training_loss=1.5794]\u001b[A\n",
      "Epoch 7:  24%|██▍       | 36/148 [00:38<01:57,  1.05s/it, training_loss=1.5794]\u001b[A\n",
      "Epoch 7:  24%|██▍       | 36/148 [00:39<01:57,  1.05s/it, training_loss=0.9495]\u001b[A\n",
      "Epoch 7:  25%|██▌       | 37/148 [00:39<01:56,  1.05s/it, training_loss=0.9495]\u001b[A\n",
      "Epoch 7:  25%|██▌       | 37/148 [00:40<01:56,  1.05s/it, training_loss=1.6857]\u001b[A\n",
      "Epoch 7:  26%|██▌       | 38/148 [00:40<01:55,  1.05s/it, training_loss=1.6857]\u001b[A\n",
      "Epoch 7:  26%|██▌       | 38/148 [00:41<01:55,  1.05s/it, training_loss=1.0450]\u001b[A\n",
      "Epoch 7:  26%|██▋       | 39/148 [00:41<01:54,  1.05s/it, training_loss=1.0450]\u001b[A\n",
      "Epoch 7:  26%|██▋       | 39/148 [00:42<01:54,  1.05s/it, training_loss=1.5250]\u001b[A\n",
      "Epoch 7:  27%|██▋       | 40/148 [00:42<01:53,  1.05s/it, training_loss=1.5250]\u001b[A\n",
      "Epoch 7:  27%|██▋       | 40/148 [00:43<01:53,  1.05s/it, training_loss=1.6231]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 41/148 [00:43<01:52,  1.05s/it, training_loss=1.6231]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 41/148 [00:44<01:52,  1.05s/it, training_loss=1.2443]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 42/148 [00:44<01:51,  1.05s/it, training_loss=1.2443]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 42/148 [00:45<01:51,  1.05s/it, training_loss=1.1211]\u001b[A\n",
      "Epoch 7:  29%|██▉       | 43/148 [00:45<01:50,  1.06s/it, training_loss=1.1211]\u001b[A\n",
      "Epoch 7:  29%|██▉       | 43/148 [00:46<01:50,  1.06s/it, training_loss=1.5289]\u001b[A\n",
      "Epoch 7:  30%|██▉       | 44/148 [00:46<01:49,  1.06s/it, training_loss=1.5289]\u001b[A\n",
      "Epoch 7:  30%|██▉       | 44/148 [00:47<01:49,  1.06s/it, training_loss=1.5508]\u001b[A\n",
      "Epoch 7:  30%|███       | 45/148 [00:47<01:48,  1.05s/it, training_loss=1.5508]\u001b[A\n",
      "Epoch 7:  30%|███       | 45/148 [00:48<01:48,  1.05s/it, training_loss=1.1327]\u001b[A\n",
      "Epoch 7:  31%|███       | 46/148 [00:48<01:47,  1.05s/it, training_loss=1.1327]\u001b[A\n",
      "Epoch 7:  31%|███       | 46/148 [00:49<01:47,  1.05s/it, training_loss=0.9266]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 47/148 [00:49<01:46,  1.05s/it, training_loss=0.9266]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 47/148 [00:50<01:46,  1.05s/it, training_loss=1.1837]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 48/148 [00:50<01:45,  1.06s/it, training_loss=1.1837]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 48/148 [00:51<01:45,  1.06s/it, training_loss=1.6026]\u001b[A\n",
      "Epoch 7:  33%|███▎      | 49/148 [00:51<01:43,  1.05s/it, training_loss=1.6026]\u001b[A\n",
      "Epoch 7:  33%|███▎      | 49/148 [00:52<01:43,  1.05s/it, training_loss=1.5714]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 50/148 [00:52<01:42,  1.05s/it, training_loss=1.5714]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 50/148 [00:53<01:42,  1.05s/it, training_loss=0.8985]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 51/148 [00:53<01:41,  1.05s/it, training_loss=0.8985]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 51/148 [00:54<01:41,  1.05s/it, training_loss=1.5884]\u001b[A\n",
      "Epoch 7:  35%|███▌      | 52/148 [00:54<01:39,  1.04s/it, training_loss=1.5884]\u001b[A\n",
      "Epoch 7:  35%|███▌      | 52/148 [00:55<01:39,  1.04s/it, training_loss=1.5267]\u001b[A\n",
      "Epoch 7:  36%|███▌      | 53/148 [00:55<01:38,  1.04s/it, training_loss=1.5267]\u001b[A\n",
      "Epoch 7:  36%|███▌      | 53/148 [00:56<01:38,  1.04s/it, training_loss=1.0924]\u001b[A\n",
      "Epoch 7:  36%|███▋      | 54/148 [00:56<01:38,  1.04s/it, training_loss=1.0924]\u001b[A\n",
      "Epoch 7:  36%|███▋      | 54/148 [00:58<01:38,  1.04s/it, training_loss=0.9183]\u001b[A\n",
      "Epoch 7:  37%|███▋      | 55/148 [00:58<01:37,  1.05s/it, training_loss=0.9183]\u001b[A\n",
      "Epoch 7:  37%|███▋      | 55/148 [00:59<01:37,  1.05s/it, training_loss=1.5576]\u001b[A\n",
      "Epoch 7:  38%|███▊      | 56/148 [00:59<01:35,  1.04s/it, training_loss=1.5576]\u001b[A\n",
      "Epoch 7:  38%|███▊      | 56/148 [01:00<01:35,  1.04s/it, training_loss=0.9253]\u001b[A\n",
      "Epoch 7:  39%|███▊      | 57/148 [01:00<01:35,  1.05s/it, training_loss=0.9253]\u001b[A\n",
      "Epoch 7:  39%|███▊      | 57/148 [01:01<01:35,  1.05s/it, training_loss=0.8877]\u001b[A\n",
      "Epoch 7:  39%|███▉      | 58/148 [01:01<01:33,  1.04s/it, training_loss=0.8877]\u001b[A\n",
      "Epoch 7:  39%|███▉      | 58/148 [01:02<01:33,  1.04s/it, training_loss=1.0803]\u001b[A\n",
      "Epoch 7:  40%|███▉      | 59/148 [01:02<01:33,  1.05s/it, training_loss=1.0803]\u001b[A\n",
      "Epoch 7:  40%|███▉      | 59/148 [01:03<01:33,  1.05s/it, training_loss=1.5463]\u001b[A\n",
      "Epoch 7:  41%|████      | 60/148 [01:03<01:32,  1.05s/it, training_loss=1.5463]\u001b[A\n",
      "Epoch 7:  41%|████      | 60/148 [01:04<01:32,  1.05s/it, training_loss=1.5365]\u001b[A\n",
      "Epoch 7:  41%|████      | 61/148 [01:04<01:30,  1.04s/it, training_loss=1.5365]\u001b[A\n",
      "Epoch 7:  41%|████      | 61/148 [01:05<01:30,  1.04s/it, training_loss=1.4685]\u001b[A\n",
      "Epoch 7:  42%|████▏     | 62/148 [01:05<01:29,  1.04s/it, training_loss=1.4685]\u001b[A\n",
      "Epoch 7:  42%|████▏     | 62/148 [01:06<01:29,  1.04s/it, training_loss=0.9133]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 63/148 [01:06<01:28,  1.04s/it, training_loss=0.9133]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 63/148 [01:07<01:28,  1.04s/it, training_loss=1.0427]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 64/148 [01:07<01:27,  1.04s/it, training_loss=1.0427]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 64/148 [01:08<01:27,  1.04s/it, training_loss=0.9740]\u001b[A\n",
      "Epoch 7:  44%|████▍     | 65/148 [01:08<01:26,  1.04s/it, training_loss=0.9740]\u001b[A\n",
      "Epoch 7:  44%|████▍     | 65/148 [01:09<01:26,  1.04s/it, training_loss=0.8916]\u001b[A\n",
      "Epoch 7:  45%|████▍     | 66/148 [01:09<01:25,  1.04s/it, training_loss=0.8916]\u001b[A\n",
      "Epoch 7:  45%|████▍     | 66/148 [01:10<01:25,  1.04s/it, training_loss=1.5559]\u001b[A\n",
      "Epoch 7:  45%|████▌     | 67/148 [01:10<01:24,  1.04s/it, training_loss=1.5559]\u001b[A\n",
      "Epoch 7:  45%|████▌     | 67/148 [01:11<01:24,  1.04s/it, training_loss=1.5024]\u001b[A\n",
      "Epoch 7:  46%|████▌     | 68/148 [01:11<01:23,  1.04s/it, training_loss=1.5024]\u001b[A\n",
      "Epoch 7:  46%|████▌     | 68/148 [01:12<01:23,  1.04s/it, training_loss=1.1330]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 69/148 [01:12<01:22,  1.04s/it, training_loss=1.1330]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 69/148 [01:13<01:22,  1.04s/it, training_loss=1.6360]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 70/148 [01:13<01:21,  1.04s/it, training_loss=1.6360]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 70/148 [01:14<01:21,  1.04s/it, training_loss=1.6349]\u001b[A\n",
      "Epoch 7:  48%|████▊     | 71/148 [01:14<01:20,  1.04s/it, training_loss=1.6349]\u001b[A\n",
      "Epoch 7:  48%|████▊     | 71/148 [01:15<01:20,  1.04s/it, training_loss=1.4295]\u001b[A\n",
      "Epoch 7:  49%|████▊     | 72/148 [01:15<01:19,  1.04s/it, training_loss=1.4295]\u001b[A\n",
      "Epoch 7:  49%|████▊     | 72/148 [01:16<01:19,  1.04s/it, training_loss=0.9436]\u001b[A\n",
      "Epoch 7:  49%|████▉     | 73/148 [01:16<01:17,  1.04s/it, training_loss=0.9436]\u001b[A\n",
      "Epoch 7:  49%|████▉     | 73/148 [01:17<01:17,  1.04s/it, training_loss=1.6893]\u001b[A\n",
      "Epoch 7:  50%|█████     | 74/148 [01:17<01:16,  1.04s/it, training_loss=1.6893]\u001b[A\n",
      "Epoch 7:  50%|█████     | 74/148 [01:18<01:16,  1.04s/it, training_loss=1.5544]\u001b[A\n",
      "Epoch 7:  51%|█████     | 75/148 [01:18<01:15,  1.04s/it, training_loss=1.5544]\u001b[A\n",
      "Epoch 7:  51%|█████     | 75/148 [01:19<01:15,  1.04s/it, training_loss=0.8775]\u001b[A\n",
      "Epoch 7:  51%|█████▏    | 76/148 [01:19<01:14,  1.04s/it, training_loss=0.8775]\u001b[A\n",
      "Epoch 7:  51%|█████▏    | 76/148 [01:20<01:14,  1.04s/it, training_loss=1.6885]\u001b[A\n",
      "Epoch 7:  52%|█████▏    | 77/148 [01:20<01:13,  1.04s/it, training_loss=1.6885]\u001b[A\n",
      "Epoch 7:  52%|█████▏    | 77/148 [01:21<01:13,  1.04s/it, training_loss=1.6161]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 78/148 [01:21<01:12,  1.04s/it, training_loss=1.6161]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 78/148 [01:23<01:12,  1.04s/it, training_loss=0.9145]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 79/148 [01:23<01:12,  1.05s/it, training_loss=0.9145]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 79/148 [01:24<01:12,  1.05s/it, training_loss=1.7105]\u001b[A\n",
      "Epoch 7:  54%|█████▍    | 80/148 [01:24<01:11,  1.05s/it, training_loss=1.7105]\u001b[A\n",
      "Epoch 7:  54%|█████▍    | 80/148 [01:25<01:11,  1.05s/it, training_loss=1.3200]\u001b[A\n",
      "Epoch 7:  55%|█████▍    | 81/148 [01:25<01:10,  1.05s/it, training_loss=1.3200]\u001b[A\n",
      "Epoch 7:  55%|█████▍    | 81/148 [01:26<01:10,  1.05s/it, training_loss=1.0780]\u001b[A\n",
      "Epoch 7:  55%|█████▌    | 82/148 [01:26<01:09,  1.05s/it, training_loss=1.0780]\u001b[A\n",
      "Epoch 7:  55%|█████▌    | 82/148 [01:27<01:09,  1.05s/it, training_loss=1.6200]\u001b[A\n",
      "Epoch 7:  56%|█████▌    | 83/148 [01:27<01:08,  1.05s/it, training_loss=1.6200]\u001b[A\n",
      "Epoch 7:  56%|█████▌    | 83/148 [01:28<01:08,  1.05s/it, training_loss=1.1162]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 84/148 [01:28<01:07,  1.05s/it, training_loss=1.1162]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 84/148 [01:29<01:07,  1.05s/it, training_loss=1.4232]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 85/148 [01:29<01:06,  1.05s/it, training_loss=1.4232]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 85/148 [01:30<01:06,  1.05s/it, training_loss=1.5494]\u001b[A\n",
      "Epoch 7:  58%|█████▊    | 86/148 [01:30<01:05,  1.05s/it, training_loss=1.5494]\u001b[A\n",
      "Epoch 7:  58%|█████▊    | 86/148 [01:31<01:05,  1.05s/it, training_loss=1.0883]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 87/148 [01:31<01:04,  1.05s/it, training_loss=1.0883]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 87/148 [01:32<01:04,  1.05s/it, training_loss=1.0163]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 88/148 [01:32<01:03,  1.05s/it, training_loss=1.0163]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 88/148 [01:33<01:03,  1.05s/it, training_loss=1.0739]\u001b[A\n",
      "Epoch 7:  60%|██████    | 89/148 [01:33<01:02,  1.05s/it, training_loss=1.0739]\u001b[A\n",
      "Epoch 7:  60%|██████    | 89/148 [01:34<01:02,  1.05s/it, training_loss=1.5502]\u001b[A\n",
      "Epoch 7:  61%|██████    | 90/148 [01:34<01:01,  1.05s/it, training_loss=1.5502]\u001b[A\n",
      "Epoch 7:  61%|██████    | 90/148 [01:35<01:01,  1.05s/it, training_loss=1.0955]\u001b[A\n",
      "Epoch 7:  61%|██████▏   | 91/148 [01:35<00:59,  1.05s/it, training_loss=1.0955]\u001b[A\n",
      "Epoch 7:  61%|██████▏   | 91/148 [01:36<00:59,  1.05s/it, training_loss=0.9125]\u001b[A\n",
      "Epoch 7:  62%|██████▏   | 92/148 [01:36<00:58,  1.05s/it, training_loss=0.9125]\u001b[A\n",
      "Epoch 7:  62%|██████▏   | 92/148 [01:37<00:58,  1.05s/it, training_loss=1.5586]\u001b[A\n",
      "Epoch 7:  63%|██████▎   | 93/148 [01:37<00:57,  1.05s/it, training_loss=1.5586]\u001b[A\n",
      "Epoch 7:  63%|██████▎   | 93/148 [01:38<00:57,  1.05s/it, training_loss=0.9139]\u001b[A\n",
      "Epoch 7:  64%|██████▎   | 94/148 [01:38<00:56,  1.05s/it, training_loss=0.9139]\u001b[A\n",
      "Epoch 7:  64%|██████▎   | 94/148 [01:39<00:56,  1.05s/it, training_loss=0.9168]\u001b[A\n",
      "Epoch 7:  64%|██████▍   | 95/148 [01:39<00:55,  1.05s/it, training_loss=0.9168]\u001b[A\n",
      "Epoch 7:  64%|██████▍   | 95/148 [01:40<00:55,  1.05s/it, training_loss=0.9256]\u001b[A\n",
      "Epoch 7:  65%|██████▍   | 96/148 [01:40<00:54,  1.05s/it, training_loss=0.9256]\u001b[A\n",
      "Epoch 7:  65%|██████▍   | 96/148 [01:41<00:54,  1.05s/it, training_loss=1.5891]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 97/148 [01:41<00:53,  1.05s/it, training_loss=1.5891]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 97/148 [01:42<00:53,  1.05s/it, training_loss=1.3326]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 98/148 [01:42<00:52,  1.05s/it, training_loss=1.3326]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 98/148 [01:44<00:52,  1.05s/it, training_loss=1.4750]\u001b[A\n",
      "Epoch 7:  67%|██████▋   | 99/148 [01:44<00:51,  1.05s/it, training_loss=1.4750]\u001b[A\n",
      "Epoch 7:  67%|██████▋   | 99/148 [01:45<00:51,  1.05s/it, training_loss=1.5849]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 100/148 [01:45<00:50,  1.05s/it, training_loss=1.5849]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 100/148 [01:46<00:50,  1.05s/it, training_loss=1.0934]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 101/148 [01:46<00:49,  1.05s/it, training_loss=1.0934]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 101/148 [01:47<00:49,  1.05s/it, training_loss=0.8549]\u001b[A\n",
      "Epoch 7:  69%|██████▉   | 102/148 [01:47<00:48,  1.05s/it, training_loss=0.8549]\u001b[A\n",
      "Epoch 7:  69%|██████▉   | 102/148 [01:48<00:48,  1.05s/it, training_loss=0.8479]\u001b[A\n",
      "Epoch 7:  70%|██████▉   | 103/148 [01:48<00:47,  1.06s/it, training_loss=0.8479]\u001b[A\n",
      "Epoch 7:  70%|██████▉   | 103/148 [01:49<00:47,  1.06s/it, training_loss=1.0827]\u001b[A\n",
      "Epoch 7:  70%|███████   | 104/148 [01:49<00:46,  1.06s/it, training_loss=1.0827]\u001b[A\n",
      "Epoch 7:  70%|███████   | 104/148 [01:50<00:46,  1.06s/it, training_loss=1.5900]\u001b[A\n",
      "Epoch 7:  71%|███████   | 105/148 [01:50<00:45,  1.06s/it, training_loss=1.5900]\u001b[A\n",
      "Epoch 7:  71%|███████   | 105/148 [01:51<00:45,  1.06s/it, training_loss=1.8310]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 106/148 [01:51<00:44,  1.06s/it, training_loss=1.8310]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 106/148 [01:52<00:44,  1.06s/it, training_loss=1.6444]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 107/148 [01:52<00:43,  1.06s/it, training_loss=1.6444]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 107/148 [01:53<00:43,  1.06s/it, training_loss=1.6489]\u001b[A\n",
      "Epoch 7:  73%|███████▎  | 108/148 [01:53<00:42,  1.06s/it, training_loss=1.6489]\u001b[A\n",
      "Epoch 7:  73%|███████▎  | 108/148 [01:54<00:42,  1.06s/it, training_loss=1.5407]\u001b[A\n",
      "Epoch 7:  74%|███████▎  | 109/148 [01:54<00:41,  1.05s/it, training_loss=1.5407]\u001b[A\n",
      "Epoch 7:  74%|███████▎  | 109/148 [01:55<00:41,  1.05s/it, training_loss=0.9783]\u001b[A\n",
      "Epoch 7:  74%|███████▍  | 110/148 [01:55<00:40,  1.06s/it, training_loss=0.9783]\u001b[A\n",
      "Epoch 7:  74%|███████▍  | 110/148 [01:56<00:40,  1.06s/it, training_loss=1.2313]\u001b[A\n",
      "Epoch 7:  75%|███████▌  | 111/148 [01:56<00:39,  1.06s/it, training_loss=1.2313]\u001b[A\n",
      "Epoch 7:  75%|███████▌  | 111/148 [01:57<00:39,  1.06s/it, training_loss=1.4164]\u001b[A\n",
      "Epoch 7:  76%|███████▌  | 112/148 [01:57<00:37,  1.05s/it, training_loss=1.4164]\u001b[A\n",
      "Epoch 7:  76%|███████▌  | 112/148 [01:58<00:37,  1.05s/it, training_loss=1.5247]\u001b[A\n",
      "Epoch 7:  76%|███████▋  | 113/148 [01:58<00:36,  1.05s/it, training_loss=1.5247]\u001b[A\n",
      "Epoch 7:  76%|███████▋  | 113/148 [01:59<00:36,  1.05s/it, training_loss=1.7095]\u001b[A\n",
      "Epoch 7:  77%|███████▋  | 114/148 [01:59<00:35,  1.05s/it, training_loss=1.7095]\u001b[A\n",
      "Epoch 7:  77%|███████▋  | 114/148 [02:00<00:35,  1.05s/it, training_loss=1.6048]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 115/148 [02:00<00:34,  1.05s/it, training_loss=1.6048]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 115/148 [02:01<00:34,  1.05s/it, training_loss=1.4413]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 116/148 [02:01<00:33,  1.05s/it, training_loss=1.4413]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 116/148 [02:03<00:33,  1.05s/it, training_loss=1.1115]\u001b[A\n",
      "Epoch 7:  79%|███████▉  | 117/148 [02:03<00:32,  1.06s/it, training_loss=1.1115]\u001b[A\n",
      "Epoch 7:  79%|███████▉  | 117/148 [02:04<00:32,  1.06s/it, training_loss=0.9295]\u001b[A\n",
      "Epoch 7:  80%|███████▉  | 118/148 [02:04<00:31,  1.06s/it, training_loss=0.9295]\u001b[A\n",
      "Epoch 7:  80%|███████▉  | 118/148 [02:05<00:31,  1.06s/it, training_loss=1.5719]\u001b[A\n",
      "Epoch 7:  80%|████████  | 119/148 [02:05<00:30,  1.05s/it, training_loss=1.5719]\u001b[A\n",
      "Epoch 7:  80%|████████  | 119/148 [02:06<00:30,  1.05s/it, training_loss=1.0813]\u001b[A\n",
      "Epoch 7:  81%|████████  | 120/148 [02:06<00:29,  1.06s/it, training_loss=1.0813]\u001b[A\n",
      "Epoch 7:  81%|████████  | 120/148 [02:07<00:29,  1.06s/it, training_loss=1.4381]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 121/148 [02:07<00:28,  1.06s/it, training_loss=1.4381]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 121/148 [02:08<00:28,  1.06s/it, training_loss=1.2898]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 122/148 [02:08<00:27,  1.06s/it, training_loss=1.2898]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 122/148 [02:09<00:27,  1.06s/it, training_loss=1.1596]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 123/148 [02:09<00:26,  1.06s/it, training_loss=1.1596]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 123/148 [02:10<00:26,  1.06s/it, training_loss=1.2391]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 124/148 [02:10<00:25,  1.06s/it, training_loss=1.2391]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 124/148 [02:11<00:25,  1.06s/it, training_loss=1.5480]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 125/148 [02:11<00:24,  1.06s/it, training_loss=1.5480]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 125/148 [02:12<00:24,  1.06s/it, training_loss=1.5745]\u001b[A\n",
      "Epoch 7:  85%|████████▌ | 126/148 [02:12<00:23,  1.06s/it, training_loss=1.5745]\u001b[A\n",
      "Epoch 7:  85%|████████▌ | 126/148 [02:13<00:23,  1.06s/it, training_loss=0.9078]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 127/148 [02:13<00:22,  1.05s/it, training_loss=0.9078]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 127/148 [02:14<00:22,  1.05s/it, training_loss=0.9118]\u001b[A\n",
      "Epoch 7:  86%|████████▋ | 128/148 [02:14<00:21,  1.06s/it, training_loss=0.9118]\u001b[A\n",
      "Epoch 7:  86%|████████▋ | 128/148 [02:15<00:21,  1.06s/it, training_loss=1.0779]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 129/148 [02:15<00:20,  1.06s/it, training_loss=1.0779]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 129/148 [02:16<00:20,  1.06s/it, training_loss=1.5259]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 130/148 [02:16<00:19,  1.06s/it, training_loss=1.5259]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 130/148 [02:17<00:19,  1.06s/it, training_loss=1.5972]\u001b[A\n",
      "Epoch 7:  89%|████████▊ | 131/148 [02:17<00:17,  1.06s/it, training_loss=1.5972]\u001b[A\n",
      "Epoch 7:  89%|████████▊ | 131/148 [02:18<00:17,  1.06s/it, training_loss=1.1348]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 132/148 [02:18<00:16,  1.05s/it, training_loss=1.1348]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 132/148 [02:19<00:16,  1.05s/it, training_loss=1.5443]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 133/148 [02:19<00:15,  1.05s/it, training_loss=1.5443]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 133/148 [02:20<00:15,  1.05s/it, training_loss=1.5936]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 134/148 [02:20<00:14,  1.05s/it, training_loss=1.5936]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 134/148 [02:22<00:14,  1.05s/it, training_loss=1.1181]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 135/148 [02:22<00:13,  1.05s/it, training_loss=1.1181]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 135/148 [02:23<00:13,  1.05s/it, training_loss=1.0949]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 136/148 [02:23<00:12,  1.05s/it, training_loss=1.0949]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 136/148 [02:24<00:12,  1.05s/it, training_loss=1.5727]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 137/148 [02:24<00:11,  1.05s/it, training_loss=1.5727]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 137/148 [02:25<00:11,  1.05s/it, training_loss=1.6051]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 138/148 [02:25<00:10,  1.05s/it, training_loss=1.6051]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 138/148 [02:26<00:10,  1.05s/it, training_loss=1.6312]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 139/148 [02:26<00:09,  1.05s/it, training_loss=1.6312]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 139/148 [02:27<00:09,  1.05s/it, training_loss=1.3224]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 140/148 [02:27<00:08,  1.04s/it, training_loss=1.3224]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 140/148 [02:28<00:08,  1.04s/it, training_loss=1.1680]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 141/148 [02:28<00:07,  1.05s/it, training_loss=1.1680]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 141/148 [02:29<00:07,  1.05s/it, training_loss=0.8927]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 142/148 [02:29<00:06,  1.05s/it, training_loss=0.8927]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 142/148 [02:30<00:06,  1.05s/it, training_loss=1.5630]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 143/148 [02:30<00:05,  1.05s/it, training_loss=1.5630]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 143/148 [02:31<00:05,  1.05s/it, training_loss=1.0828]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 144/148 [02:31<00:04,  1.05s/it, training_loss=1.0828]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 144/148 [02:32<00:04,  1.05s/it, training_loss=1.5103]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 145/148 [02:32<00:03,  1.05s/it, training_loss=1.5103]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 145/148 [02:33<00:03,  1.05s/it, training_loss=1.5771]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 146/148 [02:33<00:02,  1.05s/it, training_loss=1.5771]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 146/148 [02:34<00:02,  1.05s/it, training_loss=0.9483]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 147/148 [02:34<00:01,  1.05s/it, training_loss=0.9483]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 147/148 [02:35<00:01,  1.05s/it, training_loss=1.4931]\u001b[A\n",
      "Epoch 7: 100%|██████████| 148/148 [02:35<00:00,  1.04it/s, training_loss=1.4931]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:22:12,315 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:22:12,316 - INFO - Memory usage after evaluation start: 3705.64 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:08,  3.06it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:08,  3.00it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:08,  2.98it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:07,  2.96it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:07,  2.95it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:02<00:07,  2.94it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:06,  2.94it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:06,  2.94it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:03<00:06,  2.95it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:05,  2.95it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:05,  2.93it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:04<00:05,  2.93it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:04<00:04,  2.93it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:04,  2.93it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:05<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:05<00:03,  2.92it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:03,  2.92it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:06<00:03,  2.92it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:07<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:07<00:01,  2.92it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:08<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:08<00:00,  2.91it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:08<00:00,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:22:21,241 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 00:22:21,256 - INFO - Class 'Drama': Optimal threshold = 0.600, F1 Score = 0.570\n",
      "2025-02-16 00:22:21,271 - INFO - Class 'Horor': Optimal threshold = 0.750, F1 Score = 0.761\n",
      "2025-02-16 00:22:21,285 - INFO - Class 'Komedi': Optimal threshold = 0.650, F1 Score = 0.600\n",
      "2025-02-16 00:22:21,298 - INFO - Class 'Laga': Optimal threshold = 0.550, F1 Score = 0.386\n",
      "2025-02-16 00:22:21,311 - INFO - Class 'Romantis': Optimal threshold = 0.600, F1 Score = 0.563\n",
      "2025-02-16 00:22:21,333 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:22:21,339 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:22:21,339 - INFO - Accuracy: 0.7050\n",
      "2025-02-16 00:22:21,340 - INFO - F1_score: 0.5698\n",
      "2025-02-16 00:22:21,341 - INFO - Precision: 0.4857\n",
      "2025-02-16 00:22:21,342 - INFO - Recall: 0.6892\n",
      "2025-02-16 00:22:21,348 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:22:21,349 - INFO - Accuracy: 0.8774\n",
      "2025-02-16 00:22:21,350 - INFO - F1_score: 0.7612\n",
      "2025-02-16 00:22:21,350 - INFO - Precision: 0.6623\n",
      "2025-02-16 00:22:21,351 - INFO - Recall: 0.8947\n",
      "2025-02-16 00:22:21,358 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:22:21,358 - INFO - Accuracy: 0.8161\n",
      "2025-02-16 00:22:21,359 - INFO - F1_score: 0.6000\n",
      "2025-02-16 00:22:21,359 - INFO - Precision: 0.5806\n",
      "2025-02-16 00:22:21,361 - INFO - Recall: 0.6207\n",
      "2025-02-16 00:22:21,366 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:22:21,367 - INFO - Accuracy: 0.6705\n",
      "2025-02-16 00:22:21,367 - INFO - F1_score: 0.3857\n",
      "2025-02-16 00:22:21,369 - INFO - Precision: 0.2647\n",
      "2025-02-16 00:22:21,370 - INFO - Recall: 0.7105\n",
      "2025-02-16 00:22:21,375 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:22:21,376 - INFO - Accuracy: 0.8812\n",
      "2025-02-16 00:22:21,376 - INFO - F1_score: 0.5634\n",
      "2025-02-16 00:22:21,377 - INFO - Precision: 0.5405\n",
      "2025-02-16 00:22:21,378 - INFO - Recall: 0.5882\n",
      "2025-02-16 00:22:21,380 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:22:25,261 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:22:25,262 - INFO - Memory usage after evaluation end: 3711.39 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 6/100 [20:50<4:39:56, 178.69s/it, Train Loss=1.2909, Val Loss=0.0540, Accuracy=0.7900]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:22:33,999 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   7%|▋         | 7/100 [20:50<4:36:08, 178.15s/it, Train Loss=1.2909, Val Loss=0.0540, Accuracy=0.7900]\n",
      "Epoch 8:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=1.5242]\u001b[A\n",
      "Epoch 8:   1%|          | 1/148 [00:01<02:31,  1.03s/it, training_loss=1.5242]\u001b[A\n",
      "Epoch 8:   1%|          | 1/148 [00:02<02:31,  1.03s/it, training_loss=0.9771]\u001b[A\n",
      "Epoch 8:   1%|▏         | 2/148 [00:02<02:32,  1.05s/it, training_loss=0.9771]\u001b[A\n",
      "Epoch 8:   1%|▏         | 2/148 [00:03<02:32,  1.05s/it, training_loss=1.5400]\u001b[A\n",
      "Epoch 8:   2%|▏         | 3/148 [00:03<02:31,  1.04s/it, training_loss=1.5400]\u001b[A\n",
      "Epoch 8:   2%|▏         | 3/148 [00:04<02:31,  1.04s/it, training_loss=1.5547]\u001b[A\n",
      "Epoch 8:   3%|▎         | 4/148 [00:04<02:29,  1.04s/it, training_loss=1.5547]\u001b[A\n",
      "Epoch 8:   3%|▎         | 4/148 [00:05<02:29,  1.04s/it, training_loss=0.8317]\u001b[A\n",
      "Epoch 8:   3%|▎         | 5/148 [00:05<02:28,  1.04s/it, training_loss=0.8317]\u001b[A\n",
      "Epoch 8:   3%|▎         | 5/148 [00:06<02:28,  1.04s/it, training_loss=1.1360]\u001b[A\n",
      "Epoch 8:   4%|▍         | 6/148 [00:06<02:28,  1.05s/it, training_loss=1.1360]\u001b[A\n",
      "Epoch 8:   4%|▍         | 6/148 [00:07<02:28,  1.05s/it, training_loss=0.8942]\u001b[A\n",
      "Epoch 8:   5%|▍         | 7/148 [00:07<02:27,  1.05s/it, training_loss=0.8942]\u001b[A\n",
      "Epoch 8:   5%|▍         | 7/148 [00:08<02:27,  1.05s/it, training_loss=1.0566]\u001b[A\n",
      "Epoch 8:   5%|▌         | 8/148 [00:08<02:27,  1.05s/it, training_loss=1.0566]\u001b[A\n",
      "Epoch 8:   5%|▌         | 8/148 [00:09<02:27,  1.05s/it, training_loss=0.9974]\u001b[A\n",
      "Epoch 8:   6%|▌         | 9/148 [00:09<02:26,  1.05s/it, training_loss=0.9974]\u001b[A\n",
      "Epoch 8:   6%|▌         | 9/148 [00:10<02:26,  1.05s/it, training_loss=1.3322]\u001b[A\n",
      "Epoch 8:   7%|▋         | 10/148 [00:10<02:25,  1.06s/it, training_loss=1.3322]\u001b[A\n",
      "Epoch 8:   7%|▋         | 10/148 [00:11<02:25,  1.06s/it, training_loss=1.4461]\u001b[A\n",
      "Epoch 8:   7%|▋         | 11/148 [00:11<02:24,  1.06s/it, training_loss=1.4461]\u001b[A\n",
      "Epoch 8:   7%|▋         | 11/148 [00:12<02:24,  1.06s/it, training_loss=1.1110]\u001b[A\n",
      "Epoch 8:   8%|▊         | 12/148 [00:12<02:24,  1.06s/it, training_loss=1.1110]\u001b[A\n",
      "Epoch 8:   8%|▊         | 12/148 [00:13<02:24,  1.06s/it, training_loss=1.5043]\u001b[A\n",
      "Epoch 8:   9%|▉         | 13/148 [00:13<02:23,  1.06s/it, training_loss=1.5043]\u001b[A\n",
      "Epoch 8:   9%|▉         | 13/148 [00:14<02:23,  1.06s/it, training_loss=1.0163]\u001b[A\n",
      "Epoch 8:   9%|▉         | 14/148 [00:14<02:22,  1.06s/it, training_loss=1.0163]\u001b[A\n",
      "Epoch 8:   9%|▉         | 14/148 [00:15<02:22,  1.06s/it, training_loss=1.6335]\u001b[A\n",
      "Epoch 8:  10%|█         | 15/148 [00:15<02:21,  1.06s/it, training_loss=1.6335]\u001b[A\n",
      "Epoch 8:  10%|█         | 15/148 [00:16<02:21,  1.06s/it, training_loss=0.9586]\u001b[A\n",
      "Epoch 8:  11%|█         | 16/148 [00:16<02:21,  1.07s/it, training_loss=0.9586]\u001b[A\n",
      "Epoch 8:  11%|█         | 16/148 [00:17<02:21,  1.07s/it, training_loss=1.1042]\u001b[A\n",
      "Epoch 8:  11%|█▏        | 17/148 [00:17<02:20,  1.07s/it, training_loss=1.1042]\u001b[A\n",
      "Epoch 8:  11%|█▏        | 17/148 [00:19<02:20,  1.07s/it, training_loss=1.2090]\u001b[A\n",
      "Epoch 8:  12%|█▏        | 18/148 [00:19<02:20,  1.08s/it, training_loss=1.2090]\u001b[A\n",
      "Epoch 8:  12%|█▏        | 18/148 [00:20<02:20,  1.08s/it, training_loss=0.9665]\u001b[A\n",
      "Epoch 8:  13%|█▎        | 19/148 [00:20<02:19,  1.08s/it, training_loss=0.9665]\u001b[A\n",
      "Epoch 8:  13%|█▎        | 19/148 [00:21<02:19,  1.08s/it, training_loss=1.5841]\u001b[A\n",
      "Epoch 8:  14%|█▎        | 20/148 [00:21<02:17,  1.07s/it, training_loss=1.5841]\u001b[A\n",
      "Epoch 8:  14%|█▎        | 20/148 [00:22<02:17,  1.07s/it, training_loss=1.5340]\u001b[A\n",
      "Epoch 8:  14%|█▍        | 21/148 [00:22<02:16,  1.07s/it, training_loss=1.5340]\u001b[A\n",
      "Epoch 8:  14%|█▍        | 21/148 [00:23<02:16,  1.07s/it, training_loss=1.1056]\u001b[A\n",
      "Epoch 8:  15%|█▍        | 22/148 [00:23<02:15,  1.07s/it, training_loss=1.1056]\u001b[A\n",
      "Epoch 8:  15%|█▍        | 22/148 [00:24<02:15,  1.07s/it, training_loss=1.5315]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 23/148 [00:24<02:14,  1.07s/it, training_loss=1.5315]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 23/148 [00:25<02:14,  1.07s/it, training_loss=0.9645]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 24/148 [00:25<02:12,  1.07s/it, training_loss=0.9645]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 24/148 [00:26<02:12,  1.07s/it, training_loss=1.7482]\u001b[A\n",
      "Epoch 8:  17%|█▋        | 25/148 [00:26<02:11,  1.07s/it, training_loss=1.7482]\u001b[A\n",
      "Epoch 8:  17%|█▋        | 25/148 [00:27<02:11,  1.07s/it, training_loss=1.4840]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 26/148 [00:27<02:10,  1.07s/it, training_loss=1.4840]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 26/148 [00:28<02:10,  1.07s/it, training_loss=1.6526]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 27/148 [00:28<02:08,  1.06s/it, training_loss=1.6526]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 27/148 [00:29<02:08,  1.06s/it, training_loss=1.0557]\u001b[A\n",
      "Epoch 8:  19%|█▉        | 28/148 [00:29<02:07,  1.06s/it, training_loss=1.0557]\u001b[A\n",
      "Epoch 8:  19%|█▉        | 28/148 [00:30<02:07,  1.06s/it, training_loss=1.5105]\u001b[A\n",
      "Epoch 8:  20%|█▉        | 29/148 [00:30<02:06,  1.06s/it, training_loss=1.5105]\u001b[A\n",
      "Epoch 8:  20%|█▉        | 29/148 [00:31<02:06,  1.06s/it, training_loss=1.5982]\u001b[A\n",
      "Epoch 8:  20%|██        | 30/148 [00:31<02:04,  1.06s/it, training_loss=1.5982]\u001b[A\n",
      "Epoch 8:  20%|██        | 30/148 [00:32<02:04,  1.06s/it, training_loss=1.1315]\u001b[A\n",
      "Epoch 8:  21%|██        | 31/148 [00:32<02:04,  1.06s/it, training_loss=1.1315]\u001b[A\n",
      "Epoch 8:  21%|██        | 31/148 [00:33<02:04,  1.06s/it, training_loss=1.1315]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 32/148 [00:33<02:02,  1.06s/it, training_loss=1.1315]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 32/148 [00:35<02:02,  1.06s/it, training_loss=0.9362]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 33/148 [00:35<02:01,  1.06s/it, training_loss=0.9362]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 33/148 [00:36<02:01,  1.06s/it, training_loss=1.5605]\u001b[A\n",
      "Epoch 8:  23%|██▎       | 34/148 [00:36<02:00,  1.06s/it, training_loss=1.5605]\u001b[A\n",
      "Epoch 8:  23%|██▎       | 34/148 [00:37<02:00,  1.06s/it, training_loss=1.5442]\u001b[A\n",
      "Epoch 8:  24%|██▎       | 35/148 [00:37<01:59,  1.05s/it, training_loss=1.5442]\u001b[A\n",
      "Epoch 8:  24%|██▎       | 35/148 [00:38<01:59,  1.05s/it, training_loss=1.5193]\u001b[A\n",
      "Epoch 8:  24%|██▍       | 36/148 [00:38<01:57,  1.05s/it, training_loss=1.5193]\u001b[A\n",
      "Epoch 8:  24%|██▍       | 36/148 [00:39<01:57,  1.05s/it, training_loss=1.6427]\u001b[A\n",
      "Epoch 8:  25%|██▌       | 37/148 [00:39<01:56,  1.05s/it, training_loss=1.6427]\u001b[A\n",
      "Epoch 8:  25%|██▌       | 37/148 [00:40<01:56,  1.05s/it, training_loss=1.7105]\u001b[A\n",
      "Epoch 8:  26%|██▌       | 38/148 [00:40<01:55,  1.05s/it, training_loss=1.7105]\u001b[A\n",
      "Epoch 8:  26%|██▌       | 38/148 [00:41<01:55,  1.05s/it, training_loss=1.5382]\u001b[A\n",
      "Epoch 8:  26%|██▋       | 39/148 [00:41<01:54,  1.05s/it, training_loss=1.5382]\u001b[A\n",
      "Epoch 8:  26%|██▋       | 39/148 [00:42<01:54,  1.05s/it, training_loss=0.9328]\u001b[A\n",
      "Epoch 8:  27%|██▋       | 40/148 [00:42<01:53,  1.05s/it, training_loss=0.9328]\u001b[A\n",
      "Epoch 8:  27%|██▋       | 40/148 [00:43<01:53,  1.05s/it, training_loss=1.0158]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 41/148 [00:43<01:52,  1.05s/it, training_loss=1.0158]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 41/148 [00:44<01:52,  1.05s/it, training_loss=0.9466]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 42/148 [00:44<01:51,  1.05s/it, training_loss=0.9466]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 42/148 [00:45<01:51,  1.05s/it, training_loss=1.6423]\u001b[A\n",
      "Epoch 8:  29%|██▉       | 43/148 [00:45<01:50,  1.05s/it, training_loss=1.6423]\u001b[A\n",
      "Epoch 8:  29%|██▉       | 43/148 [00:46<01:50,  1.05s/it, training_loss=1.5501]\u001b[A\n",
      "Epoch 8:  30%|██▉       | 44/148 [00:46<01:48,  1.04s/it, training_loss=1.5501]\u001b[A\n",
      "Epoch 8:  30%|██▉       | 44/148 [00:47<01:48,  1.04s/it, training_loss=1.0549]\u001b[A\n",
      "Epoch 8:  30%|███       | 45/148 [00:47<01:47,  1.04s/it, training_loss=1.0549]\u001b[A\n",
      "Epoch 8:  30%|███       | 45/148 [00:48<01:47,  1.04s/it, training_loss=0.9017]\u001b[A\n",
      "Epoch 8:  31%|███       | 46/148 [00:48<01:46,  1.05s/it, training_loss=0.9017]\u001b[A\n",
      "Epoch 8:  31%|███       | 46/148 [00:49<01:46,  1.05s/it, training_loss=1.5461]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 47/148 [00:49<01:45,  1.04s/it, training_loss=1.5461]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 47/148 [00:50<01:45,  1.04s/it, training_loss=1.4555]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 48/148 [00:50<01:44,  1.04s/it, training_loss=1.4555]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 48/148 [00:51<01:44,  1.04s/it, training_loss=1.5798]\u001b[A\n",
      "Epoch 8:  33%|███▎      | 49/148 [00:51<01:43,  1.04s/it, training_loss=1.5798]\u001b[A\n",
      "Epoch 8:  33%|███▎      | 49/148 [00:52<01:43,  1.04s/it, training_loss=0.9165]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 50/148 [00:52<01:42,  1.04s/it, training_loss=0.9165]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 50/148 [00:53<01:42,  1.04s/it, training_loss=1.5423]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 51/148 [00:53<01:41,  1.05s/it, training_loss=1.5423]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 51/148 [00:54<01:41,  1.05s/it, training_loss=0.9853]\u001b[A\n",
      "Epoch 8:  35%|███▌      | 52/148 [00:54<01:40,  1.05s/it, training_loss=0.9853]\u001b[A\n",
      "Epoch 8:  35%|███▌      | 52/148 [00:55<01:40,  1.05s/it, training_loss=0.9250]\u001b[A\n",
      "Epoch 8:  36%|███▌      | 53/148 [00:55<01:39,  1.05s/it, training_loss=0.9250]\u001b[A\n",
      "Epoch 8:  36%|███▌      | 53/148 [00:57<01:39,  1.05s/it, training_loss=1.5933]\u001b[A\n",
      "Epoch 8:  36%|███▋      | 54/148 [00:57<01:38,  1.05s/it, training_loss=1.5933]\u001b[A\n",
      "Epoch 8:  36%|███▋      | 54/148 [00:58<01:38,  1.05s/it, training_loss=0.9887]\u001b[A\n",
      "Epoch 8:  37%|███▋      | 55/148 [00:58<01:37,  1.05s/it, training_loss=0.9887]\u001b[A\n",
      "Epoch 8:  37%|███▋      | 55/148 [00:59<01:37,  1.05s/it, training_loss=0.9550]\u001b[A\n",
      "Epoch 8:  38%|███▊      | 56/148 [00:59<01:36,  1.05s/it, training_loss=0.9550]\u001b[A\n",
      "Epoch 8:  38%|███▊      | 56/148 [01:00<01:36,  1.05s/it, training_loss=0.8585]\u001b[A\n",
      "Epoch 8:  39%|███▊      | 57/148 [01:00<01:35,  1.05s/it, training_loss=0.8585]\u001b[A\n",
      "Epoch 8:  39%|███▊      | 57/148 [01:01<01:35,  1.05s/it, training_loss=0.8944]\u001b[A\n",
      "Epoch 8:  39%|███▉      | 58/148 [01:01<01:34,  1.05s/it, training_loss=0.8944]\u001b[A\n",
      "Epoch 8:  39%|███▉      | 58/148 [01:02<01:34,  1.05s/it, training_loss=0.9511]\u001b[A\n",
      "Epoch 8:  40%|███▉      | 59/148 [01:02<01:33,  1.05s/it, training_loss=0.9511]\u001b[A\n",
      "Epoch 8:  40%|███▉      | 59/148 [01:03<01:33,  1.05s/it, training_loss=1.0093]\u001b[A\n",
      "Epoch 8:  41%|████      | 60/148 [01:03<01:32,  1.05s/it, training_loss=1.0093]\u001b[A\n",
      "Epoch 8:  41%|████      | 60/148 [01:04<01:32,  1.05s/it, training_loss=0.9209]\u001b[A\n",
      "Epoch 8:  41%|████      | 61/148 [01:04<01:31,  1.05s/it, training_loss=0.9209]\u001b[A\n",
      "Epoch 8:  41%|████      | 61/148 [01:05<01:31,  1.05s/it, training_loss=0.9419]\u001b[A\n",
      "Epoch 8:  42%|████▏     | 62/148 [01:05<01:30,  1.05s/it, training_loss=0.9419]\u001b[A\n",
      "Epoch 8:  42%|████▏     | 62/148 [01:06<01:30,  1.05s/it, training_loss=1.5990]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 63/148 [01:06<01:29,  1.05s/it, training_loss=1.5990]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 63/148 [01:07<01:29,  1.05s/it, training_loss=0.9350]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 64/148 [01:07<01:28,  1.05s/it, training_loss=0.9350]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 64/148 [01:08<01:28,  1.05s/it, training_loss=0.9459]\u001b[A\n",
      "Epoch 8:  44%|████▍     | 65/148 [01:08<01:27,  1.05s/it, training_loss=0.9459]\u001b[A\n",
      "Epoch 8:  44%|████▍     | 65/148 [01:09<01:27,  1.05s/it, training_loss=0.8341]\u001b[A\n",
      "Epoch 8:  45%|████▍     | 66/148 [01:09<01:26,  1.05s/it, training_loss=0.8341]\u001b[A\n",
      "Epoch 8:  45%|████▍     | 66/148 [01:10<01:26,  1.05s/it, training_loss=1.6258]\u001b[A\n",
      "Epoch 8:  45%|████▌     | 67/148 [01:10<01:25,  1.05s/it, training_loss=1.6258]\u001b[A\n",
      "Epoch 8:  45%|████▌     | 67/148 [01:11<01:25,  1.05s/it, training_loss=1.6608]\u001b[A\n",
      "Epoch 8:  46%|████▌     | 68/148 [01:11<01:23,  1.05s/it, training_loss=1.6608]\u001b[A\n",
      "Epoch 8:  46%|████▌     | 68/148 [01:12<01:23,  1.05s/it, training_loss=1.5371]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 69/148 [01:12<01:22,  1.04s/it, training_loss=1.5371]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 69/148 [01:13<01:22,  1.04s/it, training_loss=0.8623]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 70/148 [01:13<01:21,  1.05s/it, training_loss=0.8623]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 70/148 [01:14<01:21,  1.05s/it, training_loss=1.5734]\u001b[A\n",
      "Epoch 8:  48%|████▊     | 71/148 [01:14<01:20,  1.05s/it, training_loss=1.5734]\u001b[A\n",
      "Epoch 8:  48%|████▊     | 71/148 [01:15<01:20,  1.05s/it, training_loss=0.8670]\u001b[A\n",
      "Epoch 8:  49%|████▊     | 72/148 [01:15<01:19,  1.05s/it, training_loss=0.8670]\u001b[A\n",
      "Epoch 8:  49%|████▊     | 72/148 [01:16<01:19,  1.05s/it, training_loss=0.9019]\u001b[A\n",
      "Epoch 8:  49%|████▉     | 73/148 [01:16<01:18,  1.05s/it, training_loss=0.9019]\u001b[A\n",
      "Epoch 8:  49%|████▉     | 73/148 [01:18<01:18,  1.05s/it, training_loss=1.5061]\u001b[A\n",
      "Epoch 8:  50%|█████     | 74/148 [01:18<01:17,  1.05s/it, training_loss=1.5061]\u001b[A\n",
      "Epoch 8:  50%|█████     | 74/148 [01:19<01:17,  1.05s/it, training_loss=1.5685]\u001b[A\n",
      "Epoch 8:  51%|█████     | 75/148 [01:19<01:16,  1.04s/it, training_loss=1.5685]\u001b[A\n",
      "Epoch 8:  51%|█████     | 75/148 [01:20<01:16,  1.04s/it, training_loss=0.9154]\u001b[A\n",
      "Epoch 8:  51%|█████▏    | 76/148 [01:20<01:15,  1.05s/it, training_loss=0.9154]\u001b[A\n",
      "Epoch 8:  51%|█████▏    | 76/148 [01:21<01:15,  1.05s/it, training_loss=1.5579]\u001b[A\n",
      "Epoch 8:  52%|█████▏    | 77/148 [01:21<01:14,  1.05s/it, training_loss=1.5579]\u001b[A\n",
      "Epoch 8:  52%|█████▏    | 77/148 [01:22<01:14,  1.05s/it, training_loss=1.0481]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 78/148 [01:22<01:13,  1.05s/it, training_loss=1.0481]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 78/148 [01:23<01:13,  1.05s/it, training_loss=0.9146]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 79/148 [01:23<01:12,  1.05s/it, training_loss=0.9146]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 79/148 [01:24<01:12,  1.05s/it, training_loss=1.5801]\u001b[A\n",
      "Epoch 8:  54%|█████▍    | 80/148 [01:24<01:11,  1.05s/it, training_loss=1.5801]\u001b[A\n",
      "Epoch 8:  54%|█████▍    | 80/148 [01:25<01:11,  1.05s/it, training_loss=1.5549]\u001b[A\n",
      "Epoch 8:  55%|█████▍    | 81/148 [01:25<01:10,  1.05s/it, training_loss=1.5549]\u001b[A\n",
      "Epoch 8:  55%|█████▍    | 81/148 [01:26<01:10,  1.05s/it, training_loss=1.5791]\u001b[A\n",
      "Epoch 8:  55%|█████▌    | 82/148 [01:26<01:08,  1.04s/it, training_loss=1.5791]\u001b[A\n",
      "Epoch 8:  55%|█████▌    | 82/148 [01:27<01:08,  1.04s/it, training_loss=0.8997]\u001b[A\n",
      "Epoch 8:  56%|█████▌    | 83/148 [01:27<01:08,  1.05s/it, training_loss=0.8997]\u001b[A\n",
      "Epoch 8:  56%|█████▌    | 83/148 [01:28<01:08,  1.05s/it, training_loss=1.0168]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 84/148 [01:28<01:07,  1.05s/it, training_loss=1.0168]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 84/148 [01:29<01:07,  1.05s/it, training_loss=1.2642]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 85/148 [01:29<01:06,  1.05s/it, training_loss=1.2642]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 85/148 [01:30<01:06,  1.05s/it, training_loss=1.6309]\u001b[A\n",
      "Epoch 8:  58%|█████▊    | 86/148 [01:30<01:05,  1.05s/it, training_loss=1.6309]\u001b[A\n",
      "Epoch 8:  58%|█████▊    | 86/148 [01:31<01:05,  1.05s/it, training_loss=0.8618]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 87/148 [01:31<01:03,  1.05s/it, training_loss=0.8618]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 87/148 [01:32<01:03,  1.05s/it, training_loss=1.3780]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 88/148 [01:32<01:02,  1.05s/it, training_loss=1.3780]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 88/148 [01:33<01:02,  1.05s/it, training_loss=1.3458]\u001b[A\n",
      "Epoch 8:  60%|██████    | 89/148 [01:33<01:01,  1.05s/it, training_loss=1.3458]\u001b[A\n",
      "Epoch 8:  60%|██████    | 89/148 [01:34<01:01,  1.05s/it, training_loss=0.9800]\u001b[A\n",
      "Epoch 8:  61%|██████    | 90/148 [01:34<01:00,  1.05s/it, training_loss=0.9800]\u001b[A\n",
      "Epoch 8:  61%|██████    | 90/148 [01:35<01:00,  1.05s/it, training_loss=1.5303]\u001b[A\n",
      "Epoch 8:  61%|██████▏   | 91/148 [01:35<00:59,  1.04s/it, training_loss=1.5303]\u001b[A\n",
      "Epoch 8:  61%|██████▏   | 91/148 [01:36<00:59,  1.04s/it, training_loss=0.9429]\u001b[A\n",
      "Epoch 8:  62%|██████▏   | 92/148 [01:36<00:58,  1.05s/it, training_loss=0.9429]\u001b[A\n",
      "Epoch 8:  62%|██████▏   | 92/148 [01:37<00:58,  1.05s/it, training_loss=1.1171]\u001b[A\n",
      "Epoch 8:  63%|██████▎   | 93/148 [01:37<00:57,  1.05s/it, training_loss=1.1171]\u001b[A\n",
      "Epoch 8:  63%|██████▎   | 93/148 [01:38<00:57,  1.05s/it, training_loss=1.4857]\u001b[A\n",
      "Epoch 8:  64%|██████▎   | 94/148 [01:38<00:56,  1.05s/it, training_loss=1.4857]\u001b[A\n",
      "Epoch 8:  64%|██████▎   | 94/148 [01:40<00:56,  1.05s/it, training_loss=1.1049]\u001b[A\n",
      "Epoch 8:  64%|██████▍   | 95/148 [01:40<00:55,  1.04s/it, training_loss=1.1049]\u001b[A\n",
      "Epoch 8:  64%|██████▍   | 95/148 [01:41<00:55,  1.04s/it, training_loss=0.8564]\u001b[A\n",
      "Epoch 8:  65%|██████▍   | 96/148 [01:41<00:54,  1.05s/it, training_loss=0.8564]\u001b[A\n",
      "Epoch 8:  65%|██████▍   | 96/148 [01:42<00:54,  1.05s/it, training_loss=0.8254]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 97/148 [01:42<00:53,  1.05s/it, training_loss=0.8254]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 97/148 [01:43<00:53,  1.05s/it, training_loss=0.8260]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 98/148 [01:43<00:52,  1.05s/it, training_loss=0.8260]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 98/148 [01:44<00:52,  1.05s/it, training_loss=0.9821]\u001b[A\n",
      "Epoch 8:  67%|██████▋   | 99/148 [01:44<00:51,  1.05s/it, training_loss=0.9821]\u001b[A\n",
      "Epoch 8:  67%|██████▋   | 99/148 [01:45<00:51,  1.05s/it, training_loss=0.8308]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 100/148 [01:45<00:50,  1.05s/it, training_loss=0.8308]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 100/148 [01:46<00:50,  1.05s/it, training_loss=1.3566]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 101/148 [01:46<00:49,  1.05s/it, training_loss=1.3566]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 101/148 [01:47<00:49,  1.05s/it, training_loss=1.5339]\u001b[A\n",
      "Epoch 8:  69%|██████▉   | 102/148 [01:47<00:48,  1.05s/it, training_loss=1.5339]\u001b[A\n",
      "Epoch 8:  69%|██████▉   | 102/148 [01:48<00:48,  1.05s/it, training_loss=1.7217]\u001b[A\n",
      "Epoch 8:  70%|██████▉   | 103/148 [01:48<00:47,  1.04s/it, training_loss=1.7217]\u001b[A\n",
      "Epoch 8:  70%|██████▉   | 103/148 [01:49<00:47,  1.04s/it, training_loss=1.5952]\u001b[A\n",
      "Epoch 8:  70%|███████   | 104/148 [01:49<00:45,  1.04s/it, training_loss=1.5952]\u001b[A\n",
      "Epoch 8:  70%|███████   | 104/148 [01:50<00:45,  1.04s/it, training_loss=1.5864]\u001b[A\n",
      "Epoch 8:  71%|███████   | 105/148 [01:50<00:44,  1.04s/it, training_loss=1.5864]\u001b[A\n",
      "Epoch 8:  71%|███████   | 105/148 [01:51<00:44,  1.04s/it, training_loss=1.1566]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 106/148 [01:51<00:44,  1.05s/it, training_loss=1.1566]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 106/148 [01:52<00:44,  1.05s/it, training_loss=1.5730]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 107/148 [01:52<00:42,  1.05s/it, training_loss=1.5730]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 107/148 [01:53<00:42,  1.05s/it, training_loss=1.0145]\u001b[A\n",
      "Epoch 8:  73%|███████▎  | 108/148 [01:53<00:41,  1.05s/it, training_loss=1.0145]\u001b[A\n",
      "Epoch 8:  73%|███████▎  | 108/148 [01:54<00:41,  1.05s/it, training_loss=1.1912]\u001b[A\n",
      "Epoch 8:  74%|███████▎  | 109/148 [01:54<00:40,  1.05s/it, training_loss=1.1912]\u001b[A\n",
      "Epoch 8:  74%|███████▎  | 109/148 [01:55<00:40,  1.05s/it, training_loss=1.6096]\u001b[A\n",
      "Epoch 8:  74%|███████▍  | 110/148 [01:55<00:39,  1.05s/it, training_loss=1.6096]\u001b[A\n",
      "Epoch 8:  74%|███████▍  | 110/148 [01:56<00:39,  1.05s/it, training_loss=1.0467]\u001b[A\n",
      "Epoch 8:  75%|███████▌  | 111/148 [01:56<00:38,  1.05s/it, training_loss=1.0467]\u001b[A\n",
      "Epoch 8:  75%|███████▌  | 111/148 [01:57<00:38,  1.05s/it, training_loss=1.4161]\u001b[A\n",
      "Epoch 8:  76%|███████▌  | 112/148 [01:57<00:37,  1.05s/it, training_loss=1.4161]\u001b[A\n",
      "Epoch 8:  76%|███████▌  | 112/148 [01:58<00:37,  1.05s/it, training_loss=1.5535]\u001b[A\n",
      "Epoch 8:  76%|███████▋  | 113/148 [01:58<00:36,  1.05s/it, training_loss=1.5535]\u001b[A\n",
      "Epoch 8:  76%|███████▋  | 113/148 [01:59<00:36,  1.05s/it, training_loss=1.6568]\u001b[A\n",
      "Epoch 8:  77%|███████▋  | 114/148 [01:59<00:35,  1.04s/it, training_loss=1.6568]\u001b[A\n",
      "Epoch 8:  77%|███████▋  | 114/148 [02:00<00:35,  1.04s/it, training_loss=1.2541]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 115/148 [02:00<00:34,  1.05s/it, training_loss=1.2541]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 115/148 [02:02<00:34,  1.05s/it, training_loss=1.6168]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 116/148 [02:02<00:33,  1.05s/it, training_loss=1.6168]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 116/148 [02:03<00:33,  1.05s/it, training_loss=1.1445]\u001b[A\n",
      "Epoch 8:  79%|███████▉  | 117/148 [02:03<00:32,  1.05s/it, training_loss=1.1445]\u001b[A\n",
      "Epoch 8:  79%|███████▉  | 117/148 [02:04<00:32,  1.05s/it, training_loss=1.0986]\u001b[A\n",
      "Epoch 8:  80%|███████▉  | 118/148 [02:04<00:31,  1.05s/it, training_loss=1.0986]\u001b[A\n",
      "Epoch 8:  80%|███████▉  | 118/148 [02:05<00:31,  1.05s/it, training_loss=1.3785]\u001b[A\n",
      "Epoch 8:  80%|████████  | 119/148 [02:05<00:30,  1.05s/it, training_loss=1.3785]\u001b[A\n",
      "Epoch 8:  80%|████████  | 119/148 [02:06<00:30,  1.05s/it, training_loss=1.0329]\u001b[A\n",
      "Epoch 8:  81%|████████  | 120/148 [02:06<00:29,  1.05s/it, training_loss=1.0329]\u001b[A\n",
      "Epoch 8:  81%|████████  | 120/148 [02:07<00:29,  1.05s/it, training_loss=1.5529]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 121/148 [02:07<00:28,  1.04s/it, training_loss=1.5529]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 121/148 [02:08<00:28,  1.04s/it, training_loss=0.9780]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 122/148 [02:08<00:27,  1.05s/it, training_loss=0.9780]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 122/148 [02:09<00:27,  1.05s/it, training_loss=1.1634]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 123/148 [02:09<00:26,  1.05s/it, training_loss=1.1634]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 123/148 [02:10<00:26,  1.05s/it, training_loss=0.9331]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 124/148 [02:10<00:25,  1.05s/it, training_loss=0.9331]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 124/148 [02:11<00:25,  1.05s/it, training_loss=1.6490]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 125/148 [02:11<00:24,  1.05s/it, training_loss=1.6490]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 125/148 [02:12<00:24,  1.05s/it, training_loss=1.5150]\u001b[A\n",
      "Epoch 8:  85%|████████▌ | 126/148 [02:12<00:23,  1.05s/it, training_loss=1.5150]\u001b[A\n",
      "Epoch 8:  85%|████████▌ | 126/148 [02:13<00:23,  1.05s/it, training_loss=1.5831]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 127/148 [02:13<00:21,  1.05s/it, training_loss=1.5831]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 127/148 [02:14<00:21,  1.05s/it, training_loss=1.5584]\u001b[A\n",
      "Epoch 8:  86%|████████▋ | 128/148 [02:14<00:20,  1.05s/it, training_loss=1.5584]\u001b[A\n",
      "Epoch 8:  86%|████████▋ | 128/148 [02:15<00:20,  1.05s/it, training_loss=0.8039]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 129/148 [02:15<00:19,  1.05s/it, training_loss=0.8039]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 129/148 [02:16<00:19,  1.05s/it, training_loss=1.6246]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 130/148 [02:16<00:18,  1.05s/it, training_loss=1.6246]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 130/148 [02:17<00:18,  1.05s/it, training_loss=1.5160]\u001b[A\n",
      "Epoch 8:  89%|████████▊ | 131/148 [02:17<00:17,  1.04s/it, training_loss=1.5160]\u001b[A\n",
      "Epoch 8:  89%|████████▊ | 131/148 [02:18<00:17,  1.04s/it, training_loss=0.8941]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 132/148 [02:18<00:16,  1.05s/it, training_loss=0.8941]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 132/148 [02:19<00:16,  1.05s/it, training_loss=1.0185]\u001b[A\n",
      "Epoch 8:  90%|████████▉ | 133/148 [02:19<00:15,  1.05s/it, training_loss=1.0185]\u001b[A\n",
      "Epoch 8:  90%|████████▉ | 133/148 [02:20<00:15,  1.05s/it, training_loss=1.5616]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 134/148 [02:20<00:14,  1.05s/it, training_loss=1.5616]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 134/148 [02:21<00:14,  1.05s/it, training_loss=1.0418]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 135/148 [02:21<00:13,  1.05s/it, training_loss=1.0418]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 135/148 [02:22<00:13,  1.05s/it, training_loss=1.6744]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 136/148 [02:22<00:12,  1.04s/it, training_loss=1.6744]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 136/148 [02:24<00:12,  1.04s/it, training_loss=1.6154]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 137/148 [02:24<00:11,  1.05s/it, training_loss=1.6154]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 137/148 [02:25<00:11,  1.05s/it, training_loss=0.9313]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 138/148 [02:25<00:10,  1.05s/it, training_loss=0.9313]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 138/148 [02:26<00:10,  1.05s/it, training_loss=0.9441]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 139/148 [02:26<00:09,  1.05s/it, training_loss=0.9441]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 139/148 [02:27<00:09,  1.05s/it, training_loss=0.8713]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 140/148 [02:27<00:08,  1.05s/it, training_loss=0.8713]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 140/148 [02:28<00:08,  1.05s/it, training_loss=1.5535]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 141/148 [02:28<00:07,  1.05s/it, training_loss=1.5535]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 141/148 [02:29<00:07,  1.05s/it, training_loss=1.5700]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 142/148 [02:29<00:06,  1.05s/it, training_loss=1.5700]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 142/148 [02:30<00:06,  1.05s/it, training_loss=1.6009]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 143/148 [02:30<00:05,  1.05s/it, training_loss=1.6009]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 143/148 [02:31<00:05,  1.05s/it, training_loss=1.5253]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 144/148 [02:31<00:04,  1.05s/it, training_loss=1.5253]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 144/148 [02:32<00:04,  1.05s/it, training_loss=1.0311]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 145/148 [02:32<00:03,  1.05s/it, training_loss=1.0311]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 145/148 [02:33<00:03,  1.05s/it, training_loss=0.8677]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 146/148 [02:33<00:02,  1.05s/it, training_loss=0.8677]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 146/148 [02:34<00:02,  1.05s/it, training_loss=1.1308]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 147/148 [02:34<00:01,  1.05s/it, training_loss=1.1308]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 147/148 [02:35<00:01,  1.05s/it, training_loss=1.3439]\u001b[A\n",
      "Epoch 8: 100%|██████████| 148/148 [02:35<00:00,  1.04it/s, training_loss=1.3439]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:25:09,314 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:25:09,316 - INFO - Memory usage after evaluation start: 3711.64 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:08,  3.04it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:08,  2.95it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:08,  2.93it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:07,  2.93it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:02<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:03<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:04<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:04<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:05<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:06<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:07<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:08<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:08<00:00,  2.91it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:08<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:25:18,287 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 00:25:18,301 - INFO - Class 'Drama': Optimal threshold = 0.700, F1 Score = 0.590\n",
      "2025-02-16 00:25:18,315 - INFO - Class 'Horor': Optimal threshold = 0.750, F1 Score = 0.783\n",
      "2025-02-16 00:25:18,329 - INFO - Class 'Komedi': Optimal threshold = 0.700, F1 Score = 0.583\n",
      "2025-02-16 00:25:18,342 - INFO - Class 'Laga': Optimal threshold = 0.500, F1 Score = 0.360\n",
      "2025-02-16 00:25:18,355 - INFO - Class 'Romantis': Optimal threshold = 0.600, F1 Score = 0.507\n",
      "2025-02-16 00:25:18,376 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:25:18,382 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:25:18,382 - INFO - Accuracy: 0.7280\n",
      "2025-02-16 00:25:18,383 - INFO - F1_score: 0.5896\n",
      "2025-02-16 00:25:18,383 - INFO - Precision: 0.5152\n",
      "2025-02-16 00:25:18,384 - INFO - Recall: 0.6892\n",
      "2025-02-16 00:25:18,390 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:25:18,391 - INFO - Accuracy: 0.9004\n",
      "2025-02-16 00:25:18,392 - INFO - F1_score: 0.7833\n",
      "2025-02-16 00:25:18,392 - INFO - Precision: 0.7460\n",
      "2025-02-16 00:25:18,393 - INFO - Recall: 0.8246\n",
      "2025-02-16 00:25:18,400 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:25:18,400 - INFO - Accuracy: 0.8084\n",
      "2025-02-16 00:25:18,401 - INFO - F1_score: 0.5833\n",
      "2025-02-16 00:25:18,402 - INFO - Precision: 0.5645\n",
      "2025-02-16 00:25:18,403 - INFO - Recall: 0.6034\n",
      "2025-02-16 00:25:18,408 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:25:18,409 - INFO - Accuracy: 0.6590\n",
      "2025-02-16 00:25:18,410 - INFO - F1_score: 0.3597\n",
      "2025-02-16 00:25:18,410 - INFO - Precision: 0.2475\n",
      "2025-02-16 00:25:18,411 - INFO - Recall: 0.6579\n",
      "2025-02-16 00:25:18,417 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:25:18,418 - INFO - Accuracy: 0.8659\n",
      "2025-02-16 00:25:18,418 - INFO - F1_score: 0.5070\n",
      "2025-02-16 00:25:18,420 - INFO - Precision: 0.4865\n",
      "2025-02-16 00:25:18,421 - INFO - Recall: 0.5294\n",
      "2025-02-16 00:25:18,423 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:25:22,234 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:25:22,235 - INFO - Memory usage after evaluation end: 3717.27 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   7%|▋         | 7/100 [23:47<4:36:08, 178.15s/it, Train Loss=1.2596, Val Loss=0.0556, Accuracy=0.7923]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:25:31,107 - INFO - Learning rate: 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 8/100 [23:47<4:32:39, 177.82s/it, Train Loss=1.2596, Val Loss=0.0556, Accuracy=0.7923]\n",
      "Epoch 9:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=1.5592]\u001b[A\n",
      "Epoch 9:   1%|          | 1/148 [00:01<02:33,  1.04s/it, training_loss=1.5592]\u001b[A\n",
      "Epoch 9:   1%|          | 1/148 [00:02<02:33,  1.04s/it, training_loss=1.6573]\u001b[A\n",
      "Epoch 9:   1%|▏         | 2/148 [00:02<02:32,  1.05s/it, training_loss=1.6573]\u001b[A\n",
      "Epoch 9:   1%|▏         | 2/148 [00:03<02:32,  1.05s/it, training_loss=1.5807]\u001b[A\n",
      "Epoch 9:   2%|▏         | 3/148 [00:03<02:31,  1.05s/it, training_loss=1.5807]\u001b[A\n",
      "Epoch 9:   2%|▏         | 3/148 [00:04<02:31,  1.05s/it, training_loss=0.9757]\u001b[A\n",
      "Epoch 9:   3%|▎         | 4/148 [00:04<02:30,  1.05s/it, training_loss=0.9757]\u001b[A\n",
      "Epoch 9:   3%|▎         | 4/148 [00:05<02:30,  1.05s/it, training_loss=1.6886]\u001b[A\n",
      "Epoch 9:   3%|▎         | 5/148 [00:05<02:30,  1.05s/it, training_loss=1.6886]\u001b[A\n",
      "Epoch 9:   3%|▎         | 5/148 [00:06<02:30,  1.05s/it, training_loss=0.9509]\u001b[A\n",
      "Epoch 9:   4%|▍         | 6/148 [00:06<02:30,  1.06s/it, training_loss=0.9509]\u001b[A\n",
      "Epoch 9:   4%|▍         | 6/148 [00:07<02:30,  1.06s/it, training_loss=0.9385]\u001b[A\n",
      "Epoch 9:   5%|▍         | 7/148 [00:07<02:29,  1.06s/it, training_loss=0.9385]\u001b[A\n",
      "Epoch 9:   5%|▍         | 7/148 [00:08<02:29,  1.06s/it, training_loss=1.6710]\u001b[A\n",
      "Epoch 9:   5%|▌         | 8/148 [00:08<02:28,  1.06s/it, training_loss=1.6710]\u001b[A\n",
      "Epoch 9:   5%|▌         | 8/148 [00:09<02:28,  1.06s/it, training_loss=0.9219]\u001b[A\n",
      "Epoch 9:   6%|▌         | 9/148 [00:09<02:27,  1.06s/it, training_loss=0.9219]\u001b[A\n",
      "Epoch 9:   6%|▌         | 9/148 [00:10<02:27,  1.06s/it, training_loss=1.6276]\u001b[A\n",
      "Epoch 9:   7%|▋         | 10/148 [00:10<02:26,  1.06s/it, training_loss=1.6276]\u001b[A\n",
      "Epoch 9:   7%|▋         | 10/148 [00:11<02:26,  1.06s/it, training_loss=0.9982]\u001b[A\n",
      "Epoch 9:   7%|▋         | 11/148 [00:11<02:26,  1.07s/it, training_loss=0.9982]\u001b[A\n",
      "Epoch 9:   7%|▋         | 11/148 [00:12<02:26,  1.07s/it, training_loss=1.5582]\u001b[A\n",
      "Epoch 9:   8%|▊         | 12/148 [00:12<02:25,  1.07s/it, training_loss=1.5582]\u001b[A\n",
      "Epoch 9:   8%|▊         | 12/148 [00:13<02:25,  1.07s/it, training_loss=1.6488]\u001b[A\n",
      "Epoch 9:   9%|▉         | 13/148 [00:13<02:23,  1.06s/it, training_loss=1.6488]\u001b[A\n",
      "Epoch 9:   9%|▉         | 13/148 [00:14<02:23,  1.06s/it, training_loss=0.9461]\u001b[A\n",
      "Epoch 9:   9%|▉         | 14/148 [00:14<02:22,  1.06s/it, training_loss=0.9461]\u001b[A\n",
      "Epoch 9:   9%|▉         | 14/148 [00:15<02:22,  1.06s/it, training_loss=1.6066]\u001b[A\n",
      "Epoch 9:  10%|█         | 15/148 [00:15<02:21,  1.06s/it, training_loss=1.6066]\u001b[A\n",
      "Epoch 9:  10%|█         | 15/148 [00:16<02:21,  1.06s/it, training_loss=0.8669]\u001b[A\n",
      "Epoch 9:  11%|█         | 16/148 [00:16<02:20,  1.06s/it, training_loss=0.8669]\u001b[A\n",
      "Epoch 9:  11%|█         | 16/148 [00:18<02:20,  1.06s/it, training_loss=0.8914]\u001b[A\n",
      "Epoch 9:  11%|█▏        | 17/148 [00:18<02:19,  1.06s/it, training_loss=0.8914]\u001b[A\n",
      "Epoch 9:  11%|█▏        | 17/148 [00:19<02:19,  1.06s/it, training_loss=1.4976]\u001b[A\n",
      "Epoch 9:  12%|█▏        | 18/148 [00:19<02:17,  1.06s/it, training_loss=1.4976]\u001b[A\n",
      "Epoch 9:  12%|█▏        | 18/148 [00:20<02:17,  1.06s/it, training_loss=1.3366]\u001b[A\n",
      "Epoch 9:  13%|█▎        | 19/148 [00:20<02:17,  1.06s/it, training_loss=1.3366]\u001b[A\n",
      "Epoch 9:  13%|█▎        | 19/148 [00:21<02:17,  1.06s/it, training_loss=1.4771]\u001b[A\n",
      "Epoch 9:  14%|█▎        | 20/148 [00:21<02:15,  1.06s/it, training_loss=1.4771]\u001b[A\n",
      "Epoch 9:  14%|█▎        | 20/148 [00:22<02:15,  1.06s/it, training_loss=1.5268]\u001b[A\n",
      "Epoch 9:  14%|█▍        | 21/148 [00:22<02:14,  1.06s/it, training_loss=1.5268]\u001b[A\n",
      "Epoch 9:  14%|█▍        | 21/148 [00:23<02:14,  1.06s/it, training_loss=1.6002]\u001b[A\n",
      "Epoch 9:  15%|█▍        | 22/148 [00:23<02:13,  1.06s/it, training_loss=1.6002]\u001b[A\n",
      "Epoch 9:  15%|█▍        | 22/148 [00:24<02:13,  1.06s/it, training_loss=1.5636]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 23/148 [00:24<02:11,  1.05s/it, training_loss=1.5636]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 23/148 [00:25<02:11,  1.05s/it, training_loss=1.6245]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 24/148 [00:25<02:11,  1.06s/it, training_loss=1.6245]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 24/148 [00:26<02:11,  1.06s/it, training_loss=1.6644]\u001b[A\n",
      "Epoch 9:  17%|█▋        | 25/148 [00:26<02:09,  1.06s/it, training_loss=1.6644]\u001b[A\n",
      "Epoch 9:  17%|█▋        | 25/148 [00:27<02:09,  1.06s/it, training_loss=1.5715]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 26/148 [00:27<02:08,  1.06s/it, training_loss=1.5715]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 26/148 [00:28<02:08,  1.06s/it, training_loss=1.0495]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 27/148 [00:28<02:07,  1.06s/it, training_loss=1.0495]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 27/148 [00:29<02:07,  1.06s/it, training_loss=1.0289]\u001b[A\n",
      "Epoch 9:  19%|█▉        | 28/148 [00:29<02:06,  1.06s/it, training_loss=1.0289]\u001b[A\n",
      "Epoch 9:  19%|█▉        | 28/148 [00:30<02:06,  1.06s/it, training_loss=0.8401]\u001b[A\n",
      "Epoch 9:  20%|█▉        | 29/148 [00:30<02:05,  1.06s/it, training_loss=0.8401]\u001b[A\n",
      "Epoch 9:  20%|█▉        | 29/148 [00:31<02:05,  1.06s/it, training_loss=1.5940]\u001b[A\n",
      "Epoch 9:  20%|██        | 30/148 [00:31<02:04,  1.05s/it, training_loss=1.5940]\u001b[A\n",
      "Epoch 9:  20%|██        | 30/148 [00:32<02:04,  1.05s/it, training_loss=0.8927]\u001b[A\n",
      "Epoch 9:  21%|██        | 31/148 [00:32<02:03,  1.06s/it, training_loss=0.8927]\u001b[A\n",
      "Epoch 9:  21%|██        | 31/148 [00:33<02:03,  1.06s/it, training_loss=0.9517]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 32/148 [00:33<02:02,  1.06s/it, training_loss=0.9517]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 32/148 [00:34<02:02,  1.06s/it, training_loss=1.5575]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 33/148 [00:34<02:01,  1.05s/it, training_loss=1.5575]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 33/148 [00:35<02:01,  1.05s/it, training_loss=1.5657]\u001b[A\n",
      "Epoch 9:  23%|██▎       | 34/148 [00:35<01:59,  1.05s/it, training_loss=1.5657]\u001b[A\n",
      "Epoch 9:  23%|██▎       | 34/148 [00:37<01:59,  1.05s/it, training_loss=1.0032]\u001b[A\n",
      "Epoch 9:  24%|██▎       | 35/148 [00:37<01:58,  1.05s/it, training_loss=1.0032]\u001b[A\n",
      "Epoch 9:  24%|██▎       | 35/148 [00:38<01:58,  1.05s/it, training_loss=1.5636]\u001b[A\n",
      "Epoch 9:  24%|██▍       | 36/148 [00:38<01:57,  1.05s/it, training_loss=1.5636]\u001b[A\n",
      "Epoch 9:  24%|██▍       | 36/148 [00:39<01:57,  1.05s/it, training_loss=1.5404]\u001b[A\n",
      "Epoch 9:  25%|██▌       | 37/148 [00:39<01:55,  1.04s/it, training_loss=1.5404]\u001b[A\n",
      "Epoch 9:  25%|██▌       | 37/148 [00:40<01:55,  1.04s/it, training_loss=1.6120]\u001b[A\n",
      "Epoch 9:  26%|██▌       | 38/148 [00:40<01:54,  1.05s/it, training_loss=1.6120]\u001b[A\n",
      "Epoch 9:  26%|██▌       | 38/148 [00:41<01:54,  1.05s/it, training_loss=0.8187]\u001b[A\n",
      "Epoch 9:  26%|██▋       | 39/148 [00:41<01:53,  1.05s/it, training_loss=0.8187]\u001b[A\n",
      "Epoch 9:  26%|██▋       | 39/148 [00:42<01:53,  1.05s/it, training_loss=1.5756]\u001b[A\n",
      "Epoch 9:  27%|██▋       | 40/148 [00:42<01:52,  1.04s/it, training_loss=1.5756]\u001b[A\n",
      "Epoch 9:  27%|██▋       | 40/148 [00:43<01:52,  1.04s/it, training_loss=0.9400]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 41/148 [00:43<01:52,  1.05s/it, training_loss=0.9400]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 41/148 [00:44<01:52,  1.05s/it, training_loss=1.5973]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 42/148 [00:44<01:50,  1.05s/it, training_loss=1.5973]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 42/148 [00:45<01:50,  1.05s/it, training_loss=0.8195]\u001b[A\n",
      "Epoch 9:  29%|██▉       | 43/148 [00:45<01:49,  1.04s/it, training_loss=0.8195]\u001b[A\n",
      "Epoch 9:  29%|██▉       | 43/148 [00:46<01:49,  1.04s/it, training_loss=1.5496]\u001b[A\n",
      "Epoch 9:  30%|██▉       | 44/148 [00:46<01:48,  1.05s/it, training_loss=1.5496]\u001b[A\n",
      "Epoch 9:  30%|██▉       | 44/148 [00:47<01:48,  1.05s/it, training_loss=0.8320]\u001b[A\n",
      "Epoch 9:  30%|███       | 45/148 [00:47<01:47,  1.05s/it, training_loss=0.8320]\u001b[A\n",
      "Epoch 9:  30%|███       | 45/148 [00:48<01:47,  1.05s/it, training_loss=1.0077]\u001b[A\n",
      "Epoch 9:  31%|███       | 46/148 [00:48<01:46,  1.04s/it, training_loss=1.0077]\u001b[A\n",
      "Epoch 9:  31%|███       | 46/148 [00:49<01:46,  1.04s/it, training_loss=1.5932]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 47/148 [00:49<01:45,  1.04s/it, training_loss=1.5932]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 47/148 [00:50<01:45,  1.04s/it, training_loss=1.5264]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 48/148 [00:50<01:44,  1.04s/it, training_loss=1.5264]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 48/148 [00:51<01:44,  1.04s/it, training_loss=1.4994]\u001b[A\n",
      "Epoch 9:  33%|███▎      | 49/148 [00:51<01:42,  1.04s/it, training_loss=1.4994]\u001b[A\n",
      "Epoch 9:  33%|███▎      | 49/148 [00:52<01:42,  1.04s/it, training_loss=1.6259]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 50/148 [00:52<01:41,  1.04s/it, training_loss=1.6259]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 50/148 [00:53<01:41,  1.04s/it, training_loss=1.5842]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 51/148 [00:53<01:40,  1.04s/it, training_loss=1.5842]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 51/148 [00:54<01:40,  1.04s/it, training_loss=0.9187]\u001b[A\n",
      "Epoch 9:  35%|███▌      | 52/148 [00:54<01:39,  1.04s/it, training_loss=0.9187]\u001b[A\n",
      "Epoch 9:  35%|███▌      | 52/148 [00:55<01:39,  1.04s/it, training_loss=1.5442]\u001b[A\n",
      "Epoch 9:  36%|███▌      | 53/148 [00:55<01:38,  1.04s/it, training_loss=1.5442]\u001b[A\n",
      "Epoch 9:  36%|███▌      | 53/148 [00:56<01:38,  1.04s/it, training_loss=1.0069]\u001b[A\n",
      "Epoch 9:  36%|███▋      | 54/148 [00:56<01:38,  1.04s/it, training_loss=1.0069]\u001b[A\n",
      "Epoch 9:  36%|███▋      | 54/148 [00:57<01:38,  1.04s/it, training_loss=1.4252]\u001b[A\n",
      "Epoch 9:  37%|███▋      | 55/148 [00:57<01:36,  1.04s/it, training_loss=1.4252]\u001b[A\n",
      "Epoch 9:  37%|███▋      | 55/148 [00:58<01:36,  1.04s/it, training_loss=0.8567]\u001b[A\n",
      "Epoch 9:  38%|███▊      | 56/148 [00:58<01:36,  1.04s/it, training_loss=0.8567]\u001b[A\n",
      "Epoch 9:  38%|███▊      | 56/148 [00:59<01:36,  1.04s/it, training_loss=0.8379]\u001b[A\n",
      "Epoch 9:  39%|███▊      | 57/148 [00:59<01:34,  1.04s/it, training_loss=0.8379]\u001b[A\n",
      "Epoch 9:  39%|███▊      | 57/148 [01:00<01:34,  1.04s/it, training_loss=0.9084]\u001b[A\n",
      "Epoch 9:  39%|███▉      | 58/148 [01:00<01:34,  1.04s/it, training_loss=0.9084]\u001b[A\n",
      "Epoch 9:  39%|███▉      | 58/148 [01:02<01:34,  1.04s/it, training_loss=1.0064]\u001b[A\n",
      "Epoch 9:  40%|███▉      | 59/148 [01:02<01:32,  1.04s/it, training_loss=1.0064]\u001b[A\n",
      "Epoch 9:  40%|███▉      | 59/148 [01:03<01:32,  1.04s/it, training_loss=1.0834]\u001b[A\n",
      "Epoch 9:  41%|████      | 60/148 [01:03<01:31,  1.04s/it, training_loss=1.0834]\u001b[A\n",
      "Epoch 9:  41%|████      | 60/148 [01:04<01:31,  1.04s/it, training_loss=1.3676]\u001b[A\n",
      "Epoch 9:  41%|████      | 61/148 [01:04<01:30,  1.04s/it, training_loss=1.3676]\u001b[A\n",
      "Epoch 9:  41%|████      | 61/148 [01:05<01:30,  1.04s/it, training_loss=1.5862]\u001b[A\n",
      "Epoch 9:  42%|████▏     | 62/148 [01:05<01:29,  1.04s/it, training_loss=1.5862]\u001b[A\n",
      "Epoch 9:  42%|████▏     | 62/148 [01:06<01:29,  1.04s/it, training_loss=1.4830]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 63/148 [01:06<01:28,  1.04s/it, training_loss=1.4830]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 63/148 [01:07<01:28,  1.04s/it, training_loss=1.4922]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 64/148 [01:07<01:27,  1.04s/it, training_loss=1.4922]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 64/148 [01:08<01:27,  1.04s/it, training_loss=1.0078]\u001b[A\n",
      "Epoch 9:  44%|████▍     | 65/148 [01:08<01:26,  1.04s/it, training_loss=1.0078]\u001b[A\n",
      "Epoch 9:  44%|████▍     | 65/148 [01:09<01:26,  1.04s/it, training_loss=1.6005]\u001b[A\n",
      "Epoch 9:  45%|████▍     | 66/148 [01:09<01:25,  1.04s/it, training_loss=1.6005]\u001b[A\n",
      "Epoch 9:  45%|████▍     | 66/148 [01:10<01:25,  1.04s/it, training_loss=0.8187]\u001b[A\n",
      "Epoch 9:  45%|████▌     | 67/148 [01:10<01:24,  1.04s/it, training_loss=0.8187]\u001b[A\n",
      "Epoch 9:  45%|████▌     | 67/148 [01:11<01:24,  1.04s/it, training_loss=1.3561]\u001b[A\n",
      "Epoch 9:  46%|████▌     | 68/148 [01:11<01:23,  1.04s/it, training_loss=1.3561]\u001b[A\n",
      "Epoch 9:  46%|████▌     | 68/148 [01:12<01:23,  1.04s/it, training_loss=0.8249]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 69/148 [01:12<01:22,  1.04s/it, training_loss=0.8249]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 69/148 [01:13<01:22,  1.04s/it, training_loss=1.6688]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 70/148 [01:13<01:20,  1.04s/it, training_loss=1.6688]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 70/148 [01:14<01:20,  1.04s/it, training_loss=1.1325]\u001b[A\n",
      "Epoch 9:  48%|████▊     | 71/148 [01:14<01:20,  1.04s/it, training_loss=1.1325]\u001b[A\n",
      "Epoch 9:  48%|████▊     | 71/148 [01:15<01:20,  1.04s/it, training_loss=0.9130]\u001b[A\n",
      "Epoch 9:  49%|████▊     | 72/148 [01:15<01:19,  1.04s/it, training_loss=0.9130]\u001b[A\n",
      "Epoch 9:  49%|████▊     | 72/148 [01:16<01:19,  1.04s/it, training_loss=0.8649]\u001b[A\n",
      "Epoch 9:  49%|████▉     | 73/148 [01:16<01:18,  1.05s/it, training_loss=0.8649]\u001b[A\n",
      "Epoch 9:  49%|████▉     | 73/148 [01:17<01:18,  1.05s/it, training_loss=0.9709]\u001b[A\n",
      "Epoch 9:  50%|█████     | 74/148 [01:17<01:17,  1.05s/it, training_loss=0.9709]\u001b[A\n",
      "Epoch 9:  50%|█████     | 74/148 [01:18<01:17,  1.05s/it, training_loss=1.5409]\u001b[A\n",
      "Epoch 9:  51%|█████     | 75/148 [01:18<01:16,  1.05s/it, training_loss=1.5409]\u001b[A\n",
      "Epoch 9:  51%|█████     | 75/148 [01:19<01:16,  1.05s/it, training_loss=1.6055]\u001b[A\n",
      "Epoch 9:  51%|█████▏    | 76/148 [01:19<01:15,  1.05s/it, training_loss=1.6055]\u001b[A\n",
      "Epoch 9:  51%|█████▏    | 76/148 [01:20<01:15,  1.05s/it, training_loss=0.9369]\u001b[A\n",
      "Epoch 9:  52%|█████▏    | 77/148 [01:20<01:14,  1.05s/it, training_loss=0.9369]\u001b[A\n",
      "Epoch 9:  52%|█████▏    | 77/148 [01:21<01:14,  1.05s/it, training_loss=0.7884]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 78/148 [01:21<01:13,  1.05s/it, training_loss=0.7884]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 78/148 [01:22<01:13,  1.05s/it, training_loss=1.4623]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 79/148 [01:22<01:12,  1.05s/it, training_loss=1.4623]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 79/148 [01:23<01:12,  1.05s/it, training_loss=0.9889]\u001b[A\n",
      "Epoch 9:  54%|█████▍    | 80/148 [01:23<01:11,  1.05s/it, training_loss=0.9889]\u001b[A\n",
      "Epoch 9:  54%|█████▍    | 80/148 [01:25<01:11,  1.05s/it, training_loss=1.6461]\u001b[A\n",
      "Epoch 9:  55%|█████▍    | 81/148 [01:25<01:10,  1.05s/it, training_loss=1.6461]\u001b[A\n",
      "Epoch 9:  55%|█████▍    | 81/148 [01:26<01:10,  1.05s/it, training_loss=1.3766]\u001b[A\n",
      "Epoch 9:  55%|█████▌    | 82/148 [01:26<01:09,  1.05s/it, training_loss=1.3766]\u001b[A\n",
      "Epoch 9:  55%|█████▌    | 82/148 [01:27<01:09,  1.05s/it, training_loss=1.5555]\u001b[A\n",
      "Epoch 9:  56%|█████▌    | 83/148 [01:27<01:07,  1.05s/it, training_loss=1.5555]\u001b[A\n",
      "Epoch 9:  56%|█████▌    | 83/148 [01:28<01:07,  1.05s/it, training_loss=1.5177]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 84/148 [01:28<01:06,  1.05s/it, training_loss=1.5177]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 84/148 [01:29<01:06,  1.05s/it, training_loss=1.6509]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 85/148 [01:29<01:05,  1.05s/it, training_loss=1.6509]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 85/148 [01:30<01:05,  1.05s/it, training_loss=1.0488]\u001b[A\n",
      "Epoch 9:  58%|█████▊    | 86/148 [01:30<01:05,  1.05s/it, training_loss=1.0488]\u001b[A\n",
      "Epoch 9:  58%|█████▊    | 86/148 [01:31<01:05,  1.05s/it, training_loss=1.6639]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 87/148 [01:31<01:03,  1.05s/it, training_loss=1.6639]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 87/148 [01:32<01:03,  1.05s/it, training_loss=0.8295]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 88/148 [01:32<01:03,  1.05s/it, training_loss=0.8295]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 88/148 [01:33<01:03,  1.05s/it, training_loss=1.6229]\u001b[A\n",
      "Epoch 9:  60%|██████    | 89/148 [01:33<01:01,  1.05s/it, training_loss=1.6229]\u001b[A\n",
      "Epoch 9:  60%|██████    | 89/148 [01:34<01:01,  1.05s/it, training_loss=0.8318]\u001b[A\n",
      "Epoch 9:  61%|██████    | 90/148 [01:34<01:00,  1.05s/it, training_loss=0.8318]\u001b[A\n",
      "Epoch 9:  61%|██████    | 90/148 [01:35<01:00,  1.05s/it, training_loss=1.5465]\u001b[A\n",
      "Epoch 9:  61%|██████▏   | 91/148 [01:35<00:59,  1.05s/it, training_loss=1.5465]\u001b[A\n",
      "Epoch 9:  61%|██████▏   | 91/148 [01:36<00:59,  1.05s/it, training_loss=1.5646]\u001b[A\n",
      "Epoch 9:  62%|██████▏   | 92/148 [01:36<00:58,  1.05s/it, training_loss=1.5646]\u001b[A\n",
      "Epoch 9:  62%|██████▏   | 92/148 [01:37<00:58,  1.05s/it, training_loss=0.8799]\u001b[A\n",
      "Epoch 9:  63%|██████▎   | 93/148 [01:37<00:57,  1.05s/it, training_loss=0.8799]\u001b[A\n",
      "Epoch 9:  63%|██████▎   | 93/148 [01:38<00:57,  1.05s/it, training_loss=1.5996]\u001b[A\n",
      "Epoch 9:  64%|██████▎   | 94/148 [01:38<00:56,  1.05s/it, training_loss=1.5996]\u001b[A\n",
      "Epoch 9:  64%|██████▎   | 94/148 [01:39<00:56,  1.05s/it, training_loss=0.8288]\u001b[A\n",
      "Epoch 9:  64%|██████▍   | 95/148 [01:39<00:55,  1.05s/it, training_loss=0.8288]\u001b[A\n",
      "Epoch 9:  64%|██████▍   | 95/148 [01:40<00:55,  1.05s/it, training_loss=0.9161]\u001b[A\n",
      "Epoch 9:  65%|██████▍   | 96/148 [01:40<00:54,  1.05s/it, training_loss=0.9161]\u001b[A\n",
      "Epoch 9:  65%|██████▍   | 96/148 [01:41<00:54,  1.05s/it, training_loss=0.8306]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 97/148 [01:41<00:53,  1.05s/it, training_loss=0.8306]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 97/148 [01:42<00:53,  1.05s/it, training_loss=0.9447]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 98/148 [01:42<00:52,  1.05s/it, training_loss=0.9447]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 98/148 [01:43<00:52,  1.05s/it, training_loss=1.5923]\u001b[A\n",
      "Epoch 9:  67%|██████▋   | 99/148 [01:43<00:51,  1.05s/it, training_loss=1.5923]\u001b[A\n",
      "Epoch 9:  67%|██████▋   | 99/148 [01:44<00:51,  1.05s/it, training_loss=0.9141]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 100/148 [01:44<00:50,  1.05s/it, training_loss=0.9141]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 100/148 [01:46<00:50,  1.05s/it, training_loss=1.6184]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 101/148 [01:46<00:49,  1.05s/it, training_loss=1.6184]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 101/148 [01:47<00:49,  1.05s/it, training_loss=1.5798]\u001b[A\n",
      "Epoch 9:  69%|██████▉   | 102/148 [01:47<00:48,  1.05s/it, training_loss=1.5798]\u001b[A\n",
      "Epoch 9:  69%|██████▉   | 102/148 [01:48<00:48,  1.05s/it, training_loss=1.5547]\u001b[A\n",
      "Epoch 9:  70%|██████▉   | 103/148 [01:48<00:47,  1.05s/it, training_loss=1.5547]\u001b[A\n",
      "Epoch 9:  70%|██████▉   | 103/148 [01:49<00:47,  1.05s/it, training_loss=1.4725]\u001b[A\n",
      "Epoch 9:  70%|███████   | 104/148 [01:49<00:46,  1.05s/it, training_loss=1.4725]\u001b[A\n",
      "Epoch 9:  70%|███████   | 104/148 [01:50<00:46,  1.05s/it, training_loss=1.0427]\u001b[A\n",
      "Epoch 9:  71%|███████   | 105/148 [01:50<00:45,  1.06s/it, training_loss=1.0427]\u001b[A\n",
      "Epoch 9:  71%|███████   | 105/148 [01:51<00:45,  1.06s/it, training_loss=0.8125]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 106/148 [01:51<00:44,  1.06s/it, training_loss=0.8125]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 106/148 [01:52<00:44,  1.06s/it, training_loss=1.4865]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 107/148 [01:52<00:43,  1.05s/it, training_loss=1.4865]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 107/148 [01:53<00:43,  1.05s/it, training_loss=1.5630]\u001b[A\n",
      "Epoch 9:  73%|███████▎  | 108/148 [01:53<00:42,  1.05s/it, training_loss=1.5630]\u001b[A\n",
      "Epoch 9:  73%|███████▎  | 108/148 [01:54<00:42,  1.05s/it, training_loss=1.5685]\u001b[A\n",
      "Epoch 9:  74%|███████▎  | 109/148 [01:54<00:40,  1.05s/it, training_loss=1.5685]\u001b[A\n",
      "Epoch 9:  74%|███████▎  | 109/148 [01:55<00:40,  1.05s/it, training_loss=1.5132]\u001b[A\n",
      "Epoch 9:  74%|███████▍  | 110/148 [01:55<00:39,  1.05s/it, training_loss=1.5132]\u001b[A\n",
      "Epoch 9:  74%|███████▍  | 110/148 [01:56<00:39,  1.05s/it, training_loss=0.8637]\u001b[A\n",
      "Epoch 9:  75%|███████▌  | 111/148 [01:56<00:38,  1.05s/it, training_loss=0.8637]\u001b[A\n",
      "Epoch 9:  75%|███████▌  | 111/148 [01:57<00:38,  1.05s/it, training_loss=0.8851]\u001b[A\n",
      "Epoch 9:  76%|███████▌  | 112/148 [01:57<00:37,  1.05s/it, training_loss=0.8851]\u001b[A\n",
      "Epoch 9:  76%|███████▌  | 112/148 [01:58<00:37,  1.05s/it, training_loss=1.5194]\u001b[A\n",
      "Epoch 9:  76%|███████▋  | 113/148 [01:58<00:36,  1.05s/it, training_loss=1.5194]\u001b[A\n",
      "Epoch 9:  76%|███████▋  | 113/148 [01:59<00:36,  1.05s/it, training_loss=1.4667]\u001b[A\n",
      "Epoch 9:  77%|███████▋  | 114/148 [01:59<00:35,  1.06s/it, training_loss=1.4667]\u001b[A\n",
      "Epoch 9:  77%|███████▋  | 114/148 [02:00<00:35,  1.06s/it, training_loss=0.9117]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 115/148 [02:00<00:34,  1.06s/it, training_loss=0.9117]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 115/148 [02:01<00:34,  1.06s/it, training_loss=1.5535]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 116/148 [02:01<00:33,  1.06s/it, training_loss=1.5535]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 116/148 [02:02<00:33,  1.06s/it, training_loss=1.2524]\u001b[A\n",
      "Epoch 9:  79%|███████▉  | 117/148 [02:02<00:32,  1.06s/it, training_loss=1.2524]\u001b[A\n",
      "Epoch 9:  79%|███████▉  | 117/148 [02:03<00:32,  1.06s/it, training_loss=1.6722]\u001b[A\n",
      "Epoch 9:  80%|███████▉  | 118/148 [02:03<00:31,  1.06s/it, training_loss=1.6722]\u001b[A\n",
      "Epoch 9:  80%|███████▉  | 118/148 [02:05<00:31,  1.06s/it, training_loss=1.0199]\u001b[A\n",
      "Epoch 9:  80%|████████  | 119/148 [02:05<00:30,  1.06s/it, training_loss=1.0199]\u001b[A\n",
      "Epoch 9:  80%|████████  | 119/148 [02:06<00:30,  1.06s/it, training_loss=1.5610]\u001b[A\n",
      "Epoch 9:  81%|████████  | 120/148 [02:06<00:29,  1.06s/it, training_loss=1.5610]\u001b[A\n",
      "Epoch 9:  81%|████████  | 120/148 [02:07<00:29,  1.06s/it, training_loss=0.9799]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 121/148 [02:07<00:28,  1.06s/it, training_loss=0.9799]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 121/148 [02:08<00:28,  1.06s/it, training_loss=1.6300]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 122/148 [02:08<00:27,  1.05s/it, training_loss=1.6300]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 122/148 [02:09<00:27,  1.05s/it, training_loss=1.5352]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 123/148 [02:09<00:26,  1.05s/it, training_loss=1.5352]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 123/148 [02:10<00:26,  1.05s/it, training_loss=0.9055]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 124/148 [02:10<00:25,  1.05s/it, training_loss=0.9055]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 124/148 [02:11<00:25,  1.05s/it, training_loss=0.8274]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 125/148 [02:11<00:24,  1.06s/it, training_loss=0.8274]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 125/148 [02:12<00:24,  1.06s/it, training_loss=0.9660]\u001b[A\n",
      "Epoch 9:  85%|████████▌ | 126/148 [02:12<00:23,  1.06s/it, training_loss=0.9660]\u001b[A\n",
      "Epoch 9:  85%|████████▌ | 126/148 [02:13<00:23,  1.06s/it, training_loss=1.5470]\u001b[A\n",
      "Epoch 9:  86%|████████▌ | 127/148 [02:13<00:22,  1.05s/it, training_loss=1.5470]\u001b[A\n",
      "Epoch 9:  86%|████████▌ | 127/148 [02:14<00:22,  1.05s/it, training_loss=1.5136]\u001b[A\n",
      "Epoch 9:  86%|████████▋ | 128/148 [02:14<00:20,  1.05s/it, training_loss=1.5136]\u001b[A\n",
      "Epoch 9:  86%|████████▋ | 128/148 [02:15<00:20,  1.05s/it, training_loss=1.5256]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 129/148 [02:15<00:19,  1.05s/it, training_loss=1.5256]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 129/148 [02:16<00:19,  1.05s/it, training_loss=1.6098]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 130/148 [02:16<00:18,  1.05s/it, training_loss=1.6098]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 130/148 [02:17<00:18,  1.05s/it, training_loss=0.8743]\u001b[A\n",
      "Epoch 9:  89%|████████▊ | 131/148 [02:17<00:17,  1.05s/it, training_loss=0.8743]\u001b[A\n",
      "Epoch 9:  89%|████████▊ | 131/148 [02:18<00:17,  1.05s/it, training_loss=0.8383]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 132/148 [02:18<00:17,  1.06s/it, training_loss=0.8383]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 132/148 [02:19<00:17,  1.06s/it, training_loss=0.8134]\u001b[A\n",
      "Epoch 9:  90%|████████▉ | 133/148 [02:19<00:15,  1.06s/it, training_loss=0.8134]\u001b[A\n",
      "Epoch 9:  90%|████████▉ | 133/148 [02:20<00:15,  1.06s/it, training_loss=1.6159]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 134/148 [02:20<00:14,  1.06s/it, training_loss=1.6159]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 134/148 [02:21<00:14,  1.06s/it, training_loss=1.5629]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 135/148 [02:21<00:13,  1.05s/it, training_loss=1.5629]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 135/148 [02:22<00:13,  1.05s/it, training_loss=1.5547]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 136/148 [02:22<00:12,  1.05s/it, training_loss=1.5547]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 136/148 [02:23<00:12,  1.05s/it, training_loss=1.2410]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 137/148 [02:23<00:11,  1.05s/it, training_loss=1.2410]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 137/148 [02:25<00:11,  1.05s/it, training_loss=0.8133]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 138/148 [02:25<00:10,  1.05s/it, training_loss=0.8133]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 138/148 [02:26<00:10,  1.05s/it, training_loss=0.9388]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 139/148 [02:26<00:09,  1.06s/it, training_loss=0.9388]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 139/148 [02:27<00:09,  1.06s/it, training_loss=1.5348]\u001b[A\n",
      "Epoch 9:  95%|█████████▍| 140/148 [02:27<00:08,  1.05s/it, training_loss=1.5348]\u001b[A\n",
      "Epoch 9:  95%|█████████▍| 140/148 [02:28<00:08,  1.05s/it, training_loss=1.5885]\u001b[A\n",
      "Epoch 9:  95%|█████████▌| 141/148 [02:28<00:07,  1.05s/it, training_loss=1.5885]\u001b[A\n",
      "Epoch 9:  95%|█████████▌| 141/148 [02:29<00:07,  1.05s/it, training_loss=0.8513]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 142/148 [02:29<00:06,  1.06s/it, training_loss=0.8513]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 142/148 [02:30<00:06,  1.06s/it, training_loss=0.8630]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 143/148 [02:30<00:05,  1.05s/it, training_loss=0.8630]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 143/148 [02:31<00:05,  1.05s/it, training_loss=1.0904]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 144/148 [02:31<00:04,  1.05s/it, training_loss=1.0904]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 144/148 [02:32<00:04,  1.05s/it, training_loss=0.8827]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 145/148 [02:32<00:03,  1.05s/it, training_loss=0.8827]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 145/148 [02:33<00:03,  1.05s/it, training_loss=0.9970]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 146/148 [02:33<00:02,  1.06s/it, training_loss=0.9970]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 146/148 [02:34<00:02,  1.06s/it, training_loss=0.8859]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 147/148 [02:34<00:01,  1.05s/it, training_loss=0.8859]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 147/148 [02:35<00:01,  1.05s/it, training_loss=1.5015]\u001b[A\n",
      "Epoch 9: 100%|██████████| 148/148 [02:35<00:00,  1.03it/s, training_loss=1.5015]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:28:06,404 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:28:06,405 - INFO - Memory usage after evaluation start: 3717.39 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:08,  3.01it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:08,  2.93it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:08,  2.93it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:02<00:07,  2.91it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:06,  2.92it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:03<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:04<00:05,  2.92it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:04<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:05<00:04,  2.91it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:06<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:07<00:02,  2.92it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:08<00:01,  2.92it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:08<00:00,  2.91it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:08<00:00,  3.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:28:15,372 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 00:28:15,385 - INFO - Class 'Drama': Optimal threshold = 0.650, F1 Score = 0.581\n",
      "2025-02-16 00:28:15,400 - INFO - Class 'Horor': Optimal threshold = 0.700, F1 Score = 0.727\n",
      "2025-02-16 00:28:15,414 - INFO - Class 'Komedi': Optimal threshold = 0.650, F1 Score = 0.647\n",
      "2025-02-16 00:28:15,427 - INFO - Class 'Laga': Optimal threshold = 0.600, F1 Score = 0.349\n",
      "2025-02-16 00:28:15,440 - INFO - Class 'Romantis': Optimal threshold = 0.500, F1 Score = 0.530\n",
      "2025-02-16 00:28:15,462 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:28:15,467 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:28:15,468 - INFO - Accuracy: 0.7241\n",
      "2025-02-16 00:28:15,468 - INFO - F1_score: 0.5814\n",
      "2025-02-16 00:28:15,469 - INFO - Precision: 0.5102\n",
      "2025-02-16 00:28:15,469 - INFO - Recall: 0.6757\n",
      "2025-02-16 00:28:15,476 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:28:15,477 - INFO - Accuracy: 0.8621\n",
      "2025-02-16 00:28:15,477 - INFO - F1_score: 0.7273\n",
      "2025-02-16 00:28:15,479 - INFO - Precision: 0.6400\n",
      "2025-02-16 00:28:15,480 - INFO - Recall: 0.8421\n",
      "2025-02-16 00:28:15,485 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:28:15,485 - INFO - Accuracy: 0.8199\n",
      "2025-02-16 00:28:15,486 - INFO - F1_score: 0.6466\n",
      "2025-02-16 00:28:15,487 - INFO - Precision: 0.5733\n",
      "2025-02-16 00:28:15,487 - INFO - Recall: 0.7414\n",
      "2025-02-16 00:28:15,493 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:28:15,494 - INFO - Accuracy: 0.7854\n",
      "2025-02-16 00:28:15,494 - INFO - F1_score: 0.3488\n",
      "2025-02-16 00:28:15,495 - INFO - Precision: 0.3125\n",
      "2025-02-16 00:28:15,496 - INFO - Recall: 0.3947\n",
      "2025-02-16 00:28:15,502 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:28:15,502 - INFO - Accuracy: 0.8506\n",
      "2025-02-16 00:28:15,503 - INFO - F1_score: 0.5301\n",
      "2025-02-16 00:28:15,504 - INFO - Precision: 0.4490\n",
      "2025-02-16 00:28:15,504 - INFO - Recall: 0.6471\n",
      "2025-02-16 00:28:15,507 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:28:19,311 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:28:19,313 - INFO - Memory usage after evaluation end: 3723.14 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 8/100 [26:44<4:32:39, 177.82s/it, Train Loss=1.2695, Val Loss=0.0548, Accuracy=0.8084]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:28:28,117 - INFO - Learning rate: 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [26:44<4:29:18, 177.57s/it, Train Loss=1.2695, Val Loss=0.0548, Accuracy=0.8084]\n",
      "Epoch 10:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=0.8833]\u001b[A\n",
      "Epoch 10:   1%|          | 1/148 [00:01<02:32,  1.04s/it, training_loss=0.8833]\u001b[A\n",
      "Epoch 10:   1%|          | 1/148 [00:02<02:32,  1.04s/it, training_loss=0.8369]\u001b[A\n",
      "Epoch 10:   1%|▏         | 2/148 [00:02<02:32,  1.05s/it, training_loss=0.8369]\u001b[A\n",
      "Epoch 10:   1%|▏         | 2/148 [00:03<02:32,  1.05s/it, training_loss=1.0014]\u001b[A\n",
      "Epoch 10:   2%|▏         | 3/148 [00:03<02:31,  1.05s/it, training_loss=1.0014]\u001b[A\n",
      "Epoch 10:   2%|▏         | 3/148 [00:04<02:31,  1.05s/it, training_loss=0.8578]\u001b[A\n",
      "Epoch 10:   3%|▎         | 4/148 [00:04<02:31,  1.05s/it, training_loss=0.8578]\u001b[A\n",
      "Epoch 10:   3%|▎         | 4/148 [00:05<02:31,  1.05s/it, training_loss=1.5095]\u001b[A\n",
      "Epoch 10:   3%|▎         | 5/148 [00:05<02:30,  1.05s/it, training_loss=1.5095]\u001b[A\n",
      "Epoch 10:   3%|▎         | 5/148 [00:06<02:30,  1.05s/it, training_loss=0.8258]\u001b[A\n",
      "Epoch 10:   4%|▍         | 6/148 [00:06<02:30,  1.06s/it, training_loss=0.8258]\u001b[A\n",
      "Epoch 10:   4%|▍         | 6/148 [00:07<02:30,  1.06s/it, training_loss=0.9026]\u001b[A\n",
      "Epoch 10:   5%|▍         | 7/148 [00:07<02:28,  1.05s/it, training_loss=0.9026]\u001b[A\n",
      "Epoch 10:   5%|▍         | 7/148 [00:08<02:28,  1.05s/it, training_loss=0.9439]\u001b[A\n",
      "Epoch 10:   5%|▌         | 8/148 [00:08<02:28,  1.06s/it, training_loss=0.9439]\u001b[A\n",
      "Epoch 10:   5%|▌         | 8/148 [00:09<02:28,  1.06s/it, training_loss=1.4928]\u001b[A\n",
      "Epoch 10:   6%|▌         | 9/148 [00:09<02:27,  1.06s/it, training_loss=1.4928]\u001b[A\n",
      "Epoch 10:   6%|▌         | 9/148 [00:10<02:27,  1.06s/it, training_loss=1.5523]\u001b[A\n",
      "Epoch 10:   7%|▋         | 10/148 [00:10<02:25,  1.05s/it, training_loss=1.5523]\u001b[A\n",
      "Epoch 10:   7%|▋         | 10/148 [00:11<02:25,  1.05s/it, training_loss=0.8652]\u001b[A\n",
      "Epoch 10:   7%|▋         | 11/148 [00:11<02:25,  1.06s/it, training_loss=0.8652]\u001b[A\n",
      "Epoch 10:   7%|▋         | 11/148 [00:12<02:25,  1.06s/it, training_loss=1.4897]\u001b[A\n",
      "Epoch 10:   8%|▊         | 12/148 [00:12<02:23,  1.06s/it, training_loss=1.4897]\u001b[A\n",
      "Epoch 10:   8%|▊         | 12/148 [00:13<02:23,  1.06s/it, training_loss=0.9419]\u001b[A\n",
      "Epoch 10:   9%|▉         | 13/148 [00:13<02:23,  1.06s/it, training_loss=0.9419]\u001b[A\n",
      "Epoch 10:   9%|▉         | 13/148 [00:14<02:23,  1.06s/it, training_loss=0.8278]\u001b[A\n",
      "Epoch 10:   9%|▉         | 14/148 [00:14<02:22,  1.06s/it, training_loss=0.8278]\u001b[A\n",
      "Epoch 10:   9%|▉         | 14/148 [00:15<02:22,  1.06s/it, training_loss=1.4760]\u001b[A\n",
      "Epoch 10:  10%|█         | 15/148 [00:15<02:20,  1.06s/it, training_loss=1.4760]\u001b[A\n",
      "Epoch 10:  10%|█         | 15/148 [00:16<02:20,  1.06s/it, training_loss=0.7930]\u001b[A\n",
      "Epoch 10:  11%|█         | 16/148 [00:16<02:19,  1.06s/it, training_loss=0.7930]\u001b[A\n",
      "Epoch 10:  11%|█         | 16/148 [00:17<02:19,  1.06s/it, training_loss=0.7949]\u001b[A\n",
      "Epoch 10:  11%|█▏        | 17/148 [00:17<02:19,  1.06s/it, training_loss=0.7949]\u001b[A\n",
      "Epoch 10:  11%|█▏        | 17/148 [00:19<02:19,  1.06s/it, training_loss=1.4229]\u001b[A\n",
      "Epoch 10:  12%|█▏        | 18/148 [00:19<02:17,  1.06s/it, training_loss=1.4229]\u001b[A\n",
      "Epoch 10:  12%|█▏        | 18/148 [00:20<02:17,  1.06s/it, training_loss=1.6579]\u001b[A\n",
      "Epoch 10:  13%|█▎        | 19/148 [00:20<02:16,  1.06s/it, training_loss=1.6579]\u001b[A\n",
      "Epoch 10:  13%|█▎        | 19/148 [00:21<02:16,  1.06s/it, training_loss=0.9577]\u001b[A\n",
      "Epoch 10:  14%|█▎        | 20/148 [00:21<02:15,  1.06s/it, training_loss=0.9577]\u001b[A\n",
      "Epoch 10:  14%|█▎        | 20/148 [00:22<02:15,  1.06s/it, training_loss=0.8312]\u001b[A\n",
      "Epoch 10:  14%|█▍        | 21/148 [00:22<02:15,  1.07s/it, training_loss=0.8312]\u001b[A\n",
      "Epoch 10:  14%|█▍        | 21/148 [00:23<02:15,  1.07s/it, training_loss=0.8308]\u001b[A\n",
      "Epoch 10:  15%|█▍        | 22/148 [00:23<02:13,  1.06s/it, training_loss=0.8308]\u001b[A\n",
      "Epoch 10:  15%|█▍        | 22/148 [00:24<02:13,  1.06s/it, training_loss=0.8312]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 23/148 [00:24<02:12,  1.06s/it, training_loss=0.8312]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 23/148 [00:25<02:12,  1.06s/it, training_loss=1.5930]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 24/148 [00:25<02:11,  1.06s/it, training_loss=1.5930]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 24/148 [00:26<02:11,  1.06s/it, training_loss=1.5354]\u001b[A\n",
      "Epoch 10:  17%|█▋        | 25/148 [00:26<02:09,  1.06s/it, training_loss=1.5354]\u001b[A\n",
      "Epoch 10:  17%|█▋        | 25/148 [00:27<02:09,  1.06s/it, training_loss=1.5120]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 26/148 [00:27<02:09,  1.06s/it, training_loss=1.5120]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 26/148 [00:28<02:09,  1.06s/it, training_loss=0.7975]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 27/148 [00:28<02:08,  1.06s/it, training_loss=0.7975]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 27/148 [00:29<02:08,  1.06s/it, training_loss=0.8870]\u001b[A\n",
      "Epoch 10:  19%|█▉        | 28/148 [00:29<02:07,  1.06s/it, training_loss=0.8870]\u001b[A\n",
      "Epoch 10:  19%|█▉        | 28/148 [00:30<02:07,  1.06s/it, training_loss=0.9575]\u001b[A\n",
      "Epoch 10:  20%|█▉        | 29/148 [00:30<02:06,  1.06s/it, training_loss=0.9575]\u001b[A\n",
      "Epoch 10:  20%|█▉        | 29/148 [00:31<02:06,  1.06s/it, training_loss=0.8057]\u001b[A\n",
      "Epoch 10:  20%|██        | 30/148 [00:31<02:05,  1.06s/it, training_loss=0.8057]\u001b[A\n",
      "Epoch 10:  20%|██        | 30/148 [00:32<02:05,  1.06s/it, training_loss=1.7234]\u001b[A\n",
      "Epoch 10:  21%|██        | 31/148 [00:32<02:04,  1.06s/it, training_loss=1.7234]\u001b[A\n",
      "Epoch 10:  21%|██        | 31/148 [00:33<02:04,  1.06s/it, training_loss=0.8325]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 32/148 [00:33<02:02,  1.06s/it, training_loss=0.8325]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 32/148 [00:34<02:02,  1.06s/it, training_loss=1.5631]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 33/148 [00:34<02:01,  1.06s/it, training_loss=1.5631]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 33/148 [00:35<02:01,  1.06s/it, training_loss=1.4429]\u001b[A\n",
      "Epoch 10:  23%|██▎       | 34/148 [00:35<02:00,  1.05s/it, training_loss=1.4429]\u001b[A\n",
      "Epoch 10:  23%|██▎       | 34/148 [00:37<02:00,  1.05s/it, training_loss=1.4805]\u001b[A\n",
      "Epoch 10:  24%|██▎       | 35/148 [00:37<01:58,  1.05s/it, training_loss=1.4805]\u001b[A\n",
      "Epoch 10:  24%|██▎       | 35/148 [00:38<01:58,  1.05s/it, training_loss=0.8129]\u001b[A\n",
      "Epoch 10:  24%|██▍       | 36/148 [00:38<01:57,  1.05s/it, training_loss=0.8129]\u001b[A\n",
      "Epoch 10:  24%|██▍       | 36/148 [00:39<01:57,  1.05s/it, training_loss=0.8168]\u001b[A\n",
      "Epoch 10:  25%|██▌       | 37/148 [00:39<01:57,  1.05s/it, training_loss=0.8168]\u001b[A\n",
      "Epoch 10:  25%|██▌       | 37/148 [00:40<01:57,  1.05s/it, training_loss=1.5164]\u001b[A\n",
      "Epoch 10:  26%|██▌       | 38/148 [00:40<01:55,  1.05s/it, training_loss=1.5164]\u001b[A\n",
      "Epoch 10:  26%|██▌       | 38/148 [00:41<01:55,  1.05s/it, training_loss=1.0026]\u001b[A\n",
      "Epoch 10:  26%|██▋       | 39/148 [00:41<01:54,  1.05s/it, training_loss=1.0026]\u001b[A\n",
      "Epoch 10:  26%|██▋       | 39/148 [00:42<01:54,  1.05s/it, training_loss=1.5200]\u001b[A\n",
      "Epoch 10:  27%|██▋       | 40/148 [00:42<01:53,  1.05s/it, training_loss=1.5200]\u001b[A\n",
      "Epoch 10:  27%|██▋       | 40/148 [00:43<01:53,  1.05s/it, training_loss=0.8747]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 41/148 [00:43<01:52,  1.06s/it, training_loss=0.8747]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 41/148 [00:44<01:52,  1.06s/it, training_loss=1.6661]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 42/148 [00:44<01:51,  1.05s/it, training_loss=1.6661]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 42/148 [00:45<01:51,  1.05s/it, training_loss=1.5508]\u001b[A\n",
      "Epoch 10:  29%|██▉       | 43/148 [00:45<01:50,  1.05s/it, training_loss=1.5508]\u001b[A\n",
      "Epoch 10:  29%|██▉       | 43/148 [00:46<01:50,  1.05s/it, training_loss=0.8557]\u001b[A\n",
      "Epoch 10:  30%|██▉       | 44/148 [00:46<01:49,  1.05s/it, training_loss=0.8557]\u001b[A\n",
      "Epoch 10:  30%|██▉       | 44/148 [00:47<01:49,  1.05s/it, training_loss=1.3382]\u001b[A\n",
      "Epoch 10:  30%|███       | 45/148 [00:47<01:48,  1.06s/it, training_loss=1.3382]\u001b[A\n",
      "Epoch 10:  30%|███       | 45/148 [00:48<01:48,  1.06s/it, training_loss=0.8964]\u001b[A\n",
      "Epoch 10:  31%|███       | 46/148 [00:48<01:48,  1.06s/it, training_loss=0.8964]\u001b[A\n",
      "Epoch 10:  31%|███       | 46/148 [00:49<01:48,  1.06s/it, training_loss=1.4288]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 47/148 [00:49<01:46,  1.06s/it, training_loss=1.4288]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 47/148 [00:50<01:46,  1.06s/it, training_loss=1.5105]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 48/148 [00:50<01:45,  1.06s/it, training_loss=1.5105]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 48/148 [00:51<01:45,  1.06s/it, training_loss=0.8162]\u001b[A\n",
      "Epoch 10:  33%|███▎      | 49/148 [00:51<01:44,  1.06s/it, training_loss=0.8162]\u001b[A\n",
      "Epoch 10:  33%|███▎      | 49/148 [00:52<01:44,  1.06s/it, training_loss=1.4181]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 50/148 [00:52<01:43,  1.05s/it, training_loss=1.4181]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 50/148 [00:53<01:43,  1.05s/it, training_loss=1.0197]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 51/148 [00:53<01:42,  1.05s/it, training_loss=1.0197]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 51/148 [00:54<01:42,  1.05s/it, training_loss=1.5773]\u001b[A\n",
      "Epoch 10:  35%|███▌      | 52/148 [00:54<01:41,  1.05s/it, training_loss=1.5773]\u001b[A\n",
      "Epoch 10:  35%|███▌      | 52/148 [00:55<01:41,  1.05s/it, training_loss=0.9009]\u001b[A\n",
      "Epoch 10:  36%|███▌      | 53/148 [00:55<01:40,  1.05s/it, training_loss=0.9009]\u001b[A\n",
      "Epoch 10:  36%|███▌      | 53/148 [00:57<01:40,  1.05s/it, training_loss=1.4075]\u001b[A\n",
      "Epoch 10:  36%|███▋      | 54/148 [00:57<01:38,  1.05s/it, training_loss=1.4075]\u001b[A\n",
      "Epoch 10:  36%|███▋      | 54/148 [00:58<01:38,  1.05s/it, training_loss=1.6502]\u001b[A\n",
      "Epoch 10:  37%|███▋      | 55/148 [00:58<01:37,  1.05s/it, training_loss=1.6502]\u001b[A\n",
      "Epoch 10:  37%|███▋      | 55/148 [00:59<01:37,  1.05s/it, training_loss=0.9286]\u001b[A\n",
      "Epoch 10:  38%|███▊      | 56/148 [00:59<01:36,  1.05s/it, training_loss=0.9286]\u001b[A\n",
      "Epoch 10:  38%|███▊      | 56/148 [01:00<01:36,  1.05s/it, training_loss=0.8996]\u001b[A\n",
      "Epoch 10:  39%|███▊      | 57/148 [01:00<01:36,  1.06s/it, training_loss=0.8996]\u001b[A\n",
      "Epoch 10:  39%|███▊      | 57/148 [01:01<01:36,  1.06s/it, training_loss=0.8507]\u001b[A\n",
      "Epoch 10:  39%|███▉      | 58/148 [01:01<01:35,  1.06s/it, training_loss=0.8507]\u001b[A\n",
      "Epoch 10:  39%|███▉      | 58/148 [01:02<01:35,  1.06s/it, training_loss=1.6407]\u001b[A\n",
      "Epoch 10:  40%|███▉      | 59/148 [01:02<01:33,  1.06s/it, training_loss=1.6407]\u001b[A\n",
      "Epoch 10:  40%|███▉      | 59/148 [01:03<01:33,  1.06s/it, training_loss=0.8099]\u001b[A\n",
      "Epoch 10:  41%|████      | 60/148 [01:03<01:32,  1.05s/it, training_loss=0.8099]\u001b[A\n",
      "Epoch 10:  41%|████      | 60/148 [01:04<01:32,  1.05s/it, training_loss=0.8963]\u001b[A\n",
      "Epoch 10:  41%|████      | 61/148 [01:04<01:31,  1.06s/it, training_loss=0.8963]\u001b[A\n",
      "Epoch 10:  41%|████      | 61/148 [01:05<01:31,  1.06s/it, training_loss=1.6451]\u001b[A\n",
      "Epoch 10:  42%|████▏     | 62/148 [01:05<01:30,  1.05s/it, training_loss=1.6451]\u001b[A\n",
      "Epoch 10:  42%|████▏     | 62/148 [01:06<01:30,  1.05s/it, training_loss=0.9479]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 63/148 [01:06<01:29,  1.06s/it, training_loss=0.9479]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 63/148 [01:07<01:29,  1.06s/it, training_loss=0.9076]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 64/148 [01:07<01:28,  1.06s/it, training_loss=0.9076]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 64/148 [01:08<01:28,  1.06s/it, training_loss=0.8312]\u001b[A\n",
      "Epoch 10:  44%|████▍     | 65/148 [01:08<01:27,  1.06s/it, training_loss=0.8312]\u001b[A\n",
      "Epoch 10:  44%|████▍     | 65/148 [01:09<01:27,  1.06s/it, training_loss=0.8139]\u001b[A\n",
      "Epoch 10:  45%|████▍     | 66/148 [01:09<01:26,  1.06s/it, training_loss=0.8139]\u001b[A\n",
      "Epoch 10:  45%|████▍     | 66/148 [01:10<01:26,  1.06s/it, training_loss=0.9714]\u001b[A\n",
      "Epoch 10:  45%|████▌     | 67/148 [01:10<01:25,  1.06s/it, training_loss=0.9714]\u001b[A\n",
      "Epoch 10:  45%|████▌     | 67/148 [01:11<01:25,  1.06s/it, training_loss=1.5755]\u001b[A\n",
      "Epoch 10:  46%|████▌     | 68/148 [01:11<01:24,  1.05s/it, training_loss=1.5755]\u001b[A\n",
      "Epoch 10:  46%|████▌     | 68/148 [01:12<01:24,  1.05s/it, training_loss=1.5479]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 69/148 [01:12<01:22,  1.05s/it, training_loss=1.5479]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 69/148 [01:13<01:22,  1.05s/it, training_loss=0.8553]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 70/148 [01:13<01:21,  1.05s/it, training_loss=0.8553]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 70/148 [01:14<01:21,  1.05s/it, training_loss=0.8457]\u001b[A\n",
      "Epoch 10:  48%|████▊     | 71/148 [01:14<01:20,  1.05s/it, training_loss=0.8457]\u001b[A\n",
      "Epoch 10:  48%|████▊     | 71/148 [01:15<01:20,  1.05s/it, training_loss=1.5435]\u001b[A\n",
      "Epoch 10:  49%|████▊     | 72/148 [01:16<01:19,  1.05s/it, training_loss=1.5435]\u001b[A\n",
      "Epoch 10:  49%|████▊     | 72/148 [01:17<01:19,  1.05s/it, training_loss=1.6073]\u001b[A\n",
      "Epoch 10:  49%|████▉     | 73/148 [01:17<01:18,  1.05s/it, training_loss=1.6073]\u001b[A\n",
      "Epoch 10:  49%|████▉     | 73/148 [01:18<01:18,  1.05s/it, training_loss=0.9798]\u001b[A\n",
      "Epoch 10:  50%|█████     | 74/148 [01:18<01:17,  1.05s/it, training_loss=0.9798]\u001b[A\n",
      "Epoch 10:  50%|█████     | 74/148 [01:19<01:17,  1.05s/it, training_loss=1.5814]\u001b[A\n",
      "Epoch 10:  51%|█████     | 75/148 [01:19<01:16,  1.05s/it, training_loss=1.5814]\u001b[A\n",
      "Epoch 10:  51%|█████     | 75/148 [01:20<01:16,  1.05s/it, training_loss=1.5232]\u001b[A\n",
      "Epoch 10:  51%|█████▏    | 76/148 [01:20<01:15,  1.05s/it, training_loss=1.5232]\u001b[A\n",
      "Epoch 10:  51%|█████▏    | 76/148 [01:21<01:15,  1.05s/it, training_loss=0.9815]\u001b[A\n",
      "Epoch 10:  52%|█████▏    | 77/148 [01:21<01:14,  1.05s/it, training_loss=0.9815]\u001b[A\n",
      "Epoch 10:  52%|█████▏    | 77/148 [01:22<01:14,  1.05s/it, training_loss=0.8936]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 78/148 [01:22<01:13,  1.05s/it, training_loss=0.8936]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 78/148 [01:23<01:13,  1.05s/it, training_loss=1.6459]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 79/148 [01:23<01:12,  1.04s/it, training_loss=1.6459]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 79/148 [01:24<01:12,  1.04s/it, training_loss=1.5100]\u001b[A\n",
      "Epoch 10:  54%|█████▍    | 80/148 [01:24<01:11,  1.05s/it, training_loss=1.5100]\u001b[A\n",
      "Epoch 10:  54%|█████▍    | 80/148 [01:25<01:11,  1.05s/it, training_loss=1.5227]\u001b[A\n",
      "Epoch 10:  55%|█████▍    | 81/148 [01:25<01:10,  1.04s/it, training_loss=1.5227]\u001b[A\n",
      "Epoch 10:  55%|█████▍    | 81/148 [01:26<01:10,  1.04s/it, training_loss=0.8349]\u001b[A\n",
      "Epoch 10:  55%|█████▌    | 82/148 [01:26<01:09,  1.05s/it, training_loss=0.8349]\u001b[A\n",
      "Epoch 10:  55%|█████▌    | 82/148 [01:27<01:09,  1.05s/it, training_loss=0.8241]\u001b[A\n",
      "Epoch 10:  56%|█████▌    | 83/148 [01:27<01:07,  1.05s/it, training_loss=0.8241]\u001b[A\n",
      "Epoch 10:  56%|█████▌    | 83/148 [01:28<01:07,  1.05s/it, training_loss=1.5626]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 84/148 [01:28<01:06,  1.04s/it, training_loss=1.5626]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 84/148 [01:29<01:06,  1.04s/it, training_loss=0.9204]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 85/148 [01:29<01:06,  1.05s/it, training_loss=0.9204]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 85/148 [01:30<01:06,  1.05s/it, training_loss=1.0009]\u001b[A\n",
      "Epoch 10:  58%|█████▊    | 86/148 [01:30<01:05,  1.05s/it, training_loss=1.0009]\u001b[A\n",
      "Epoch 10:  58%|█████▊    | 86/148 [01:31<01:05,  1.05s/it, training_loss=1.2403]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 87/148 [01:31<01:04,  1.05s/it, training_loss=1.2403]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 87/148 [01:32<01:04,  1.05s/it, training_loss=1.5826]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 88/148 [01:32<01:02,  1.05s/it, training_loss=1.5826]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 88/148 [01:33<01:02,  1.05s/it, training_loss=1.0170]\u001b[A\n",
      "Epoch 10:  60%|██████    | 89/148 [01:33<01:01,  1.05s/it, training_loss=1.0170]\u001b[A\n",
      "Epoch 10:  60%|██████    | 89/148 [01:34<01:01,  1.05s/it, training_loss=1.4797]\u001b[A\n",
      "Epoch 10:  61%|██████    | 90/148 [01:34<01:00,  1.04s/it, training_loss=1.4797]\u001b[A\n",
      "Epoch 10:  61%|██████    | 90/148 [01:35<01:00,  1.04s/it, training_loss=1.0749]\u001b[A\n",
      "Epoch 10:  61%|██████▏   | 91/148 [01:35<00:59,  1.04s/it, training_loss=1.0749]\u001b[A\n",
      "Epoch 10:  61%|██████▏   | 91/148 [01:36<00:59,  1.04s/it, training_loss=1.6076]\u001b[A\n",
      "Epoch 10:  62%|██████▏   | 92/148 [01:36<00:58,  1.04s/it, training_loss=1.6076]\u001b[A\n",
      "Epoch 10:  62%|██████▏   | 92/148 [01:37<00:58,  1.04s/it, training_loss=1.5195]\u001b[A\n",
      "Epoch 10:  63%|██████▎   | 93/148 [01:37<00:57,  1.04s/it, training_loss=1.5195]\u001b[A\n",
      "Epoch 10:  63%|██████▎   | 93/148 [01:38<00:57,  1.04s/it, training_loss=1.4686]\u001b[A\n",
      "Epoch 10:  64%|██████▎   | 94/148 [01:38<00:56,  1.04s/it, training_loss=1.4686]\u001b[A\n",
      "Epoch 10:  64%|██████▎   | 94/148 [01:40<00:56,  1.04s/it, training_loss=0.9618]\u001b[A\n",
      "Epoch 10:  64%|██████▍   | 95/148 [01:40<00:55,  1.04s/it, training_loss=0.9618]\u001b[A\n",
      "Epoch 10:  64%|██████▍   | 95/148 [01:41<00:55,  1.04s/it, training_loss=1.5439]\u001b[A\n",
      "Epoch 10:  65%|██████▍   | 96/148 [01:41<00:54,  1.04s/it, training_loss=1.5439]\u001b[A\n",
      "Epoch 10:  65%|██████▍   | 96/148 [01:42<00:54,  1.04s/it, training_loss=0.8445]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 97/148 [01:42<00:53,  1.04s/it, training_loss=0.8445]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 97/148 [01:43<00:53,  1.04s/it, training_loss=1.0538]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 98/148 [01:43<00:52,  1.05s/it, training_loss=1.0538]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 98/148 [01:44<00:52,  1.05s/it, training_loss=0.8025]\u001b[A\n",
      "Epoch 10:  67%|██████▋   | 99/148 [01:44<00:51,  1.05s/it, training_loss=0.8025]\u001b[A\n",
      "Epoch 10:  67%|██████▋   | 99/148 [01:45<00:51,  1.05s/it, training_loss=1.0201]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 100/148 [01:45<00:50,  1.05s/it, training_loss=1.0201]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 100/148 [01:46<00:50,  1.05s/it, training_loss=0.9710]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 101/148 [01:46<00:49,  1.04s/it, training_loss=0.9710]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 101/148 [01:47<00:49,  1.04s/it, training_loss=1.5905]\u001b[A\n",
      "Epoch 10:  69%|██████▉   | 102/148 [01:47<00:48,  1.04s/it, training_loss=1.5905]\u001b[A\n",
      "Epoch 10:  69%|██████▉   | 102/148 [01:48<00:48,  1.04s/it, training_loss=1.4576]\u001b[A\n",
      "Epoch 10:  70%|██████▉   | 103/148 [01:48<00:46,  1.04s/it, training_loss=1.4576]\u001b[A\n",
      "Epoch 10:  70%|██████▉   | 103/148 [01:49<00:46,  1.04s/it, training_loss=0.8119]\u001b[A\n",
      "Epoch 10:  70%|███████   | 104/148 [01:49<00:46,  1.05s/it, training_loss=0.8119]\u001b[A\n",
      "Epoch 10:  70%|███████   | 104/148 [01:50<00:46,  1.05s/it, training_loss=1.6025]\u001b[A\n",
      "Epoch 10:  71%|███████   | 105/148 [01:50<00:44,  1.04s/it, training_loss=1.6025]\u001b[A\n",
      "Epoch 10:  71%|███████   | 105/148 [01:51<00:44,  1.04s/it, training_loss=0.8309]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 106/148 [01:51<00:43,  1.04s/it, training_loss=0.8309]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 106/148 [01:52<00:43,  1.04s/it, training_loss=0.8031]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 107/148 [01:52<00:42,  1.04s/it, training_loss=0.8031]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 107/148 [01:53<00:42,  1.04s/it, training_loss=0.8467]\u001b[A\n",
      "Epoch 10:  73%|███████▎  | 108/148 [01:53<00:41,  1.04s/it, training_loss=0.8467]\u001b[A\n",
      "Epoch 10:  73%|███████▎  | 108/148 [01:54<00:41,  1.04s/it, training_loss=0.8047]\u001b[A\n",
      "Epoch 10:  74%|███████▎  | 109/148 [01:54<00:40,  1.04s/it, training_loss=0.8047]\u001b[A\n",
      "Epoch 10:  74%|███████▎  | 109/148 [01:55<00:40,  1.04s/it, training_loss=1.5017]\u001b[A\n",
      "Epoch 10:  74%|███████▍  | 110/148 [01:55<00:39,  1.04s/it, training_loss=1.5017]\u001b[A\n",
      "Epoch 10:  74%|███████▍  | 110/148 [01:56<00:39,  1.04s/it, training_loss=1.5894]\u001b[A\n",
      "Epoch 10:  75%|███████▌  | 111/148 [01:56<00:38,  1.04s/it, training_loss=1.5894]\u001b[A\n",
      "Epoch 10:  75%|███████▌  | 111/148 [01:57<00:38,  1.04s/it, training_loss=0.9005]\u001b[A\n",
      "Epoch 10:  76%|███████▌  | 112/148 [01:57<00:37,  1.05s/it, training_loss=0.9005]\u001b[A\n",
      "Epoch 10:  76%|███████▌  | 112/148 [01:58<00:37,  1.05s/it, training_loss=1.4859]\u001b[A\n",
      "Epoch 10:  76%|███████▋  | 113/148 [01:58<00:36,  1.05s/it, training_loss=1.4859]\u001b[A\n",
      "Epoch 10:  76%|███████▋  | 113/148 [01:59<00:36,  1.05s/it, training_loss=1.5660]\u001b[A\n",
      "Epoch 10:  77%|███████▋  | 114/148 [01:59<00:35,  1.05s/it, training_loss=1.5660]\u001b[A\n",
      "Epoch 10:  77%|███████▋  | 114/148 [02:00<00:35,  1.05s/it, training_loss=0.8235]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 115/148 [02:00<00:34,  1.06s/it, training_loss=0.8235]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 115/148 [02:02<00:34,  1.06s/it, training_loss=1.0005]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 116/148 [02:02<00:33,  1.05s/it, training_loss=1.0005]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 116/148 [02:03<00:33,  1.05s/it, training_loss=0.8178]\u001b[A\n",
      "Epoch 10:  79%|███████▉  | 117/148 [02:03<00:32,  1.05s/it, training_loss=0.8178]\u001b[A\n",
      "Epoch 10:  79%|███████▉  | 117/148 [02:04<00:32,  1.05s/it, training_loss=0.9802]\u001b[A\n",
      "Epoch 10:  80%|███████▉  | 118/148 [02:04<00:31,  1.05s/it, training_loss=0.9802]\u001b[A\n",
      "Epoch 10:  80%|███████▉  | 118/148 [02:05<00:31,  1.05s/it, training_loss=1.6533]\u001b[A\n",
      "Epoch 10:  80%|████████  | 119/148 [02:05<00:30,  1.05s/it, training_loss=1.6533]\u001b[A\n",
      "Epoch 10:  80%|████████  | 119/148 [02:06<00:30,  1.05s/it, training_loss=0.8607]\u001b[A\n",
      "Epoch 10:  81%|████████  | 120/148 [02:06<00:29,  1.05s/it, training_loss=0.8607]\u001b[A\n",
      "Epoch 10:  81%|████████  | 120/148 [02:07<00:29,  1.05s/it, training_loss=1.5051]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 121/148 [02:07<00:28,  1.05s/it, training_loss=1.5051]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 121/148 [02:08<00:28,  1.05s/it, training_loss=0.9898]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 122/148 [02:08<00:27,  1.04s/it, training_loss=0.9898]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 122/148 [02:09<00:27,  1.04s/it, training_loss=1.5633]\u001b[A\n",
      "Epoch 10:  83%|████████▎ | 123/148 [02:09<00:26,  1.04s/it, training_loss=1.5633]\u001b[A\n",
      "Epoch 10:  83%|████████▎ | 123/148 [02:10<00:26,  1.04s/it, training_loss=0.8352]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 124/148 [02:10<00:25,  1.05s/it, training_loss=0.8352]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 124/148 [02:11<00:25,  1.05s/it, training_loss=1.4252]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 125/148 [02:11<00:24,  1.05s/it, training_loss=1.4252]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 125/148 [02:12<00:24,  1.05s/it, training_loss=0.8031]\u001b[A\n",
      "Epoch 10:  85%|████████▌ | 126/148 [02:12<00:23,  1.05s/it, training_loss=0.8031]\u001b[A\n",
      "Epoch 10:  85%|████████▌ | 126/148 [02:13<00:23,  1.05s/it, training_loss=0.8684]\u001b[A\n",
      "Epoch 10:  86%|████████▌ | 127/148 [02:13<00:22,  1.05s/it, training_loss=0.8684]\u001b[A\n",
      "Epoch 10:  86%|████████▌ | 127/148 [02:14<00:22,  1.05s/it, training_loss=0.8309]\u001b[A\n",
      "Epoch 10:  86%|████████▋ | 128/148 [02:14<00:21,  1.05s/it, training_loss=0.8309]\u001b[A\n",
      "Epoch 10:  86%|████████▋ | 128/148 [02:15<00:21,  1.05s/it, training_loss=0.9824]\u001b[A\n",
      "Epoch 10:  87%|████████▋ | 129/148 [02:15<00:19,  1.05s/it, training_loss=0.9824]\u001b[A\n",
      "Epoch 10:  87%|████████▋ | 129/148 [02:16<00:19,  1.05s/it, training_loss=0.8384]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 130/148 [02:16<00:18,  1.05s/it, training_loss=0.8384]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 130/148 [02:17<00:18,  1.05s/it, training_loss=0.8538]\u001b[A\n",
      "Epoch 10:  89%|████████▊ | 131/148 [02:17<00:17,  1.05s/it, training_loss=0.8538]\u001b[A\n",
      "Epoch 10:  89%|████████▊ | 131/148 [02:18<00:17,  1.05s/it, training_loss=0.9917]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 132/148 [02:18<00:16,  1.05s/it, training_loss=0.9917]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 132/148 [02:19<00:16,  1.05s/it, training_loss=1.6282]\u001b[A\n",
      "Epoch 10:  90%|████████▉ | 133/148 [02:19<00:15,  1.04s/it, training_loss=1.6282]\u001b[A\n",
      "Epoch 10:  90%|████████▉ | 133/148 [02:20<00:15,  1.04s/it, training_loss=1.4180]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 134/148 [02:20<00:14,  1.04s/it, training_loss=1.4180]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 134/148 [02:21<00:14,  1.04s/it, training_loss=0.9380]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 135/148 [02:21<00:13,  1.04s/it, training_loss=0.9380]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 135/148 [02:22<00:13,  1.04s/it, training_loss=0.9302]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 136/148 [02:22<00:12,  1.04s/it, training_loss=0.9302]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 136/148 [02:23<00:12,  1.04s/it, training_loss=1.1757]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 137/148 [02:23<00:11,  1.04s/it, training_loss=1.1757]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 137/148 [02:25<00:11,  1.04s/it, training_loss=0.8450]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 138/148 [02:25<00:10,  1.04s/it, training_loss=0.8450]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 138/148 [02:26<00:10,  1.04s/it, training_loss=1.5425]\u001b[A\n",
      "Epoch 10:  94%|█████████▍| 139/148 [02:26<00:09,  1.04s/it, training_loss=1.5425]\u001b[A\n",
      "Epoch 10:  94%|█████████▍| 139/148 [02:27<00:09,  1.04s/it, training_loss=0.8515]\u001b[A\n",
      "Epoch 10:  95%|█████████▍| 140/148 [02:27<00:08,  1.05s/it, training_loss=0.8515]\u001b[A\n",
      "Epoch 10:  95%|█████████▍| 140/148 [02:28<00:08,  1.05s/it, training_loss=1.4989]\u001b[A\n",
      "Epoch 10:  95%|█████████▌| 141/148 [02:28<00:07,  1.05s/it, training_loss=1.4989]\u001b[A\n",
      "Epoch 10:  95%|█████████▌| 141/148 [02:29<00:07,  1.05s/it, training_loss=1.6687]\u001b[A\n",
      "Epoch 10:  96%|█████████▌| 142/148 [02:29<00:06,  1.05s/it, training_loss=1.6687]\u001b[A\n",
      "Epoch 10:  96%|█████████▌| 142/148 [02:30<00:06,  1.05s/it, training_loss=0.9246]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 143/148 [02:30<00:05,  1.05s/it, training_loss=0.9246]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 143/148 [02:31<00:05,  1.05s/it, training_loss=0.8313]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 144/148 [02:31<00:04,  1.05s/it, training_loss=0.8313]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 144/148 [02:32<00:04,  1.05s/it, training_loss=1.6073]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 145/148 [02:32<00:03,  1.05s/it, training_loss=1.6073]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 145/148 [02:33<00:03,  1.05s/it, training_loss=1.7649]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 146/148 [02:33<00:02,  1.04s/it, training_loss=1.7649]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 146/148 [02:34<00:02,  1.04s/it, training_loss=0.9446]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 147/148 [02:34<00:01,  1.04s/it, training_loss=0.9446]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 147/148 [02:35<00:01,  1.04s/it, training_loss=0.8926]\u001b[A\n",
      "Epoch 10: 100%|██████████| 148/148 [02:35<00:00,  1.04it/s, training_loss=0.8926]\u001b[A\n",
      "                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:31:03,334 - INFO - Starting model evaluation...\n",
      "2025-02-16 00:31:03,335 - INFO - Memory usage after evaluation start: 3723.14 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:08,  3.06it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:08,  2.98it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:01<00:08,  2.94it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:07,  2.93it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:07,  2.93it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:02<00:07,  2.92it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:02<00:06,  2.92it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:03<00:06,  2.91it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:03<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:05,  2.92it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:04<00:05,  2.91it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:04<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:04<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:05<00:04,  2.92it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:05<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:06<00:03,  2.91it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:06<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:07<00:02,  2.91it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:07<00:01,  2.92it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:07<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:08<00:01,  2.91it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:08<00:00,  2.91it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:08<00:00,  3.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:31:12,295 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 00:31:12,310 - INFO - Class 'Drama': Optimal threshold = 0.750, F1 Score = 0.564\n",
      "2025-02-16 00:31:12,325 - INFO - Class 'Horor': Optimal threshold = 0.750, F1 Score = 0.726\n",
      "2025-02-16 00:31:12,338 - INFO - Class 'Komedi': Optimal threshold = 0.650, F1 Score = 0.636\n",
      "2025-02-16 00:31:12,351 - INFO - Class 'Laga': Optimal threshold = 0.500, F1 Score = 0.361\n",
      "2025-02-16 00:31:12,364 - INFO - Class 'Romantis': Optimal threshold = 0.400, F1 Score = 0.396\n",
      "2025-02-16 00:31:12,385 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 00:31:12,391 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 00:31:12,391 - INFO - Accuracy: 0.7280\n",
      "2025-02-16 00:31:12,392 - INFO - F1_score: 0.5644\n",
      "2025-02-16 00:31:12,393 - INFO - Precision: 0.5169\n",
      "2025-02-16 00:31:12,394 - INFO - Recall: 0.6216\n",
      "2025-02-16 00:31:12,400 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 00:31:12,400 - INFO - Accuracy: 0.8582\n",
      "2025-02-16 00:31:12,401 - INFO - F1_score: 0.7259\n",
      "2025-02-16 00:31:12,401 - INFO - Precision: 0.6282\n",
      "2025-02-16 00:31:12,402 - INFO - Recall: 0.8596\n",
      "2025-02-16 00:31:12,408 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 00:31:12,408 - INFO - Accuracy: 0.8161\n",
      "2025-02-16 00:31:12,409 - INFO - F1_score: 0.6364\n",
      "2025-02-16 00:31:12,410 - INFO - Precision: 0.5676\n",
      "2025-02-16 00:31:12,411 - INFO - Recall: 0.7241\n",
      "2025-02-16 00:31:12,417 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 00:31:12,418 - INFO - Accuracy: 0.7011\n",
      "2025-02-16 00:31:12,418 - INFO - F1_score: 0.3607\n",
      "2025-02-16 00:31:12,420 - INFO - Precision: 0.2619\n",
      "2025-02-16 00:31:12,421 - INFO - Recall: 0.5789\n",
      "2025-02-16 00:31:12,426 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 00:31:12,427 - INFO - Accuracy: 0.7893\n",
      "2025-02-16 00:31:12,427 - INFO - F1_score: 0.3956\n",
      "2025-02-16 00:31:12,428 - INFO - Precision: 0.3158\n",
      "2025-02-16 00:31:12,429 - INFO - Recall: 0.5294\n",
      "2025-02-16 00:31:12,431 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:31:16,210 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices\n",
      "2025-02-16 00:31:16,211 - INFO - Memory usage after evaluation end: 3728.89 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [29:41<4:29:18, 177.57s/it, Train Loss=1.1635, Val Loss=0.0588, Accuracy=0.7785]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:31:24,956 - INFO - \n",
      "Early stopping triggered after 10 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [29:41<5:00:13, 197.95s/it, Train Loss=1.1635, Val Loss=0.0588, Accuracy=0.7785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:31:26,819 - INFO - Saved training history plots to /kaggle/working/logs/experiments/20250215_214222/plots/training_history.png\n",
      "2025-02-16 00:31:26,820 - INFO - Training history saved successfully\n",
      "2025-02-16 00:31:29,405 - INFO - \n",
      "Testing model on a sample...\n",
      "2025-02-16 00:31:29,413 - INFO - Loading and preprocessing data...\n",
      "2025-02-16 00:31:29,414 - INFO - Memory usage after start: 3732.64 MB\n",
      "2025-02-16 00:31:29,427 - INFO - Successfully loaded data using utf-8 encoding\n",
      "2025-02-16 00:31:29,428 - INFO - Memory usage after data loading: 3732.64 MB\n",
      "2025-02-16 00:31:29,429 - INFO - Taking sample of 1 from 1738 total samples\n",
      "2025-02-16 00:31:29,430 - INFO - \n",
      "Sample data:\n",
      "2025-02-16 00:31:29,431 - INFO - \n",
      "Sample 1:\n",
      "2025-02-16 00:31:29,432 - INFO - Synopsis: Setelah kematian yang tampak, Siena mampu melihat tanda-tanda bahwa orang-orang akan meninggal. Namu...\n",
      "2025-02-16 00:31:29,433 - INFO - Genre: Horor\n",
      "2025-02-16 00:31:29,433 - INFO - \n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2743.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:31:29,442 - INFO - Memory usage after preprocessing: 3732.64 MB\n",
      "2025-02-16 00:31:29,492 - INFO - \n",
      "Sample prediction results:\n",
      "2025-02-16 00:31:29,493 - INFO - Sample text: setelah kematian yang tampak siena mampu melihat tanda tanda bahwa orang orang akan meninggal namun ...\n",
      "2025-02-16 00:31:29,494 - INFO - Genre: Horor, Probability: 0.9214, Threshold Used: 0.750\n",
      "2025-02-16 00:31:29,496 - INFO - \n",
      "Training completed successfully!\n",
      "2025-02-16 00:31:29,496 - INFO - All results and models saved in: /kaggle/working/logs/experiments/20250215_214222\n",
      "2025-02-16 00:31:29,497 - INFO - \n",
      "Cleaning up resources...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 00:31:30,785 - INFO - Cleaning up resources...\n"
     ]
    }
   ],
   "source": [
    "# BAGIAN KEEMPAT - Training dan Hyperparameter Optimization\n",
    "\n",
    "class ModelTrainer:\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def train_model(sample_size: Optional[int] = None) -> Tuple:\n",
    "        Config.SAMPLE_SIZE = sample_size\n",
    "        logging.info(\"Starting model training\")\n",
    "        log_memory(\"training start\")\n",
    "\n",
    "        try:\n",
    "            # Load dan preprocess data\n",
    "            df = DataProcessor.load_and_preprocess_data(Config.DATA_PATH, Config.SAMPLE_SIZE)\n",
    "            logging.info(f\"\\nDataset statistics:\")\n",
    "            logging.info(f\"Total samples after preprocessing: {len(df)}\")\n",
    "\n",
    "            # Prepare data\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            X_train, X_test, y_train, y_test = DataProcessor.prepare_data(df, mlb)\n",
    "\n",
    "            # Initialize threshold optimizer and performance tracker\n",
    "            threshold_optimizer = DynamicThresholdOptimizer(len(mlb.classes_))\n",
    "            performance_tracker = PerformanceTracker(len(mlb.classes_), mlb.classes_)\n",
    "\n",
    "            # Log genre distribution\n",
    "            genre_labels = mlb.fit_transform(df['genre'])\n",
    "            genre_counts = genre_labels.sum(axis=0)\n",
    "            for genre, count in zip(mlb.classes_, genre_counts):\n",
    "                logging.info(f\"Genre '{genre}': {count} samples\")\n",
    "\n",
    "            logging.info(f\"\\nTraining set size: {len(X_train)}\")\n",
    "            logging.info(f\"Testing set size: {len(X_test)}\")\n",
    "\n",
    "            # Setup model dan data loaders\n",
    "            with ModelManager(*ModelSetup.setup_model_and_tokenizer(len(mlb.classes_))) as (model, tokenizer):\n",
    "                train_loader, val_loader = ModelSetup.setup_dataloaders(\n",
    "                    X_train, X_test, y_train, y_test,\n",
    "                    tokenizer, Config.MODEL_PARAMS['BATCH_SIZE']\n",
    "                )\n",
    "\n",
    "                # Training loop\n",
    "                best_val_loss = float('inf')\n",
    "                best_accuracy = 0.0\n",
    "                patience_counter = 0\n",
    "                training_losses = []\n",
    "                validation_losses = []\n",
    "                accuracies = []\n",
    "\n",
    "                optimizer = torch.optim.AdamW(\n",
    "                    model.parameters(),\n",
    "                    lr=Config.MODEL_PARAMS['LEARNING_RATE'],\n",
    "                    weight_decay=Config.MODEL_PARAMS['WEIGHT_DECAY']\n",
    "                )\n",
    "\n",
    "                scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                    optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "                )\n",
    "\n",
    "                epochs_range = tqdm(range(Config.MODEL_PARAMS['EPOCHS']), \n",
    "                                  desc=\"Training Progress\",\n",
    "                                  position=0, leave=True)\n",
    "                \n",
    "                for epoch in epochs_range:\n",
    "                    try:\n",
    "                        # Training phase\n",
    "                        model.train()\n",
    "                        epoch_metrics = ModelTrainer._train_epoch(\n",
    "                            model, train_loader, optimizer,\n",
    "                            epoch + 1\n",
    "                        )\n",
    "                        training_losses.append(epoch_metrics['train_loss'])\n",
    "\n",
    "                        # Evaluation phase with dynamic thresholding\n",
    "                        validation_metrics = ModelEvaluator.evaluate_model(\n",
    "                            model, val_loader, mlb,\n",
    "                            threshold_optimizer=threshold_optimizer,\n",
    "                            performance_tracker=performance_tracker,\n",
    "                            epoch=epoch\n",
    "                        )\n",
    "                        \n",
    "                        current_accuracy = validation_metrics['accuracy']\n",
    "                        accuracies.append(current_accuracy)\n",
    "\n",
    "                        # Validation loss calculation\n",
    "                        avg_val_loss = ModelTrainer._calculate_validation_loss(\n",
    "                            model, val_loader\n",
    "                        )\n",
    "                        validation_losses.append(avg_val_loss)\n",
    "\n",
    "                        # Update progress bar\n",
    "                        epochs_range.set_postfix({\n",
    "                            'Train Loss': f\"{epoch_metrics['train_loss']:.4f}\",\n",
    "                            'Val Loss': f\"{avg_val_loss:.4f}\",\n",
    "                            'Accuracy': f\"{current_accuracy:.4f}\"\n",
    "                        })\n",
    "\n",
    "                        # Model improvement check\n",
    "                        model_improved = ModelTrainer._check_model_improvement(\n",
    "                            model, tokenizer, current_accuracy, avg_val_loss,\n",
    "                            best_accuracy, best_val_loss\n",
    "                        )\n",
    "\n",
    "                        if model_improved:\n",
    "                            best_accuracy = max(best_accuracy, current_accuracy)\n",
    "                            best_val_loss = min(best_val_loss, avg_val_loss)\n",
    "                            patience_counter = 0\n",
    "                        else:\n",
    "                            patience_counter += 1\n",
    "\n",
    "                        # Early stopping check\n",
    "                        if patience_counter >= Config.MODEL_PARAMS['PATIENCE']:\n",
    "                            logging.info(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "                            break\n",
    "\n",
    "                        scheduler.step(avg_val_loss)\n",
    "                        logging.info(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "                        # Clear GPU cache periodically\n",
    "                        if torch.cuda.is_available() and (epoch + 1) % 5 == 0:\n",
    "                            torch.cuda.empty_cache()\n",
    "                            gc.collect()\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Error during epoch {epoch + 1}: {str(e)}\")\n",
    "                        raise\n",
    "\n",
    "                # Save performance history and plots\n",
    "                performance_tracker.plot_performance_trends(Config.PLOTS_DIR)\n",
    "                performance_tracker.save_performance_history(Config.METRICS_DIR)\n",
    "                threshold_optimizer.save_threshold_history(Config.METRICS_DIR, mlb.classes_)\n",
    "\n",
    "                # Save training history\n",
    "                ModelTrainer._save_training_history(\n",
    "                    training_losses, validation_losses, accuracies,\n",
    "                    best_accuracy, best_val_loss, df, mlb,\n",
    "                    threshold_optimizer, performance_tracker\n",
    "                )\n",
    "\n",
    "                return model, tokenizer, mlb, threshold_optimizer\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in training: {str(e)}\")\n",
    "            raise\n",
    "        finally:\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    @staticmethod\n",
    "    def _save_training_history(training_losses: List[float],\n",
    "                             validation_losses: List[float],\n",
    "                             accuracies: List[float],\n",
    "                             best_accuracy: float,\n",
    "                             best_val_loss: float,\n",
    "                             df: pd.DataFrame,\n",
    "                             mlb: MultiLabelBinarizer,\n",
    "                             threshold_optimizer: DynamicThresholdOptimizer,\n",
    "                             performance_tracker: PerformanceTracker) -> None:\n",
    "        \"\"\"Save training history and plot results with threshold and performance info\"\"\"\n",
    "        try:\n",
    "            # Initialize genre_labels\n",
    "            genre_labels = mlb.fit_transform(df['genre'])\n",
    "            \n",
    "            history_data = {\n",
    "                'model_info': {\n",
    "                    'classes': mlb.classes_.tolist(),\n",
    "                    'total_samples': len(df),\n",
    "                    'genre_distribution': {\n",
    "                        genre: int(count) for genre, count in zip(mlb.classes_, genre_labels.sum(axis=0))\n",
    "                    }\n",
    "                },\n",
    "                'training_config': {\n",
    "                    'batch_size': Config.MODEL_PARAMS['BATCH_SIZE'],\n",
    "                    'learning_rate': Config.MODEL_PARAMS['LEARNING_RATE'],\n",
    "                    'max_length': Config.MODEL_PARAMS['MAX_LENGTH'],\n",
    "                    'weight_decay': Config.MODEL_PARAMS['WEIGHT_DECAY'],\n",
    "                    'early_stopping': Config.MODEL_PARAMS['PATIENCE'],\n",
    "                    'mixup_prob': Config.MODEL_PARAMS['MIXUP_PROB'],\n",
    "                    'train_split': 1-Config.MODEL_PARAMS['TEST_SIZE'],\n",
    "                    'test_split': Config.MODEL_PARAMS['TEST_SIZE']\n",
    "                },\n",
    "                'training_history': {\n",
    "                    'epochs': list(range(1, len(training_losses) + 1)),\n",
    "                    'training_loss': [float(loss) for loss in training_losses],\n",
    "                    'validation_loss': [float(loss) for loss in validation_losses],\n",
    "                    'accuracy': [float(acc) for acc in accuracies],\n",
    "                    'best_accuracy': float(best_accuracy),\n",
    "                    'best_val_loss': float(best_val_loss)\n",
    "                },\n",
    "                'thresholding_info': {\n",
    "                    'final_thresholds': {\n",
    "                        mlb.classes_[i]: thresh for i, thresh in enumerate(threshold_optimizer.thresholds)\n",
    "                    },\n",
    "                    'best_thresholds': {\n",
    "                        mlb.classes_[i]: thresh for i, thresh in enumerate(threshold_optimizer.best_thresholds)\n",
    "                    },\n",
    "                    'best_f1_scores': {\n",
    "                        mlb.classes_[i]: score for i, score in enumerate(threshold_optimizer.best_f1_scores)\n",
    "                    }\n",
    "                },\n",
    "                'per_class_performance': performance_tracker.best_metrics\n",
    "            }\n",
    "    \n",
    "            # Save history to JSON\n",
    "            history_file = Config.METRICS_DIR / 'training_history.json'\n",
    "            with open(history_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(history_data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "            # Plot training history\n",
    "            Visualization.plot_training_history(history_data['training_history'])\n",
    "            logging.info(\"Training history saved successfully\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving training history: {str(e)}\")\n",
    "            raise\n",
    "    @staticmethod\n",
    "    def _train_epoch(model: torch.nn.Module,\n",
    "                    train_loader: DataLoader,\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    epoch: int) -> Dict:\n",
    "        \"\"\"Train model for one epoch\"\"\"\n",
    "        total_loss = 0\n",
    "        steps = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\",\n",
    "                          position=1, leave=False)\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            try:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if np.random.random() < Config.MODEL_PARAMS['MIXUP_PROB']:\n",
    "                    batch = DataAugmentation.apply_mixup(batch)\n",
    "\n",
    "                input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = LossFunctions.label_smoothing_loss(\n",
    "                    outputs.logits, labels, Config.MODEL_PARAMS['SMOOTHING']\n",
    "                )\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                steps += 1\n",
    "                progress_bar.set_postfix({'training_loss': f'{loss.item():.4f}'})\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                    logging.error(\"GPU out of memory during training. Try reducing batch size.\")\n",
    "                raise\n",
    "\n",
    "        return {'train_loss': total_loss / steps}\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_validation_loss(model: torch.nn.Module,\n",
    "                                 val_loader: DataLoader) -> float:\n",
    "        \"\"\"Calculate validation loss\"\"\"\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        steps = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                try:\n",
    "                    input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                    attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                    labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = LossFunctions.focal_loss(outputs.logits, labels)\n",
    "                    total_loss += loss.item()\n",
    "                    steps += 1\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                        logging.error(\"GPU out of memory during validation. Try reducing batch size.\")\n",
    "                    raise\n",
    "\n",
    "        return total_loss / steps\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_model_improvement(model: torch.nn.Module,\n",
    "                               tokenizer,\n",
    "                               current_accuracy: float,\n",
    "                               current_loss: float,\n",
    "                               best_accuracy: float,\n",
    "                               best_loss: float) -> bool:\n",
    "        \"\"\"Check if model improved and save if necessary\"\"\"\n",
    "        improved = False\n",
    "\n",
    "        try:\n",
    "            if current_accuracy > best_accuracy:\n",
    "                logging.info(f\"New best accuracy: {current_accuracy:.4f}\")\n",
    "                model.save_pretrained(str(Config.MODEL_BEST_ACC))  # Convert to string for Colab\n",
    "                tokenizer.save_pretrained(str(Config.TOKENIZER_BEST_ACC))\n",
    "                improved = True\n",
    "\n",
    "            if current_loss < best_loss:\n",
    "                logging.info(f\"New best loss: {current_loss:.4f}\")\n",
    "                model.save_pretrained(str(Config.MODEL_BEST_LOSS))\n",
    "                tokenizer.save_pretrained(str(Config.TOKENIZER_BEST_LOSS))\n",
    "                improved = True\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "        return improved\n",
    "\n",
    "\n",
    "class HyperparameterOptimizer:\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def objective(trial: Trial, df: pd.DataFrame, mlb: MultiLabelBinarizer) -> float:\n",
    "        \"\"\"Objective function untuk Optuna optimization\"\"\"\n",
    "        try:\n",
    "            # Get trial parameters\n",
    "            params = HyperparameterOptimizer._get_trial_parameters(trial)\n",
    "\n",
    "            # Prepare data\n",
    "            X_train, X_test, y_train, y_test = DataProcessor.prepare_data(df, mlb)\n",
    "\n",
    "            # Setup model dan data loaders\n",
    "            with ModelManager(*ModelSetup.setup_model_and_tokenizer(len(mlb.classes_))) as (model, tokenizer):\n",
    "                train_loader, val_loader = ModelSetup.setup_dataloaders(\n",
    "                    X_train, X_test, y_train, y_test,\n",
    "                    tokenizer, params['batch_size']\n",
    "                )\n",
    "\n",
    "                # Training loop singkat untuk optimasi\n",
    "                best_val_metrics = HyperparameterOptimizer._train_trial(\n",
    "                    trial, model, train_loader, val_loader, mlb, params\n",
    "                )\n",
    "\n",
    "                # Clear GPU cache after each trial\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            return best_val_metrics['macro_f1']\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in optimization objective: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_trial_parameters(trial: Trial) -> Dict:\n",
    "        \"\"\"Get parameters for trial\"\"\"\n",
    "        params = {}\n",
    "        try:\n",
    "            # Batch size dari list nilai diskrit\n",
    "            params['batch_size'] = trial.suggest_categorical('batch_size',\n",
    "                Config.OPTIM_PARAMS['batch_size'])\n",
    "\n",
    "            # Learning rate dari list nilai diskrit\n",
    "            params['learning_rate'] = trial.suggest_categorical('learning_rate',\n",
    "                Config.OPTIM_PARAMS['learning_rate'])\n",
    "\n",
    "            # Weight decay dari list nilai diskrit\n",
    "            params['weight_decay'] = trial.suggest_categorical('weight_decay',\n",
    "                Config.OPTIM_PARAMS['weight_decay'])\n",
    "\n",
    "            # Mixup probability dari list nilai diskrit\n",
    "            params['mixup_prob'] = trial.suggest_categorical('mixup_prob',\n",
    "                Config.OPTIM_PARAMS['mixup_prob'])\n",
    "\n",
    "            # Smoothing dari list nilai diskrit\n",
    "            params['smoothing'] = trial.suggest_categorical('smoothing',\n",
    "                Config.OPTIM_PARAMS['smoothing'])\n",
    "\n",
    "            logging.info(f\"Trial parameter set: {params}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error getting trial parameters: {str(e)}\")\n",
    "            raise\n",
    "        return params\n",
    "\n",
    "    @staticmethod\n",
    "    def _train_trial(trial: Trial,\n",
    "                    model: torch.nn.Module,\n",
    "                    train_loader: DataLoader,\n",
    "                    val_loader: DataLoader,\n",
    "                    mlb: MultiLabelBinarizer,\n",
    "                    params: Dict) -> Dict:\n",
    "        \"\"\"Train model for one trial\"\"\"\n",
    "        try:\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=params['learning_rate'],\n",
    "                weight_decay=params['weight_decay']\n",
    "            )\n",
    "\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "            )\n",
    "\n",
    "            best_val_metrics = None\n",
    "\n",
    "            for epoch in range(3):  # Reduced epochs for optimization\n",
    "                # Training\n",
    "                model.train()\n",
    "                total_loss = 0\n",
    "                steps = 0\n",
    "\n",
    "                progress_bar = tqdm(train_loader,\n",
    "                                  desc=f\"Epoch {epoch+1}/3\",\n",
    "                                  position=0,\n",
    "                                  leave=False)\n",
    "\n",
    "                for batch in progress_bar:\n",
    "                    try:\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        if np.random.random() < params['mixup_prob']:\n",
    "                            batch = DataAugmentation.apply_mixup(batch)\n",
    "\n",
    "                        input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                        attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                        labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                        loss = LossFunctions.label_smoothing_loss(\n",
    "                            outputs.logits, labels, params['smoothing']\n",
    "                        )\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        total_loss += loss.item()\n",
    "                        steps += 1\n",
    "\n",
    "                        # Update progress bar\n",
    "                        progress_bar.set_postfix({\n",
    "                            'loss': f'{loss.item():.4f}',\n",
    "                            'avg_loss': f'{(total_loss/steps):.4f}'\n",
    "                        })\n",
    "\n",
    "                    except RuntimeError as e:\n",
    "                        if \"out of memory\" in str(e):\n",
    "                            if torch.cuda.is_available():\n",
    "                                torch.cuda.empty_cache()\n",
    "                            logging.error(\"GPU OOM in trial. Trying to recover...\")\n",
    "                            continue\n",
    "                        raise\n",
    "\n",
    "                avg_loss = total_loss / steps\n",
    "\n",
    "                # Evaluation\n",
    "                metrics = ModelEvaluator.evaluate_model(model, val_loader, mlb)\n",
    "                current_f1 = metrics['macro_f1']\n",
    "\n",
    "                logging.info(f\"Trial {trial.number}, Epoch {epoch+1}: \"\n",
    "                           f\"Loss = {avg_loss:.4f}, F1 = {current_f1:.4f}\")\n",
    "\n",
    "                if best_val_metrics is None or current_f1 > best_val_metrics['macro_f1']:\n",
    "                    best_val_metrics = metrics\n",
    "\n",
    "                scheduler.step(metrics['macro_f1'])\n",
    "\n",
    "                # Report intermediate value\n",
    "                trial.report(metrics['macro_f1'], epoch)\n",
    "\n",
    "                # Handle pruning based on the intermediate value\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "                # Clear GPU cache\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            return best_val_metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in trial training: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def run_optimization(df: pd.DataFrame,\n",
    "                        mlb: MultiLabelBinarizer,\n",
    "                        n_trials: int = 30) -> Dict:\n",
    "\n",
    "        try:\n",
    "            study = optuna.create_study(\n",
    "                direction=\"maximize\",\n",
    "                sampler=optuna.samplers.TPESampler(seed=42),\n",
    "                pruner=optuna.pruners.MedianPruner()\n",
    "            )\n",
    "\n",
    "            objective_func = lambda trial: HyperparameterOptimizer.objective(trial, df, mlb)\n",
    "\n",
    "            logging.info(\"Starting hyperparameter optimization...\")\n",
    "            study.optimize(objective_func, n_trials=n_trials,\n",
    "                         callbacks=[lambda study, trial: gc.collect()])\n",
    "\n",
    "            # Log results\n",
    "            logging.info(\"\\nHyperparameter Optimization Results:\")\n",
    "            logging.info(f\"Best trial number: {study.best_trial.number}\")\n",
    "            logging.info(f\"Best F1-score: {study.best_trial.value:.4f}\")\n",
    "            logging.info(\"\\nBest hyperparameters:\")\n",
    "            for param, value in study.best_trial.params.items():\n",
    "                logging.info(f\"{param}: {value}\")\n",
    "\n",
    "            # Save study results\n",
    "            results_file = Config.METRICS_DIR / 'optuna_results.json'\n",
    "            results = {\n",
    "                'best_trial': {\n",
    "                    'number': study.best_trial.number,\n",
    "                    'value': study.best_trial.value,\n",
    "                    'params': study.best_trial.params\n",
    "                },\n",
    "                'all_trials': [\n",
    "                    {\n",
    "                        'number': trial.number,\n",
    "                        'value': trial.value,\n",
    "                        'params': trial.params\n",
    "                    }\n",
    "                    for trial in study.trials if trial.value is not None\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            with open(results_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            # Save visualizations\n",
    "            try:\n",
    "                # Optimization history plot\n",
    "                fig1 = optuna.visualization.plot_optimization_history(study)\n",
    "                fig1.write_image(str(Config.PLOTS_DIR / \"optuna_optimization_history.png\"))\n",
    "\n",
    "                # Parameter importance plot\n",
    "                fig2 = optuna.visualization.plot_param_importances(study)\n",
    "                fig2.write_image(str(Config.PLOTS_DIR / \"optuna_param_importances.png\"))\n",
    "\n",
    "                # Parameter relationships plot\n",
    "                fig3 = optuna.visualization.plot_parallel_coordinate(study)\n",
    "                fig3.write_image(str(Config.PLOTS_DIR / \"optuna_param_relationships.png\"))\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Could not create optimization plots: {str(e)}\")\n",
    "\n",
    "            return study.best_trial.params\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during optimization: {str(e)}\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Clean up\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "# Fungsi get_args untuk Colab\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Training parameters\n",
    "        self.sample_size = None  # Number of samples to use (default: use all data)\n",
    "        self.epochs = Config.MODEL_PARAMS['EPOCHS']\n",
    "        self.batch_size = Config.MODEL_PARAMS['BATCH_SIZE']\n",
    "        self.learning_rate = Config.MODEL_PARAMS['LEARNING_RATE']\n",
    "        self.max_length = Config.MODEL_PARAMS['MAX_LENGTH']\n",
    "\n",
    "        # Model configuration\n",
    "        self.test_size = Config.MODEL_PARAMS['TEST_SIZE']\n",
    "        self.weight_decay = Config.MODEL_PARAMS['WEIGHT_DECAY']\n",
    "        self.mixup_prob = Config.MODEL_PARAMS['MIXUP_PROB']\n",
    "        self.patience = Config.MODEL_PARAMS['PATIENCE']\n",
    "\n",
    "        # System configuration\n",
    "        self.output_dir = None\n",
    "        self.no_cuda = False\n",
    "        self.seed = 42\n",
    "\n",
    "        # Label Smoothing\n",
    "        self.smoothing = Config.MODEL_PARAMS['SMOOTHING']\n",
    "\n",
    "        # Optuna specific\n",
    "        self.n_trials = 20\n",
    "\n",
    "# Modifikasi fungsi get_args\n",
    "def get_args():\n",
    "    return Args()\n",
    "\n",
    "def main(args: Args) -> None:\n",
    "    \"\"\"Main function\"\"\"\n",
    "    try:\n",
    "        # Check environment first\n",
    "        if not check_environment():\n",
    "            raise RuntimeError(\"Environment check failed!\")\n",
    "\n",
    "        # Update configuration\n",
    "        Config.MODEL_PARAMS.update({\n",
    "            'EPOCHS': args.epochs,\n",
    "            'BATCH_SIZE': args.batch_size,\n",
    "            'LEARNING_RATE': args.learning_rate,\n",
    "            'MAX_LENGTH': args.max_length,\n",
    "            'TEST_SIZE': args.test_size,\n",
    "            'WEIGHT_DECAY': args.weight_decay,\n",
    "            'MIXUP_PROB': args.mixup_prob,\n",
    "            'PATIENCE': args.patience,\n",
    "            'SMOOTHING': args.smoothing\n",
    "        })\n",
    "\n",
    "        if args.no_cuda:\n",
    "            Config.DEVICE = torch.device('cpu')\n",
    "            logging.info(\"CUDA disabled by user\")\n",
    "\n",
    "        # Initialize logging dan experiment info\n",
    "        log_system_info()\n",
    "\n",
    "        logging.info(\"Starting movie genre classification with hyperparameter optimization\")\n",
    "        logging.info(f\"Using device: {Config.DEVICE}\")\n",
    "\n",
    "        # Log initial configuration\n",
    "        logging.info(\"\\nInitial Configuration:\")\n",
    "        logging.info(f\"Sample Size: {Config.SAMPLE_SIZE if Config.SAMPLE_SIZE else 'Full Dataset'}\")\n",
    "        for param, value in Config.MODEL_PARAMS.items():\n",
    "            logging.info(f\"{param}: {value}\")\n",
    "\n",
    "        # Load and preprocess data\n",
    "        logging.info(\"\\nLoading and preprocessing data...\")\n",
    "        df = DataProcessor.load_and_preprocess_data(Config.DATA_PATH, Config.SAMPLE_SIZE)\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        # Run hyperparameter optimization\n",
    "        logging.info(\"\\nStarting hyperparameter optimization...\")\n",
    "        best_params = HyperparameterOptimizer.run_optimization(df, mlb, args.n_trials)\n",
    "\n",
    "        # Update configuration with best parameters\n",
    "        logging.info(\"\\nBest Hyperparameters found:\")\n",
    "        for param, value in best_params.items():\n",
    "            logging.info(f\"{param}: {value}\")\n",
    "            if param in Config.MODEL_PARAMS:\n",
    "                Config.MODEL_PARAMS[param] = value\n",
    "\n",
    "        # Train final model with best parameters\n",
    "        logging.info(\"\\nTraining final model with optimized parameters...\")\n",
    "        model, tokenizer, mlb, threshold_optimizer = ModelTrainer.train_model(Config.SAMPLE_SIZE)\n",
    "\n",
    "        # Test on a sample\n",
    "        logging.info(\"\\nTesting model on a sample...\")\n",
    "        df_sample = DataProcessor.load_and_preprocess_data(Config.DATA_PATH, sample_size=1)\n",
    "        sample_text = df_sample['sinopsis'].iloc[0]\n",
    "\n",
    "        model.eval()\n",
    "        inputs = tokenizer(\n",
    "            sample_text,\n",
    "            return_tensors='pt',\n",
    "            max_length=Config.MODEL_PARAMS['MAX_LENGTH'],\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids'].to(Config.DEVICE)\n",
    "        attention_mask = inputs['attention_mask'].to(Config.DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.sigmoid(outputs.logits)\n",
    "            \n",
    "            # Gunakan threshold_optimizer untuk prediksi\n",
    "            raw_predictions = probs.cpu().numpy()\n",
    "            thresholded_preds = threshold_optimizer.apply_thresholds(raw_predictions)\n",
    "\n",
    "        # Buat prediksi dengan threshold yang dioptimalkan\n",
    "        predictions = []\n",
    "        for idx, pred in enumerate(thresholded_preds[0]):\n",
    "            if pred > 0:  # Karena sudah di-threshold\n",
    "                predictions.append({\n",
    "                    'genre': mlb.classes_[idx],\n",
    "                    'probability': float(probs[0][idx].item()),\n",
    "                    'threshold_used': threshold_optimizer.thresholds[idx]\n",
    "                })\n",
    "\n",
    "        predictions.sort(key=lambda x: x['probability'], reverse=True)\n",
    "\n",
    "        # Log prediction results dengan informasi threshold\n",
    "        logging.info(\"\\nSample prediction results:\")\n",
    "        logging.info(f\"Sample text: {sample_text[:100]}...\")\n",
    "        for pred in predictions:\n",
    "            logging.info(\n",
    "                f\"Genre: {pred['genre']}, \"\n",
    "                f\"Probability: {pred['probability']:.4f}, \"\n",
    "                f\"Threshold Used: {pred['threshold_used']:.3f}\"\n",
    "            )\n",
    "\n",
    "        # Save final configuration\n",
    "        final_config = {\n",
    "            'hyperparameters': best_params,\n",
    "            'model_info': {\n",
    "                'num_classes': len(mlb.classes_),\n",
    "                'classes': mlb.classes_.tolist()\n",
    "            },\n",
    "            'training_info': {\n",
    "                'device': str(Config.DEVICE),\n",
    "                'final_sample_size': len(df),\n",
    "                'optimization_trials': args.n_trials\n",
    "            },\n",
    "            'threshold_info': {\n",
    "                'final_thresholds': {\n",
    "                    class_name: float(thresh) \n",
    "                    for class_name, thresh in zip(mlb.classes_, threshold_optimizer.thresholds)\n",
    "                },\n",
    "                'best_f1_scores': {\n",
    "                    class_name: float(score)\n",
    "                    for class_name, score in zip(mlb.classes_, threshold_optimizer.best_f1_scores)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(Config.EXPERIMENT_DIR / 'final_configuration.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_config, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        logging.info(\"\\nTraining completed successfully!\")\n",
    "        logging.info(f\"All results and models saved in: {Config.EXPERIMENT_DIR}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"\\nTraining interrupted by user\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"\\nError during execution: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logging.info(\"\\nCleaning up resources...\")\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# Entry point for Colab\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seeds for reproducibility\n",
    "    args = get_args()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    try:\n",
    "        main(args)\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"\\nTraining interrupted by user\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Training failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logging.info(\"Cleaning up resources...\")\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36d2360c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T00:31:34.199913Z",
     "iopub.status.busy": "2025-02-16T00:31:34.199603Z",
     "iopub.status.idle": "2025-02-16T00:32:25.442778Z",
     "shell.execute_reply": "2025-02-16T00:32:25.441666Z"
    },
    "papermill": {
     "duration": 53.279879,
     "end_time": "2025-02-16T00:32:26.407620",
     "exception": false,
     "start_time": "2025-02-16T00:31:33.127741",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/logs/experiments/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/accuracies_trends.png (deflated 6%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices/confusion_matrix_Horor.png (deflated 20%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices/confusion_matrix_Laga.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices/confusion_matrix_Komedi.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices/confusion_matrix_Romantis.png (deflated 18%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/confusion_matrices/confusion_matrix_Drama.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/f1_scores_trends.png (deflated 6%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/training_history.png (deflated 14%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/precisions_trends.png (deflated 5%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/plots/recalls_trends.png (deflated 4%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/best_accuracy/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/best_accuracy/tokenizer.json (deflated 71%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/best_accuracy/special_tokens_map.json (deflated 42%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/best_accuracy/tokenizer_config.json (deflated 74%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/best_accuracy/vocab.txt (deflated 53%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/best_loss/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/best_loss/tokenizer.json (deflated 71%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/best_loss/special_tokens_map.json (deflated 42%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/best_loss/tokenizer_config.json (deflated 74%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/tokenizer/best_loss/vocab.txt (deflated 53%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/model/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/model/best_accuracy/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/model/best_accuracy/config.json (deflated 56%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/model/best_accuracy/model.safetensors (deflated 7%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/model/best_loss/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/model/best_loss/config.json (deflated 56%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/model/best_loss/model.safetensors (deflated 7%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/metrics/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/metrics/optuna_results.json (deflated 90%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/metrics/performance_history.json (deflated 83%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/metrics/evaluation_metrics.json (deflated 69%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/metrics/training_history.json (deflated 73%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/metrics/threshold_history.json (deflated 91%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/training.log (deflated 86%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250215_214222/final_configuration.json (deflated 63%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r folder.zip /kaggle/working/logs/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c9e2dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T00:32:28.512876Z",
     "iopub.status.busy": "2025-02-16T00:32:28.512544Z",
     "iopub.status.idle": "2025-02-16T00:32:28.518433Z",
     "shell.execute_reply": "2025-02-16T00:32:28.517654Z"
    },
    "papermill": {
     "duration": 1.042531,
     "end_time": "2025-02-16T00:32:28.519828",
     "exception": false,
     "start_time": "2025-02-16T00:32:27.477297",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='folder.zip' target='_blank'>folder.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/folder.zip"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'folder.zip')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6639588,
     "sourceId": 10712322,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10229.27397,
   "end_time": "2025-02-16T00:32:32.521255",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-15T21:42:03.247285",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01ecfdc5a35b488f8980390b2ff57fdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "029c937e05a140f38856b439aab7755b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "05ecd4b01d754d499dfcfe48c60026b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_957dc22c7e0844768bc25a9ff8e15c85",
       "placeholder": "​",
       "style": "IPY_MODEL_20fd0d9292044757ada10d658a855530",
       "tabbable": null,
       "tooltip": null,
       "value": " 498M/498M [00:04&lt;00:00, 135MB/s]"
      }
     },
     "15537d6779b348e79c38e28e2169c25f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_dc3894df74aa4d628d150d4ce245c0d9",
        "IPY_MODEL_b4d577e011f14aa5bfb85de674f9f95d",
        "IPY_MODEL_d9519036c6e6470e8d82e0b6020a2b43"
       ],
       "layout": "IPY_MODEL_d6e19a52e796409b8b90bafc9ccea068",
       "tabbable": null,
       "tooltip": null
      }
     },
     "1a61327e395f4d389af47c68fc0bba72": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "20fd0d9292044757ada10d658a855530": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2383d055c1d148358a5b334d7b341434": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ba511c7821b5440eba2d9df1c16d6720",
       "placeholder": "​",
       "style": "IPY_MODEL_01ecfdc5a35b488f8980390b2ff57fdd",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 163kB/s]"
      }
     },
     "25e690e9d20e43ddb6376998519fb4a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e42ff14f4384f069603904cad67f23a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "4c8aea1c698e4d19a8db61ed05aab2d0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_25e690e9d20e43ddb6376998519fb4a7",
       "placeholder": "​",
       "style": "IPY_MODEL_bd4b0760c5e94c979b10c85a1d553c83",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 12.7kB/s]"
      }
     },
     "4e90b12f43cc4789b6b18c35b6161f66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_68c8675315d943bc8f2a0fd9d516f78c",
       "placeholder": "​",
       "style": "IPY_MODEL_de30c859410c46349289e2a09546e884",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 7.02MB/s]"
      }
     },
     "68c8675315d943bc8f2a0fd9d516f78c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "68d01b06a30743ac86191c3ee19d619c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6918894103c9489c82c05e217ec1a694": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6b0f631d9d4b447eb4c728a0a5710ca8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6bbfe2c37ff14eb5a325a7f09f7b465d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70012d274f15449594f333f6074ef102": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "70507ddbadab4d28a173e80a04993a6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "71dbfc9ac9aa40f3807f6ecef068389b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "728353a40a2b4e52b4cc63aafdc25382": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_70012d274f15449594f333f6074ef102",
       "placeholder": "​",
       "style": "IPY_MODEL_82e8d2ff8109426abd27658c8081a01d",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "79545a3555aa43398036838ea1d85c8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "798967d24e82459c98e300b88dd99514": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b3d4c8185c5145cd90d1391cedbc1da4",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_79545a3555aa43398036838ea1d85c8e",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "82e8d2ff8109426abd27658c8081a01d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "853006c99fad4cb8bee5c686583a9b8f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e3f0059957434c2e959c0bb9caf70198",
        "IPY_MODEL_f2cd406cd9d54e3193f85d9173186ac2",
        "IPY_MODEL_4c8aea1c698e4d19a8db61ed05aab2d0"
       ],
       "layout": "IPY_MODEL_6bbfe2c37ff14eb5a325a7f09f7b465d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "8de8f9dcd13c4b97929437c6afe78d44": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8f8b134088d944f89f18f3c2d9c7efed": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_728353a40a2b4e52b4cc63aafdc25382",
        "IPY_MODEL_798967d24e82459c98e300b88dd99514",
        "IPY_MODEL_4e90b12f43cc4789b6b18c35b6161f66"
       ],
       "layout": "IPY_MODEL_ab65e5033b1a44d48e9d0740df214311",
       "tabbable": null,
       "tooltip": null
      }
     },
     "908d85744bd64895a76ed3af5c37f54e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "957dc22c7e0844768bc25a9ff8e15c85": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "97caaaccfd0f480db4721bd2605dcb64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_aeb91535c40b400ab527216fb55dec42",
       "max": 497810400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8de8f9dcd13c4b97929437c6afe78d44",
       "tabbable": null,
       "tooltip": null,
       "value": 497810400.0
      }
     },
     "99791723a5ab45c4b82b18998088a1dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "a1a8a1ee1e5d4b0b9b425c81aa8dbb1a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "ab65e5033b1a44d48e9d0740df214311": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aeb91535c40b400ab527216fb55dec42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "af561d37f6d448c6a0182f17fce252ea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b0eb09d5480e49b7bb4d3b62ff464e7b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b3d4c8185c5145cd90d1391cedbc1da4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4d577e011f14aa5bfb85de674f9f95d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_1a61327e395f4d389af47c68fc0bba72",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_99791723a5ab45c4b82b18998088a1dc",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "ba511c7821b5440eba2d9df1c16d6720": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd4b0760c5e94c979b10c85a1d553c83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c24b246881ad4434b2e636a7721a236f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ce7f8fa492254a53bf4e0d397c438ee4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_e49f2ed29a7a401980789756503d1b05",
       "placeholder": "​",
       "style": "IPY_MODEL_af561d37f6d448c6a0182f17fce252ea",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "d3b29537543749d882ae4ce97d71a920": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d3c8db21bc094fd28f6d226cb183df9c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ea25e2da537140e09171745d150c8b05",
        "IPY_MODEL_97caaaccfd0f480db4721bd2605dcb64",
        "IPY_MODEL_05ecd4b01d754d499dfcfe48c60026b7"
       ],
       "layout": "IPY_MODEL_f6b9f527b84e4b71b9bcf4f1313dfaed",
       "tabbable": null,
       "tooltip": null
      }
     },
     "d5650f85f8824f918f058d26887cfd34": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6e19a52e796409b8b90bafc9ccea068": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d9519036c6e6470e8d82e0b6020a2b43": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d5650f85f8824f918f058d26887cfd34",
       "placeholder": "​",
       "style": "IPY_MODEL_029c937e05a140f38856b439aab7755b",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 201B/s]"
      }
     },
     "dc3894df74aa4d628d150d4ce245c0d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_70507ddbadab4d28a173e80a04993a6a",
       "placeholder": "​",
       "style": "IPY_MODEL_c24b246881ad4434b2e636a7721a236f",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "de30c859410c46349289e2a09546e884": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e19185194afb4e4991f70ab8b93dd1f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6918894103c9489c82c05e217ec1a694",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a1a8a1ee1e5d4b0b9b425c81aa8dbb1a",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "e3f0059957434c2e959c0bb9caf70198": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_908d85744bd64895a76ed3af5c37f54e",
       "placeholder": "​",
       "style": "IPY_MODEL_d3b29537543749d882ae4ce97d71a920",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "e49f2ed29a7a401980789756503d1b05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ea25e2da537140e09171745d150c8b05": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b0eb09d5480e49b7bb4d3b62ff464e7b",
       "placeholder": "​",
       "style": "IPY_MODEL_71dbfc9ac9aa40f3807f6ecef068389b",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "f2cd406cd9d54e3193f85d9173186ac2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6b0f631d9d4b447eb4c728a0a5710ca8",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3e42ff14f4384f069603904cad67f23a",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "f53fdde964144217818ef92a91885e64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_ce7f8fa492254a53bf4e0d397c438ee4",
        "IPY_MODEL_e19185194afb4e4991f70ab8b93dd1f1",
        "IPY_MODEL_2383d055c1d148358a5b334d7b341434"
       ],
       "layout": "IPY_MODEL_68d01b06a30743ac86191c3ee19d619c",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f6b9f527b84e4b71b9bcf4f1313dfaed": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
