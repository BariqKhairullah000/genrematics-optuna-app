{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ecd19a8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-16T17:16:00.876979Z",
     "iopub.status.busy": "2025-02-16T17:16:00.876745Z",
     "iopub.status.idle": "2025-02-16T17:16:02.157610Z",
     "shell.execute_reply": "2025-02-16T17:16:02.156676Z"
    },
    "papermill": {
     "duration": 1.287498,
     "end_time": "2025-02-16T17:16:02.159448",
     "exception": false,
     "start_time": "2025-02-16T17:16:00.871950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/datasets-classificationsynopsis/final_combined_movies_5genres.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20d1241",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T17:16:02.169345Z",
     "iopub.status.busy": "2025-02-16T17:16:02.168851Z",
     "iopub.status.idle": "2025-02-16T17:16:07.659522Z",
     "shell.execute_reply": "2025-02-16T17:16:07.658641Z"
    },
    "papermill": {
     "duration": 5.496672,
     "end_time": "2025-02-16T17:16:07.660921",
     "exception": false,
     "start_time": "2025-02-16T17:16:02.164249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.2.0)\r\n",
      "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.1)\r\n",
      "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\r\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\r\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\r\n",
      "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.9)\r\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\r\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->optuna) (2.4.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->optuna) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->optuna) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->optuna) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->optuna) (2024.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Movie Genre Classification with IndoBERT\n",
    "Environment: Kaggle\n",
    "\"\"\"\n",
    "\n",
    "!pip install optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e73ec97d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T17:16:07.669643Z",
     "iopub.status.busy": "2025-02-16T17:16:07.669353Z",
     "iopub.status.idle": "2025-02-16T17:16:23.325954Z",
     "shell.execute_reply": "2025-02-16T17:16:23.325126Z"
    },
    "papermill": {
     "duration": 15.662481,
     "end_time": "2025-02-16T17:16:23.327299",
     "exception": false,
     "start_time": "2025-02-16T17:16:07.664818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files in dataset directory:\n",
      "- final_combined_movies_5genres.csv\n",
      "GPU tersedia: Tesla T4\n",
      "GPU Memory: 15.83 GB\n",
      "Created directory: /kaggle/working/logs\n",
      "Created directory: /kaggle/working/backups\n",
      "Created directory: /kaggle/working/logs/experiments/20250216_171623\n",
      "Created directory: /kaggle/working/logs/experiments/20250216_171623/model\n",
      "Created directory: /kaggle/working/logs/experiments/20250216_171623/tokenizer\n",
      "Created directory: /kaggle/working/logs/experiments/20250216_171623/metrics\n",
      "Created directory: /kaggle/working/logs/experiments/20250216_171623/plots\n",
      "Created directory: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:16:23,310 - INFO - Log file created at: /kaggle/working/logs/experiments/20250216_171623/training.log\n",
      "2025-02-16 17:16:23,311 - INFO - System Information:\n",
      "2025-02-16 17:16:23,311 - INFO - Python Version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "2025-02-16 17:16:23,318 - INFO - CPU Count: 4\n",
      "2025-02-16 17:16:23,319 - INFO - Initial Memory Usage: 634.78 MB\n",
      "2025-02-16 17:16:23,320 - INFO - GPU Device: Tesla T4\n",
      "2025-02-16 17:16:23,321 - INFO - GPU Memory Total: 15.83 GB\n",
      "2025-02-16 17:16:23,321 - INFO - CUDA Version: 12.1\n"
     ]
    }
   ],
   "source": [
    "# BAGIAN PERTAMA - Import dan Konfigurasi\n",
    "import os\n",
    "import logging\n",
    "import datetime\n",
    "import json\n",
    "import argparse\n",
    "import gc\n",
    "import sys\n",
    "import codecs\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Union\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, accuracy_score\n",
    "from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import psutil\n",
    "import optuna\n",
    "from optuna.trial import Trial\n",
    "\n",
    "# Define Base Path for Kaggle\n",
    "BASE_PATH = Path('/kaggle/working')\n",
    "DATASETS_PATH = Path('/kaggle/input/datasets-classificationsynopsis')\n",
    "\n",
    "# Configuration Constants\n",
    "class Config:\n",
    "    # Model Parameters\n",
    "    MODEL_PARAMS = {\n",
    "        'EPOCHS': 100,\n",
    "        'BATCH_SIZE': 10,\n",
    "        'LEARNING_RATE': 1e-5,\n",
    "        'MAX_LENGTH': 512,\n",
    "        'TEST_SIZE': 0.15,\n",
    "        'WEIGHT_DECAY': 0.05,\n",
    "        'MIXUP_PROB': 0.5,\n",
    "        'PATIENCE': 5,\n",
    "        'SMOOTHING': 0.2\n",
    "    }\n",
    "\n",
    "    # Optimization Parameters\n",
    "    OPTIM_PARAMS = {\n",
    "        'batch_size': [2, 4, 8],           \n",
    "        'learning_rate': [3E-6, 5E-6, 8E-6], \n",
    "        'weight_decay': [0.01, 0.02],\n",
    "        'mixup_prob': [0.2, 0.3],\n",
    "        'smoothing': [0.1, 0.15]\n",
    "\n",
    "    }\n",
    "\n",
    "    # Paths Configuration untuk Kaggle\n",
    "    BASE_DIR = BASE_PATH\n",
    "    DATA_PATH = Path('/kaggle/input/datasets-classificationsynopsis/final_combined_movies_5genres.csv')\n",
    "    LOG_DIR = BASE_DIR / 'logs'\n",
    "    BACKUP_DIR = BASE_DIR / 'backups'\n",
    "    TIMESTAMP = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    EXPERIMENT_DIR = LOG_DIR / 'experiments' / TIMESTAMP\n",
    "\n",
    "    # Model and Data Paths\n",
    "    MODEL_SAVE_DIR = EXPERIMENT_DIR / 'model'\n",
    "    TOKENIZER_SAVE_DIR = EXPERIMENT_DIR / 'tokenizer'\n",
    "    METRICS_DIR = EXPERIMENT_DIR / 'metrics'\n",
    "    PLOTS_DIR = EXPERIMENT_DIR / 'plots'\n",
    "    CM_DIR = PLOTS_DIR / 'confusion_matrices'\n",
    "\n",
    "    # Model Files\n",
    "    MODEL_BEST_ACC = MODEL_SAVE_DIR / \"best_accuracy\"\n",
    "    MODEL_BEST_LOSS = MODEL_SAVE_DIR / \"best_loss\"\n",
    "    TOKENIZER_BEST_ACC = TOKENIZER_SAVE_DIR / \"best_accuracy\"\n",
    "    TOKENIZER_BEST_LOSS = TOKENIZER_SAVE_DIR / \"best_loss\"\n",
    "    DATA_PATH = Path('/kaggle/input/datasets-classificationsynopsis/final_combined_movies_5genres.csv')  # Path langsung ke file CSV\n",
    "\n",
    "    # Device Configuration\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    SAMPLE_SIZE: Optional[int] = None\n",
    "\n",
    "    @classmethod\n",
    "    def create_directories(cls) -> None:\n",
    "        \"\"\"Create all necessary directories in Kaggle working directory\"\"\"\n",
    "        directories = [\n",
    "            cls.LOG_DIR, cls.BACKUP_DIR,\n",
    "            cls.EXPERIMENT_DIR, cls.MODEL_SAVE_DIR, cls.TOKENIZER_SAVE_DIR,\n",
    "            cls.METRICS_DIR, cls.PLOTS_DIR, cls.CM_DIR\n",
    "        ]\n",
    "        for dir_path in directories:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "            print(f\"Created directory: {dir_path}\")\n",
    "\n",
    "    @classmethod\n",
    "    def setup_logging(cls) -> None:\n",
    "        \"\"\"Setup logging configuration untuk Kaggle\"\"\"\n",
    "        log_file = cls.EXPERIMENT_DIR / 'training.log'\n",
    "        for handler in logging.root.handlers[:]:\n",
    "            logging.root.removeHandler(handler)\n",
    "\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "            handlers=[\n",
    "                logging.FileHandler(log_file, encoding='utf-8', mode='a'),\n",
    "                logging.StreamHandler(sys.stdout)\n",
    "            ]\n",
    "        )\n",
    "        logging.info(f\"Log file created at: {log_file}\")\n",
    "\n",
    "# Environment Check Function\n",
    "def check_environment() -> bool:\n",
    "    \"\"\"Verify Kaggle environment and paths\"\"\"\n",
    "    try:\n",
    "        # Check if datasets directory exists\n",
    "        if not DATASETS_PATH.exists():\n",
    "            raise RuntimeError(f\"Dataset directory tidak ditemukan di: {DATASETS_PATH}\")\n",
    "        \n",
    "        # List available files in dataset directory\n",
    "        print(\"\\nFiles in dataset directory:\")\n",
    "        for file in DATASETS_PATH.glob('*'):\n",
    "            print(f\"- {file.name}\")\n",
    "\n",
    "        # Check if dataset exists\n",
    "        if not Config.DATA_PATH.exists():\n",
    "            raise RuntimeError(f\"Dataset tidak ditemukan di: {Config.DATA_PATH}\")\n",
    "\n",
    "        # Check GPU availability\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1e9  # Convert to GB\n",
    "            print(f\"GPU tersedia: {gpu_name}\")\n",
    "            print(f\"GPU Memory: {gpu_memory:.2f} GB\")\n",
    "        else:\n",
    "            print(\"WARNING: GPU tidak tersedia, menggunakan CPU\")\n",
    "\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error dalam setup environment: {str(e)}\")\n",
    "        return False\n",
    "class DynamicThresholdOptimizer:\n",
    "    \"\"\"Class untuk mengoptimalkan threshold per-class secara dinamis\"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        self.num_classes = num_classes\n",
    "        self.thresholds = [0.5] * num_classes  # Initial thresholds\n",
    "        self.performance_history = {i: [] for i in range(num_classes)}\n",
    "        self.best_thresholds = [0.5] * num_classes\n",
    "        self.best_f1_scores = [0.0] * num_classes\n",
    "\n",
    "    def optimize_thresholds(self, true_labels, predictions, class_names):\n",
    "        \"\"\"Optimize thresholds based on F1 score\"\"\"\n",
    "        logging.info(\"Optimizing classification thresholds...\")\n",
    "        \n",
    "        for class_idx in range(self.num_classes):\n",
    "            best_threshold = 0.5\n",
    "            best_f1 = 0.0\n",
    "            \n",
    "            # Test different thresholds\n",
    "            for threshold in np.arange(0.3, 0.8, 0.05):\n",
    "                class_preds = (predictions[:, class_idx] > threshold).astype(int)\n",
    "                f1 = f1_score(true_labels[:, class_idx], class_preds, zero_division=0)\n",
    "                \n",
    "                if f1 > best_f1:\n",
    "                    best_f1 = f1\n",
    "                    best_threshold = threshold\n",
    "            \n",
    "            self.thresholds[class_idx] = best_threshold\n",
    "            self.performance_history[class_idx].append({\n",
    "                'threshold': best_threshold,\n",
    "                'f1_score': best_f1\n",
    "            })\n",
    "            \n",
    "            if best_f1 > self.best_f1_scores[class_idx]:\n",
    "                self.best_f1_scores[class_idx] = best_f1\n",
    "                self.best_thresholds[class_idx] = best_threshold\n",
    "            \n",
    "            logging.info(f\"Class '{class_names[class_idx]}': Optimal threshold = {best_threshold:.3f}, F1 Score = {best_f1:.3f}\")\n",
    "\n",
    "    def apply_thresholds(self, predictions):\n",
    "        \"\"\"Apply optimized thresholds to predictions\"\"\"\n",
    "        thresholded_preds = np.zeros_like(predictions)\n",
    "        for i in range(self.num_classes):\n",
    "            thresholded_preds[:, i] = (predictions[:, i] > self.thresholds[i]).astype(int)\n",
    "        return thresholded_preds\n",
    "\n",
    "    def save_threshold_history(self, save_path, class_names):\n",
    "        \"\"\"Save threshold optimization history\"\"\"\n",
    "        history_data = {\n",
    "            'class_thresholds': {\n",
    "                class_names[i]: {\n",
    "                    'current_threshold': self.thresholds[i],\n",
    "                    'best_threshold': self.best_thresholds[i],\n",
    "                    'best_f1_score': self.best_f1_scores[i],\n",
    "                    'history': self.performance_history[i]\n",
    "                } for i in range(self.num_classes)\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(save_path / 'threshold_history.json', 'w') as f:\n",
    "            json.dump(history_data, f, indent=4)\n",
    "\n",
    "class PerformanceTracker:\n",
    "    \"\"\"Class untuk melacak performa per-class selama training\"\"\"\n",
    "    def __init__(self, num_classes, class_names):\n",
    "        self.num_classes = num_classes\n",
    "        self.class_names = class_names\n",
    "        self.metrics_history = {name: {\n",
    "            'f1_scores': [],\n",
    "            'precisions': [],\n",
    "            'recalls': [],\n",
    "            'accuracies': []\n",
    "        } for name in class_names}\n",
    "        self.best_metrics = {name: {\n",
    "            'f1_score': 0.0,\n",
    "            'precision': 0.0,\n",
    "            'recall': 0.0,\n",
    "            'accuracy': 0.0,\n",
    "            'epoch': 0\n",
    "        } for name in class_names}\n",
    "\n",
    "    def update_metrics(self, true_labels, predictions, epoch):\n",
    "        \"\"\"Update performance metrics for each class\"\"\"\n",
    "        for i, class_name in enumerate(self.class_names):\n",
    "            # Calculate metrics\n",
    "            accuracy = accuracy_score(true_labels[:, i], predictions[:, i])\n",
    "            precision = precision_score(true_labels[:, i], predictions[:, i], zero_division=0)\n",
    "            recall = recall_score(true_labels[:, i], predictions[:, i], zero_division=0)\n",
    "            f1 = f1_score(true_labels[:, i], predictions[:, i], zero_division=0)\n",
    "            \n",
    "            # Update history\n",
    "            self.metrics_history[class_name]['accuracies'].append(accuracy)\n",
    "            self.metrics_history[class_name]['precisions'].append(precision)\n",
    "            self.metrics_history[class_name]['recalls'].append(recall)\n",
    "            self.metrics_history[class_name]['f1_scores'].append(f1)\n",
    "            \n",
    "            # Update best metrics if necessary\n",
    "            if f1 > self.best_metrics[class_name]['f1_score']:\n",
    "                self.best_metrics[class_name].update({\n",
    "                    'f1_score': f1,\n",
    "                    'precision': precision,\n",
    "                    'recall': recall,\n",
    "                    'accuracy': accuracy,\n",
    "                    'epoch': epoch\n",
    "                })\n",
    "\n",
    "    def plot_performance_trends(self, save_path):\n",
    "        \"\"\"Plot performance trends untuk setiap class\"\"\"\n",
    "        for metric in ['f1_scores', 'precisions', 'recalls', 'accuracies']:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            for class_name in self.class_names:\n",
    "                plt.plot(\n",
    "                    self.metrics_history[class_name][metric],\n",
    "                    label=class_name\n",
    "                )\n",
    "            \n",
    "            plt.title(f'{metric.replace(\"_\", \" \").title()} Trends per Class')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Score')\n",
    "            plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "            plt.grid(True)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(save_path / f'{metric}_trends.png')\n",
    "            plt.close()\n",
    "\n",
    "    def save_performance_history(self, save_path):\n",
    "        \"\"\"Save performance history ke file\"\"\"\n",
    "        history_data = {\n",
    "            'metrics_history': self.metrics_history,\n",
    "            'best_metrics': self.best_metrics\n",
    "        }\n",
    "        \n",
    "        with open(save_path / 'performance_history.json', 'w') as f:\n",
    "            json.dump(history_data, f, indent=4)\n",
    "\n",
    "# Memory Management\n",
    "class ModelManager:\n",
    "    \"\"\"Context manager for model memory management\"\"\"\n",
    "    def __init__(self, model, tokenizer):\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __enter__(self):\n",
    "        return self.model, self.tokenizer\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        del self.model\n",
    "        del self.tokenizer\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# Error Handling\n",
    "def error_handler(func):\n",
    "    \"\"\"Decorator for consistent error handling\"\"\"\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in {func.__name__}: {str(e)}\")\n",
    "            raise\n",
    "    return wrapper\n",
    "\n",
    "# Utility Functions\n",
    "def get_memory_usage() -> float:\n",
    "    \"\"\"Get current memory usage of the program\"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    return process.memory_info().rss / 1024 / 1024  # in MB\n",
    "\n",
    "def log_memory(step_name: str) -> None:\n",
    "    \"\"\"Log memory usage with consistent format\"\"\"\n",
    "    memory = get_memory_usage()\n",
    "    logging.info(f\"Memory usage after {step_name}: {memory:.2f} MB\")\n",
    "\n",
    "def log_system_info() -> None:\n",
    "    \"\"\"Log system information including GPU details\"\"\"\n",
    "    logging.info(\"System Information:\")\n",
    "    logging.info(f\"Python Version: {sys.version}\")\n",
    "    logging.info(f\"CPU Count: {os.cpu_count()}\")\n",
    "    logging.info(f\"Initial Memory Usage: {get_memory_usage():.2f} MB\")\n",
    "    if torch.cuda.is_available():\n",
    "        logging.info(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
    "        logging.info(f\"GPU Memory Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        logging.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "\n",
    "# Create directories and setup logging\n",
    "if check_environment():\n",
    "    Config.create_directories()\n",
    "    Config.setup_logging()\n",
    "    log_system_info()\n",
    "else:\n",
    "    print(\"Failed to initialize environment. Please check the setup.\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5fac963",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T17:16:23.336515Z",
     "iopub.status.busy": "2025-02-16T17:16:23.336105Z",
     "iopub.status.idle": "2025-02-16T17:16:23.356366Z",
     "shell.execute_reply": "2025-02-16T17:16:23.355616Z"
    },
    "papermill": {
     "duration": 0.026237,
     "end_time": "2025-02-16T17:16:23.357741",
     "exception": false,
     "start_time": "2025-02-16T17:16:23.331504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAGIAN KEDUA - Dataset dan Data Processing\n",
    "\n",
    "class MovieDataset(Dataset):\n",
    "    \"\"\"Dataset class untuk movie genre classification\"\"\"\n",
    "    def __init__(self, texts: Union[List, np.ndarray],\n",
    "                 labels: Union[List, np.ndarray],\n",
    "                 tokenizer,\n",
    "                 max_length: int = 512):\n",
    "        # Input validation\n",
    "        if not isinstance(texts, (list, np.ndarray)):\n",
    "            raise ValueError(\"texts must be a list or numpy array\")\n",
    "        if not isinstance(labels, (list, np.ndarray)):\n",
    "            raise ValueError(\"labels must be a list or numpy array\")\n",
    "        if len(texts) != len(labels):\n",
    "            raise ValueError(\"texts and labels must have the same length\")\n",
    "\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        text = str(self.texts[idx])\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten().long(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten().long(),\n",
    "            'labels': torch.FloatTensor(self.labels[idx])\n",
    "        }\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Class for handling data preprocessing and loading\"\"\"\n",
    "    @staticmethod\n",
    "    def clean_text(text: str) -> str:\n",
    "        \"\"\"Clean and preprocess text data\"\"\"\n",
    "        if isinstance(text, str):\n",
    "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "            text = re.sub(r'\\S+@\\S+', '', text)\n",
    "            text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            return text.strip().lower()\n",
    "        return ''\n",
    "\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def load_and_preprocess_data(data_path: Path, sample_size: Optional[int] = None) -> pd.DataFrame:\n",
    "        \"\"\"Load and preprocess data with proper encoding handling\"\"\"\n",
    "        if not data_path.exists():\n",
    "            raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "\n",
    "        if sample_size is not None and (not isinstance(sample_size, int) or sample_size <= 0):\n",
    "            raise ValueError(\"sample_size must be a positive integer\")\n",
    "\n",
    "        logging.info(\"Loading and preprocessing data...\")\n",
    "        log_memory(\"start\")\n",
    "        initial_size = None\n",
    "\n",
    "        # Try different encodings for Google Drive compatibility\n",
    "        encodings_to_try = ['utf-8', 'utf-8-sig', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "        df = None\n",
    "\n",
    "        for encoding in encodings_to_try:\n",
    "            try:\n",
    "                df = pd.read_csv(data_path, encoding=encoding)\n",
    "                logging.info(f\"Successfully loaded data using {encoding} encoding\")\n",
    "                initial_size = len(df)\n",
    "                break\n",
    "            except (UnicodeDecodeError, UnicodeError):\n",
    "                continue\n",
    "\n",
    "        if df is None:\n",
    "            raise UnicodeError(f\"Failed to read file with any of these encodings: {encodings_to_try}\")\n",
    "\n",
    "        log_memory(\"data loading\")\n",
    "\n",
    "        # Sample data if requested\n",
    "        if sample_size:\n",
    "            if sample_size > initial_size:\n",
    "                logging.warning(f\"Requested sample_size ({sample_size}) is larger than dataset size ({initial_size})\")\n",
    "                sample_size = initial_size\n",
    "            logging.info(f\"Taking sample of {sample_size} from {initial_size} total samples\")\n",
    "            df = df.head(sample_size)\n",
    "        else:\n",
    "            logging.info(f\"Using full dataset with {initial_size} samples\")\n",
    "\n",
    "        # Log sample data\n",
    "        logging.info(\"\\nSample data:\")\n",
    "        for i, row in df.head(3).iterrows():\n",
    "            logging.info(f\"\\nSample {i+1}:\")\n",
    "            logging.info(f\"Synopsis: {row['sinopsis'][:100]}...\")\n",
    "            logging.info(f\"Genre: {row['genre']}\")\n",
    "\n",
    "        # Preprocess data\n",
    "        logging.info(\"\\nPreprocessing text data...\")\n",
    "        tqdm.pandas()\n",
    "        df['sinopsis'] = df['sinopsis'].progress_apply(DataProcessor.clean_text)\n",
    "        df['genre'] = df['genre'].str.split(',')\n",
    "        df = df.dropna(subset=['sinopsis', 'genre'])\n",
    "\n",
    "        log_memory(\"preprocessing\")\n",
    "        return df\n",
    "\n",
    "    @staticmethod\n",
    "    def prepare_data(df: pd.DataFrame, mlb: MultiLabelBinarizer) -> Tuple:\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        genre_labels = mlb.fit_transform(df['genre'])\n",
    "        return train_test_split(\n",
    "            df['sinopsis'].values,\n",
    "            genre_labels,\n",
    "            test_size=Config.MODEL_PARAMS['TEST_SIZE'],\n",
    "            random_state=42,\n",
    "            stratify=genre_labels if len(genre_labels.shape) == 1 else None\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def create_weighted_sampler(genre_labels: np.ndarray) -> WeightedRandomSampler:\n",
    "        \"\"\"Create weighted sampler for balanced batch sampling\"\"\"\n",
    "        logging.info(\"Creating weighted sampler for balanced batch sampling...\")\n",
    "\n",
    "        sample_weights = np.zeros(len(genre_labels))\n",
    "        for i in range(genre_labels.shape[1]):\n",
    "            sample_weights += genre_labels[:, i] * (1.0 / np.sum(genre_labels[:, i]))\n",
    "\n",
    "        sample_weights = sample_weights / sample_weights.sum()\n",
    "        sampler = WeightedRandomSampler(\n",
    "            weights=sample_weights,\n",
    "            num_samples=len(sample_weights),\n",
    "            replacement=True\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Created sampler with {len(sample_weights)} weights\")\n",
    "        return sampler\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_class_weights(genre_labels: np.ndarray, mlb: MultiLabelBinarizer) -> torch.Tensor:\n",
    "        \"\"\"Calculate class weights for handling imbalanced data\"\"\"\n",
    "        class_weights = []\n",
    "        logging.info(\"\\nCalculating class weights for handling imbalanced data...\")\n",
    "\n",
    "        for i in range(genre_labels.shape[1]):\n",
    "            genre = mlb.classes_[i]\n",
    "            positive_samples = np.sum(genre_labels[:, i])\n",
    "            total_samples = len(genre_labels)\n",
    "\n",
    "            weights = compute_class_weight(\n",
    "                class_weight='balanced',\n",
    "                classes=np.array([0, 1]),\n",
    "                y=genre_labels[:, i]\n",
    "            )\n",
    "            class_weights.append(weights[1])\n",
    "\n",
    "            logging.info(f\"{genre}:\")\n",
    "            logging.info(f\"  Positive samples: {positive_samples}\")\n",
    "            logging.info(f\"  Negative samples: {total_samples - positive_samples}\")\n",
    "            logging.info(f\"  Weight: {weights[1]:.2f}\")\n",
    "\n",
    "        return torch.FloatTensor(class_weights).to(Config.DEVICE)\n",
    "\n",
    "class ModelSetup:\n",
    "    \"\"\"Class for handling model setup and data loaders\"\"\"\n",
    "    @staticmethod\n",
    "    def setup_model_and_tokenizer(num_labels: int) -> Tuple:\n",
    "        \"\"\"Setup model dan tokenizer\"\"\"\n",
    "        logging.info(\"Setting up model and tokenizer...\")\n",
    "        tokenizer = AutoTokenizer.from_pretrained('indobenchmark/indobert-base-p1')\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            'indobenchmark/indobert-base-p1',\n",
    "            num_labels=num_labels,\n",
    "            problem_type=\"multi_label_classification\"\n",
    "        ).to(Config.DEVICE)\n",
    "        logging.info(\"Model and tokenizer setup completed\")\n",
    "        return model, tokenizer\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_dataloaders(X_train: np.ndarray,\n",
    "                         X_test: np.ndarray,\n",
    "                         y_train: np.ndarray,\n",
    "                         y_test: np.ndarray,\n",
    "                         tokenizer,\n",
    "                         batch_size: int) -> Tuple:\n",
    "        \"\"\"Setup data loaders\"\"\"\n",
    "        logging.info(\"Setting up data loaders...\")\n",
    "        train_dataset = MovieDataset(X_train, y_train, tokenizer)\n",
    "        val_dataset = MovieDataset(X_test, y_test, tokenizer)\n",
    "        sampler = DataProcessor.create_weighted_sampler(y_train)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=batch_size,\n",
    "            sampler=sampler,\n",
    "            num_workers=0,  # Set to 0 for Colab compatibility\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            num_workers=0,  # Set to 0 for Colab compatibility\n",
    "            pin_memory=True if torch.cuda.is_available() else False\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Created data loaders with batch size {batch_size}\")\n",
    "        return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe5aaf8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T17:16:23.366496Z",
     "iopub.status.busy": "2025-02-16T17:16:23.366263Z",
     "iopub.status.idle": "2025-02-16T17:16:23.391921Z",
     "shell.execute_reply": "2025-02-16T17:16:23.391315Z"
    },
    "papermill": {
     "duration": 0.031336,
     "end_time": "2025-02-16T17:16:23.393024",
     "exception": false,
     "start_time": "2025-02-16T17:16:23.361688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BAGIAN KETIGA - Loss Functions dan Training\n",
    "\n",
    "class LossFunctions:\n",
    "    \"\"\"Class untuk menangani berbagai loss functions\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def focal_loss(predictions: torch.Tensor,\n",
    "                  targets: torch.Tensor,\n",
    "                  gamma: float = 2.0,\n",
    "                  alpha: float = 0.25) -> torch.Tensor:\n",
    "        \"\"\"Calculate focal loss for multi-label classification\"\"\"\n",
    "        ce_loss = F.binary_cross_entropy_with_logits(predictions, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = alpha * (1-pt)**gamma * ce_loss\n",
    "        return focal_loss.mean()\n",
    "\n",
    "    @staticmethod\n",
    "    def label_smoothing_loss(outputs: torch.Tensor,\n",
    "                           targets: torch.Tensor,\n",
    "                           smoothing: float) -> torch.Tensor:\n",
    "        \"\"\"Calculate loss with label smoothing\"\"\"\n",
    "        log_probs = F.log_softmax(outputs, dim=-1)\n",
    "        targets = torch.clamp(targets * (1.0 - smoothing), min=smoothing / (targets.size(-1) - 1))\n",
    "        return torch.mean(torch.sum(-targets * log_probs, dim=-1))\n",
    "\n",
    "class DataAugmentation:\n",
    "    \"\"\"Class untuk menangani augmentasi data\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def apply_mixup(batch: Dict[str, torch.Tensor], alpha: float = 0.2) -> Dict[str, torch.Tensor]:\n",
    "        \"\"\"Apply mixup augmentation to batch\"\"\"\n",
    "        # Move tensors to device\n",
    "        input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "        labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        mixed_input_ids = lam * input_ids + (1 - lam) * input_ids.flip(0)\n",
    "        mixed_attention_mask = lam * attention_mask + (1 - lam) * attention_mask.flip(0)\n",
    "        mixed_labels = lam * labels + (1 - lam) * labels.flip(0)\n",
    "\n",
    "        return {\n",
    "            'input_ids': mixed_input_ids.long(),\n",
    "            'attention_mask': mixed_attention_mask.long(),\n",
    "            'labels': mixed_labels\n",
    "        }\n",
    "\n",
    "class Visualization:\n",
    "    \"\"\"Class untuk menangani visualisasi\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_confusion_matrices(predictions: np.ndarray,\n",
    "                              labels: np.ndarray,\n",
    "                              classes: List[str]) -> None:\n",
    "        \"\"\"Plot detailed confusion matrices for each genre\"\"\"\n",
    "        logging.info(\"Generating detailed confusion matrices for each genre...\")\n",
    "\n",
    "        # Pastikan input dalam format yang benar\n",
    "        predictions = np.array(predictions)\n",
    "        labels = np.array(labels)\n",
    "\n",
    "        if len(predictions.shape) == 1:\n",
    "            predictions = predictions.reshape(-1, 1)\n",
    "        if len(labels.shape) == 1:\n",
    "            labels = labels.reshape(-1, 1)\n",
    "\n",
    "        for i, genre in enumerate(classes):\n",
    "            try:\n",
    "                genre_preds = predictions[:, i]\n",
    "                genre_labels = labels[:, i]\n",
    "\n",
    "                # Calculate confusion matrix\n",
    "                cm = confusion_matrix(genre_labels, genre_preds)\n",
    "\n",
    "                # Extract values\n",
    "                TN, FP = cm[0]\n",
    "                FN, TP = cm[1]\n",
    "\n",
    "                # Calculate metrics\n",
    "                accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "                precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "                recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "                f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "                # Create plot\n",
    "                plt.figure(figsize=(12, 8))\n",
    "\n",
    "                # Main confusion matrix plot\n",
    "                main_ax = plt.subplot2grid((3, 3), (0, 0), rowspan=2, colspan=2)\n",
    "\n",
    "                # Plot heatmap\n",
    "                plot_labels = [f'Non-{genre}', genre]\n",
    "                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                          xticklabels=plot_labels,\n",
    "                          yticklabels=plot_labels,\n",
    "                          ax=main_ax)\n",
    "\n",
    "                main_ax.set_title(f'Confusion Matrix - {genre}')\n",
    "                main_ax.set_ylabel('True Label')\n",
    "                main_ax.set_xlabel('Predicted Label')\n",
    "\n",
    "                # Create text box for detailed metrics\n",
    "                plt.subplot2grid((3, 3), (0, 2), rowspan=3)\n",
    "                plt.axis('off')\n",
    "\n",
    "                metrics_text = [\n",
    "                    f'Detailed Metrics for {genre}:\\n',\n",
    "                    f'\\nConfusion Matrix Values:',\n",
    "                    f'True Negative (TN): {TN}',\n",
    "                    f'False Positive (FP): {FP}',\n",
    "                    f'False Negative (FN): {FN}',\n",
    "                    f'True Positive (TP): {TP}',\n",
    "                    f'\\nPerformance Metrics:',\n",
    "                    f'Accuracy: {accuracy:.3f}',\n",
    "                    f'Precision: {precision:.3f}',\n",
    "                    f'Recall: {recall:.3f}',\n",
    "                    f'F1 Score: {f1:.3f}',\n",
    "                    f'\\nAdditional Information:',\n",
    "                    f'Total Samples: {len(genre_labels)}',\n",
    "                    f'Positive Samples: {np.sum(genre_labels)}',\n",
    "                    f'Negative Samples: {len(genre_labels) - np.sum(genre_labels)}'\n",
    "                ]\n",
    "\n",
    "                plt.text(0, 0.95, '\\n'.join(metrics_text),\n",
    "                        fontsize=10,\n",
    "                        verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round,pad=1', facecolor='white', alpha=0.8))\n",
    "\n",
    "                # Add interpretation text\n",
    "                interpretation_ax = plt.subplot2grid((3, 3), (2, 0), colspan=2)\n",
    "                interpretation_ax.axis('off')\n",
    "\n",
    "                interpretation_text = [\n",
    "                    'Matrix Interpretation:',\n",
    "                    f'• Model correctly identified {TN} non-{genre} movies (True Negatives)',\n",
    "                    f'• Model correctly identified {TP} {genre} movies (True Positives)',\n",
    "                    f'• Model incorrectly classified {FP} non-{genre} movies as {genre} (False Positives)',\n",
    "                    f'• Model failed to identify {FN} {genre} movies (False Negatives)'\n",
    "                ]\n",
    "\n",
    "                interpretation_ax.text(0, 0.5, '\\n'.join(interpretation_text),\n",
    "                                    fontsize=9,\n",
    "                                    verticalalignment='center',\n",
    "                                    bbox=dict(boxstyle='round,pad=1', facecolor='lightyellow', alpha=0.3))\n",
    "\n",
    "                plt.tight_layout()\n",
    "                plot_path = Config.CM_DIR / f'confusion_matrix_{genre}.png'\n",
    "                plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "                plt.close()\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error plotting confusion matrix for genre {genre}: {str(e)}\")\n",
    "                continue\n",
    "\n",
    "        logging.info(f\"Confusion matrices saved in: {Config.CM_DIR}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def plot_training_history(history_data: Dict) -> None:\n",
    "        \"\"\"Plot and save training metrics\"\"\"\n",
    "        plt.figure(figsize=(15, 5))\n",
    "\n",
    "        # Plot Loss\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.plot(history_data['epochs'], history_data['training_loss'],\n",
    "                label='Training Loss', marker='o')\n",
    "        plt.plot(history_data['epochs'], history_data['validation_loss'],\n",
    "                label='Validation Loss', marker='o')\n",
    "        plt.title('Training History - Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Plot Accuracy\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.plot(history_data['epochs'], history_data['accuracy'],\n",
    "                label='Accuracy', marker='o', color='green')\n",
    "        plt.title('Training History - Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        # Plot Loss Difference\n",
    "        plt.subplot(1, 3, 3)\n",
    "        loss_diff = np.array(history_data['training_loss']) - np.array(history_data['validation_loss'])\n",
    "        plt.plot(history_data['epochs'], loss_diff,\n",
    "                label='Loss Difference', marker='o', color='red')\n",
    "        plt.title('Learning Curve (Train-Val Loss)')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Difference')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plot_path = Config.PLOTS_DIR / 'training_history.png'\n",
    "        plt.savefig(plot_path, dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        logging.info(f\"Saved training history plots to {plot_path}\")\n",
    "\n",
    "class ModelEvaluator:\n",
    "    \"\"\"Class untuk evaluasi model\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def evaluate_model(model: torch.nn.Module,\n",
    "                      val_loader: DataLoader,\n",
    "                      mlb: MultiLabelBinarizer,\n",
    "                      threshold_optimizer: DynamicThresholdOptimizer = None,\n",
    "                      performance_tracker: PerformanceTracker = None,\n",
    "                      epoch: int = None) -> Dict:\n",
    "        \"\"\"Evaluate model performance with dynamic thresholding\"\"\"\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        raw_predictions = []\n",
    "\n",
    "        logging.info(\"Starting model evaluation...\")\n",
    "        log_memory(\"evaluation start\")\n",
    "\n",
    "        try:\n",
    "            with torch.no_grad(), tqdm(val_loader, desc=\"Evaluating\") as pbar:\n",
    "                for batch in pbar:\n",
    "                    input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                    attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                    labels = batch['labels'].cpu().numpy()\n",
    "\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    logits = outputs.logits\n",
    "                    probs = torch.sigmoid(logits).cpu().numpy()\n",
    "                    \n",
    "                    raw_predictions.extend(probs)\n",
    "                    all_labels.extend(labels)\n",
    "\n",
    "            raw_predictions = np.array(raw_predictions)\n",
    "            all_labels = np.array(all_labels)\n",
    "\n",
    "            # Apply dynamic thresholding if available\n",
    "            if threshold_optimizer is not None:\n",
    "                threshold_optimizer.optimize_thresholds(all_labels, raw_predictions, mlb.classes_)\n",
    "                all_preds = threshold_optimizer.apply_thresholds(raw_predictions)\n",
    "            else:\n",
    "                all_preds = (raw_predictions > 0.5).astype(int)\n",
    "\n",
    "            # Update performance tracker if available\n",
    "            if performance_tracker is not None and epoch is not None:\n",
    "                performance_tracker.update_metrics(all_labels, all_preds, epoch)\n",
    "\n",
    "            # Calculate all metrics\n",
    "            correct_predictions = np.sum(all_preds == all_labels)\n",
    "            total_predictions = all_labels.size\n",
    "            accuracy = correct_predictions / total_predictions\n",
    "\n",
    "            # Calculate per-genre metrics\n",
    "            genre_metrics = ModelEvaluator._calculate_genre_metrics(\n",
    "                all_preds, all_labels, mlb.classes_\n",
    "            )\n",
    "\n",
    "            # Calculate macro metrics\n",
    "            macro_metrics = ModelEvaluator._calculate_macro_metrics(genre_metrics)\n",
    "\n",
    "            # Save metrics\n",
    "            evaluation_metrics = {\n",
    "                'overall': macro_metrics,\n",
    "                'per_genre': genre_metrics\n",
    "            }\n",
    "\n",
    "            metrics_file = Config.METRICS_DIR / 'evaluation_metrics.json'\n",
    "            with open(metrics_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(evaluation_metrics, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            # Plot confusion matrices\n",
    "            Visualization.plot_confusion_matrices(all_preds, all_labels, mlb.classes_)\n",
    "\n",
    "            log_memory(\"evaluation end\")\n",
    "\n",
    "            return {\n",
    "                'accuracy': float(accuracy),\n",
    "                'macro_f1': float(macro_metrics['macro_f1']),\n",
    "                'genre_metrics': genre_metrics,\n",
    "                'raw_predictions': raw_predictions,\n",
    "                'true_labels': all_labels\n",
    "            }\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during model evaluation: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_macro_metrics(genre_metrics: Dict) -> Dict:\n",
    "        \"\"\"Calculate macro-averaged metrics\"\"\"\n",
    "        return {\n",
    "            'accuracy': np.mean([metrics['accuracy'] for metrics in genre_metrics.values()]),\n",
    "            'macro_f1': np.mean([metrics['f1_score'] for metrics in genre_metrics.values()]),\n",
    "            'macro_precision': np.mean([metrics['precision'] for metrics in genre_metrics.values()]),\n",
    "            'macro_recall': np.mean([metrics['recall'] for metrics in genre_metrics.values()])\n",
    "        }\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_genre_metrics(predictions: np.ndarray,\n",
    "                               labels: np.ndarray,\n",
    "                               classes: List[str]) -> Dict:\n",
    "        \"\"\"Calculate metrics for each genre\"\"\"\n",
    "        genre_metrics = {}\n",
    "        logging.info(\"\\nPer-genre Performance Metrics:\")\n",
    "\n",
    "        for i, genre in enumerate(classes):\n",
    "            genre_preds = predictions[:, i]\n",
    "            genre_labels = labels[:, i]\n",
    "\n",
    "            metrics = {\n",
    "                'accuracy': float(np.mean(genre_preds == genre_labels)),\n",
    "                'f1_score': float(f1_score(genre_labels, genre_preds, zero_division=0)),\n",
    "                'precision': float(precision_score(genre_labels, genre_preds, zero_division=0)),\n",
    "                'recall': float(recall_score(genre_labels, genre_preds, zero_division=0))\n",
    "            }\n",
    "\n",
    "            genre_metrics[genre] = metrics\n",
    "            logging.info(f\"\\nMetrics for {genre}:\")\n",
    "            for metric_name, value in metrics.items():\n",
    "                logging.info(f\"{metric_name.capitalize()}: {value:.4f}\")\n",
    "\n",
    "        return genre_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eabe29c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T17:16:23.401940Z",
     "iopub.status.busy": "2025-02-16T17:16:23.401742Z",
     "iopub.status.idle": "2025-02-16T19:51:00.335322Z",
     "shell.execute_reply": "2025-02-16T19:51:00.334292Z"
    },
    "papermill": {
     "duration": 9278.477124,
     "end_time": "2025-02-16T19:51:01.873991",
     "exception": false,
     "start_time": "2025-02-16T17:16:23.396867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files in dataset directory:\n",
      "- final_combined_movies_5genres.csv\n",
      "GPU tersedia: Tesla T4\n",
      "GPU Memory: 15.83 GB\n",
      "2025-02-16 17:16:23,459 - INFO - System Information:\n",
      "2025-02-16 17:16:23,461 - INFO - Python Version: 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      "2025-02-16 17:16:23,461 - INFO - CPU Count: 4\n",
      "2025-02-16 17:16:23,463 - INFO - Initial Memory Usage: 635.78 MB\n",
      "2025-02-16 17:16:23,463 - INFO - GPU Device: Tesla T4\n",
      "2025-02-16 17:16:23,464 - INFO - GPU Memory Total: 15.83 GB\n",
      "2025-02-16 17:16:23,465 - INFO - CUDA Version: 12.1\n",
      "2025-02-16 17:16:23,466 - INFO - Starting movie genre classification with hyperparameter optimization\n",
      "2025-02-16 17:16:23,466 - INFO - Using device: cuda\n",
      "2025-02-16 17:16:23,467 - INFO - \n",
      "Initial Configuration:\n",
      "2025-02-16 17:16:23,468 - INFO - Sample Size: Full Dataset\n",
      "2025-02-16 17:16:23,468 - INFO - EPOCHS: 100\n",
      "2025-02-16 17:16:23,469 - INFO - BATCH_SIZE: 10\n",
      "2025-02-16 17:16:23,470 - INFO - LEARNING_RATE: 1e-05\n",
      "2025-02-16 17:16:23,470 - INFO - MAX_LENGTH: 512\n",
      "2025-02-16 17:16:23,471 - INFO - TEST_SIZE: 0.15\n",
      "2025-02-16 17:16:23,472 - INFO - WEIGHT_DECAY: 0.05\n",
      "2025-02-16 17:16:23,472 - INFO - MIXUP_PROB: 0.5\n",
      "2025-02-16 17:16:23,476 - INFO - PATIENCE: 5\n",
      "2025-02-16 17:16:23,476 - INFO - SMOOTHING: 0.2\n",
      "2025-02-16 17:16:23,477 - INFO - \n",
      "Loading and preprocessing data...\n",
      "2025-02-16 17:16:23,479 - INFO - Loading and preprocessing data...\n",
      "2025-02-16 17:16:23,480 - INFO - Memory usage after start: 635.78 MB\n",
      "2025-02-16 17:16:23,530 - INFO - Successfully loaded data using utf-8 encoding\n",
      "2025-02-16 17:16:23,531 - INFO - Memory usage after data loading: 638.22 MB\n",
      "2025-02-16 17:16:23,532 - INFO - Using full dataset with 1738 samples\n",
      "2025-02-16 17:16:23,533 - INFO - \n",
      "Sample data:\n",
      "2025-02-16 17:16:23,535 - INFO - \n",
      "Sample 1:\n",
      "2025-02-16 17:16:23,540 - INFO - Synopsis: Setelah kematian yang tampak, Siena mampu melihat tanda-tanda bahwa orang-orang akan meninggal. Namu...\n",
      "2025-02-16 17:16:23,541 - INFO - Genre: Horor\n",
      "2025-02-16 17:16:23,542 - INFO - \n",
      "Sample 2:\n",
      "2025-02-16 17:16:23,543 - INFO - Synopsis: Alfi (Al Ghazali) bertemu dengan Alana (Caitlin Halderman), seorang siswa baru di sekolahnya. Ternya...\n",
      "2025-02-16 17:16:23,545 - INFO - Genre: Drama\n",
      "2025-02-16 17:16:23,546 - INFO - \n",
      "Sample 3:\n",
      "2025-02-16 17:16:23,547 - INFO - Synopsis: Ketika gaji staf di sekolahnya dicuri, seorang guru baru yang enggan berusaha untuk mendapatkan kemb...\n",
      "2025-02-16 17:16:23,548 - INFO - Genre: Komedi\n",
      "2025-02-16 17:16:23,550 - INFO - \n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1738/1738 [00:00<00:00, 13716.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:16:23,697 - INFO - Memory usage after preprocessing: 639.85 MB\n",
      "2025-02-16 17:16:23,698 - INFO - \n",
      "Starting hyperparameter optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[I 2025-02-16 17:16:23,699] A new study created in memory with name: no-name-a3e650c4-ac39-4d78-8311-833087d97fd0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:16:23,701 - INFO - Starting hyperparameter optimization...\n",
      "2025-02-16 17:16:23,703 - INFO - Trial parameter set: {'batch_size': 4, 'learning_rate': 3e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}\n",
      "2025-02-16 17:16:23,709 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ef4724843e475c96480c500e6baccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36509814834e4726b2db216d649078b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc86b2b704e4dc391829a67615f6cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/229k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc2c563852f4de99c8b0394f68ab15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08fc270eff94458481bb332b5228ace2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/498M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:16:46,515 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 17:16:46,517 - INFO - Setting up data loaders...\n",
      "2025-02-16 17:16:46,517 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 17:16:46,520 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 17:16:46,522 - INFO - Created data loaders with batch size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:19:11,092 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:19:11,094 - INFO - Memory usage after evaluation start: 1717.90 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:19:18,874 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:19:18,884 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:19:18,885 - INFO - Accuracy: 0.4559\n",
      "2025-02-16 17:19:18,885 - INFO - F1_score: 0.4621\n",
      "2025-02-16 17:19:18,887 - INFO - Precision: 0.3211\n",
      "2025-02-16 17:19:18,887 - INFO - Recall: 0.8243\n",
      "2025-02-16 17:19:18,893 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:19:18,894 - INFO - Accuracy: 0.7280\n",
      "2025-02-16 17:19:18,894 - INFO - F1_score: 0.5644\n",
      "2025-02-16 17:19:18,895 - INFO - Precision: 0.4340\n",
      "2025-02-16 17:19:18,897 - INFO - Recall: 0.8070\n",
      "2025-02-16 17:19:18,903 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:19:18,903 - INFO - Accuracy: 0.6207\n",
      "2025-02-16 17:19:18,904 - INFO - F1_score: 0.4072\n",
      "2025-02-16 17:19:18,905 - INFO - Precision: 0.3119\n",
      "2025-02-16 17:19:18,905 - INFO - Recall: 0.5862\n",
      "2025-02-16 17:19:18,912 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:19:18,913 - INFO - Accuracy: 0.2912\n",
      "2025-02-16 17:19:18,913 - INFO - F1_score: 0.2570\n",
      "2025-02-16 17:19:18,914 - INFO - Precision: 0.1517\n",
      "2025-02-16 17:19:18,915 - INFO - Recall: 0.8421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:19:18,922 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:19:18,923 - INFO - Accuracy: 0.7969\n",
      "2025-02-16 17:19:18,924 - INFO - F1_score: 0.3614\n",
      "2025-02-16 17:19:18,924 - INFO - Precision: 0.3061\n",
      "2025-02-16 17:19:18,925 - INFO - Recall: 0.4412\n",
      "2025-02-16 17:19:18,928 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 17:19:23,794 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:19:23,796 - INFO - Memory usage after evaluation end: 1759.54 MB\n",
      "2025-02-16 17:19:23,796 - INFO - Trial 0, Epoch 1: Loss = 1.5835, F1 = 0.4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:21:51,707 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:21:51,709 - INFO - Memory usage after evaluation start: 1759.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:21:59,557 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:21:59,562 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:21:59,563 - INFO - Accuracy: 0.5862\n",
      "2025-02-16 17:21:59,564 - INFO - F1_score: 0.5000\n",
      "2025-02-16 17:21:59,564 - INFO - Precision: 0.3803\n",
      "2025-02-16 17:21:59,565 - INFO - Recall: 0.7297\n",
      "2025-02-16 17:21:59,571 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:21:59,572 - INFO - Accuracy: 0.7280\n",
      "2025-02-16 17:21:59,573 - INFO - F1_score: 0.6077\n",
      "2025-02-16 17:21:59,573 - INFO - Precision: 0.4435\n",
      "2025-02-16 17:21:59,574 - INFO - Recall: 0.9649\n",
      "2025-02-16 17:21:59,580 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:21:59,581 - INFO - Accuracy: 0.4828\n",
      "2025-02-16 17:21:59,581 - INFO - F1_score: 0.4255\n",
      "2025-02-16 17:21:59,582 - INFO - Precision: 0.2825\n",
      "2025-02-16 17:21:59,584 - INFO - Recall: 0.8621\n",
      "2025-02-16 17:21:59,589 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:21:59,590 - INFO - Accuracy: 0.5594\n",
      "2025-02-16 17:21:59,591 - INFO - F1_score: 0.3114\n",
      "2025-02-16 17:21:59,591 - INFO - Precision: 0.2016\n",
      "2025-02-16 17:21:59,593 - INFO - Recall: 0.6842\n",
      "2025-02-16 17:21:59,599 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:21:59,600 - INFO - Accuracy: 0.6782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:21:59,600 - INFO - F1_score: 0.3636\n",
      "2025-02-16 17:21:59,602 - INFO - Precision: 0.2449\n",
      "2025-02-16 17:21:59,603 - INFO - Recall: 0.7059\n",
      "2025-02-16 17:21:59,605 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 17:22:03,803 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:22:03,804 - INFO - Memory usage after evaluation end: 1784.99 MB\n",
      "2025-02-16 17:22:03,806 - INFO - Trial 0, Epoch 2: Loss = 1.4657, F1 = 0.4417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:24:31,689 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:24:31,691 - INFO - Memory usage after evaluation start: 1785.87 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:24:39,521 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:24:39,528 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:24:39,529 - INFO - Accuracy: 0.5326\n",
      "2025-02-16 17:24:39,529 - INFO - F1_score: 0.5041\n",
      "2025-02-16 17:24:39,530 - INFO - Precision: 0.3605\n",
      "2025-02-16 17:24:39,532 - INFO - Recall: 0.8378\n",
      "2025-02-16 17:24:39,539 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:24:39,539 - INFO - Accuracy: 0.7816\n",
      "2025-02-16 17:24:39,540 - INFO - F1_score: 0.6545\n",
      "2025-02-16 17:24:39,541 - INFO - Precision: 0.5000\n",
      "2025-02-16 17:24:39,543 - INFO - Recall: 0.9474\n",
      "2025-02-16 17:24:39,551 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:24:39,551 - INFO - Accuracy: 0.3793\n",
      "2025-02-16 17:24:39,552 - INFO - F1_score: 0.4044\n",
      "2025-02-16 17:24:39,553 - INFO - Precision: 0.2570\n",
      "2025-02-16 17:24:39,553 - INFO - Recall: 0.9483\n",
      "2025-02-16 17:24:39,561 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:24:39,562 - INFO - Accuracy: 0.7816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:24:39,563 - INFO - F1_score: 0.4124\n",
      "2025-02-16 17:24:39,564 - INFO - Precision: 0.3390\n",
      "2025-02-16 17:24:39,566 - INFO - Recall: 0.5263\n",
      "2025-02-16 17:24:39,573 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:24:39,574 - INFO - Accuracy: 0.6398\n",
      "2025-02-16 17:24:39,574 - INFO - F1_score: 0.3380\n",
      "2025-02-16 17:24:39,576 - INFO - Precision: 0.2222\n",
      "2025-02-16 17:24:39,577 - INFO - Recall: 0.7059\n",
      "2025-02-16 17:24:39,579 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 17:24:43,774 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:24:43,775 - INFO - Memory usage after evaluation end: 1813.56 MB\n",
      "2025-02-16 17:24:43,776 - INFO - Trial 0, Epoch 3: Loss = 1.3669, F1 = 0.4627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 17:24:44,815] Trial 0 finished with value: 0.46268431258728926 and parameters: {'batch_size': 4, 'learning_rate': 3e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 0 with value: 0.46268431258728926.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:24:45,126 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}\n",
      "2025-02-16 17:24:45,130 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:24:46,101 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 17:24:46,102 - INFO - Setting up data loaders...\n",
      "2025-02-16 17:24:46,103 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 17:24:46,105 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 17:24:46,106 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:27:32,165 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:27:32,168 - INFO - Memory usage after evaluation start: 1905.47 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:27:40,135 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:27:40,142 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:27:40,143 - INFO - Accuracy: 0.5785\n",
      "2025-02-16 17:27:40,144 - INFO - F1_score: 0.4860\n",
      "2025-02-16 17:27:40,144 - INFO - Precision: 0.3714\n",
      "2025-02-16 17:27:40,145 - INFO - Recall: 0.7027\n",
      "2025-02-16 17:27:40,152 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:27:40,152 - INFO - Accuracy: 0.8774\n",
      "2025-02-16 17:27:40,154 - INFO - F1_score: 0.7714\n",
      "2025-02-16 17:27:40,155 - INFO - Precision: 0.6506\n",
      "2025-02-16 17:27:40,155 - INFO - Recall: 0.9474\n",
      "2025-02-16 17:27:40,163 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:27:40,163 - INFO - Accuracy: 0.3410\n",
      "2025-02-16 17:27:40,164 - INFO - F1_score: 0.3723\n",
      "2025-02-16 17:27:40,165 - INFO - Precision: 0.2361\n",
      "2025-02-16 17:27:40,166 - INFO - Recall: 0.8793\n",
      "2025-02-16 17:27:40,173 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:27:40,174 - INFO - Accuracy: 0.6130\n",
      "2025-02-16 17:27:40,174 - INFO - F1_score: 0.3484\n",
      "2025-02-16 17:27:40,175 - INFO - Precision: 0.2308\n",
      "2025-02-16 17:27:40,177 - INFO - Recall: 0.7105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:27:40,184 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:27:40,184 - INFO - Accuracy: 0.8123\n",
      "2025-02-16 17:27:40,185 - INFO - F1_score: 0.4235\n",
      "2025-02-16 17:27:40,186 - INFO - Precision: 0.3529\n",
      "2025-02-16 17:27:40,186 - INFO - Recall: 0.5294\n",
      "2025-02-16 17:27:40,189 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 17:27:44,511 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:27:44,512 - INFO - Memory usage after evaluation end: 1925.59 MB\n",
      "2025-02-16 17:27:44,514 - INFO - Trial 1, Epoch 1: Loss = 1.4730, F1 = 0.4803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:30:31,354 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:30:31,355 - INFO - Memory usage after evaluation start: 1925.59 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:30:39,310 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:30:39,317 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:30:39,317 - INFO - Accuracy: 0.4253\n",
      "2025-02-16 17:30:39,318 - INFO - F1_score: 0.4755\n",
      "2025-02-16 17:30:39,319 - INFO - Precision: 0.3208\n",
      "2025-02-16 17:30:39,319 - INFO - Recall: 0.9189\n",
      "2025-02-16 17:30:39,326 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:30:39,327 - INFO - Accuracy: 0.7586\n",
      "2025-02-16 17:30:39,328 - INFO - F1_score: 0.6316\n",
      "2025-02-16 17:30:39,329 - INFO - Precision: 0.4737\n",
      "2025-02-16 17:30:39,329 - INFO - Recall: 0.9474\n",
      "2025-02-16 17:30:39,336 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:30:39,336 - INFO - Accuracy: 0.5096\n",
      "2025-02-16 17:30:39,337 - INFO - F1_score: 0.4336\n",
      "2025-02-16 17:30:39,337 - INFO - Precision: 0.2917\n",
      "2025-02-16 17:30:39,338 - INFO - Recall: 0.8448\n",
      "2025-02-16 17:30:39,344 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:30:39,345 - INFO - Accuracy: 0.7318\n",
      "2025-02-16 17:30:39,346 - INFO - F1_score: 0.3636\n",
      "2025-02-16 17:30:39,347 - INFO - Precision: 0.2778\n",
      "2025-02-16 17:30:39,348 - INFO - Recall: 0.5263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:30:39,355 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:30:39,356 - INFO - Accuracy: 0.8084\n",
      "2025-02-16 17:30:39,357 - INFO - F1_score: 0.4444\n",
      "2025-02-16 17:30:39,359 - INFO - Precision: 0.3571\n",
      "2025-02-16 17:30:39,360 - INFO - Recall: 0.5882\n",
      "2025-02-16 17:30:39,362 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 17:30:43,440 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:30:43,442 - INFO - Memory usage after evaluation end: 1916.01 MB\n",
      "2025-02-16 17:30:43,443 - INFO - Trial 1, Epoch 2: Loss = 1.2482, F1 = 0.4698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:33:29,747 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:33:29,749 - INFO - Memory usage after evaluation start: 1916.01 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:33:37,670 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:33:37,676 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:33:37,677 - INFO - Accuracy: 0.3640\n",
      "2025-02-16 17:33:37,678 - INFO - F1_score: 0.4575\n",
      "2025-02-16 17:33:37,679 - INFO - Precision: 0.3017\n",
      "2025-02-16 17:33:37,680 - INFO - Recall: 0.9459\n",
      "2025-02-16 17:33:37,686 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:33:37,686 - INFO - Accuracy: 0.7816\n",
      "2025-02-16 17:33:37,687 - INFO - F1_score: 0.6545\n",
      "2025-02-16 17:33:37,688 - INFO - Precision: 0.5000\n",
      "2025-02-16 17:33:37,689 - INFO - Recall: 0.9474\n",
      "2025-02-16 17:33:37,695 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:33:37,696 - INFO - Accuracy: 0.7280\n",
      "2025-02-16 17:33:37,696 - INFO - F1_score: 0.5298\n",
      "2025-02-16 17:33:37,697 - INFO - Precision: 0.4301\n",
      "2025-02-16 17:33:37,699 - INFO - Recall: 0.6897\n",
      "2025-02-16 17:33:37,704 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:33:37,705 - INFO - Accuracy: 0.7931\n",
      "2025-02-16 17:33:37,705 - INFO - F1_score: 0.4000\n",
      "2025-02-16 17:33:37,706 - INFO - Precision: 0.3462\n",
      "2025-02-16 17:33:37,707 - INFO - Recall: 0.4737\n",
      "2025-02-16 17:33:37,713 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:33:37,713 - INFO - Accuracy: 0.7893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:33:37,714 - INFO - F1_score: 0.4554\n",
      "2025-02-16 17:33:37,715 - INFO - Precision: 0.3433\n",
      "2025-02-16 17:33:37,715 - INFO - Recall: 0.6765\n",
      "2025-02-16 17:33:37,718 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 17:33:41,827 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:33:41,828 - INFO - Memory usage after evaluation end: 1932.70 MB\n",
      "2025-02-16 17:33:41,829 - INFO - Trial 1, Epoch 3: Loss = 1.1208, F1 = 0.4995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 17:33:42,997] Trial 1 finished with value: 0.49946173269450045 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}. Best is trial 1 with value: 0.49946173269450045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:33:43,370 - INFO - Trial parameter set: {'batch_size': 4, 'learning_rate': 5e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-16 17:33:43,374 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:33:44,267 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 17:33:44,268 - INFO - Setting up data loaders...\n",
      "2025-02-16 17:33:44,269 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 17:33:44,270 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 17:33:44,271 - INFO - Created data loaders with batch size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:36:11,861 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:36:11,863 - INFO - Memory usage after evaluation start: 1934.09 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:36:19,706 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:36:19,714 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:36:19,714 - INFO - Accuracy: 0.5479\n",
      "2025-02-16 17:36:19,715 - INFO - F1_score: 0.5124\n",
      "2025-02-16 17:36:19,716 - INFO - Precision: 0.3690\n",
      "2025-02-16 17:36:19,716 - INFO - Recall: 0.8378\n",
      "2025-02-16 17:36:19,723 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:36:19,723 - INFO - Accuracy: 0.7548\n",
      "2025-02-16 17:36:19,724 - INFO - F1_score: 0.6322\n",
      "2025-02-16 17:36:19,725 - INFO - Precision: 0.4701\n",
      "2025-02-16 17:36:19,725 - INFO - Recall: 0.9649\n",
      "2025-02-16 17:36:19,732 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:36:19,732 - INFO - Accuracy: 0.4291\n",
      "2025-02-16 17:36:19,733 - INFO - F1_score: 0.4157\n",
      "2025-02-16 17:36:19,733 - INFO - Precision: 0.2690\n",
      "2025-02-16 17:36:19,734 - INFO - Recall: 0.9138\n",
      "2025-02-16 17:36:19,740 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:36:19,740 - INFO - Accuracy: 0.7816\n",
      "2025-02-16 17:36:19,741 - INFO - F1_score: 0.3736\n",
      "2025-02-16 17:36:19,742 - INFO - Precision: 0.3208\n",
      "2025-02-16 17:36:19,742 - INFO - Recall: 0.4474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:36:19,749 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:36:19,750 - INFO - Accuracy: 0.4023\n",
      "2025-02-16 17:36:19,751 - INFO - F1_score: 0.2844\n",
      "2025-02-16 17:36:19,751 - INFO - Precision: 0.1685\n",
      "2025-02-16 17:36:19,752 - INFO - Recall: 0.9118\n",
      "2025-02-16 17:36:19,755 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 17:36:23,845 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:36:23,846 - INFO - Memory usage after evaluation end: 1938.79 MB\n",
      "2025-02-16 17:36:23,847 - INFO - Trial 2, Epoch 1: Loss = 1.5212, F1 = 0.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:38:51,888 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:38:51,890 - INFO - Memory usage after evaluation start: 1938.79 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:38:59,722 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:38:59,728 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:38:59,729 - INFO - Accuracy: 0.4904\n",
      "2025-02-16 17:38:59,729 - INFO - F1_score: 0.4981\n",
      "2025-02-16 17:38:59,730 - INFO - Precision: 0.3455\n",
      "2025-02-16 17:38:59,731 - INFO - Recall: 0.8919\n",
      "2025-02-16 17:38:59,737 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:38:59,738 - INFO - Accuracy: 0.7701\n",
      "2025-02-16 17:38:59,738 - INFO - F1_score: 0.6429\n",
      "2025-02-16 17:38:59,740 - INFO - Precision: 0.4865\n",
      "2025-02-16 17:38:59,740 - INFO - Recall: 0.9474\n",
      "2025-02-16 17:38:59,746 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:38:59,747 - INFO - Accuracy: 0.5939\n",
      "2025-02-16 17:38:59,748 - INFO - F1_score: 0.4592\n",
      "2025-02-16 17:38:59,749 - INFO - Precision: 0.3261\n",
      "2025-02-16 17:38:59,750 - INFO - Recall: 0.7759\n",
      "2025-02-16 17:38:59,755 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:38:59,756 - INFO - Accuracy: 0.7548\n",
      "2025-02-16 17:38:59,756 - INFO - F1_score: 0.4074\n",
      "2025-02-16 17:38:59,757 - INFO - Precision: 0.3143\n",
      "2025-02-16 17:38:59,758 - INFO - Recall: 0.5789\n",
      "2025-02-16 17:38:59,764 - INFO - \n",
      "Metrics for Romantis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:38:59,765 - INFO - Accuracy: 0.5594\n",
      "2025-02-16 17:38:59,766 - INFO - F1_score: 0.3353\n",
      "2025-02-16 17:38:59,767 - INFO - Precision: 0.2086\n",
      "2025-02-16 17:38:59,768 - INFO - Recall: 0.8529\n",
      "2025-02-16 17:38:59,770 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 17:39:03,871 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:39:03,872 - INFO - Memory usage after evaluation end: 1955.17 MB\n",
      "2025-02-16 17:39:03,873 - INFO - Trial 2, Epoch 2: Loss = 1.3426, F1 = 0.4686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:41:31,818 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:41:31,819 - INFO - Memory usage after evaluation start: 1955.17 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:41:39,671 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:41:39,682 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:41:39,683 - INFO - Accuracy: 0.4215\n",
      "2025-02-16 17:41:39,684 - INFO - F1_score: 0.4811\n",
      "2025-02-16 17:41:39,685 - INFO - Precision: 0.3226\n",
      "2025-02-16 17:41:39,686 - INFO - Recall: 0.9459\n",
      "2025-02-16 17:41:39,696 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:41:39,697 - INFO - Accuracy: 0.8238\n",
      "2025-02-16 17:41:39,698 - INFO - F1_score: 0.6933\n",
      "2025-02-16 17:41:39,699 - INFO - Precision: 0.5591\n",
      "2025-02-16 17:41:39,701 - INFO - Recall: 0.9123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:41:39,713 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:41:39,714 - INFO - Accuracy: 0.3678\n",
      "2025-02-16 17:41:39,715 - INFO - F1_score: 0.4043\n",
      "2025-02-16 17:41:39,716 - INFO - Precision: 0.2557\n",
      "2025-02-16 17:41:39,718 - INFO - Recall: 0.9655\n",
      "2025-02-16 17:41:39,728 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:41:39,729 - INFO - Accuracy: 0.7816\n",
      "2025-02-16 17:41:39,730 - INFO - F1_score: 0.4356\n",
      "2025-02-16 17:41:39,732 - INFO - Precision: 0.3492\n",
      "2025-02-16 17:41:39,733 - INFO - Recall: 0.5789\n",
      "2025-02-16 17:41:39,740 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:41:39,741 - INFO - Accuracy: 0.8046\n",
      "2025-02-16 17:41:39,742 - INFO - F1_score: 0.4742\n",
      "2025-02-16 17:41:39,744 - INFO - Precision: 0.3651\n",
      "2025-02-16 17:41:39,744 - INFO - Recall: 0.6765\n",
      "2025-02-16 17:41:39,746 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 17:41:43,927 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:41:43,929 - INFO - Memory usage after evaluation end: 1984.06 MB\n",
      "2025-02-16 17:41:43,929 - INFO - Trial 2, Epoch 3: Loss = 1.2313, F1 = 0.4977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 17:41:45,308] Trial 2 finished with value: 0.49772709762695355 and parameters: {'batch_size': 4, 'learning_rate': 5e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}. Best is trial 1 with value: 0.49946173269450045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:41:45,776 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}\n",
      "2025-02-16 17:41:45,781 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:41:46,658 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 17:41:46,660 - INFO - Setting up data loaders...\n",
      "2025-02-16 17:41:46,661 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 17:41:46,663 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 17:41:46,664 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:44:04,741 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:44:04,743 - INFO - Memory usage after evaluation start: 2142.91 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:44:12,097 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:44:12,103 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:44:12,104 - INFO - Accuracy: 0.4636\n",
      "2025-02-16 17:44:12,104 - INFO - F1_score: 0.4815\n",
      "2025-02-16 17:44:12,106 - INFO - Precision: 0.3316\n",
      "2025-02-16 17:44:12,107 - INFO - Recall: 0.8784\n",
      "2025-02-16 17:44:12,112 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:44:12,113 - INFO - Accuracy: 0.7433\n",
      "2025-02-16 17:44:12,113 - INFO - F1_score: 0.5732\n",
      "2025-02-16 17:44:12,114 - INFO - Precision: 0.4500\n",
      "2025-02-16 17:44:12,116 - INFO - Recall: 0.7895\n",
      "2025-02-16 17:44:12,121 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:44:12,122 - INFO - Accuracy: 0.3678\n",
      "2025-02-16 17:44:12,122 - INFO - F1_score: 0.4000\n",
      "2025-02-16 17:44:12,123 - INFO - Precision: 0.2535\n",
      "2025-02-16 17:44:12,124 - INFO - Recall: 0.9483\n",
      "2025-02-16 17:44:12,130 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:44:12,130 - INFO - Accuracy: 0.5057\n",
      "2025-02-16 17:44:12,131 - INFO - F1_score: 0.3385\n",
      "2025-02-16 17:44:12,132 - INFO - Precision: 0.2102\n",
      "2025-02-16 17:44:12,133 - INFO - Recall: 0.8684\n",
      "2025-02-16 17:44:12,138 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:44:12,139 - INFO - Accuracy: 0.7203\n",
      "2025-02-16 17:44:12,141 - INFO - F1_score: 0.3652\n",
      "2025-02-16 17:44:12,142 - INFO - Precision: 0.2593\n",
      "2025-02-16 17:44:12,142 - INFO - Recall: 0.6176\n",
      "2025-02-16 17:44:12,144 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:44:16,084 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:44:16,086 - INFO - Memory usage after evaluation end: 2146.66 MB\n",
      "2025-02-16 17:44:16,086 - INFO - Trial 3, Epoch 1: Loss = 1.5504, F1 = 0.4317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:46:34,179 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:46:34,181 - INFO - Memory usage after evaluation start: 2146.66 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:46:41,555 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:46:41,561 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:46:41,561 - INFO - Accuracy: 0.4828\n",
      "2025-02-16 17:46:41,562 - INFO - F1_score: 0.4867\n",
      "2025-02-16 17:46:41,563 - INFO - Precision: 0.3386\n",
      "2025-02-16 17:46:41,563 - INFO - Recall: 0.8649\n",
      "2025-02-16 17:46:41,569 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:46:41,570 - INFO - Accuracy: 0.7280\n",
      "2025-02-16 17:46:41,570 - INFO - F1_score: 0.6034\n",
      "2025-02-16 17:46:41,572 - INFO - Precision: 0.4426\n",
      "2025-02-16 17:46:41,572 - INFO - Recall: 0.9474\n",
      "2025-02-16 17:46:41,578 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:46:41,579 - INFO - Accuracy: 0.6284\n",
      "2025-02-16 17:46:41,579 - INFO - F1_score: 0.4757\n",
      "2025-02-16 17:46:41,580 - INFO - Precision: 0.3465\n",
      "2025-02-16 17:46:41,581 - INFO - Recall: 0.7586\n",
      "2025-02-16 17:46:41,587 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:46:41,588 - INFO - Accuracy: 0.6743\n",
      "2025-02-16 17:46:41,588 - INFO - F1_score: 0.3796\n",
      "2025-02-16 17:46:41,589 - INFO - Precision: 0.2626\n",
      "2025-02-16 17:46:41,589 - INFO - Recall: 0.6842\n",
      "2025-02-16 17:46:41,596 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:46:41,596 - INFO - Accuracy: 0.7280\n",
      "2025-02-16 17:46:41,597 - INFO - F1_score: 0.4228\n",
      "2025-02-16 17:46:41,598 - INFO - Precision: 0.2921\n",
      "2025-02-16 17:46:41,598 - INFO - Recall: 0.7647\n",
      "2025-02-16 17:46:41,601 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:46:45,606 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:46:45,607 - INFO - Memory usage after evaluation end: 2168.07 MB\n",
      "2025-02-16 17:46:45,608 - INFO - Trial 3, Epoch 2: Loss = 1.4210, F1 = 0.4736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:49:03,907 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:49:03,908 - INFO - Memory usage after evaluation start: 2168.07 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:49:11,274 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:49:11,281 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:49:11,281 - INFO - Accuracy: 0.4330\n",
      "2025-02-16 17:49:11,282 - INFO - F1_score: 0.4638\n",
      "2025-02-16 17:49:11,283 - INFO - Precision: 0.3168\n",
      "2025-02-16 17:49:11,283 - INFO - Recall: 0.8649\n",
      "2025-02-16 17:49:11,289 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:49:11,290 - INFO - Accuracy: 0.6973\n",
      "2025-02-16 17:49:11,291 - INFO - F1_score: 0.5820\n",
      "2025-02-16 17:49:11,292 - INFO - Precision: 0.4167\n",
      "2025-02-16 17:49:11,292 - INFO - Recall: 0.9649\n",
      "2025-02-16 17:49:11,299 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:49:11,299 - INFO - Accuracy: 0.5134\n",
      "2025-02-16 17:49:11,300 - INFO - F1_score: 0.4549\n",
      "2025-02-16 17:49:11,301 - INFO - Precision: 0.3029\n",
      "2025-02-16 17:49:11,302 - INFO - Recall: 0.9138\n",
      "2025-02-16 17:49:11,307 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:49:11,308 - INFO - Accuracy: 0.7816\n",
      "2025-02-16 17:49:11,309 - INFO - F1_score: 0.4242\n",
      "2025-02-16 17:49:11,310 - INFO - Precision: 0.3443\n",
      "2025-02-16 17:49:11,311 - INFO - Recall: 0.5526\n",
      "2025-02-16 17:49:11,316 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:49:11,317 - INFO - Accuracy: 0.8429\n",
      "2025-02-16 17:49:11,317 - INFO - F1_score: 0.4533\n",
      "2025-02-16 17:49:11,318 - INFO - Precision: 0.4146\n",
      "2025-02-16 17:49:11,320 - INFO - Recall: 0.5000\n",
      "2025-02-16 17:49:11,321 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:49:15,280 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:49:15,281 - INFO - Memory usage after evaluation end: 2158.01 MB\n",
      "2025-02-16 17:49:15,282 - INFO - Trial 3, Epoch 3: Loss = 1.2760, F1 = 0.4757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 17:49:16,793] Trial 3 finished with value: 0.475658015569193 and parameters: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 1 with value: 0.49946173269450045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:49:17,275 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 5e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}\n",
      "2025-02-16 17:49:17,280 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:49:18,170 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 17:49:18,171 - INFO - Setting up data loaders...\n",
      "2025-02-16 17:49:18,172 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 17:49:18,175 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 17:49:18,176 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:51:36,331 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:51:36,332 - INFO - Memory usage after evaluation start: 2207.48 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:51:43,686 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:51:43,693 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:51:43,694 - INFO - Accuracy: 0.5670\n",
      "2025-02-16 17:51:43,694 - INFO - F1_score: 0.4978\n",
      "2025-02-16 17:51:43,695 - INFO - Precision: 0.3709\n",
      "2025-02-16 17:51:43,697 - INFO - Recall: 0.7568\n",
      "2025-02-16 17:51:43,702 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:51:43,703 - INFO - Accuracy: 0.5172\n",
      "2025-02-16 17:51:43,704 - INFO - F1_score: 0.4375\n",
      "2025-02-16 17:51:43,705 - INFO - Precision: 0.2934\n",
      "2025-02-16 17:51:43,707 - INFO - Recall: 0.8596\n",
      "2025-02-16 17:51:43,714 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:51:43,715 - INFO - Accuracy: 0.5249\n",
      "2025-02-16 17:51:43,716 - INFO - F1_score: 0.3981\n",
      "2025-02-16 17:51:43,718 - INFO - Precision: 0.2770\n",
      "2025-02-16 17:51:43,719 - INFO - Recall: 0.7069\n",
      "2025-02-16 17:51:43,726 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:51:43,730 - INFO - Accuracy: 0.4100\n",
      "2025-02-16 17:51:43,731 - INFO - F1_score: 0.2596\n",
      "2025-02-16 17:51:43,732 - INFO - Precision: 0.1588\n",
      "2025-02-16 17:51:43,732 - INFO - Recall: 0.7105\n",
      "2025-02-16 17:51:43,741 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:51:43,742 - INFO - Accuracy: 0.7241\n",
      "2025-02-16 17:51:43,743 - INFO - F1_score: 0.3898\n",
      "2025-02-16 17:51:43,744 - INFO - Precision: 0.2738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:51:43,745 - INFO - Recall: 0.6765\n",
      "2025-02-16 17:51:43,746 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 17:51:47,686 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:51:47,687 - INFO - Memory usage after evaluation end: 2211.22 MB\n",
      "2025-02-16 17:51:47,688 - INFO - Trial 4, Epoch 1: Loss = 1.5618, F1 = 0.3966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:54:06,133 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:54:06,135 - INFO - Memory usage after evaluation start: 2211.22 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:54:13,502 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:54:13,508 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:54:13,509 - INFO - Accuracy: 0.6360\n",
      "2025-02-16 17:54:13,509 - INFO - F1_score: 0.5226\n",
      "2025-02-16 17:54:13,510 - INFO - Precision: 0.4160\n",
      "2025-02-16 17:54:13,511 - INFO - Recall: 0.7027\n",
      "2025-02-16 17:54:13,518 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:54:13,518 - INFO - Accuracy: 0.6552\n",
      "2025-02-16 17:54:13,519 - INFO - F1_score: 0.5500\n",
      "2025-02-16 17:54:13,520 - INFO - Precision: 0.3846\n",
      "2025-02-16 17:54:13,521 - INFO - Recall: 0.9649\n",
      "2025-02-16 17:54:13,527 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:54:13,527 - INFO - Accuracy: 0.4828\n",
      "2025-02-16 17:54:13,529 - INFO - F1_score: 0.4304\n",
      "2025-02-16 17:54:13,529 - INFO - Precision: 0.2849\n",
      "2025-02-16 17:54:13,530 - INFO - Recall: 0.8793\n",
      "2025-02-16 17:54:13,536 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:54:13,537 - INFO - Accuracy: 0.7011\n",
      "2025-02-16 17:54:13,538 - INFO - F1_score: 0.3710\n",
      "2025-02-16 17:54:13,538 - INFO - Precision: 0.2674\n",
      "2025-02-16 17:54:13,540 - INFO - Recall: 0.6053\n",
      "2025-02-16 17:54:13,545 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:54:13,546 - INFO - Accuracy: 0.7241\n",
      "2025-02-16 17:54:13,547 - INFO - F1_score: 0.4000\n",
      "2025-02-16 17:54:13,547 - INFO - Precision: 0.2791\n",
      "2025-02-16 17:54:13,549 - INFO - Recall: 0.7059\n",
      "2025-02-16 17:54:13,551 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:54:17,601 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:54:17,603 - INFO - Memory usage after evaluation end: 2232.68 MB\n",
      "2025-02-16 17:54:17,604 - INFO - Trial 4, Epoch 2: Loss = 1.4419, F1 = 0.4548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:56:35,899 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:56:35,900 - INFO - Memory usage after evaluation start: 2232.68 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:56:43,267 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:56:43,273 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:56:43,274 - INFO - Accuracy: 0.5632\n",
      "2025-02-16 17:56:43,274 - INFO - F1_score: 0.5210\n",
      "2025-02-16 17:56:43,275 - INFO - Precision: 0.3780\n",
      "2025-02-16 17:56:43,275 - INFO - Recall: 0.8378\n",
      "2025-02-16 17:56:43,281 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:56:43,282 - INFO - Accuracy: 0.8429\n",
      "2025-02-16 17:56:43,283 - INFO - F1_score: 0.7211\n",
      "2025-02-16 17:56:43,283 - INFO - Precision: 0.5889\n",
      "2025-02-16 17:56:43,284 - INFO - Recall: 0.9298\n",
      "2025-02-16 17:56:43,290 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:56:43,291 - INFO - Accuracy: 0.5019\n",
      "2025-02-16 17:56:43,292 - INFO - F1_score: 0.4298\n",
      "2025-02-16 17:56:43,293 - INFO - Precision: 0.2882\n",
      "2025-02-16 17:56:43,294 - INFO - Recall: 0.8448\n",
      "2025-02-16 17:56:43,299 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:56:43,300 - INFO - Accuracy: 0.6169\n",
      "2025-02-16 17:56:43,300 - INFO - F1_score: 0.3421\n",
      "2025-02-16 17:56:43,301 - INFO - Precision: 0.2281\n",
      "2025-02-16 17:56:43,302 - INFO - Recall: 0.6842\n",
      "2025-02-16 17:56:43,308 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:56:43,309 - INFO - Accuracy: 0.6360\n",
      "2025-02-16 17:56:43,309 - INFO - F1_score: 0.3448\n",
      "2025-02-16 17:56:43,310 - INFO - Precision: 0.2252\n",
      "2025-02-16 17:56:43,311 - INFO - Recall: 0.7353\n",
      "2025-02-16 17:56:43,313 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:56:47,307 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:56:47,309 - INFO - Memory usage after evaluation end: 2233.51 MB\n",
      "2025-02-16 17:56:47,310 - INFO - Trial 4, Epoch 3: Loss = 1.3503, F1 = 0.4718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 17:56:48,945] Trial 4 finished with value: 0.47177084990075874 and parameters: {'batch_size': 8, 'learning_rate': 5e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.15}. Best is trial 1 with value: 0.49946173269450045.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:56:49,448 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-16 17:56:49,452 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:56:50,349 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 17:56:50,350 - INFO - Setting up data loaders...\n",
      "2025-02-16 17:56:50,351 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 17:56:50,353 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 17:56:50,354 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:59:08,608 - INFO - Starting model evaluation...\n",
      "2025-02-16 17:59:08,609 - INFO - Memory usage after evaluation start: 2234.84 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:59:15,979 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 17:59:15,985 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 17:59:15,986 - INFO - Accuracy: 0.6284\n",
      "2025-02-16 17:59:15,986 - INFO - F1_score: 0.5403\n",
      "2025-02-16 17:59:15,988 - INFO - Precision: 0.4161\n",
      "2025-02-16 17:59:15,989 - INFO - Recall: 0.7703\n",
      "2025-02-16 17:59:15,994 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 17:59:15,995 - INFO - Accuracy: 0.7471\n",
      "2025-02-16 17:59:15,996 - INFO - F1_score: 0.6207\n",
      "2025-02-16 17:59:15,997 - INFO - Precision: 0.4615\n",
      "2025-02-16 17:59:15,998 - INFO - Recall: 0.9474\n",
      "2025-02-16 17:59:16,004 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 17:59:16,004 - INFO - Accuracy: 0.7471\n",
      "2025-02-16 17:59:16,005 - INFO - F1_score: 0.3774\n",
      "2025-02-16 17:59:16,006 - INFO - Precision: 0.4167\n",
      "2025-02-16 17:59:16,007 - INFO - Recall: 0.3448\n",
      "2025-02-16 17:59:16,013 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 17:59:16,014 - INFO - Accuracy: 0.6897\n",
      "2025-02-16 17:59:16,014 - INFO - F1_score: 0.3910\n",
      "2025-02-16 17:59:16,015 - INFO - Precision: 0.2737\n",
      "2025-02-16 17:59:16,016 - INFO - Recall: 0.6842\n",
      "2025-02-16 17:59:16,022 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 17:59:16,023 - INFO - Accuracy: 0.5709\n",
      "2025-02-16 17:59:16,024 - INFO - F1_score: 0.3171\n",
      "2025-02-16 17:59:16,024 - INFO - Precision: 0.2000\n",
      "2025-02-16 17:59:16,025 - INFO - Recall: 0.7647\n",
      "2025-02-16 17:59:16,027 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 17:59:20,466 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 17:59:20,467 - INFO - Memory usage after evaluation end: 2239.50 MB\n",
      "2025-02-16 17:59:20,469 - INFO - Trial 5, Epoch 1: Loss = 1.5273, F1 = 0.4493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:01:39,028 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:01:39,030 - INFO - Memory usage after evaluation start: 2239.50 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:01:46,404 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:01:46,411 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:01:46,411 - INFO - Accuracy: 0.6858\n",
      "2025-02-16 18:01:46,412 - INFO - F1_score: 0.5638\n",
      "2025-02-16 18:01:46,413 - INFO - Precision: 0.4649\n",
      "2025-02-16 18:01:46,414 - INFO - Recall: 0.7162\n",
      "2025-02-16 18:01:46,420 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:01:46,420 - INFO - Accuracy: 0.6935\n",
      "2025-02-16 18:01:46,421 - INFO - F1_score: 0.5789\n",
      "2025-02-16 18:01:46,422 - INFO - Precision: 0.4135\n",
      "2025-02-16 18:01:46,423 - INFO - Recall: 0.9649\n",
      "2025-02-16 18:01:46,429 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:01:46,429 - INFO - Accuracy: 0.5326\n",
      "2025-02-16 18:01:46,431 - INFO - F1_score: 0.4602\n",
      "2025-02-16 18:01:46,432 - INFO - Precision: 0.3095\n",
      "2025-02-16 18:01:46,433 - INFO - Recall: 0.8966\n",
      "2025-02-16 18:01:46,438 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:01:46,438 - INFO - Accuracy: 0.7778\n",
      "2025-02-16 18:01:46,439 - INFO - F1_score: 0.4630\n",
      "2025-02-16 18:01:46,440 - INFO - Precision: 0.3571\n",
      "2025-02-16 18:01:46,441 - INFO - Recall: 0.6579\n",
      "2025-02-16 18:01:46,447 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:01:46,447 - INFO - Accuracy: 0.7548\n",
      "2025-02-16 18:01:46,448 - INFO - F1_score: 0.4286\n",
      "2025-02-16 18:01:46,449 - INFO - Precision: 0.3077\n",
      "2025-02-16 18:01:46,450 - INFO - Recall: 0.7059\n",
      "2025-02-16 18:01:46,452 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:01:50,636 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:01:50,637 - INFO - Memory usage after evaluation end: 2256.05 MB\n",
      "2025-02-16 18:01:50,638 - INFO - Trial 5, Epoch 2: Loss = 1.3212, F1 = 0.4989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:04:09,085 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:04:09,087 - INFO - Memory usage after evaluation start: 2256.05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:04:16,458 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:04:16,463 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:04:16,464 - INFO - Accuracy: 0.5824\n",
      "2025-02-16 18:04:16,465 - INFO - F1_score: 0.5439\n",
      "2025-02-16 18:04:16,466 - INFO - Precision: 0.3939\n",
      "2025-02-16 18:04:16,467 - INFO - Recall: 0.8784\n",
      "2025-02-16 18:04:16,473 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:04:16,473 - INFO - Accuracy: 0.8391\n",
      "2025-02-16 18:04:16,474 - INFO - F1_score: 0.7200\n",
      "2025-02-16 18:04:16,475 - INFO - Precision: 0.5806\n",
      "2025-02-16 18:04:16,475 - INFO - Recall: 0.9474\n",
      "2025-02-16 18:04:16,481 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:04:16,482 - INFO - Accuracy: 0.6015\n",
      "2025-02-16 18:04:16,482 - INFO - F1_score: 0.4747\n",
      "2025-02-16 18:04:16,483 - INFO - Precision: 0.3357\n",
      "2025-02-16 18:04:16,483 - INFO - Recall: 0.8103\n",
      "2025-02-16 18:04:16,490 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:04:16,491 - INFO - Accuracy: 0.7165\n",
      "2025-02-16 18:04:16,491 - INFO - F1_score: 0.4127\n",
      "2025-02-16 18:04:16,492 - INFO - Precision: 0.2955\n",
      "2025-02-16 18:04:16,494 - INFO - Recall: 0.6842\n",
      "2025-02-16 18:04:16,499 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:04:16,500 - INFO - Accuracy: 0.7241\n",
      "2025-02-16 18:04:16,500 - INFO - F1_score: 0.4098\n",
      "2025-02-16 18:04:16,501 - INFO - Precision: 0.2841\n",
      "2025-02-16 18:04:16,503 - INFO - Recall: 0.7353\n",
      "2025-02-16 18:04:16,504 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:04:20,777 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:04:20,778 - INFO - Memory usage after evaluation end: 2280.91 MB\n",
      "2025-02-16 18:04:20,779 - INFO - Trial 5, Epoch 3: Loss = 1.2059, F1 = 0.5122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 18:04:22,553] Trial 5 finished with value: 0.5122430014825927 and parameters: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.1}. Best is trial 5 with value: 0.5122430014825927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:04:23,113 - INFO - Trial parameter set: {'batch_size': 4, 'learning_rate': 5e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-16 18:04:23,118 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:04:24,040 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 18:04:24,041 - INFO - Setting up data loaders...\n",
      "2025-02-16 18:04:24,042 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 18:04:24,044 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 18:04:24,046 - INFO - Created data loaders with batch size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:06:51,606 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:06:51,609 - INFO - Memory usage after evaluation start: 2288.65 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:06:59,429 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:06:59,435 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:06:59,436 - INFO - Accuracy: 0.5019\n",
      "2025-02-16 18:06:59,437 - INFO - F1_score: 0.5000\n",
      "2025-02-16 18:06:59,437 - INFO - Precision: 0.3495\n",
      "2025-02-16 18:06:59,439 - INFO - Recall: 0.8784\n",
      "2025-02-16 18:06:59,444 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:06:59,445 - INFO - Accuracy: 0.8506\n",
      "2025-02-16 18:06:59,445 - INFO - F1_score: 0.6723\n",
      "2025-02-16 18:06:59,446 - INFO - Precision: 0.6452\n",
      "2025-02-16 18:06:59,447 - INFO - Recall: 0.7018\n",
      "2025-02-16 18:06:59,453 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:06:59,454 - INFO - Accuracy: 0.4138\n",
      "2025-02-16 18:06:59,455 - INFO - F1_score: 0.4183\n",
      "2025-02-16 18:06:59,456 - INFO - Precision: 0.2683\n",
      "2025-02-16 18:06:59,456 - INFO - Recall: 0.9483\n",
      "2025-02-16 18:06:59,462 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:06:59,463 - INFO - Accuracy: 0.3525\n",
      "2025-02-16 18:06:59,464 - INFO - F1_score: 0.2869\n",
      "2025-02-16 18:06:59,465 - INFO - Precision: 0.1709\n",
      "2025-02-16 18:06:59,465 - INFO - Recall: 0.8947\n",
      "2025-02-16 18:06:59,471 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:06:59,472 - INFO - Accuracy: 0.5900\n",
      "2025-02-16 18:06:59,472 - INFO - F1_score: 0.3436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:06:59,473 - INFO - Precision: 0.2171\n",
      "2025-02-16 18:06:59,474 - INFO - Recall: 0.8235\n",
      "2025-02-16 18:06:59,476 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:07:03,696 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:07:03,698 - INFO - Memory usage after evaluation end: 2310.64 MB\n",
      "2025-02-16 18:07:03,699 - INFO - Trial 6, Epoch 1: Loss = 1.5199, F1 = 0.4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:09:31,981 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:09:31,982 - INFO - Memory usage after evaluation start: 2310.64 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:09:39,819 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:09:39,824 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:09:39,825 - INFO - Accuracy: 0.5364\n",
      "2025-02-16 18:09:39,826 - INFO - F1_score: 0.4895\n",
      "2025-02-16 18:09:39,826 - INFO - Precision: 0.3558\n",
      "2025-02-16 18:09:39,828 - INFO - Recall: 0.7838\n",
      "2025-02-16 18:09:39,833 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:09:39,834 - INFO - Accuracy: 0.8008\n",
      "2025-02-16 18:09:39,835 - INFO - F1_score: 0.6750\n",
      "2025-02-16 18:09:39,835 - INFO - Precision: 0.5243\n",
      "2025-02-16 18:09:39,836 - INFO - Recall: 0.9474\n",
      "2025-02-16 18:09:39,842 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:09:39,843 - INFO - Accuracy: 0.6245\n",
      "2025-02-16 18:09:39,843 - INFO - F1_score: 0.4948\n",
      "2025-02-16 18:09:39,844 - INFO - Precision: 0.3529\n",
      "2025-02-16 18:09:39,845 - INFO - Recall: 0.8276\n",
      "2025-02-16 18:09:39,851 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:09:39,852 - INFO - Accuracy: 0.6207\n",
      "2025-02-16 18:09:39,852 - INFO - F1_score: 0.3529\n",
      "2025-02-16 18:09:39,853 - INFO - Precision: 0.2348\n",
      "2025-02-16 18:09:39,854 - INFO - Recall: 0.7105\n",
      "2025-02-16 18:09:39,860 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:09:39,860 - INFO - Accuracy: 0.6935\n",
      "2025-02-16 18:09:39,861 - INFO - F1_score: 0.3846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:09:39,861 - INFO - Precision: 0.2604\n",
      "2025-02-16 18:09:39,862 - INFO - Recall: 0.7353\n",
      "2025-02-16 18:09:39,865 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:09:44,004 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:09:44,006 - INFO - Memory usage after evaluation end: 2339.43 MB\n",
      "2025-02-16 18:09:44,007 - INFO - Trial 6, Epoch 2: Loss = 1.2975, F1 = 0.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:12:12,253 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:12:12,256 - INFO - Memory usage after evaluation start: 2339.68 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:12:20,104 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:12:20,109 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:12:20,110 - INFO - Accuracy: 0.5172\n",
      "2025-02-16 18:12:20,111 - INFO - F1_score: 0.5078\n",
      "2025-02-16 18:12:20,112 - INFO - Precision: 0.3571\n",
      "2025-02-16 18:12:20,113 - INFO - Recall: 0.8784\n",
      "2025-02-16 18:12:20,119 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:12:20,119 - INFO - Accuracy: 0.8199\n",
      "2025-02-16 18:12:20,120 - INFO - F1_score: 0.6968\n",
      "2025-02-16 18:12:20,120 - INFO - Precision: 0.5510\n",
      "2025-02-16 18:12:20,121 - INFO - Recall: 0.9474\n",
      "2025-02-16 18:12:20,127 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:12:20,128 - INFO - Accuracy: 0.4866\n",
      "2025-02-16 18:12:20,128 - INFO - F1_score: 0.4370\n",
      "2025-02-16 18:12:20,129 - INFO - Precision: 0.2889\n",
      "2025-02-16 18:12:20,130 - INFO - Recall: 0.8966\n",
      "2025-02-16 18:12:20,136 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:12:20,137 - INFO - Accuracy: 0.6782\n",
      "2025-02-16 18:12:20,137 - INFO - F1_score: 0.3636\n",
      "2025-02-16 18:12:20,138 - INFO - Precision: 0.2553\n",
      "2025-02-16 18:12:20,139 - INFO - Recall: 0.6316\n",
      "2025-02-16 18:12:20,145 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:12:20,146 - INFO - Accuracy: 0.7625\n",
      "2025-02-16 18:12:20,146 - INFO - F1_score: 0.4364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:12:20,147 - INFO - Precision: 0.3158\n",
      "2025-02-16 18:12:20,148 - INFO - Recall: 0.7059\n",
      "2025-02-16 18:12:20,151 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:12:24,334 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:12:24,336 - INFO - Memory usage after evaluation end: 2364.10 MB\n",
      "2025-02-16 18:12:24,338 - INFO - Trial 6, Epoch 3: Loss = 1.1415, F1 = 0.4883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 18:12:26,264] Trial 6 finished with value: 0.4883122966928707 and parameters: {'batch_size': 4, 'learning_rate': 5e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 5 with value: 0.5122430014825927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:12:26,879 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 5e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-16 18:12:26,883 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:12:27,777 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 18:12:27,778 - INFO - Setting up data loaders...\n",
      "2025-02-16 18:12:27,779 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 18:12:27,781 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 18:12:27,782 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:14:46,039 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:14:46,041 - INFO - Memory usage after evaluation start: 2376.29 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:14:53,431 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:14:53,437 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:14:53,438 - INFO - Accuracy: 0.5479\n",
      "2025-02-16 18:14:53,439 - INFO - F1_score: 0.5042\n",
      "2025-02-16 18:14:53,440 - INFO - Precision: 0.3659\n",
      "2025-02-16 18:14:53,441 - INFO - Recall: 0.8108\n",
      "2025-02-16 18:14:53,446 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:14:53,447 - INFO - Accuracy: 0.7203\n",
      "2025-02-16 18:14:53,447 - INFO - F1_score: 0.6011\n",
      "2025-02-16 18:14:53,448 - INFO - Precision: 0.4365\n",
      "2025-02-16 18:14:53,449 - INFO - Recall: 0.9649\n",
      "2025-02-16 18:14:53,455 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:14:53,456 - INFO - Accuracy: 0.3103\n",
      "2025-02-16 18:14:53,457 - INFO - F1_score: 0.3617\n",
      "2025-02-16 18:14:53,458 - INFO - Precision: 0.2277\n",
      "2025-02-16 18:14:53,459 - INFO - Recall: 0.8793\n",
      "2025-02-16 18:14:53,464 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:14:53,465 - INFO - Accuracy: 0.5249\n",
      "2025-02-16 18:14:53,466 - INFO - F1_score: 0.3261\n",
      "2025-02-16 18:14:53,466 - INFO - Precision: 0.2055\n",
      "2025-02-16 18:14:53,468 - INFO - Recall: 0.7895\n",
      "2025-02-16 18:14:53,473 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:14:53,474 - INFO - Accuracy: 0.5326\n",
      "2025-02-16 18:14:53,475 - INFO - F1_score: 0.3222\n",
      "2025-02-16 18:14:53,475 - INFO - Precision: 0.1986\n",
      "2025-02-16 18:14:53,476 - INFO - Recall: 0.8529\n",
      "2025-02-16 18:14:53,479 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:14:57,652 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:14:57,654 - INFO - Memory usage after evaluation end: 2395.32 MB\n",
      "2025-02-16 18:14:57,655 - INFO - Trial 7, Epoch 1: Loss = 1.5323, F1 = 0.4231\n",
      "2025-02-16 18:14:57,656 - ERROR - Error in trial training: \n",
      "2025-02-16 18:14:58,408 - ERROR - Error in optimization objective: \n",
      "2025-02-16 18:14:58,409 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 18:14:58,410] Trial 7 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:14:59,045 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.15}\n",
      "2025-02-16 18:14:59,049 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:14:59,883 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 18:14:59,885 - INFO - Setting up data loaders...\n",
      "2025-02-16 18:14:59,886 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 18:14:59,888 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 18:14:59,889 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:17:46,137 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:17:46,139 - INFO - Memory usage after evaluation start: 2643.95 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:17:54,064 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:17:54,070 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:17:54,071 - INFO - Accuracy: 0.7050\n",
      "2025-02-16 18:17:54,072 - INFO - F1_score: 0.5276\n",
      "2025-02-16 18:17:54,072 - INFO - Precision: 0.4831\n",
      "2025-02-16 18:17:54,074 - INFO - Recall: 0.5811\n",
      "2025-02-16 18:17:54,080 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:17:54,080 - INFO - Accuracy: 0.7356\n",
      "2025-02-16 18:17:54,081 - INFO - F1_score: 0.6145\n",
      "2025-02-16 18:17:54,082 - INFO - Precision: 0.4508\n",
      "2025-02-16 18:17:54,083 - INFO - Recall: 0.9649\n",
      "2025-02-16 18:17:54,089 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:17:54,089 - INFO - Accuracy: 0.5824\n",
      "2025-02-16 18:17:54,090 - INFO - F1_score: 0.4734\n",
      "2025-02-16 18:17:54,091 - INFO - Precision: 0.3289\n",
      "2025-02-16 18:17:54,091 - INFO - Recall: 0.8448\n",
      "2025-02-16 18:17:54,098 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:17:54,098 - INFO - Accuracy: 0.6858\n",
      "2025-02-16 18:17:54,099 - INFO - F1_score: 0.3881\n",
      "2025-02-16 18:17:54,099 - INFO - Precision: 0.2708\n",
      "2025-02-16 18:17:54,101 - INFO - Recall: 0.6842\n",
      "2025-02-16 18:17:54,107 - INFO - \n",
      "Metrics for Romantis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:17:54,107 - INFO - Accuracy: 0.4904\n",
      "2025-02-16 18:17:54,108 - INFO - F1_score: 0.3179\n",
      "2025-02-16 18:17:54,109 - INFO - Precision: 0.1925\n",
      "2025-02-16 18:17:54,110 - INFO - Recall: 0.9118\n",
      "2025-02-16 18:17:54,112 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:17:58,139 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:17:58,140 - INFO - Memory usage after evaluation end: 2648.62 MB\n",
      "2025-02-16 18:17:58,141 - INFO - Trial 8, Epoch 1: Loss = 1.4403, F1 = 0.4643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:20:44,901 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:20:44,903 - INFO - Memory usage after evaluation start: 2648.62 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:20:52,840 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:20:52,846 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:20:52,847 - INFO - Accuracy: 0.3985\n",
      "2025-02-16 18:20:52,848 - INFO - F1_score: 0.4714\n",
      "2025-02-16 18:20:52,848 - INFO - Precision: 0.3139\n",
      "2025-02-16 18:20:52,850 - INFO - Recall: 0.9459\n",
      "2025-02-16 18:20:52,855 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:20:52,856 - INFO - Accuracy: 0.8736\n",
      "2025-02-16 18:20:52,857 - INFO - F1_score: 0.7481\n",
      "2025-02-16 18:20:52,858 - INFO - Precision: 0.6622\n",
      "2025-02-16 18:20:52,859 - INFO - Recall: 0.8596\n",
      "2025-02-16 18:20:52,865 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:20:52,865 - INFO - Accuracy: 0.5785\n",
      "2025-02-16 18:20:52,866 - INFO - F1_score: 0.4608\n",
      "2025-02-16 18:20:52,866 - INFO - Precision: 0.3219\n",
      "2025-02-16 18:20:52,867 - INFO - Recall: 0.8103\n",
      "2025-02-16 18:20:52,874 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:20:52,874 - INFO - Accuracy: 0.5709\n",
      "2025-02-16 18:20:52,875 - INFO - F1_score: 0.3488\n",
      "2025-02-16 18:20:52,875 - INFO - Precision: 0.2239\n",
      "2025-02-16 18:20:52,876 - INFO - Recall: 0.7895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:20:52,883 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:20:52,884 - INFO - Accuracy: 0.7126\n",
      "2025-02-16 18:20:52,885 - INFO - F1_score: 0.3697\n",
      "2025-02-16 18:20:52,885 - INFO - Precision: 0.2588\n",
      "2025-02-16 18:20:52,887 - INFO - Recall: 0.6471\n",
      "2025-02-16 18:20:52,889 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:20:56,993 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:20:56,994 - INFO - Memory usage after evaluation end: 2654.28 MB\n",
      "2025-02-16 18:20:56,995 - INFO - Trial 8, Epoch 2: Loss = 1.2426, F1 = 0.4798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:23:43,737 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:23:43,739 - INFO - Memory usage after evaluation start: 2654.28 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:23:51,669 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:23:51,675 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:23:51,675 - INFO - Accuracy: 0.5134\n",
      "2025-02-16 18:23:51,676 - INFO - F1_score: 0.4940\n",
      "2025-02-16 18:23:51,677 - INFO - Precision: 0.3503\n",
      "2025-02-16 18:23:51,677 - INFO - Recall: 0.8378\n",
      "2025-02-16 18:23:51,684 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:23:51,684 - INFO - Accuracy: 0.8161\n",
      "2025-02-16 18:23:51,685 - INFO - F1_score: 0.6842\n",
      "2025-02-16 18:23:51,685 - INFO - Precision: 0.5474\n",
      "2025-02-16 18:23:51,686 - INFO - Recall: 0.9123\n",
      "2025-02-16 18:23:51,692 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:23:51,693 - INFO - Accuracy: 0.6130\n",
      "2025-02-16 18:23:51,693 - INFO - F1_score: 0.4925\n",
      "2025-02-16 18:23:51,694 - INFO - Precision: 0.3475\n",
      "2025-02-16 18:23:51,696 - INFO - Recall: 0.8448\n",
      "2025-02-16 18:23:51,701 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:23:51,701 - INFO - Accuracy: 0.7088\n",
      "2025-02-16 18:23:51,702 - INFO - F1_score: 0.3667\n",
      "2025-02-16 18:23:51,703 - INFO - Precision: 0.2683\n",
      "2025-02-16 18:23:51,704 - INFO - Recall: 0.5789\n",
      "2025-02-16 18:23:51,709 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:23:51,710 - INFO - Accuracy: 0.7625\n",
      "2025-02-16 18:23:51,711 - INFO - F1_score: 0.4561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:23:51,712 - INFO - Precision: 0.3250\n",
      "2025-02-16 18:23:51,713 - INFO - Recall: 0.7647\n",
      "2025-02-16 18:23:51,715 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:23:55,744 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:23:55,745 - INFO - Memory usage after evaluation end: 2659.96 MB\n",
      "2025-02-16 18:23:55,746 - INFO - Trial 8, Epoch 3: Loss = 1.1345, F1 = 0.4987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 18:23:57,817] Trial 8 finished with value: 0.49870075195998165 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.15}. Best is trial 5 with value: 0.5122430014825927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:23:58,478 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 5e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-16 18:23:58,481 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:23:59,441 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 18:23:59,442 - INFO - Setting up data loaders...\n",
      "2025-02-16 18:23:59,443 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 18:23:59,444 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 18:23:59,445 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:26:17,424 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:26:17,426 - INFO - Memory usage after evaluation start: 2648.64 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:26:24,804 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:26:24,810 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:26:24,811 - INFO - Accuracy: 0.4636\n",
      "2025-02-16 18:26:24,812 - INFO - F1_score: 0.4776\n",
      "2025-02-16 18:26:24,812 - INFO - Precision: 0.3299\n",
      "2025-02-16 18:26:24,813 - INFO - Recall: 0.8649\n",
      "2025-02-16 18:26:24,820 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:26:24,820 - INFO - Accuracy: 0.3908\n",
      "2025-02-16 18:26:24,821 - INFO - F1_score: 0.4133\n",
      "2025-02-16 18:26:24,822 - INFO - Precision: 0.2617\n",
      "2025-02-16 18:26:24,823 - INFO - Recall: 0.9825\n",
      "2025-02-16 18:26:24,829 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:26:24,829 - INFO - Accuracy: 0.4636\n",
      "2025-02-16 18:26:24,830 - INFO - F1_score: 0.4167\n",
      "2025-02-16 18:26:24,831 - INFO - Precision: 0.2747\n",
      "2025-02-16 18:26:24,832 - INFO - Recall: 0.8621\n",
      "2025-02-16 18:26:24,838 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:26:24,838 - INFO - Accuracy: 0.5096\n",
      "2025-02-16 18:26:24,839 - INFO - F1_score: 0.3191\n",
      "2025-02-16 18:26:24,840 - INFO - Precision: 0.2000\n",
      "2025-02-16 18:26:24,841 - INFO - Recall: 0.7895\n",
      "2025-02-16 18:26:24,847 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:26:24,848 - INFO - Accuracy: 0.8084\n",
      "2025-02-16 18:26:24,848 - INFO - F1_score: 0.4048\n",
      "2025-02-16 18:26:24,849 - INFO - Precision: 0.3400\n",
      "2025-02-16 18:26:24,850 - INFO - Recall: 0.5000\n",
      "2025-02-16 18:26:24,852 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:26:29,068 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:26:29,069 - INFO - Memory usage after evaluation end: 2652.23 MB\n",
      "2025-02-16 18:26:29,071 - INFO - Trial 9, Epoch 1: Loss = 1.5398, F1 = 0.4063\n",
      "2025-02-16 18:26:29,072 - ERROR - Error in trial training: \n",
      "2025-02-16 18:26:29,925 - ERROR - Error in optimization objective: \n",
      "2025-02-16 18:26:29,926 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 18:26:29,927] Trial 9 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:26:30,674 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 3e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-16 18:26:30,677 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:26:31,569 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 18:26:31,570 - INFO - Setting up data loaders...\n",
      "2025-02-16 18:26:31,571 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 18:26:31,573 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 18:26:31,574 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:28:49,546 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:28:49,548 - INFO - Memory usage after evaluation start: 2644.56 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:28:56,935 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:28:56,941 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:28:56,942 - INFO - Accuracy: 0.5096\n",
      "2025-02-16 18:28:56,943 - INFO - F1_score: 0.5039\n",
      "2025-02-16 18:28:56,944 - INFO - Precision: 0.3533\n",
      "2025-02-16 18:28:56,945 - INFO - Recall: 0.8784\n",
      "2025-02-16 18:28:56,951 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:28:56,952 - INFO - Accuracy: 0.7126\n",
      "2025-02-16 18:28:56,952 - INFO - F1_score: 0.5399\n",
      "2025-02-16 18:28:56,953 - INFO - Precision: 0.4151\n",
      "2025-02-16 18:28:56,955 - INFO - Recall: 0.7719\n",
      "2025-02-16 18:28:56,960 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:28:56,961 - INFO - Accuracy: 0.5939\n",
      "2025-02-16 18:28:56,962 - INFO - F1_score: 0.4592\n",
      "2025-02-16 18:28:56,962 - INFO - Precision: 0.3261\n",
      "2025-02-16 18:28:56,963 - INFO - Recall: 0.7759\n",
      "2025-02-16 18:28:56,969 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:28:56,970 - INFO - Accuracy: 0.4559\n",
      "2025-02-16 18:28:56,970 - INFO - F1_score: 0.2970\n",
      "2025-02-16 18:28:56,971 - INFO - Precision: 0.1829\n",
      "2025-02-16 18:28:56,972 - INFO - Recall: 0.7895\n",
      "2025-02-16 18:28:56,978 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:28:56,979 - INFO - Accuracy: 0.7433\n",
      "2025-02-16 18:28:56,980 - INFO - F1_score: 0.3495\n",
      "2025-02-16 18:28:56,980 - INFO - Precision: 0.2609\n",
      "2025-02-16 18:28:56,981 - INFO - Recall: 0.5294\n",
      "2025-02-16 18:28:56,984 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:29:01,065 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:29:01,067 - INFO - Memory usage after evaluation end: 2649.26 MB\n",
      "2025-02-16 18:29:01,068 - INFO - Trial 10, Epoch 1: Loss = 1.5632, F1 = 0.4299\n",
      "2025-02-16 18:29:01,070 - ERROR - Error in trial training: \n",
      "2025-02-16 18:29:01,928 - ERROR - Error in optimization objective: \n",
      "2025-02-16 18:29:01,929 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 18:29:01,930] Trial 10 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:29:02,682 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}\n",
      "2025-02-16 18:29:02,686 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:29:03,539 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 18:29:03,540 - INFO - Setting up data loaders...\n",
      "2025-02-16 18:29:03,541 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 18:29:03,543 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 18:29:03,545 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:31:50,349 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:31:50,351 - INFO - Memory usage after evaluation start: 2869.50 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:31:58,283 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:31:58,289 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:31:58,290 - INFO - Accuracy: 0.5287\n",
      "2025-02-16 18:31:58,290 - INFO - F1_score: 0.4896\n",
      "2025-02-16 18:31:58,291 - INFO - Precision: 0.3533\n",
      "2025-02-16 18:31:58,293 - INFO - Recall: 0.7973\n",
      "2025-02-16 18:31:58,298 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:31:58,299 - INFO - Accuracy: 0.8544\n",
      "2025-02-16 18:31:58,300 - INFO - F1_score: 0.7206\n",
      "2025-02-16 18:31:58,300 - INFO - Precision: 0.6203\n",
      "2025-02-16 18:31:58,302 - INFO - Recall: 0.8596\n",
      "2025-02-16 18:31:58,307 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:31:58,308 - INFO - Accuracy: 0.3142\n",
      "2025-02-16 18:31:58,309 - INFO - F1_score: 0.3849\n",
      "2025-02-16 18:31:58,309 - INFO - Precision: 0.2403\n",
      "2025-02-16 18:31:58,311 - INFO - Recall: 0.9655\n",
      "2025-02-16 18:31:58,316 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:31:58,317 - INFO - Accuracy: 0.6513\n",
      "2025-02-16 18:31:58,317 - INFO - F1_score: 0.3636\n",
      "2025-02-16 18:31:58,318 - INFO - Precision: 0.2476\n",
      "2025-02-16 18:31:58,320 - INFO - Recall: 0.6842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:31:58,326 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:31:58,327 - INFO - Accuracy: 0.7088\n",
      "2025-02-16 18:31:58,328 - INFO - F1_score: 0.4154\n",
      "2025-02-16 18:31:58,329 - INFO - Precision: 0.2812\n",
      "2025-02-16 18:31:58,329 - INFO - Recall: 0.7941\n",
      "2025-02-16 18:31:58,331 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:32:02,447 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:32:02,448 - INFO - Memory usage after evaluation end: 2873.33 MB\n",
      "2025-02-16 18:32:02,449 - INFO - Trial 11, Epoch 1: Loss = 1.4629, F1 = 0.4748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:34:49,903 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:34:49,905 - INFO - Memory usage after evaluation start: 2873.33 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:34:57,847 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:34:57,853 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:34:57,854 - INFO - Accuracy: 0.5211\n",
      "2025-02-16 18:34:57,854 - INFO - F1_score: 0.4898\n",
      "2025-02-16 18:34:57,855 - INFO - Precision: 0.3509\n",
      "2025-02-16 18:34:57,856 - INFO - Recall: 0.8108\n",
      "2025-02-16 18:34:57,862 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:34:57,862 - INFO - Accuracy: 0.8161\n",
      "2025-02-16 18:34:57,863 - INFO - F1_score: 0.6883\n",
      "2025-02-16 18:34:57,864 - INFO - Precision: 0.5464\n",
      "2025-02-16 18:34:57,865 - INFO - Recall: 0.9298\n",
      "2025-02-16 18:34:57,871 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:34:57,872 - INFO - Accuracy: 0.3985\n",
      "2025-02-16 18:34:57,873 - INFO - F1_score: 0.4030\n",
      "2025-02-16 18:34:57,873 - INFO - Precision: 0.2585\n",
      "2025-02-16 18:34:57,875 - INFO - Recall: 0.9138\n",
      "2025-02-16 18:34:57,880 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:34:57,880 - INFO - Accuracy: 0.7816\n",
      "2025-02-16 18:34:57,881 - INFO - F1_score: 0.4124\n",
      "2025-02-16 18:34:57,882 - INFO - Precision: 0.3390\n",
      "2025-02-16 18:34:57,882 - INFO - Recall: 0.5263\n",
      "2025-02-16 18:34:57,889 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:34:57,890 - INFO - Accuracy: 0.6782\n",
      "2025-02-16 18:34:57,890 - INFO - F1_score: 0.3731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:34:57,891 - INFO - Precision: 0.2500\n",
      "2025-02-16 18:34:57,892 - INFO - Recall: 0.7353\n",
      "2025-02-16 18:34:57,895 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:35:02,025 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:35:02,026 - INFO - Memory usage after evaluation end: 2878.96 MB\n",
      "2025-02-16 18:35:02,027 - INFO - Trial 11, Epoch 2: Loss = 1.2498, F1 = 0.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:37:49,512 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:37:49,514 - INFO - Memory usage after evaluation start: 2878.96 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:37:57,454 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:37:57,460 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:37:57,461 - INFO - Accuracy: 0.5211\n",
      "2025-02-16 18:37:57,461 - INFO - F1_score: 0.5098\n",
      "2025-02-16 18:37:57,462 - INFO - Precision: 0.3591\n",
      "2025-02-16 18:37:57,464 - INFO - Recall: 0.8784\n",
      "2025-02-16 18:37:57,470 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:37:57,470 - INFO - Accuracy: 0.7931\n",
      "2025-02-16 18:37:57,471 - INFO - F1_score: 0.6538\n",
      "2025-02-16 18:37:57,472 - INFO - Precision: 0.5152\n",
      "2025-02-16 18:37:57,472 - INFO - Recall: 0.8947\n",
      "2025-02-16 18:37:57,479 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:37:57,480 - INFO - Accuracy: 0.6360\n",
      "2025-02-16 18:37:57,481 - INFO - F1_score: 0.4809\n",
      "2025-02-16 18:37:57,481 - INFO - Precision: 0.3520\n",
      "2025-02-16 18:37:57,482 - INFO - Recall: 0.7586\n",
      "2025-02-16 18:37:57,489 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:37:57,490 - INFO - Accuracy: 0.7510\n",
      "2025-02-16 18:37:57,491 - INFO - F1_score: 0.4144\n",
      "2025-02-16 18:37:57,492 - INFO - Precision: 0.3151\n",
      "2025-02-16 18:37:57,492 - INFO - Recall: 0.6053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:37:57,499 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:37:57,500 - INFO - Accuracy: 0.7318\n",
      "2025-02-16 18:37:57,500 - INFO - F1_score: 0.4531\n",
      "2025-02-16 18:37:57,501 - INFO - Precision: 0.3085\n",
      "2025-02-16 18:37:57,503 - INFO - Recall: 0.8529\n",
      "2025-02-16 18:37:57,504 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:38:01,575 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:38:01,577 - INFO - Memory usage after evaluation end: 2884.75 MB\n",
      "2025-02-16 18:38:01,578 - INFO - Trial 11, Epoch 3: Loss = 1.0898, F1 = 0.5024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 18:38:03,961] Trial 11 finished with value: 0.5024127613538173 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.15}. Best is trial 5 with value: 0.5122430014825927.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:38:04,734 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-16 18:38:04,738 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:38:05,702 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 18:38:05,703 - INFO - Setting up data loaders...\n",
      "2025-02-16 18:38:05,704 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 18:38:05,706 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 18:38:05,707 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:40:52,353 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:40:52,355 - INFO - Memory usage after evaluation start: 2981.68 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:41:00,317 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:41:00,324 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:41:00,324 - INFO - Accuracy: 0.6513\n",
      "2025-02-16 18:41:00,325 - INFO - F1_score: 0.5517\n",
      "2025-02-16 18:41:00,325 - INFO - Precision: 0.4341\n",
      "2025-02-16 18:41:00,326 - INFO - Recall: 0.7568\n",
      "2025-02-16 18:41:00,333 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:41:00,333 - INFO - Accuracy: 0.7893\n",
      "2025-02-16 18:41:00,334 - INFO - F1_score: 0.6541\n",
      "2025-02-16 18:41:00,334 - INFO - Precision: 0.5098\n",
      "2025-02-16 18:41:00,335 - INFO - Recall: 0.9123\n",
      "2025-02-16 18:41:00,341 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:41:00,342 - INFO - Accuracy: 0.7241\n",
      "2025-02-16 18:41:00,343 - INFO - F1_score: 0.5610\n",
      "2025-02-16 18:41:00,343 - INFO - Precision: 0.4340\n",
      "2025-02-16 18:41:00,344 - INFO - Recall: 0.7931\n",
      "2025-02-16 18:41:00,350 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:41:00,351 - INFO - Accuracy: 0.7433\n",
      "2025-02-16 18:41:00,351 - INFO - F1_score: 0.3964\n",
      "2025-02-16 18:41:00,352 - INFO - Precision: 0.3014\n",
      "2025-02-16 18:41:00,353 - INFO - Recall: 0.5789\n",
      "2025-02-16 18:41:00,359 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:41:00,360 - INFO - Accuracy: 0.6820\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:41:00,360 - INFO - F1_score: 0.3759\n",
      "2025-02-16 18:41:00,361 - INFO - Precision: 0.2525\n",
      "2025-02-16 18:41:00,362 - INFO - Recall: 0.7353\n",
      "2025-02-16 18:41:00,365 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:41:04,248 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:41:04,250 - INFO - Memory usage after evaluation end: 2985.18 MB\n",
      "2025-02-16 18:41:04,251 - INFO - Trial 12, Epoch 1: Loss = 1.4341, F1 = 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:43:51,977 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:43:51,980 - INFO - Memory usage after evaluation start: 2985.43 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:43:59,948 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:43:59,954 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:43:59,955 - INFO - Accuracy: 0.5594\n",
      "2025-02-16 18:43:59,955 - INFO - F1_score: 0.5306\n",
      "2025-02-16 18:43:59,956 - INFO - Precision: 0.3801\n",
      "2025-02-16 18:43:59,957 - INFO - Recall: 0.8784\n",
      "2025-02-16 18:43:59,963 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:43:59,963 - INFO - Accuracy: 0.8161\n",
      "2025-02-16 18:43:59,964 - INFO - F1_score: 0.6883\n",
      "2025-02-16 18:43:59,965 - INFO - Precision: 0.5464\n",
      "2025-02-16 18:43:59,966 - INFO - Recall: 0.9298\n",
      "2025-02-16 18:43:59,972 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:43:59,972 - INFO - Accuracy: 0.6475\n",
      "2025-02-16 18:43:59,973 - INFO - F1_score: 0.5208\n",
      "2025-02-16 18:43:59,973 - INFO - Precision: 0.3731\n",
      "2025-02-16 18:43:59,974 - INFO - Recall: 0.8621\n",
      "2025-02-16 18:43:59,980 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:43:59,980 - INFO - Accuracy: 0.7050\n",
      "2025-02-16 18:43:59,981 - INFO - F1_score: 0.3937\n",
      "2025-02-16 18:43:59,982 - INFO - Precision: 0.2809\n",
      "2025-02-16 18:43:59,982 - INFO - Recall: 0.6579\n",
      "2025-02-16 18:43:59,989 - INFO - \n",
      "Metrics for Romantis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:43:59,989 - INFO - Accuracy: 0.8046\n",
      "2025-02-16 18:43:59,990 - INFO - F1_score: 0.4632\n",
      "2025-02-16 18:43:59,991 - INFO - Precision: 0.3607\n",
      "2025-02-16 18:43:59,991 - INFO - Recall: 0.6471\n",
      "2025-02-16 18:43:59,994 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:44:03,803 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:44:03,805 - INFO - Memory usage after evaluation end: 2990.93 MB\n",
      "2025-02-16 18:44:03,806 - INFO - Trial 12, Epoch 2: Loss = 1.1741, F1 = 0.5193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:46:51,272 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:46:51,274 - INFO - Memory usage after evaluation start: 2991.18 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:46:59,217 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:46:59,223 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:46:59,223 - INFO - Accuracy: 0.6437\n",
      "2025-02-16 18:46:59,224 - INFO - F1_score: 0.5419\n",
      "2025-02-16 18:46:59,224 - INFO - Precision: 0.4264\n",
      "2025-02-16 18:46:59,225 - INFO - Recall: 0.7432\n",
      "2025-02-16 18:46:59,232 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:46:59,233 - INFO - Accuracy: 0.6858\n",
      "2025-02-16 18:46:59,233 - INFO - F1_score: 0.5729\n",
      "2025-02-16 18:46:59,234 - INFO - Precision: 0.4074\n",
      "2025-02-16 18:46:59,236 - INFO - Recall: 0.9649\n",
      "2025-02-16 18:46:59,241 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:46:59,242 - INFO - Accuracy: 0.5900\n",
      "2025-02-16 18:46:59,242 - INFO - F1_score: 0.4880\n",
      "2025-02-16 18:46:59,244 - INFO - Precision: 0.3377\n",
      "2025-02-16 18:46:59,245 - INFO - Recall: 0.8793\n",
      "2025-02-16 18:46:59,250 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:46:59,250 - INFO - Accuracy: 0.7931\n",
      "2025-02-16 18:46:59,251 - INFO - F1_score: 0.3077\n",
      "2025-02-16 18:46:59,252 - INFO - Precision: 0.3000\n",
      "2025-02-16 18:46:59,253 - INFO - Recall: 0.3158\n",
      "2025-02-16 18:46:59,259 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:46:59,259 - INFO - Accuracy: 0.8161\n",
      "2025-02-16 18:46:59,260 - INFO - F1_score: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:46:59,261 - INFO - Precision: 0.3871\n",
      "2025-02-16 18:46:59,263 - INFO - Recall: 0.7059\n",
      "2025-02-16 18:46:59,264 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:47:03,071 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:47:03,072 - INFO - Memory usage after evaluation end: 2996.68 MB\n",
      "2025-02-16 18:47:03,074 - INFO - Trial 12, Epoch 3: Loss = 0.9537, F1 = 0.4821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 18:47:05,594] Trial 12 finished with value: 0.5193231897362796 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 12 with value: 0.5193231897362796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:47:06,414 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-16 18:47:06,417 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:47:07,445 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 18:47:07,446 - INFO - Setting up data loaders...\n",
      "2025-02-16 18:47:07,447 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 18:47:07,449 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 18:47:07,450 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:49:54,104 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:49:54,106 - INFO - Memory usage after evaluation start: 3192.65 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:50:02,084 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:50:02,090 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:50:02,091 - INFO - Accuracy: 0.5441\n",
      "2025-02-16 18:50:02,091 - INFO - F1_score: 0.4936\n",
      "2025-02-16 18:50:02,092 - INFO - Precision: 0.3602\n",
      "2025-02-16 18:50:02,093 - INFO - Recall: 0.7838\n",
      "2025-02-16 18:50:02,099 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:50:02,100 - INFO - Accuracy: 0.7969\n",
      "2025-02-16 18:50:02,101 - INFO - F1_score: 0.6708\n",
      "2025-02-16 18:50:02,102 - INFO - Precision: 0.5192\n",
      "2025-02-16 18:50:02,103 - INFO - Recall: 0.9474\n",
      "2025-02-16 18:50:02,109 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:50:02,109 - INFO - Accuracy: 0.5057\n",
      "2025-02-16 18:50:02,110 - INFO - F1_score: 0.4367\n",
      "2025-02-16 18:50:02,112 - INFO - Precision: 0.2924\n",
      "2025-02-16 18:50:02,112 - INFO - Recall: 0.8621\n",
      "2025-02-16 18:50:02,118 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:50:02,119 - INFO - Accuracy: 0.6667\n",
      "2025-02-16 18:50:02,120 - INFO - F1_score: 0.3650\n",
      "2025-02-16 18:50:02,120 - INFO - Precision: 0.2525\n",
      "2025-02-16 18:50:02,122 - INFO - Recall: 0.6579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:50:02,129 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:50:02,130 - INFO - Accuracy: 0.8046\n",
      "2025-02-16 18:50:02,130 - INFO - F1_score: 0.4632\n",
      "2025-02-16 18:50:02,131 - INFO - Precision: 0.3607\n",
      "2025-02-16 18:50:02,133 - INFO - Recall: 0.6471\n",
      "2025-02-16 18:50:02,134 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:50:05,982 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:50:05,983 - INFO - Memory usage after evaluation end: 3196.40 MB\n",
      "2025-02-16 18:50:05,984 - INFO - Trial 13, Epoch 1: Loss = 1.4711, F1 = 0.4858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:52:53,664 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:52:53,665 - INFO - Memory usage after evaluation start: 3196.40 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:53:01,625 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:53:01,631 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:53:01,631 - INFO - Accuracy: 0.4828\n",
      "2025-02-16 18:53:01,632 - INFO - F1_score: 0.4788\n",
      "2025-02-16 18:53:01,633 - INFO - Precision: 0.3351\n",
      "2025-02-16 18:53:01,634 - INFO - Recall: 0.8378\n",
      "2025-02-16 18:53:01,639 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:53:01,640 - INFO - Accuracy: 0.7433\n",
      "2025-02-16 18:53:01,641 - INFO - F1_score: 0.6171\n",
      "2025-02-16 18:53:01,641 - INFO - Precision: 0.4576\n",
      "2025-02-16 18:53:01,643 - INFO - Recall: 0.9474\n",
      "2025-02-16 18:53:01,648 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:53:01,649 - INFO - Accuracy: 0.6475\n",
      "2025-02-16 18:53:01,649 - INFO - F1_score: 0.4889\n",
      "2025-02-16 18:53:01,650 - INFO - Precision: 0.3607\n",
      "2025-02-16 18:53:01,651 - INFO - Recall: 0.7586\n",
      "2025-02-16 18:53:01,657 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:53:01,658 - INFO - Accuracy: 0.6782\n",
      "2025-02-16 18:53:01,658 - INFO - F1_score: 0.3731\n",
      "2025-02-16 18:53:01,659 - INFO - Precision: 0.2604\n",
      "2025-02-16 18:53:01,659 - INFO - Recall: 0.6579\n",
      "2025-02-16 18:53:01,665 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:53:01,666 - INFO - Accuracy: 0.8621\n",
      "2025-02-16 18:53:01,666 - INFO - F1_score: 0.5385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:53:01,667 - INFO - Precision: 0.4773\n",
      "2025-02-16 18:53:01,668 - INFO - Recall: 0.6176\n",
      "2025-02-16 18:53:01,671 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:53:05,485 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:53:05,486 - INFO - Memory usage after evaluation end: 3202.02 MB\n",
      "2025-02-16 18:53:05,487 - INFO - Trial 13, Epoch 2: Loss = 1.2497, F1 = 0.4993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:55:53,086 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:55:53,087 - INFO - Memory usage after evaluation start: 3202.27 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:56:01,020 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:56:01,026 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:56:01,027 - INFO - Accuracy: 0.3831\n",
      "2025-02-16 18:56:01,028 - INFO - F1_score: 0.4615\n",
      "2025-02-16 18:56:01,028 - INFO - Precision: 0.3067\n",
      "2025-02-16 18:56:01,030 - INFO - Recall: 0.9324\n",
      "2025-02-16 18:56:01,035 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:56:01,036 - INFO - Accuracy: 0.7854\n",
      "2025-02-16 18:56:01,036 - INFO - F1_score: 0.6456\n",
      "2025-02-16 18:56:01,037 - INFO - Precision: 0.5050\n",
      "2025-02-16 18:56:01,039 - INFO - Recall: 0.8947\n",
      "2025-02-16 18:56:01,044 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:56:01,045 - INFO - Accuracy: 0.6820\n",
      "2025-02-16 18:56:01,046 - INFO - F1_score: 0.5257\n",
      "2025-02-16 18:56:01,046 - INFO - Precision: 0.3932\n",
      "2025-02-16 18:56:01,048 - INFO - Recall: 0.7931\n",
      "2025-02-16 18:56:01,053 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:56:01,054 - INFO - Accuracy: 0.7011\n",
      "2025-02-16 18:56:01,055 - INFO - F1_score: 0.3710\n",
      "2025-02-16 18:56:01,055 - INFO - Precision: 0.2674\n",
      "2025-02-16 18:56:01,056 - INFO - Recall: 0.6053\n",
      "2025-02-16 18:56:01,062 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:56:01,063 - INFO - Accuracy: 0.8544\n",
      "2025-02-16 18:56:01,063 - INFO - F1_score: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:56:01,064 - INFO - Precision: 0.4565\n",
      "2025-02-16 18:56:01,065 - INFO - Recall: 0.6176\n",
      "2025-02-16 18:56:01,067 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:56:04,889 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:56:04,890 - INFO - Memory usage after evaluation end: 3208.02 MB\n",
      "2025-02-16 18:56:04,892 - INFO - Trial 13, Epoch 3: Loss = 1.1018, F1 = 0.5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 18:56:07,528] Trial 13 finished with value: 0.5057580218882791 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}. Best is trial 12 with value: 0.5193231897362796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:56:08,396 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-16 18:56:08,400 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:56:09,433 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 18:56:09,434 - INFO - Setting up data loaders...\n",
      "2025-02-16 18:56:09,435 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 18:56:09,437 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 18:56:09,439 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:58:56,193 - INFO - Starting model evaluation...\n",
      "2025-02-16 18:58:56,195 - INFO - Memory usage after evaluation start: 3316.40 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:59:04,151 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 18:59:04,158 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 18:59:04,158 - INFO - Accuracy: 0.5709\n",
      "2025-02-16 18:59:04,159 - INFO - F1_score: 0.5294\n",
      "2025-02-16 18:59:04,160 - INFO - Precision: 0.3841\n",
      "2025-02-16 18:59:04,161 - INFO - Recall: 0.8514\n",
      "2025-02-16 18:59:04,167 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 18:59:04,167 - INFO - Accuracy: 0.8467\n",
      "2025-02-16 18:59:04,168 - INFO - F1_score: 0.7101\n",
      "2025-02-16 18:59:04,169 - INFO - Precision: 0.6049\n",
      "2025-02-16 18:59:04,170 - INFO - Recall: 0.8596\n",
      "2025-02-16 18:59:04,176 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 18:59:04,177 - INFO - Accuracy: 0.5517\n",
      "2025-02-16 18:59:04,177 - INFO - F1_score: 0.4658\n",
      "2025-02-16 18:59:04,178 - INFO - Precision: 0.3168\n",
      "2025-02-16 18:59:04,179 - INFO - Recall: 0.8793\n",
      "2025-02-16 18:59:04,185 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 18:59:04,186 - INFO - Accuracy: 0.7241\n",
      "2025-02-16 18:59:04,186 - INFO - F1_score: 0.4000\n",
      "2025-02-16 18:59:04,187 - INFO - Precision: 0.2927\n",
      "2025-02-16 18:59:04,189 - INFO - Recall: 0.6316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 18:59:04,196 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 18:59:04,196 - INFO - Accuracy: 0.5211\n",
      "2025-02-16 18:59:04,197 - INFO - F1_score: 0.3094\n",
      "2025-02-16 18:59:04,198 - INFO - Precision: 0.1905\n",
      "2025-02-16 18:59:04,198 - INFO - Recall: 0.8235\n",
      "2025-02-16 18:59:04,201 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 18:59:08,044 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 18:59:08,045 - INFO - Memory usage after evaluation end: 3321.03 MB\n",
      "2025-02-16 18:59:08,047 - INFO - Trial 14, Epoch 1: Loss = 1.4688, F1 = 0.4829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:01:55,674 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:01:55,676 - INFO - Memory usage after evaluation start: 3321.15 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:02:03,615 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:02:03,620 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:02:03,621 - INFO - Accuracy: 0.4904\n",
      "2025-02-16 19:02:03,622 - INFO - F1_score: 0.4904\n",
      "2025-02-16 19:02:03,622 - INFO - Precision: 0.3422\n",
      "2025-02-16 19:02:03,623 - INFO - Recall: 0.8649\n",
      "2025-02-16 19:02:03,629 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:02:03,630 - INFO - Accuracy: 0.8199\n",
      "2025-02-16 19:02:03,631 - INFO - F1_score: 0.6803\n",
      "2025-02-16 19:02:03,632 - INFO - Precision: 0.5556\n",
      "2025-02-16 19:02:03,633 - INFO - Recall: 0.8772\n",
      "2025-02-16 19:02:03,639 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:02:03,639 - INFO - Accuracy: 0.6092\n",
      "2025-02-16 19:02:03,640 - INFO - F1_score: 0.4457\n",
      "2025-02-16 19:02:03,640 - INFO - Precision: 0.3254\n",
      "2025-02-16 19:02:03,641 - INFO - Recall: 0.7069\n",
      "2025-02-16 19:02:03,647 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:02:03,648 - INFO - Accuracy: 0.5824\n",
      "2025-02-16 19:02:03,649 - INFO - F1_score: 0.3394\n",
      "2025-02-16 19:02:03,650 - INFO - Precision: 0.2205\n",
      "2025-02-16 19:02:03,651 - INFO - Recall: 0.7368\n",
      "2025-02-16 19:02:03,657 - INFO - \n",
      "Metrics for Romantis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:02:03,658 - INFO - Accuracy: 0.7625\n",
      "2025-02-16 19:02:03,658 - INFO - F1_score: 0.4259\n",
      "2025-02-16 19:02:03,659 - INFO - Precision: 0.3108\n",
      "2025-02-16 19:02:03,661 - INFO - Recall: 0.6765\n",
      "2025-02-16 19:02:03,663 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 19:02:07,511 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:02:07,512 - INFO - Memory usage after evaluation end: 3326.65 MB\n",
      "2025-02-16 19:02:07,513 - INFO - Trial 14, Epoch 2: Loss = 1.1864, F1 = 0.4763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:04:55,285 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:04:55,286 - INFO - Memory usage after evaluation start: 3326.90 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:05:03,213 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:05:03,218 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:05:03,219 - INFO - Accuracy: 0.5326\n",
      "2025-02-16 19:05:03,219 - INFO - F1_score: 0.5081\n",
      "2025-02-16 19:05:03,220 - INFO - Precision: 0.3621\n",
      "2025-02-16 19:05:03,221 - INFO - Recall: 0.8514\n",
      "2025-02-16 19:05:03,227 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:05:03,228 - INFO - Accuracy: 0.8391\n",
      "2025-02-16 19:05:03,228 - INFO - F1_score: 0.7083\n",
      "2025-02-16 19:05:03,229 - INFO - Precision: 0.5862\n",
      "2025-02-16 19:05:03,230 - INFO - Recall: 0.8947\n",
      "2025-02-16 19:05:03,236 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:05:03,237 - INFO - Accuracy: 0.4789\n",
      "2025-02-16 19:05:03,237 - INFO - F1_score: 0.4380\n",
      "2025-02-16 19:05:03,238 - INFO - Precision: 0.2880\n",
      "2025-02-16 19:05:03,239 - INFO - Recall: 0.9138\n",
      "2025-02-16 19:05:03,245 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:05:03,245 - INFO - Accuracy: 0.7241\n",
      "2025-02-16 19:05:03,246 - INFO - F1_score: 0.4000\n",
      "2025-02-16 19:05:03,247 - INFO - Precision: 0.2927\n",
      "2025-02-16 19:05:03,248 - INFO - Recall: 0.6316\n",
      "2025-02-16 19:05:03,254 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:05:03,254 - INFO - Accuracy: 0.7548\n",
      "2025-02-16 19:05:03,255 - INFO - F1_score: 0.3962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:05:03,256 - INFO - Precision: 0.2917\n",
      "2025-02-16 19:05:03,257 - INFO - Recall: 0.6176\n",
      "2025-02-16 19:05:03,260 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 19:05:07,064 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:05:07,065 - INFO - Memory usage after evaluation end: 3333.03 MB\n",
      "2025-02-16 19:05:07,066 - INFO - Trial 14, Epoch 3: Loss = 1.0667, F1 = 0.4901\n",
      "2025-02-16 19:05:07,068 - ERROR - Error in trial training: \n",
      "2025-02-16 19:05:08,000 - ERROR - Error in optimization objective: \n",
      "2025-02-16 19:05:08,002 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 19:05:08,003] Trial 14 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:05:08,936 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-16 19:05:08,940 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:05:10,043 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 19:05:10,044 - INFO - Setting up data loaders...\n",
      "2025-02-16 19:05:10,045 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 19:05:10,047 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 19:05:10,048 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:07:27,998 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:07:28,001 - INFO - Memory usage after evaluation start: 3335.04 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:07:35,394 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:07:35,399 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:07:35,400 - INFO - Accuracy: 0.5441\n",
      "2025-02-16 19:07:35,401 - INFO - F1_score: 0.4979\n",
      "2025-02-16 19:07:35,402 - INFO - Precision: 0.3620\n",
      "2025-02-16 19:07:35,402 - INFO - Recall: 0.7973\n",
      "2025-02-16 19:07:35,408 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:07:35,409 - INFO - Accuracy: 0.6782\n",
      "2025-02-16 19:07:35,410 - INFO - F1_score: 0.4815\n",
      "2025-02-16 19:07:35,411 - INFO - Precision: 0.3714\n",
      "2025-02-16 19:07:35,411 - INFO - Recall: 0.6842\n",
      "2025-02-16 19:07:35,417 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:07:35,418 - INFO - Accuracy: 0.6743\n",
      "2025-02-16 19:07:35,419 - INFO - F1_score: 0.3411\n",
      "2025-02-16 19:07:35,420 - INFO - Precision: 0.3099\n",
      "2025-02-16 19:07:35,420 - INFO - Recall: 0.3793\n",
      "2025-02-16 19:07:35,426 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:07:35,426 - INFO - Accuracy: 0.5019\n",
      "2025-02-16 19:07:35,427 - INFO - F1_score: 0.3299\n",
      "2025-02-16 19:07:35,428 - INFO - Precision: 0.2051\n",
      "2025-02-16 19:07:35,428 - INFO - Recall: 0.8421\n",
      "2025-02-16 19:07:35,435 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:07:35,436 - INFO - Accuracy: 0.7739\n",
      "2025-02-16 19:07:35,436 - INFO - F1_score: 0.3656\n",
      "2025-02-16 19:07:35,437 - INFO - Precision: 0.2881\n",
      "2025-02-16 19:07:35,438 - INFO - Recall: 0.5000\n",
      "2025-02-16 19:07:35,440 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:07:39,274 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:07:39,276 - INFO - Memory usage after evaluation end: 3338.67 MB\n",
      "2025-02-16 19:07:39,276 - INFO - Trial 15, Epoch 1: Loss = 1.5864, F1 = 0.4032\n",
      "2025-02-16 19:07:39,278 - ERROR - Error in trial training: \n",
      "2025-02-16 19:07:40,423 - ERROR - Error in optimization objective: \n",
      "2025-02-16 19:07:40,424 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 19:07:40,425] Trial 15 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:07:41,375 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-16 19:07:41,379 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:07:42,384 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 19:07:42,385 - INFO - Setting up data loaders...\n",
      "2025-02-16 19:07:42,386 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 19:07:42,388 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 19:07:42,390 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:10:29,052 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:10:29,054 - INFO - Memory usage after evaluation start: 3340.68 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:10:36,999 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:10:37,006 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:10:37,006 - INFO - Accuracy: 0.5402\n",
      "2025-02-16 19:10:37,007 - INFO - F1_score: 0.4872\n",
      "2025-02-16 19:10:37,008 - INFO - Precision: 0.3563\n",
      "2025-02-16 19:10:37,009 - INFO - Recall: 0.7703\n",
      "2025-02-16 19:10:37,015 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:10:37,016 - INFO - Accuracy: 0.8046\n",
      "2025-02-16 19:10:37,016 - INFO - F1_score: 0.6752\n",
      "2025-02-16 19:10:37,017 - INFO - Precision: 0.5300\n",
      "2025-02-16 19:10:37,018 - INFO - Recall: 0.9298\n",
      "2025-02-16 19:10:37,024 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:10:37,025 - INFO - Accuracy: 0.4521\n",
      "2025-02-16 19:10:37,026 - INFO - F1_score: 0.4392\n",
      "2025-02-16 19:10:37,026 - INFO - Precision: 0.2843\n",
      "2025-02-16 19:10:37,027 - INFO - Recall: 0.9655\n",
      "2025-02-16 19:10:37,034 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:10:37,034 - INFO - Accuracy: 0.6628\n",
      "2025-02-16 19:10:37,035 - INFO - F1_score: 0.4133\n",
      "2025-02-16 19:10:37,036 - INFO - Precision: 0.2768\n",
      "2025-02-16 19:10:37,037 - INFO - Recall: 0.8158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:10:37,043 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:10:37,044 - INFO - Accuracy: 0.6552\n",
      "2025-02-16 19:10:37,046 - INFO - F1_score: 0.3662\n",
      "2025-02-16 19:10:37,046 - INFO - Precision: 0.2407\n",
      "2025-02-16 19:10:37,048 - INFO - Recall: 0.7647\n",
      "2025-02-16 19:10:37,049 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 19:10:40,971 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:10:40,973 - INFO - Memory usage after evaluation end: 3344.43 MB\n",
      "2025-02-16 19:10:40,974 - INFO - Trial 16, Epoch 1: Loss = 1.4523, F1 = 0.4762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:13:28,796 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:13:28,798 - INFO - Memory usage after evaluation start: 3344.55 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:13:36,726 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:13:36,732 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:13:36,732 - INFO - Accuracy: 0.5134\n",
      "2025-02-16 19:13:36,733 - INFO - F1_score: 0.5097\n",
      "2025-02-16 19:13:36,734 - INFO - Precision: 0.3568\n",
      "2025-02-16 19:13:36,735 - INFO - Recall: 0.8919\n",
      "2025-02-16 19:13:36,740 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:13:36,741 - INFO - Accuracy: 0.7050\n",
      "2025-02-16 19:13:36,742 - INFO - F1_score: 0.5882\n",
      "2025-02-16 19:13:36,743 - INFO - Precision: 0.4231\n",
      "2025-02-16 19:13:36,744 - INFO - Recall: 0.9649\n",
      "2025-02-16 19:13:36,750 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:13:36,751 - INFO - Accuracy: 0.5900\n",
      "2025-02-16 19:13:36,751 - INFO - F1_score: 0.4880\n",
      "2025-02-16 19:13:36,752 - INFO - Precision: 0.3377\n",
      "2025-02-16 19:13:36,754 - INFO - Recall: 0.8793\n",
      "2025-02-16 19:13:36,760 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:13:36,761 - INFO - Accuracy: 0.5517\n",
      "2025-02-16 19:13:36,762 - INFO - F1_score: 0.3314\n",
      "2025-02-16 19:13:36,762 - INFO - Precision: 0.2117\n",
      "2025-02-16 19:13:36,763 - INFO - Recall: 0.7632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:13:36,770 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:13:36,771 - INFO - Accuracy: 0.8161\n",
      "2025-02-16 19:13:36,771 - INFO - F1_score: 0.4419\n",
      "2025-02-16 19:13:36,772 - INFO - Precision: 0.3654\n",
      "2025-02-16 19:13:36,773 - INFO - Recall: 0.5588\n",
      "2025-02-16 19:13:36,776 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 19:13:40,675 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:13:40,677 - INFO - Memory usage after evaluation end: 3350.05 MB\n",
      "2025-02-16 19:13:40,677 - INFO - Trial 16, Epoch 2: Loss = 1.1865, F1 = 0.4718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:16:28,382 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:16:28,384 - INFO - Memory usage after evaluation start: 3350.05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:16:36,326 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:16:36,333 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:16:36,334 - INFO - Accuracy: 0.4828\n",
      "2025-02-16 19:16:36,334 - INFO - F1_score: 0.4906\n",
      "2025-02-16 19:16:36,335 - INFO - Precision: 0.3403\n",
      "2025-02-16 19:16:36,337 - INFO - Recall: 0.8784\n",
      "2025-02-16 19:16:36,343 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:16:36,343 - INFO - Accuracy: 0.8161\n",
      "2025-02-16 19:16:36,344 - INFO - F1_score: 0.6800\n",
      "2025-02-16 19:16:36,345 - INFO - Precision: 0.5484\n",
      "2025-02-16 19:16:36,346 - INFO - Recall: 0.8947\n",
      "2025-02-16 19:16:36,352 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:16:36,353 - INFO - Accuracy: 0.6284\n",
      "2025-02-16 19:16:36,354 - INFO - F1_score: 0.5026\n",
      "2025-02-16 19:16:36,355 - INFO - Precision: 0.3577\n",
      "2025-02-16 19:16:36,356 - INFO - Recall: 0.8448\n",
      "2025-02-16 19:16:36,362 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:16:36,363 - INFO - Accuracy: 0.6897\n",
      "2025-02-16 19:16:36,364 - INFO - F1_score: 0.4088\n",
      "2025-02-16 19:16:36,365 - INFO - Precision: 0.2828\n",
      "2025-02-16 19:16:36,366 - INFO - Recall: 0.7368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:16:36,374 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:16:36,375 - INFO - Accuracy: 0.7816\n",
      "2025-02-16 19:16:36,375 - INFO - F1_score: 0.4571\n",
      "2025-02-16 19:16:36,376 - INFO - Precision: 0.3380\n",
      "2025-02-16 19:16:36,376 - INFO - Recall: 0.7059\n",
      "2025-02-16 19:16:36,379 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 19:16:40,244 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:16:40,246 - INFO - Memory usage after evaluation end: 3355.80 MB\n",
      "2025-02-16 19:16:40,247 - INFO - Trial 16, Epoch 3: Loss = 1.0191, F1 = 0.5078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 19:16:43,236] Trial 16 finished with value: 0.50780642430608 and parameters: {'batch_size': 2, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.2, 'smoothing': 0.1}. Best is trial 12 with value: 0.5193231897362796.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:16:44,222 - INFO - Trial parameter set: {'batch_size': 2, 'learning_rate': 3e-06, 'weight_decay': 0.01, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-16 19:16:44,226 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:16:45,301 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 19:16:45,302 - INFO - Setting up data loaders...\n",
      "2025-02-16 19:16:45,303 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 19:16:45,305 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 19:16:45,306 - INFO - Created data loaders with batch size 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:19:31,966 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:19:31,968 - INFO - Memory usage after evaluation start: 3357.95 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 131/131 [00:07<00:00, 16.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:19:39,904 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:19:39,910 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:19:39,911 - INFO - Accuracy: 0.6513\n",
      "2025-02-16 19:19:39,911 - INFO - F1_score: 0.5081\n",
      "2025-02-16 19:19:39,912 - INFO - Precision: 0.4234\n",
      "2025-02-16 19:19:39,913 - INFO - Recall: 0.6351\n",
      "2025-02-16 19:19:39,919 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:19:39,920 - INFO - Accuracy: 0.6437\n",
      "2025-02-16 19:19:39,920 - INFO - F1_score: 0.5419\n",
      "2025-02-16 19:19:39,922 - INFO - Precision: 0.3767\n",
      "2025-02-16 19:19:39,922 - INFO - Recall: 0.9649\n",
      "2025-02-16 19:19:39,928 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:19:39,929 - INFO - Accuracy: 0.6782\n",
      "2025-02-16 19:19:39,929 - INFO - F1_score: 0.4085\n",
      "2025-02-16 19:19:39,931 - INFO - Precision: 0.3452\n",
      "2025-02-16 19:19:39,932 - INFO - Recall: 0.5000\n",
      "2025-02-16 19:19:39,937 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:19:39,938 - INFO - Accuracy: 0.5594\n",
      "2025-02-16 19:19:39,938 - INFO - F1_score: 0.3353\n",
      "2025-02-16 19:19:39,939 - INFO - Precision: 0.2148\n",
      "2025-02-16 19:19:39,940 - INFO - Recall: 0.7632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:19:39,947 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:19:39,948 - INFO - Accuracy: 0.7701\n",
      "2025-02-16 19:19:39,948 - INFO - F1_score: 0.4231\n",
      "2025-02-16 19:19:39,949 - INFO - Precision: 0.3143\n",
      "2025-02-16 19:19:39,950 - INFO - Recall: 0.6471\n",
      "2025-02-16 19:19:39,952 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 19:19:43,713 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:19:43,715 - INFO - Memory usage after evaluation end: 3361.45 MB\n",
      "2025-02-16 19:19:43,716 - INFO - Trial 17, Epoch 1: Loss = 1.5410, F1 = 0.4434\n",
      "2025-02-16 19:19:43,717 - ERROR - Error in trial training: \n",
      "2025-02-16 19:19:44,845 - ERROR - Error in optimization objective: \n",
      "2025-02-16 19:19:44,846 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 19:19:44,847] Trial 17 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:19:45,861 - INFO - Trial parameter set: {'batch_size': 8, 'learning_rate': 8e-06, 'weight_decay': 0.02, 'mixup_prob': 0.3, 'smoothing': 0.1}\n",
      "2025-02-16 19:19:45,865 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:19:46,837 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 19:19:46,838 - INFO - Setting up data loaders...\n",
      "2025-02-16 19:19:46,839 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 19:19:46,841 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 19:19:46,842 - INFO - Created data loaders with batch size 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:22:05,228 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:22:05,230 - INFO - Memory usage after evaluation start: 3485.26 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 33/33 [00:07<00:00,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:22:12,618 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:22:12,624 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:22:12,625 - INFO - Accuracy: 0.5019\n",
      "2025-02-16 19:22:12,626 - INFO - F1_score: 0.4800\n",
      "2025-02-16 19:22:12,627 - INFO - Precision: 0.3409\n",
      "2025-02-16 19:22:12,627 - INFO - Recall: 0.8108\n",
      "2025-02-16 19:22:12,634 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:22:12,634 - INFO - Accuracy: 0.3640\n",
      "2025-02-16 19:22:12,635 - INFO - F1_score: 0.4029\n",
      "2025-02-16 19:22:12,636 - INFO - Precision: 0.2534\n",
      "2025-02-16 19:22:12,637 - INFO - Recall: 0.9825\n",
      "2025-02-16 19:22:12,643 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:22:12,644 - INFO - Accuracy: 0.3716\n",
      "2025-02-16 19:22:12,644 - INFO - F1_score: 0.3881\n",
      "2025-02-16 19:22:12,645 - INFO - Precision: 0.2476\n",
      "2025-02-16 19:22:12,646 - INFO - Recall: 0.8966\n",
      "2025-02-16 19:22:12,651 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:22:12,652 - INFO - Accuracy: 0.6284\n",
      "2025-02-16 19:22:12,653 - INFO - F1_score: 0.3217\n",
      "2025-02-16 19:22:12,653 - INFO - Precision: 0.2190\n",
      "2025-02-16 19:22:12,655 - INFO - Recall: 0.6053\n",
      "2025-02-16 19:22:12,660 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:22:12,661 - INFO - Accuracy: 0.5134\n",
      "2025-02-16 19:22:12,662 - INFO - F1_score: 0.3135\n",
      "2025-02-16 19:22:12,663 - INFO - Precision: 0.1921\n",
      "2025-02-16 19:22:12,663 - INFO - Recall: 0.8529\n",
      "2025-02-16 19:22:12,665 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:22:16,604 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:22:16,606 - INFO - Memory usage after evaluation end: 3488.76 MB\n",
      "2025-02-16 19:22:16,607 - INFO - Trial 18, Epoch 1: Loss = 1.5425, F1 = 0.3812\n",
      "2025-02-16 19:22:16,609 - ERROR - Error in trial training: \n",
      "2025-02-16 19:22:17,790 - ERROR - Error in optimization objective: \n",
      "2025-02-16 19:22:17,792 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 19:22:17,793] Trial 18 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:22:18,839 - INFO - Trial parameter set: {'batch_size': 4, 'learning_rate': 8e-06, 'weight_decay': 0.01, 'mixup_prob': 0.2, 'smoothing': 0.1}\n",
      "2025-02-16 19:22:18,854 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:22:19,917 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 19:22:19,918 - INFO - Setting up data loaders...\n",
      "2025-02-16 19:22:19,919 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 19:22:19,921 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 19:22:19,923 - INFO - Created data loaders with batch size 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:24:48,072 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:24:48,073 - INFO - Memory usage after evaluation start: 3368.29 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 66/66 [00:07<00:00,  8.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:24:55,940 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:24:55,946 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:24:55,947 - INFO - Accuracy: 0.3525\n",
      "2025-02-16 19:24:55,948 - INFO - F1_score: 0.4566\n",
      "2025-02-16 19:24:55,948 - INFO - Precision: 0.2996\n",
      "2025-02-16 19:24:55,950 - INFO - Recall: 0.9595\n",
      "2025-02-16 19:24:55,955 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:24:55,956 - INFO - Accuracy: 0.8046\n",
      "2025-02-16 19:24:55,956 - INFO - F1_score: 0.6710\n",
      "2025-02-16 19:24:55,958 - INFO - Precision: 0.5306\n",
      "2025-02-16 19:24:55,958 - INFO - Recall: 0.9123\n",
      "2025-02-16 19:24:55,964 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:24:55,964 - INFO - Accuracy: 0.7548\n",
      "2025-02-16 19:24:55,965 - INFO - F1_score: 0.3725\n",
      "2025-02-16 19:24:55,966 - INFO - Precision: 0.4318\n",
      "2025-02-16 19:24:55,966 - INFO - Recall: 0.3276\n",
      "2025-02-16 19:24:55,972 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:24:55,973 - INFO - Accuracy: 0.5479\n",
      "2025-02-16 19:24:55,974 - INFO - F1_score: 0.3295\n",
      "2025-02-16 19:24:55,974 - INFO - Precision: 0.2101\n",
      "2025-02-16 19:24:55,975 - INFO - Recall: 0.7632\n",
      "2025-02-16 19:24:55,981 - INFO - \n",
      "Metrics for Romantis:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:24:55,982 - INFO - Accuracy: 0.7318\n",
      "2025-02-16 19:24:55,982 - INFO - F1_score: 0.4167\n",
      "2025-02-16 19:24:55,984 - INFO - Precision: 0.2907\n",
      "2025-02-16 19:24:55,984 - INFO - Recall: 0.7353\n",
      "2025-02-16 19:24:55,986 - INFO - Generating detailed confusion matrices for each genre...\n",
      "2025-02-16 19:24:59,846 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:24:59,848 - INFO - Memory usage after evaluation end: 3373.04 MB\n",
      "2025-02-16 19:24:59,849 - INFO - Trial 19, Epoch 1: Loss = 1.4472, F1 = 0.4493\n",
      "2025-02-16 19:24:59,851 - ERROR - Error in trial training: \n",
      "2025-02-16 19:25:01,017 - ERROR - Error in optimization objective: \n",
      "2025-02-16 19:25:01,018 - ERROR - Error in objective: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-16 19:25:01,019] Trial 19 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:25:02,065 - INFO - \n",
      "Hyperparameter Optimization Results:\n",
      "2025-02-16 19:25:02,068 - INFO - Best trial number: 12\n",
      "2025-02-16 19:25:02,069 - INFO - Best F1-score: 0.5193\n",
      "2025-02-16 19:25:02,070 - INFO - \n",
      "Best hyperparameters:\n",
      "2025-02-16 19:25:02,071 - INFO - batch_size: 2\n",
      "2025-02-16 19:25:02,072 - INFO - learning_rate: 8e-06\n",
      "2025-02-16 19:25:02,073 - INFO - weight_decay: 0.01\n",
      "2025-02-16 19:25:02,074 - INFO - mixup_prob: 0.2\n",
      "2025-02-16 19:25:02,075 - INFO - smoothing: 0.1\n",
      "2025-02-16 19:25:03,511 - WARNING - Could not create optimization plots: \n",
      "Image export using the \"kaleido\" engine requires the kaleido package,\n",
      "which can be installed using pip:\n",
      "    $ pip install -U kaleido\n",
      "\n",
      "2025-02-16 19:25:04,638 - INFO - \n",
      "Best Hyperparameters found:\n",
      "2025-02-16 19:25:04,640 - INFO - batch_size: 2\n",
      "2025-02-16 19:25:04,640 - INFO - learning_rate: 8e-06\n",
      "2025-02-16 19:25:04,642 - INFO - weight_decay: 0.01\n",
      "2025-02-16 19:25:04,643 - INFO - mixup_prob: 0.2\n",
      "2025-02-16 19:25:04,644 - INFO - smoothing: 0.1\n",
      "2025-02-16 19:25:04,645 - INFO - \n",
      "Training final model with optimized parameters...\n",
      "2025-02-16 19:25:04,646 - INFO - Starting model training\n",
      "2025-02-16 19:25:04,647 - INFO - Memory usage after training start: 3382.66 MB\n",
      "2025-02-16 19:25:04,658 - INFO - Loading and preprocessing data...\n",
      "2025-02-16 19:25:04,659 - INFO - Memory usage after start: 3382.66 MB\n",
      "2025-02-16 19:25:04,673 - INFO - Successfully loaded data using utf-8 encoding\n",
      "2025-02-16 19:25:04,674 - INFO - Memory usage after data loading: 3382.91 MB\n",
      "2025-02-16 19:25:04,675 - INFO - Using full dataset with 1738 samples\n",
      "2025-02-16 19:25:04,675 - INFO - \n",
      "Sample data:\n",
      "2025-02-16 19:25:04,676 - INFO - \n",
      "Sample 1:\n",
      "2025-02-16 19:25:04,678 - INFO - Synopsis: Setelah kematian yang tampak, Siena mampu melihat tanda-tanda bahwa orang-orang akan meninggal. Namu...\n",
      "2025-02-16 19:25:04,679 - INFO - Genre: Horor\n",
      "2025-02-16 19:25:04,680 - INFO - \n",
      "Sample 2:\n",
      "2025-02-16 19:25:04,681 - INFO - Synopsis: Alfi (Al Ghazali) bertemu dengan Alana (Caitlin Halderman), seorang siswa baru di sekolahnya. Ternya...\n",
      "2025-02-16 19:25:04,682 - INFO - Genre: Drama\n",
      "2025-02-16 19:25:04,683 - INFO - \n",
      "Sample 3:\n",
      "2025-02-16 19:25:04,684 - INFO - Synopsis: Ketika gaji staf di sekolahnya dicuri, seorang guru baru yang enggan berusaha untuk mendapatkan kemb...\n",
      "2025-02-16 19:25:04,685 - INFO - Genre: Komedi\n",
      "2025-02-16 19:25:04,686 - INFO - \n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1738/1738 [00:00<00:00, 14700.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:25:04,812 - INFO - Memory usage after preprocessing: 3383.54 MB\n",
      "2025-02-16 19:25:04,813 - INFO - \n",
      "Dataset statistics:\n",
      "2025-02-16 19:25:04,813 - INFO - Total samples after preprocessing: 1738\n",
      "2025-02-16 19:25:04,819 - INFO - Genre 'Drama': 510 samples\n",
      "2025-02-16 19:25:04,819 - INFO - Genre 'Horor': 349 samples\n",
      "2025-02-16 19:25:04,820 - INFO - Genre 'Komedi': 374 samples\n",
      "2025-02-16 19:25:04,820 - INFO - Genre 'Laga': 297 samples\n",
      "2025-02-16 19:25:04,822 - INFO - Genre 'Romantis': 208 samples\n",
      "2025-02-16 19:25:04,823 - INFO - \n",
      "Training set size: 1477\n",
      "2025-02-16 19:25:04,824 - INFO - Testing set size: 261\n",
      "2025-02-16 19:25:04,824 - INFO - Setting up model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:25:05,765 - INFO - Model and tokenizer setup completed\n",
      "2025-02-16 19:25:05,766 - INFO - Setting up data loaders...\n",
      "2025-02-16 19:25:05,767 - INFO - Creating weighted sampler for balanced batch sampling...\n",
      "2025-02-16 19:25:05,769 - INFO - Created sampler with 1477 weights\n",
      "2025-02-16 19:25:05,770 - INFO - Created data loaders with batch size 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [00:00<?, ?it/s]\n",
      "Epoch 1:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:   0%|          | 0/148 [00:01<?, ?it/s, training_loss=1.8541]\u001b[A\n",
      "Epoch 1:   1%|          | 1/148 [00:01<03:05,  1.26s/it, training_loss=1.8541]\u001b[A\n",
      "Epoch 1:   1%|          | 1/148 [00:02<03:05,  1.26s/it, training_loss=1.6993]\u001b[A\n",
      "Epoch 1:   1%|▏         | 2/148 [00:02<02:33,  1.05s/it, training_loss=1.6993]\u001b[A\n",
      "Epoch 1:   1%|▏         | 2/148 [00:03<02:33,  1.05s/it, training_loss=1.7109]\u001b[A\n",
      "Epoch 1:   2%|▏         | 3/148 [00:03<02:22,  1.02it/s, training_loss=1.7109]\u001b[A\n",
      "Epoch 1:   2%|▏         | 3/148 [00:03<02:22,  1.02it/s, training_loss=1.6743]\u001b[A\n",
      "Epoch 1:   3%|▎         | 4/148 [00:03<02:17,  1.05it/s, training_loss=1.6743]\u001b[A\n",
      "Epoch 1:   3%|▎         | 4/148 [00:04<02:17,  1.05it/s, training_loss=1.6275]\u001b[A\n",
      "Epoch 1:   3%|▎         | 5/148 [00:04<02:14,  1.07it/s, training_loss=1.6275]\u001b[A\n",
      "Epoch 1:   3%|▎         | 5/148 [00:05<02:14,  1.07it/s, training_loss=1.6878]\u001b[A\n",
      "Epoch 1:   4%|▍         | 6/148 [00:05<02:11,  1.08it/s, training_loss=1.6878]\u001b[A\n",
      "Epoch 1:   4%|▍         | 6/148 [00:06<02:11,  1.08it/s, training_loss=1.6418]\u001b[A\n",
      "Epoch 1:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=1.6418]\u001b[A\n",
      "Epoch 1:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=1.5351]\u001b[A\n",
      "Epoch 1:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=1.5351]\u001b[A\n",
      "Epoch 1:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=1.6431]\u001b[A\n",
      "Epoch 1:   6%|▌         | 9/148 [00:08<02:06,  1.10it/s, training_loss=1.6431]\u001b[A\n",
      "Epoch 1:   6%|▌         | 9/148 [00:09<02:06,  1.10it/s, training_loss=1.5752]\u001b[A\n",
      "Epoch 1:   7%|▋         | 10/148 [00:09<02:05,  1.10it/s, training_loss=1.5752]\u001b[A\n",
      "Epoch 1:   7%|▋         | 10/148 [00:10<02:05,  1.10it/s, training_loss=1.6303]\u001b[A\n",
      "Epoch 1:   7%|▋         | 11/148 [00:10<02:04,  1.10it/s, training_loss=1.6303]\u001b[A\n",
      "Epoch 1:   7%|▋         | 11/148 [00:11<02:04,  1.10it/s, training_loss=1.5769]\u001b[A\n",
      "Epoch 1:   8%|▊         | 12/148 [00:11<02:03,  1.10it/s, training_loss=1.5769]\u001b[A\n",
      "Epoch 1:   8%|▊         | 12/148 [00:12<02:03,  1.10it/s, training_loss=1.6128]\u001b[A\n",
      "Epoch 1:   9%|▉         | 13/148 [00:12<02:02,  1.10it/s, training_loss=1.6128]\u001b[A\n",
      "Epoch 1:   9%|▉         | 13/148 [00:13<02:02,  1.10it/s, training_loss=1.6010]\u001b[A\n",
      "Epoch 1:   9%|▉         | 14/148 [00:13<02:02,  1.10it/s, training_loss=1.6010]\u001b[A\n",
      "Epoch 1:   9%|▉         | 14/148 [00:13<02:02,  1.10it/s, training_loss=1.6344]\u001b[A\n",
      "Epoch 1:  10%|█         | 15/148 [00:13<02:01,  1.09it/s, training_loss=1.6344]\u001b[A\n",
      "Epoch 1:  10%|█         | 15/148 [00:14<02:01,  1.09it/s, training_loss=1.6358]\u001b[A\n",
      "Epoch 1:  11%|█         | 16/148 [00:14<02:00,  1.09it/s, training_loss=1.6358]\u001b[A\n",
      "Epoch 1:  11%|█         | 16/148 [00:15<02:00,  1.09it/s, training_loss=1.5615]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 17/148 [00:15<01:59,  1.10it/s, training_loss=1.5615]\u001b[A\n",
      "Epoch 1:  11%|█▏        | 17/148 [00:16<01:59,  1.10it/s, training_loss=1.5807]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 18/148 [00:16<01:58,  1.09it/s, training_loss=1.5807]\u001b[A\n",
      "Epoch 1:  12%|█▏        | 18/148 [00:17<01:58,  1.09it/s, training_loss=1.5038]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 19/148 [00:17<01:58,  1.09it/s, training_loss=1.5038]\u001b[A\n",
      "Epoch 1:  13%|█▎        | 19/148 [00:18<01:58,  1.09it/s, training_loss=1.8524]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 20/148 [00:18<01:57,  1.09it/s, training_loss=1.8524]\u001b[A\n",
      "Epoch 1:  14%|█▎        | 20/148 [00:19<01:57,  1.09it/s, training_loss=1.7155]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 21/148 [00:19<01:56,  1.09it/s, training_loss=1.7155]\u001b[A\n",
      "Epoch 1:  14%|█▍        | 21/148 [00:20<01:56,  1.09it/s, training_loss=1.5646]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 22/148 [00:20<01:55,  1.09it/s, training_loss=1.5646]\u001b[A\n",
      "Epoch 1:  15%|█▍        | 22/148 [00:21<01:55,  1.09it/s, training_loss=1.6122]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 23/148 [00:21<01:55,  1.08it/s, training_loss=1.6122]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 23/148 [00:22<01:55,  1.08it/s, training_loss=1.7526]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=1.7526]\u001b[A\n",
      "Epoch 1:  16%|█▌        | 24/148 [00:23<01:54,  1.08it/s, training_loss=1.5173]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 25/148 [00:23<01:53,  1.09it/s, training_loss=1.5173]\u001b[A\n",
      "Epoch 1:  17%|█▋        | 25/148 [00:24<01:53,  1.09it/s, training_loss=1.5211]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 26/148 [00:24<01:52,  1.09it/s, training_loss=1.5211]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 26/148 [00:24<01:52,  1.09it/s, training_loss=1.5086]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 27/148 [00:24<01:51,  1.09it/s, training_loss=1.5086]\u001b[A\n",
      "Epoch 1:  18%|█▊        | 27/148 [00:25<01:51,  1.09it/s, training_loss=1.6525]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 28/148 [00:25<01:50,  1.09it/s, training_loss=1.6525]\u001b[A\n",
      "Epoch 1:  19%|█▉        | 28/148 [00:26<01:50,  1.09it/s, training_loss=1.5897]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 29/148 [00:26<01:49,  1.08it/s, training_loss=1.5897]\u001b[A\n",
      "Epoch 1:  20%|█▉        | 29/148 [00:27<01:49,  1.08it/s, training_loss=1.6131]\u001b[A\n",
      "Epoch 1:  20%|██        | 30/148 [00:27<01:49,  1.08it/s, training_loss=1.6131]\u001b[A\n",
      "Epoch 1:  20%|██        | 30/148 [00:28<01:49,  1.08it/s, training_loss=1.5283]\u001b[A\n",
      "Epoch 1:  21%|██        | 31/148 [00:28<01:48,  1.08it/s, training_loss=1.5283]\u001b[A\n",
      "Epoch 1:  21%|██        | 31/148 [00:29<01:48,  1.08it/s, training_loss=1.6299]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 32/148 [00:29<01:47,  1.08it/s, training_loss=1.6299]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 32/148 [00:30<01:47,  1.08it/s, training_loss=1.6935]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 33/148 [00:30<01:46,  1.08it/s, training_loss=1.6935]\u001b[A\n",
      "Epoch 1:  22%|██▏       | 33/148 [00:31<01:46,  1.08it/s, training_loss=1.6063]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 34/148 [00:31<01:45,  1.08it/s, training_loss=1.6063]\u001b[A\n",
      "Epoch 1:  23%|██▎       | 34/148 [00:32<01:45,  1.08it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 35/148 [00:32<01:44,  1.08it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 1:  24%|██▎       | 35/148 [00:33<01:44,  1.08it/s, training_loss=1.4605]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 36/148 [00:33<01:44,  1.08it/s, training_loss=1.4605]\u001b[A\n",
      "Epoch 1:  24%|██▍       | 36/148 [00:34<01:44,  1.08it/s, training_loss=1.6005]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 37/148 [00:34<01:43,  1.07it/s, training_loss=1.6005]\u001b[A\n",
      "Epoch 1:  25%|██▌       | 37/148 [00:35<01:43,  1.07it/s, training_loss=1.5741]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 38/148 [00:35<01:43,  1.06it/s, training_loss=1.5741]\u001b[A\n",
      "Epoch 1:  26%|██▌       | 38/148 [00:36<01:43,  1.06it/s, training_loss=1.6498]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 39/148 [00:36<01:42,  1.07it/s, training_loss=1.6498]\u001b[A\n",
      "Epoch 1:  26%|██▋       | 39/148 [00:37<01:42,  1.07it/s, training_loss=1.7582]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 40/148 [00:37<01:41,  1.07it/s, training_loss=1.7582]\u001b[A\n",
      "Epoch 1:  27%|██▋       | 40/148 [00:38<01:41,  1.07it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 41/148 [00:38<01:40,  1.07it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 41/148 [00:38<01:40,  1.07it/s, training_loss=1.5394]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 42/148 [00:38<01:39,  1.07it/s, training_loss=1.5394]\u001b[A\n",
      "Epoch 1:  28%|██▊       | 42/148 [00:39<01:39,  1.07it/s, training_loss=1.5784]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 43/148 [00:39<01:38,  1.07it/s, training_loss=1.5784]\u001b[A\n",
      "Epoch 1:  29%|██▉       | 43/148 [00:40<01:38,  1.07it/s, training_loss=1.7114]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 44/148 [00:40<01:37,  1.07it/s, training_loss=1.7114]\u001b[A\n",
      "Epoch 1:  30%|██▉       | 44/148 [00:41<01:37,  1.07it/s, training_loss=1.6023]\u001b[A\n",
      "Epoch 1:  30%|███       | 45/148 [00:41<01:36,  1.07it/s, training_loss=1.6023]\u001b[A\n",
      "Epoch 1:  30%|███       | 45/148 [00:42<01:36,  1.07it/s, training_loss=1.7371]\u001b[A\n",
      "Epoch 1:  31%|███       | 46/148 [00:42<01:35,  1.07it/s, training_loss=1.7371]\u001b[A\n",
      "Epoch 1:  31%|███       | 46/148 [00:43<01:35,  1.07it/s, training_loss=1.5293]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 47/148 [00:43<01:34,  1.07it/s, training_loss=1.5293]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 47/148 [00:44<01:34,  1.07it/s, training_loss=1.4989]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 48/148 [00:44<01:33,  1.07it/s, training_loss=1.4989]\u001b[A\n",
      "Epoch 1:  32%|███▏      | 48/148 [00:45<01:33,  1.07it/s, training_loss=1.5546]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 49/148 [00:45<01:32,  1.07it/s, training_loss=1.5546]\u001b[A\n",
      "Epoch 1:  33%|███▎      | 49/148 [00:46<01:32,  1.07it/s, training_loss=1.4744]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 50/148 [00:46<01:31,  1.07it/s, training_loss=1.4744]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 50/148 [00:47<01:31,  1.07it/s, training_loss=1.4908]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 51/148 [00:47<01:30,  1.07it/s, training_loss=1.4908]\u001b[A\n",
      "Epoch 1:  34%|███▍      | 51/148 [00:48<01:30,  1.07it/s, training_loss=1.6272]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 52/148 [00:48<01:29,  1.07it/s, training_loss=1.6272]\u001b[A\n",
      "Epoch 1:  35%|███▌      | 52/148 [00:49<01:29,  1.07it/s, training_loss=1.5112]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 53/148 [00:49<01:28,  1.07it/s, training_loss=1.5112]\u001b[A\n",
      "Epoch 1:  36%|███▌      | 53/148 [00:50<01:28,  1.07it/s, training_loss=1.5045]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 54/148 [00:50<01:27,  1.08it/s, training_loss=1.5045]\u001b[A\n",
      "Epoch 1:  36%|███▋      | 54/148 [00:51<01:27,  1.08it/s, training_loss=1.6754]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 55/148 [00:51<01:26,  1.08it/s, training_loss=1.6754]\u001b[A\n",
      "Epoch 1:  37%|███▋      | 55/148 [00:52<01:26,  1.08it/s, training_loss=1.5387]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 56/148 [00:52<01:25,  1.08it/s, training_loss=1.5387]\u001b[A\n",
      "Epoch 1:  38%|███▊      | 56/148 [00:52<01:25,  1.08it/s, training_loss=1.5782]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 57/148 [00:52<01:23,  1.08it/s, training_loss=1.5782]\u001b[A\n",
      "Epoch 1:  39%|███▊      | 57/148 [00:53<01:23,  1.08it/s, training_loss=1.5055]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 58/148 [00:53<01:23,  1.08it/s, training_loss=1.5055]\u001b[A\n",
      "Epoch 1:  39%|███▉      | 58/148 [00:54<01:23,  1.08it/s, training_loss=1.6904]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 59/148 [00:54<01:22,  1.08it/s, training_loss=1.6904]\u001b[A\n",
      "Epoch 1:  40%|███▉      | 59/148 [00:55<01:22,  1.08it/s, training_loss=1.6218]\u001b[A\n",
      "Epoch 1:  41%|████      | 60/148 [00:55<01:21,  1.08it/s, training_loss=1.6218]\u001b[A\n",
      "Epoch 1:  41%|████      | 60/148 [00:56<01:21,  1.08it/s, training_loss=1.5384]\u001b[A\n",
      "Epoch 1:  41%|████      | 61/148 [00:56<01:20,  1.09it/s, training_loss=1.5384]\u001b[A\n",
      "Epoch 1:  41%|████      | 61/148 [00:57<01:20,  1.09it/s, training_loss=1.5479]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 62/148 [00:57<01:19,  1.09it/s, training_loss=1.5479]\u001b[A\n",
      "Epoch 1:  42%|████▏     | 62/148 [00:58<01:19,  1.09it/s, training_loss=1.5806]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 63/148 [00:58<01:18,  1.08it/s, training_loss=1.5806]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 63/148 [00:59<01:18,  1.08it/s, training_loss=1.5130]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 64/148 [00:59<01:17,  1.09it/s, training_loss=1.5130]\u001b[A\n",
      "Epoch 1:  43%|████▎     | 64/148 [01:00<01:17,  1.09it/s, training_loss=1.4620]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 65/148 [01:00<01:16,  1.09it/s, training_loss=1.4620]\u001b[A\n",
      "Epoch 1:  44%|████▍     | 65/148 [01:01<01:16,  1.09it/s, training_loss=1.5832]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=1.5832]\u001b[A\n",
      "Epoch 1:  45%|████▍     | 66/148 [01:02<01:15,  1.09it/s, training_loss=1.5178]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=1.5178]\u001b[A\n",
      "Epoch 1:  45%|████▌     | 67/148 [01:03<01:14,  1.09it/s, training_loss=1.5751]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=1.5751]\u001b[A\n",
      "Epoch 1:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=1.6270]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=1.6270]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=1.5294]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=1.5294]\u001b[A\n",
      "Epoch 1:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 1:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.6863]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 72/148 [01:06<01:09,  1.10it/s, training_loss=1.6863]\u001b[A\n",
      "Epoch 1:  49%|████▊     | 72/148 [01:07<01:09,  1.10it/s, training_loss=1.4987]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 73/148 [01:07<01:08,  1.09it/s, training_loss=1.4987]\u001b[A\n",
      "Epoch 1:  49%|████▉     | 73/148 [01:08<01:08,  1.09it/s, training_loss=1.6555]\u001b[A\n",
      "Epoch 1:  50%|█████     | 74/148 [01:08<01:07,  1.10it/s, training_loss=1.6555]\u001b[A\n",
      "Epoch 1:  50%|█████     | 74/148 [01:09<01:07,  1.10it/s, training_loss=1.4347]\u001b[A\n",
      "Epoch 1:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.4347]\u001b[A\n",
      "Epoch 1:  51%|█████     | 75/148 [01:10<01:06,  1.09it/s, training_loss=1.6742]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=1.6742]\u001b[A\n",
      "Epoch 1:  51%|█████▏    | 76/148 [01:11<01:05,  1.09it/s, training_loss=1.6337]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 77/148 [01:11<01:04,  1.10it/s, training_loss=1.6337]\u001b[A\n",
      "Epoch 1:  52%|█████▏    | 77/148 [01:12<01:04,  1.10it/s, training_loss=1.4659]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 78/148 [01:12<01:04,  1.09it/s, training_loss=1.4659]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 78/148 [01:13<01:04,  1.09it/s, training_loss=1.6226]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 79/148 [01:13<01:02,  1.10it/s, training_loss=1.6226]\u001b[A\n",
      "Epoch 1:  53%|█████▎    | 79/148 [01:14<01:02,  1.10it/s, training_loss=1.4673]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.4673]\u001b[A\n",
      "Epoch 1:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.4884]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=1.4884]\u001b[A\n",
      "Epoch 1:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=1.5350]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.5350]\u001b[A\n",
      "Epoch 1:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.5513]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=1.5513]\u001b[A\n",
      "Epoch 1:  56%|█████▌    | 83/148 [01:17<00:59,  1.09it/s, training_loss=1.4925]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 84/148 [01:17<00:58,  1.10it/s, training_loss=1.4925]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 84/148 [01:18<00:58,  1.10it/s, training_loss=1.6195]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 85/148 [01:18<00:57,  1.10it/s, training_loss=1.6195]\u001b[A\n",
      "Epoch 1:  57%|█████▋    | 85/148 [01:19<00:57,  1.10it/s, training_loss=1.6670]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 86/148 [01:19<00:56,  1.10it/s, training_loss=1.6670]\u001b[A\n",
      "Epoch 1:  58%|█████▊    | 86/148 [01:20<00:56,  1.10it/s, training_loss=1.5291]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 87/148 [01:20<00:55,  1.10it/s, training_loss=1.5291]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 87/148 [01:21<00:55,  1.10it/s, training_loss=1.6508]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 88/148 [01:21<00:54,  1.09it/s, training_loss=1.6508]\u001b[A\n",
      "Epoch 1:  59%|█████▉    | 88/148 [01:22<00:54,  1.09it/s, training_loss=1.5921]\u001b[A\n",
      "Epoch 1:  60%|██████    | 89/148 [01:22<00:53,  1.09it/s, training_loss=1.5921]\u001b[A\n",
      "Epoch 1:  60%|██████    | 89/148 [01:23<00:53,  1.09it/s, training_loss=1.5434]\u001b[A\n",
      "Epoch 1:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=1.5434]\u001b[A\n",
      "Epoch 1:  61%|██████    | 90/148 [01:24<00:53,  1.09it/s, training_loss=1.5331]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.5331]\u001b[A\n",
      "Epoch 1:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.6291]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 92/148 [01:24<00:51,  1.10it/s, training_loss=1.6291]\u001b[A\n",
      "Epoch 1:  62%|██████▏   | 92/148 [01:25<00:51,  1.10it/s, training_loss=1.5276]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.5276]\u001b[A\n",
      "Epoch 1:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.7325]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 94/148 [01:26<00:49,  1.10it/s, training_loss=1.7325]\u001b[A\n",
      "Epoch 1:  64%|██████▎   | 94/148 [01:27<00:49,  1.10it/s, training_loss=1.6078]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 95/148 [01:27<00:48,  1.10it/s, training_loss=1.6078]\u001b[A\n",
      "Epoch 1:  64%|██████▍   | 95/148 [01:28<00:48,  1.10it/s, training_loss=1.3509]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 96/148 [01:28<00:47,  1.10it/s, training_loss=1.3509]\u001b[A\n",
      "Epoch 1:  65%|██████▍   | 96/148 [01:29<00:47,  1.10it/s, training_loss=1.4814]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 97/148 [01:29<00:46,  1.10it/s, training_loss=1.4814]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 97/148 [01:30<00:46,  1.10it/s, training_loss=1.6000]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 98/148 [01:30<00:45,  1.10it/s, training_loss=1.6000]\u001b[A\n",
      "Epoch 1:  66%|██████▌   | 98/148 [01:31<00:45,  1.10it/s, training_loss=1.5173]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 99/148 [01:31<00:44,  1.10it/s, training_loss=1.5173]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 99/148 [01:32<00:44,  1.10it/s, training_loss=1.6352]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 100/148 [01:32<00:43,  1.10it/s, training_loss=1.6352]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 100/148 [01:33<00:43,  1.10it/s, training_loss=1.5929]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 101/148 [01:33<00:42,  1.10it/s, training_loss=1.5929]\u001b[A\n",
      "Epoch 1:  68%|██████▊   | 101/148 [01:34<00:42,  1.10it/s, training_loss=1.5314]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 102/148 [01:34<00:41,  1.10it/s, training_loss=1.5314]\u001b[A\n",
      "Epoch 1:  69%|██████▉   | 102/148 [01:35<00:41,  1.10it/s, training_loss=1.3506]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 103/148 [01:35<00:40,  1.10it/s, training_loss=1.3506]\u001b[A\n",
      "Epoch 1:  70%|██████▉   | 103/148 [01:35<00:40,  1.10it/s, training_loss=1.5031]\u001b[A\n",
      "Epoch 1:  70%|███████   | 104/148 [01:35<00:40,  1.10it/s, training_loss=1.5031]\u001b[A\n",
      "Epoch 1:  70%|███████   | 104/148 [01:36<00:40,  1.10it/s, training_loss=1.7075]\u001b[A\n",
      "Epoch 1:  71%|███████   | 105/148 [01:36<00:39,  1.10it/s, training_loss=1.7075]\u001b[A\n",
      "Epoch 1:  71%|███████   | 105/148 [01:37<00:39,  1.10it/s, training_loss=1.5587]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 106/148 [01:37<00:38,  1.10it/s, training_loss=1.5587]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 106/148 [01:38<00:38,  1.10it/s, training_loss=1.5503]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 107/148 [01:38<00:37,  1.10it/s, training_loss=1.5503]\u001b[A\n",
      "Epoch 1:  72%|███████▏  | 107/148 [01:39<00:37,  1.10it/s, training_loss=1.5818]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=1.5818]\u001b[A\n",
      "Epoch 1:  73%|███████▎  | 108/148 [01:40<00:36,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 1:  74%|███████▎  | 109/148 [01:41<00:35,  1.09it/s, training_loss=1.4202]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.4202]\u001b[A\n",
      "Epoch 1:  74%|███████▍  | 110/148 [01:42<00:34,  1.09it/s, training_loss=1.6016]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=1.6016]\u001b[A\n",
      "Epoch 1:  75%|███████▌  | 111/148 [01:43<00:33,  1.09it/s, training_loss=1.5140]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 112/148 [01:43<00:32,  1.09it/s, training_loss=1.5140]\u001b[A\n",
      "Epoch 1:  76%|███████▌  | 112/148 [01:44<00:32,  1.09it/s, training_loss=1.3705]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 113/148 [01:44<00:31,  1.09it/s, training_loss=1.3705]\u001b[A\n",
      "Epoch 1:  76%|███████▋  | 113/148 [01:45<00:31,  1.09it/s, training_loss=1.4226]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.4226]\u001b[A\n",
      "Epoch 1:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.5935]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.5935]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=1.5813]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.5813]\u001b[A\n",
      "Epoch 1:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=1.6144]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.6144]\u001b[A\n",
      "Epoch 1:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 1:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.6131]\u001b[A\n",
      "Epoch 1:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.6131]\u001b[A\n",
      "Epoch 1:  80%|████████  | 119/148 [01:50<00:26,  1.09it/s, training_loss=1.2868]\u001b[A\n",
      "Epoch 1:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.2868]\u001b[A\n",
      "Epoch 1:  81%|████████  | 120/148 [01:51<00:25,  1.09it/s, training_loss=1.4815]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.4815]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 121/148 [01:52<00:24,  1.09it/s, training_loss=1.4318]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.4318]\u001b[A\n",
      "Epoch 1:  82%|████████▏ | 122/148 [01:53<00:23,  1.09it/s, training_loss=1.4791]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=1.4791]\u001b[A\n",
      "Epoch 1:  83%|████████▎ | 123/148 [01:54<00:22,  1.09it/s, training_loss=1.5172]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 124/148 [01:54<00:21,  1.09it/s, training_loss=1.5172]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 124/148 [01:55<00:21,  1.09it/s, training_loss=1.6444]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=1.6444]\u001b[A\n",
      "Epoch 1:  84%|████████▍ | 125/148 [01:56<00:21,  1.09it/s, training_loss=1.4573]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=1.4573]\u001b[A\n",
      "Epoch 1:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=1.4870]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=1.4870]\u001b[A\n",
      "Epoch 1:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.6995]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.6995]\u001b[A\n",
      "Epoch 1:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.5775]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.5775]\u001b[A\n",
      "Epoch 1:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=1.4734]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.4734]\u001b[A\n",
      "Epoch 1:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=1.4530]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.4530]\u001b[A\n",
      "Epoch 1:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=1.5059]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.5059]\u001b[A\n",
      "Epoch 1:  89%|████████▉ | 132/148 [02:02<00:14,  1.09it/s, training_loss=1.4664]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.4664]\u001b[A\n",
      "Epoch 1:  90%|████████▉ | 133/148 [02:03<00:13,  1.09it/s, training_loss=1.5728]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.5728]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 134/148 [02:04<00:12,  1.09it/s, training_loss=1.3997]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=1.3997]\u001b[A\n",
      "Epoch 1:  91%|█████████ | 135/148 [02:05<00:11,  1.09it/s, training_loss=1.4788]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.4788]\u001b[A\n",
      "Epoch 1:  92%|█████████▏| 136/148 [02:06<00:11,  1.09it/s, training_loss=1.5986]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.5986]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 137/148 [02:07<00:10,  1.09it/s, training_loss=1.3201]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.3201]\u001b[A\n",
      "Epoch 1:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.6267]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.6267]\u001b[A\n",
      "Epoch 1:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.5143]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 140/148 [02:08<00:07,  1.08it/s, training_loss=1.5143]\u001b[A\n",
      "Epoch 1:  95%|█████████▍| 140/148 [02:09<00:07,  1.08it/s, training_loss=1.5426]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 141/148 [02:09<00:06,  1.08it/s, training_loss=1.5426]\u001b[A\n",
      "Epoch 1:  95%|█████████▌| 141/148 [02:10<00:06,  1.08it/s, training_loss=1.5867]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=1.5867]\u001b[A\n",
      "Epoch 1:  96%|█████████▌| 142/148 [02:11<00:05,  1.09it/s, training_loss=1.5931]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.5931]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=1.6244]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=1.6244]\u001b[A\n",
      "Epoch 1:  97%|█████████▋| 144/148 [02:13<00:03,  1.09it/s, training_loss=1.5854]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=1.5854]\u001b[A\n",
      "Epoch 1:  98%|█████████▊| 145/148 [02:14<00:02,  1.09it/s, training_loss=1.6205]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 146/148 [02:14<00:01,  1.09it/s, training_loss=1.6205]\u001b[A\n",
      "Epoch 1:  99%|█████████▊| 146/148 [02:15<00:01,  1.09it/s, training_loss=1.6502]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.6502]\u001b[A\n",
      "Epoch 1:  99%|█████████▉| 147/148 [02:16<00:00,  1.09it/s, training_loss=1.5297]\u001b[A\n",
      "Epoch 1: 100%|██████████| 148/148 [02:16<00:00,  1.18it/s, training_loss=1.5297]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:27:21,810 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:27:21,811 - INFO - Memory usage after evaluation start: 3569.00 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.68it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.64it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.61it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.61it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.62it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.60it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.60it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.59it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.60it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.59it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.59it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.59it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.59it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.59it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.59it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:05<00:02,  3.59it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.59it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.59it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.58it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.59it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:27:29,079 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 19:27:29,094 - INFO - Class 'Drama': Optimal threshold = 0.550, F1 Score = 0.520\n",
      "2025-02-16 19:27:29,108 - INFO - Class 'Horor': Optimal threshold = 0.550, F1 Score = 0.667\n",
      "2025-02-16 19:27:29,122 - INFO - Class 'Komedi': Optimal threshold = 0.550, F1 Score = 0.519\n",
      "2025-02-16 19:27:29,135 - INFO - Class 'Laga': Optimal threshold = 0.450, F1 Score = 0.318\n",
      "2025-02-16 19:27:29,148 - INFO - Class 'Romantis': Optimal threshold = 0.600, F1 Score = 0.430\n",
      "2025-02-16 19:27:29,171 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:27:29,177 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:27:29,178 - INFO - Accuracy: 0.6743\n",
      "2025-02-16 19:27:29,178 - INFO - F1_score: 0.5198\n",
      "2025-02-16 19:27:29,179 - INFO - Precision: 0.4466\n",
      "2025-02-16 19:27:29,180 - INFO - Recall: 0.6216\n",
      "2025-02-16 19:27:29,186 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:27:29,187 - INFO - Accuracy: 0.8046\n",
      "2025-02-16 19:27:29,187 - INFO - F1_score: 0.6667\n",
      "2025-02-16 19:27:29,188 - INFO - Precision: 0.5312\n",
      "2025-02-16 19:27:29,188 - INFO - Recall: 0.8947\n",
      "2025-02-16 19:27:29,195 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:27:29,195 - INFO - Accuracy: 0.7011\n",
      "2025-02-16 19:27:29,196 - INFO - F1_score: 0.5185\n",
      "2025-02-16 19:27:29,198 - INFO - Precision: 0.4038\n",
      "2025-02-16 19:27:29,198 - INFO - Recall: 0.7241\n",
      "2025-02-16 19:27:29,205 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:27:29,205 - INFO - Accuracy: 0.5556\n",
      "2025-02-16 19:27:29,206 - INFO - F1_score: 0.3176\n",
      "2025-02-16 19:27:29,206 - INFO - Precision: 0.2045\n",
      "2025-02-16 19:27:29,207 - INFO - Recall: 0.7105\n",
      "2025-02-16 19:27:29,213 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:27:29,214 - INFO - Accuracy: 0.7969\n",
      "2025-02-16 19:27:29,214 - INFO - F1_score: 0.4301\n",
      "2025-02-16 19:27:29,215 - INFO - Precision: 0.3390\n",
      "2025-02-16 19:27:29,216 - INFO - Recall: 0.5882\n",
      "2025-02-16 19:27:29,218 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:27:33,078 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:27:33,080 - INFO - Memory usage after evaluation end: 3571.75 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   0%|          | 0/100 [02:34<?, ?it/s, Train Loss=1.5694, Val Loss=0.0439, Accuracy=0.7065]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:27:40,495 - INFO - New best accuracy: 0.7065\n",
      "2025-02-16 19:27:41,313 - INFO - New best loss: 0.0439\n",
      "2025-02-16 19:27:41,903 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 1/100 [02:36<4:17:36, 156.13s/it, Train Loss=1.5694, Val Loss=0.0439, Accuracy=0.7065]\n",
      "Epoch 2:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.5767]\u001b[A\n",
      "Epoch 2:   1%|          | 1/148 [00:00<02:12,  1.11it/s, training_loss=1.5767]\u001b[A\n",
      "Epoch 2:   1%|          | 1/148 [00:01<02:12,  1.11it/s, training_loss=1.6365]\u001b[A\n",
      "Epoch 2:   1%|▏         | 2/148 [00:01<02:12,  1.11it/s, training_loss=1.6365]\u001b[A\n",
      "Epoch 2:   1%|▏         | 2/148 [00:02<02:12,  1.11it/s, training_loss=1.3667]\u001b[A\n",
      "Epoch 2:   2%|▏         | 3/148 [00:02<02:12,  1.09it/s, training_loss=1.3667]\u001b[A\n",
      "Epoch 2:   2%|▏         | 3/148 [00:03<02:12,  1.09it/s, training_loss=1.4103]\u001b[A\n",
      "Epoch 2:   3%|▎         | 4/148 [00:03<02:11,  1.09it/s, training_loss=1.4103]\u001b[A\n",
      "Epoch 2:   3%|▎         | 4/148 [00:04<02:11,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 2:   3%|▎         | 5/148 [00:04<02:10,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 2:   3%|▎         | 5/148 [00:05<02:10,  1.09it/s, training_loss=1.5661]\u001b[A\n",
      "Epoch 2:   4%|▍         | 6/148 [00:05<02:09,  1.10it/s, training_loss=1.5661]\u001b[A\n",
      "Epoch 2:   4%|▍         | 6/148 [00:06<02:09,  1.10it/s, training_loss=1.4789]\u001b[A\n",
      "Epoch 2:   5%|▍         | 7/148 [00:06<02:08,  1.10it/s, training_loss=1.4789]\u001b[A\n",
      "Epoch 2:   5%|▍         | 7/148 [00:07<02:08,  1.10it/s, training_loss=1.3990]\u001b[A\n",
      "Epoch 2:   5%|▌         | 8/148 [00:07<02:07,  1.09it/s, training_loss=1.3990]\u001b[A\n",
      "Epoch 2:   5%|▌         | 8/148 [00:08<02:07,  1.09it/s, training_loss=1.6058]\u001b[A\n",
      "Epoch 2:   6%|▌         | 9/148 [00:08<02:06,  1.10it/s, training_loss=1.6058]\u001b[A\n",
      "Epoch 2:   6%|▌         | 9/148 [00:09<02:06,  1.10it/s, training_loss=1.5857]\u001b[A\n",
      "Epoch 2:   7%|▋         | 10/148 [00:09<02:05,  1.10it/s, training_loss=1.5857]\u001b[A\n",
      "Epoch 2:   7%|▋         | 10/148 [00:10<02:05,  1.10it/s, training_loss=1.5293]\u001b[A\n",
      "Epoch 2:   7%|▋         | 11/148 [00:10<02:04,  1.10it/s, training_loss=1.5293]\u001b[A\n",
      "Epoch 2:   7%|▋         | 11/148 [00:10<02:04,  1.10it/s, training_loss=1.4582]\u001b[A\n",
      "Epoch 2:   8%|▊         | 12/148 [00:10<02:04,  1.09it/s, training_loss=1.4582]\u001b[A\n",
      "Epoch 2:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.6277]\u001b[A\n",
      "Epoch 2:   9%|▉         | 13/148 [00:11<02:03,  1.09it/s, training_loss=1.6277]\u001b[A\n",
      "Epoch 2:   9%|▉         | 13/148 [00:12<02:03,  1.09it/s, training_loss=1.6186]\u001b[A\n",
      "Epoch 2:   9%|▉         | 14/148 [00:12<02:02,  1.09it/s, training_loss=1.6186]\u001b[A\n",
      "Epoch 2:   9%|▉         | 14/148 [00:13<02:02,  1.09it/s, training_loss=1.7052]\u001b[A\n",
      "Epoch 2:  10%|█         | 15/148 [00:13<02:02,  1.09it/s, training_loss=1.7052]\u001b[A\n",
      "Epoch 2:  10%|█         | 15/148 [00:14<02:02,  1.09it/s, training_loss=1.4475]\u001b[A\n",
      "Epoch 2:  11%|█         | 16/148 [00:14<02:01,  1.09it/s, training_loss=1.4475]\u001b[A\n",
      "Epoch 2:  11%|█         | 16/148 [00:15<02:01,  1.09it/s, training_loss=1.4664]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 17/148 [00:15<02:01,  1.08it/s, training_loss=1.4664]\u001b[A\n",
      "Epoch 2:  11%|█▏        | 17/148 [00:16<02:01,  1.08it/s, training_loss=1.5395]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 18/148 [00:16<01:59,  1.09it/s, training_loss=1.5395]\u001b[A\n",
      "Epoch 2:  12%|█▏        | 18/148 [00:17<01:59,  1.09it/s, training_loss=1.6694]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 19/148 [00:17<01:58,  1.08it/s, training_loss=1.6694]\u001b[A\n",
      "Epoch 2:  13%|█▎        | 19/148 [00:18<01:58,  1.08it/s, training_loss=1.4661]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 20/148 [00:18<01:58,  1.08it/s, training_loss=1.4661]\u001b[A\n",
      "Epoch 2:  14%|█▎        | 20/148 [00:19<01:58,  1.08it/s, training_loss=1.4974]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 21/148 [00:19<01:56,  1.09it/s, training_loss=1.4974]\u001b[A\n",
      "Epoch 2:  14%|█▍        | 21/148 [00:20<01:56,  1.09it/s, training_loss=1.3821]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 22/148 [00:20<01:56,  1.08it/s, training_loss=1.3821]\u001b[A\n",
      "Epoch 2:  15%|█▍        | 22/148 [00:21<01:56,  1.08it/s, training_loss=1.4012]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 23/148 [00:21<01:55,  1.08it/s, training_loss=1.4012]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 23/148 [00:22<01:55,  1.08it/s, training_loss=1.6053]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=1.6053]\u001b[A\n",
      "Epoch 2:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=1.6029]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 25/148 [00:22<01:53,  1.09it/s, training_loss=1.6029]\u001b[A\n",
      "Epoch 2:  17%|█▋        | 25/148 [00:23<01:53,  1.09it/s, training_loss=1.3442]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 26/148 [00:23<01:52,  1.08it/s, training_loss=1.3442]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 26/148 [00:24<01:52,  1.08it/s, training_loss=1.3421]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 27/148 [00:24<01:52,  1.08it/s, training_loss=1.3421]\u001b[A\n",
      "Epoch 2:  18%|█▊        | 27/148 [00:25<01:52,  1.08it/s, training_loss=1.3020]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 28/148 [00:25<01:51,  1.08it/s, training_loss=1.3020]\u001b[A\n",
      "Epoch 2:  19%|█▉        | 28/148 [00:26<01:51,  1.08it/s, training_loss=1.2697]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 29/148 [00:26<01:50,  1.08it/s, training_loss=1.2697]\u001b[A\n",
      "Epoch 2:  20%|█▉        | 29/148 [00:27<01:50,  1.08it/s, training_loss=1.4487]\u001b[A\n",
      "Epoch 2:  20%|██        | 30/148 [00:27<01:49,  1.07it/s, training_loss=1.4487]\u001b[A\n",
      "Epoch 2:  20%|██        | 30/148 [00:28<01:49,  1.07it/s, training_loss=1.6179]\u001b[A\n",
      "Epoch 2:  21%|██        | 31/148 [00:28<01:48,  1.08it/s, training_loss=1.6179]\u001b[A\n",
      "Epoch 2:  21%|██        | 31/148 [00:29<01:48,  1.08it/s, training_loss=1.5134]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 32/148 [00:29<01:47,  1.08it/s, training_loss=1.5134]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 32/148 [00:30<01:47,  1.08it/s, training_loss=1.5491]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 33/148 [00:30<01:46,  1.08it/s, training_loss=1.5491]\u001b[A\n",
      "Epoch 2:  22%|██▏       | 33/148 [00:31<01:46,  1.08it/s, training_loss=1.5366]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 34/148 [00:31<01:45,  1.08it/s, training_loss=1.5366]\u001b[A\n",
      "Epoch 2:  23%|██▎       | 34/148 [00:32<01:45,  1.08it/s, training_loss=1.6152]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 35/148 [00:32<01:43,  1.09it/s, training_loss=1.6152]\u001b[A\n",
      "Epoch 2:  24%|██▎       | 35/148 [00:33<01:43,  1.09it/s, training_loss=1.4156]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 36/148 [00:33<01:43,  1.09it/s, training_loss=1.4156]\u001b[A\n",
      "Epoch 2:  24%|██▍       | 36/148 [00:34<01:43,  1.09it/s, training_loss=1.4338]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 37/148 [00:34<01:42,  1.09it/s, training_loss=1.4338]\u001b[A\n",
      "Epoch 2:  25%|██▌       | 37/148 [00:34<01:42,  1.09it/s, training_loss=1.5089]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 38/148 [00:34<01:41,  1.08it/s, training_loss=1.5089]\u001b[A\n",
      "Epoch 2:  26%|██▌       | 38/148 [00:35<01:41,  1.08it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 39/148 [00:35<01:40,  1.09it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 2:  26%|██▋       | 39/148 [00:36<01:40,  1.09it/s, training_loss=1.6618]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 40/148 [00:36<01:38,  1.09it/s, training_loss=1.6618]\u001b[A\n",
      "Epoch 2:  27%|██▋       | 40/148 [00:37<01:38,  1.09it/s, training_loss=1.3912]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 41/148 [00:37<01:37,  1.09it/s, training_loss=1.3912]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 41/148 [00:38<01:37,  1.09it/s, training_loss=1.3530]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=1.3530]\u001b[A\n",
      "Epoch 2:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=1.5377]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 43/148 [00:39<01:36,  1.09it/s, training_loss=1.5377]\u001b[A\n",
      "Epoch 2:  29%|██▉       | 43/148 [00:40<01:36,  1.09it/s, training_loss=1.5530]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 44/148 [00:40<01:35,  1.09it/s, training_loss=1.5530]\u001b[A\n",
      "Epoch 2:  30%|██▉       | 44/148 [00:41<01:35,  1.09it/s, training_loss=1.5576]\u001b[A\n",
      "Epoch 2:  30%|███       | 45/148 [00:41<01:34,  1.09it/s, training_loss=1.5576]\u001b[A\n",
      "Epoch 2:  30%|███       | 45/148 [00:42<01:34,  1.09it/s, training_loss=1.2908]\u001b[A\n",
      "Epoch 2:  31%|███       | 46/148 [00:42<01:33,  1.09it/s, training_loss=1.2908]\u001b[A\n",
      "Epoch 2:  31%|███       | 46/148 [00:43<01:33,  1.09it/s, training_loss=1.5581]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 47/148 [00:43<01:32,  1.10it/s, training_loss=1.5581]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 47/148 [00:44<01:32,  1.10it/s, training_loss=1.4454]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 48/148 [00:44<01:31,  1.10it/s, training_loss=1.4454]\u001b[A\n",
      "Epoch 2:  32%|███▏      | 48/148 [00:45<01:31,  1.10it/s, training_loss=1.6518]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 49/148 [00:45<01:30,  1.10it/s, training_loss=1.6518]\u001b[A\n",
      "Epoch 2:  33%|███▎      | 49/148 [00:45<01:30,  1.10it/s, training_loss=1.7912]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 50/148 [00:45<01:29,  1.10it/s, training_loss=1.7912]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 50/148 [00:46<01:29,  1.10it/s, training_loss=1.1866]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 51/148 [00:46<01:28,  1.10it/s, training_loss=1.1866]\u001b[A\n",
      "Epoch 2:  34%|███▍      | 51/148 [00:47<01:28,  1.10it/s, training_loss=1.4350]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 52/148 [00:47<01:28,  1.09it/s, training_loss=1.4350]\u001b[A\n",
      "Epoch 2:  35%|███▌      | 52/148 [00:48<01:28,  1.09it/s, training_loss=1.5632]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 53/148 [00:48<01:27,  1.09it/s, training_loss=1.5632]\u001b[A\n",
      "Epoch 2:  36%|███▌      | 53/148 [00:49<01:27,  1.09it/s, training_loss=1.5927]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 54/148 [00:49<01:25,  1.09it/s, training_loss=1.5927]\u001b[A\n",
      "Epoch 2:  36%|███▋      | 54/148 [00:50<01:25,  1.09it/s, training_loss=1.5042]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.5042]\u001b[A\n",
      "Epoch 2:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.6792]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 56/148 [00:51<01:24,  1.10it/s, training_loss=1.6792]\u001b[A\n",
      "Epoch 2:  38%|███▊      | 56/148 [00:52<01:24,  1.10it/s, training_loss=1.5024]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.5024]\u001b[A\n",
      "Epoch 2:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=1.4067]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 58/148 [00:53<01:22,  1.09it/s, training_loss=1.4067]\u001b[A\n",
      "Epoch 2:  39%|███▉      | 58/148 [00:54<01:22,  1.09it/s, training_loss=1.5858]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 59/148 [00:54<01:21,  1.09it/s, training_loss=1.5858]\u001b[A\n",
      "Epoch 2:  40%|███▉      | 59/148 [00:55<01:21,  1.09it/s, training_loss=1.4455]\u001b[A\n",
      "Epoch 2:  41%|████      | 60/148 [00:55<01:21,  1.09it/s, training_loss=1.4455]\u001b[A\n",
      "Epoch 2:  41%|████      | 60/148 [00:56<01:21,  1.09it/s, training_loss=1.5490]\u001b[A\n",
      "Epoch 2:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=1.5490]\u001b[A\n",
      "Epoch 2:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=1.3151]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 62/148 [00:56<01:18,  1.09it/s, training_loss=1.3151]\u001b[A\n",
      "Epoch 2:  42%|████▏     | 62/148 [00:57<01:18,  1.09it/s, training_loss=1.4724]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 63/148 [00:57<01:18,  1.09it/s, training_loss=1.4724]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 63/148 [00:58<01:18,  1.09it/s, training_loss=1.4882]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 64/148 [00:58<01:17,  1.09it/s, training_loss=1.4882]\u001b[A\n",
      "Epoch 2:  43%|████▎     | 64/148 [00:59<01:17,  1.09it/s, training_loss=1.5704]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 65/148 [00:59<01:16,  1.09it/s, training_loss=1.5704]\u001b[A\n",
      "Epoch 2:  44%|████▍     | 65/148 [01:00<01:16,  1.09it/s, training_loss=1.5824]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 66/148 [01:00<01:15,  1.09it/s, training_loss=1.5824]\u001b[A\n",
      "Epoch 2:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=1.3251]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 67/148 [01:01<01:14,  1.09it/s, training_loss=1.3251]\u001b[A\n",
      "Epoch 2:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=1.2810]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=1.2810]\u001b[A\n",
      "Epoch 2:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=1.5288]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=1.5288]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=1.4375]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=1.4375]\u001b[A\n",
      "Epoch 2:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=1.5230]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=1.5230]\u001b[A\n",
      "Epoch 2:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.2852]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=1.2852]\u001b[A\n",
      "Epoch 2:  49%|████▊     | 72/148 [01:07<01:09,  1.09it/s, training_loss=1.3937]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 73/148 [01:07<01:09,  1.09it/s, training_loss=1.3937]\u001b[A\n",
      "Epoch 2:  49%|████▉     | 73/148 [01:07<01:09,  1.09it/s, training_loss=1.6559]\u001b[A\n",
      "Epoch 2:  50%|█████     | 74/148 [01:07<01:07,  1.09it/s, training_loss=1.6559]\u001b[A\n",
      "Epoch 2:  50%|█████     | 74/148 [01:08<01:07,  1.09it/s, training_loss=1.5604]\u001b[A\n",
      "Epoch 2:  51%|█████     | 75/148 [01:08<01:06,  1.09it/s, training_loss=1.5604]\u001b[A\n",
      "Epoch 2:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.6513]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 76/148 [01:09<01:05,  1.10it/s, training_loss=1.6513]\u001b[A\n",
      "Epoch 2:  51%|█████▏    | 76/148 [01:10<01:05,  1.10it/s, training_loss=1.3603]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 77/148 [01:10<01:04,  1.09it/s, training_loss=1.3603]\u001b[A\n",
      "Epoch 2:  52%|█████▏    | 77/148 [01:11<01:04,  1.09it/s, training_loss=1.5770]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 78/148 [01:11<01:03,  1.10it/s, training_loss=1.5770]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 78/148 [01:12<01:03,  1.10it/s, training_loss=1.4521]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 79/148 [01:12<01:03,  1.09it/s, training_loss=1.4521]\u001b[A\n",
      "Epoch 2:  53%|█████▎    | 79/148 [01:13<01:03,  1.09it/s, training_loss=1.4123]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.4123]\u001b[A\n",
      "Epoch 2:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.4382]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=1.4382]\u001b[A\n",
      "Epoch 2:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=1.5748]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.5748]\u001b[A\n",
      "Epoch 2:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.3198]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 83/148 [01:16<00:59,  1.10it/s, training_loss=1.3198]\u001b[A\n",
      "Epoch 2:  56%|█████▌    | 83/148 [01:17<00:59,  1.10it/s, training_loss=1.6043]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 84/148 [01:17<00:58,  1.10it/s, training_loss=1.6043]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 84/148 [01:17<00:58,  1.10it/s, training_loss=1.7415]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 85/148 [01:17<00:57,  1.09it/s, training_loss=1.7415]\u001b[A\n",
      "Epoch 2:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.4777]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 86/148 [01:18<00:56,  1.09it/s, training_loss=1.4777]\u001b[A\n",
      "Epoch 2:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.6623]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 87/148 [01:19<00:55,  1.10it/s, training_loss=1.6623]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 87/148 [01:20<00:55,  1.10it/s, training_loss=1.6325]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 88/148 [01:20<00:54,  1.09it/s, training_loss=1.6325]\u001b[A\n",
      "Epoch 2:  59%|█████▉    | 88/148 [01:21<00:54,  1.09it/s, training_loss=1.5757]\u001b[A\n",
      "Epoch 2:  60%|██████    | 89/148 [01:21<00:53,  1.09it/s, training_loss=1.5757]\u001b[A\n",
      "Epoch 2:  60%|██████    | 89/148 [01:22<00:53,  1.09it/s, training_loss=1.5468]\u001b[A\n",
      "Epoch 2:  61%|██████    | 90/148 [01:22<00:52,  1.09it/s, training_loss=1.5468]\u001b[A\n",
      "Epoch 2:  61%|██████    | 90/148 [01:23<00:52,  1.09it/s, training_loss=1.4857]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=1.4857]\u001b[A\n",
      "Epoch 2:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.3829]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.3829]\u001b[A\n",
      "Epoch 2:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=1.6785]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.6785]\u001b[A\n",
      "Epoch 2:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.6095]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=1.6095]\u001b[A\n",
      "Epoch 2:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.6098]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.6098]\u001b[A\n",
      "Epoch 2:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=1.2484]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.2484]\u001b[A\n",
      "Epoch 2:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.4477]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 97/148 [01:28<00:46,  1.09it/s, training_loss=1.4477]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.3147]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 98/148 [01:29<00:45,  1.09it/s, training_loss=1.3147]\u001b[A\n",
      "Epoch 2:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=1.5562]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 99/148 [01:30<00:44,  1.09it/s, training_loss=1.5562]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=1.3053]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 100/148 [01:31<00:43,  1.09it/s, training_loss=1.3053]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 100/148 [01:32<00:43,  1.09it/s, training_loss=1.2792]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 101/148 [01:32<00:43,  1.09it/s, training_loss=1.2792]\u001b[A\n",
      "Epoch 2:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.6456]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.6456]\u001b[A\n",
      "Epoch 2:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=1.6134]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 103/148 [01:34<00:41,  1.09it/s, training_loss=1.6134]\u001b[A\n",
      "Epoch 2:  70%|██████▉   | 103/148 [01:35<00:41,  1.09it/s, training_loss=1.3470]\u001b[A\n",
      "Epoch 2:  70%|███████   | 104/148 [01:35<00:40,  1.09it/s, training_loss=1.3470]\u001b[A\n",
      "Epoch 2:  70%|███████   | 104/148 [01:36<00:40,  1.09it/s, training_loss=1.6637]\u001b[A\n",
      "Epoch 2:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=1.6637]\u001b[A\n",
      "Epoch 2:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.3050]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.3050]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=1.2933]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 107/148 [01:38<00:37,  1.10it/s, training_loss=1.2933]\u001b[A\n",
      "Epoch 2:  72%|███████▏  | 107/148 [01:39<00:37,  1.10it/s, training_loss=1.5517]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 108/148 [01:39<00:36,  1.10it/s, training_loss=1.5517]\u001b[A\n",
      "Epoch 2:  73%|███████▎  | 108/148 [01:39<00:36,  1.10it/s, training_loss=1.3332]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 109/148 [01:39<00:35,  1.09it/s, training_loss=1.3332]\u001b[A\n",
      "Epoch 2:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.1892]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 110/148 [01:40<00:34,  1.09it/s, training_loss=1.1892]\u001b[A\n",
      "Epoch 2:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.1882]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 111/148 [01:41<00:34,  1.08it/s, training_loss=1.1882]\u001b[A\n",
      "Epoch 2:  75%|███████▌  | 111/148 [01:42<00:34,  1.08it/s, training_loss=1.1233]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 112/148 [01:42<00:33,  1.09it/s, training_loss=1.1233]\u001b[A\n",
      "Epoch 2:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.6987]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 113/148 [01:43<00:32,  1.09it/s, training_loss=1.6987]\u001b[A\n",
      "Epoch 2:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.5535]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.5535]\u001b[A\n",
      "Epoch 2:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.3558]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.3558]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=1.3051]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.3051]\u001b[A\n",
      "Epoch 2:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=1.2602]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.2602]\u001b[A\n",
      "Epoch 2:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 2:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.1622]\u001b[A\n",
      "Epoch 2:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.1622]\u001b[A\n",
      "Epoch 2:  80%|████████  | 119/148 [01:50<00:26,  1.09it/s, training_loss=1.2245]\u001b[A\n",
      "Epoch 2:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.2245]\u001b[A\n",
      "Epoch 2:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.5115]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 121/148 [01:50<00:24,  1.09it/s, training_loss=1.5115]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.6076]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 122/148 [01:51<00:23,  1.09it/s, training_loss=1.6076]\u001b[A\n",
      "Epoch 2:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.5548]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 123/148 [01:52<00:22,  1.09it/s, training_loss=1.5548]\u001b[A\n",
      "Epoch 2:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=1.4954]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 124/148 [01:53<00:21,  1.09it/s, training_loss=1.4954]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 124/148 [01:54<00:21,  1.09it/s, training_loss=1.4742]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 125/148 [01:54<00:20,  1.10it/s, training_loss=1.4742]\u001b[A\n",
      "Epoch 2:  84%|████████▍ | 125/148 [01:55<00:20,  1.10it/s, training_loss=1.4944]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 126/148 [01:55<00:20,  1.09it/s, training_loss=1.4944]\u001b[A\n",
      "Epoch 2:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=1.4285]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=1.4285]\u001b[A\n",
      "Epoch 2:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.2727]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.2727]\u001b[A\n",
      "Epoch 2:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.2132]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 129/148 [01:58<00:17,  1.08it/s, training_loss=1.2132]\u001b[A\n",
      "Epoch 2:  87%|████████▋ | 129/148 [01:59<00:17,  1.08it/s, training_loss=1.2452]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.2452]\u001b[A\n",
      "Epoch 2:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=1.2583]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.2583]\u001b[A\n",
      "Epoch 2:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=1.6078]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.6078]\u001b[A\n",
      "Epoch 2:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.3343]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 133/148 [02:01<00:13,  1.09it/s, training_loss=1.3343]\u001b[A\n",
      "Epoch 2:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 134/148 [02:02<00:12,  1.09it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.3266]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 135/148 [02:03<00:11,  1.09it/s, training_loss=1.3266]\u001b[A\n",
      "Epoch 2:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=1.5101]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 136/148 [02:04<00:11,  1.09it/s, training_loss=1.5101]\u001b[A\n",
      "Epoch 2:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.5325]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.5325]\u001b[A\n",
      "Epoch 2:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.4959]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.4959]\u001b[A\n",
      "Epoch 2:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.6472]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=1.6472]\u001b[A\n",
      "Epoch 2:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=1.3048]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=1.3048]\u001b[A\n",
      "Epoch 2:  95%|█████████▌| 141/148 [02:10<00:06,  1.09it/s, training_loss=1.6091]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=1.6091]\u001b[A\n",
      "Epoch 2:  96%|█████████▌| 142/148 [02:11<00:05,  1.09it/s, training_loss=1.5088]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.5088]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=1.5148]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=1.5148]\u001b[A\n",
      "Epoch 2:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=1.3371]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 145/148 [02:12<00:02,  1.09it/s, training_loss=1.3371]\u001b[A\n",
      "Epoch 2:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=1.0625]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 146/148 [02:13<00:01,  1.09it/s, training_loss=1.0625]\u001b[A\n",
      "Epoch 2:  99%|█████████▊| 146/148 [02:14<00:01,  1.09it/s, training_loss=1.2645]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 147/148 [02:14<00:00,  1.09it/s, training_loss=1.2645]\u001b[A\n",
      "Epoch 2:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.4176]\u001b[A\n",
      "Epoch 2: 100%|██████████| 148/148 [02:15<00:00,  1.19it/s, training_loss=1.4176]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:29:57,410 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:29:57,412 - INFO - Memory usage after evaluation start: 3876.13 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:06,  3.72it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.65it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.63it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.63it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.63it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.62it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.62it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.62it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.62it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.62it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:30:04,643 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 19:30:04,660 - INFO - Class 'Drama': Optimal threshold = 0.500, F1 Score = 0.502\n",
      "2025-02-16 19:30:04,675 - INFO - Class 'Horor': Optimal threshold = 0.650, F1 Score = 0.759\n",
      "2025-02-16 19:30:04,689 - INFO - Class 'Komedi': Optimal threshold = 0.700, F1 Score = 0.544\n",
      "2025-02-16 19:30:04,702 - INFO - Class 'Laga': Optimal threshold = 0.550, F1 Score = 0.466\n",
      "2025-02-16 19:30:04,715 - INFO - Class 'Romantis': Optimal threshold = 0.600, F1 Score = 0.489\n",
      "2025-02-16 19:30:04,737 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:30:04,742 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:30:04,743 - INFO - Accuracy: 0.5057\n",
      "2025-02-16 19:30:04,744 - INFO - F1_score: 0.5019\n",
      "2025-02-16 19:30:04,745 - INFO - Precision: 0.3514\n",
      "2025-02-16 19:30:04,746 - INFO - Recall: 0.8784\n",
      "2025-02-16 19:30:04,752 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:30:04,752 - INFO - Accuracy: 0.8927\n",
      "2025-02-16 19:30:04,753 - INFO - F1_score: 0.7586\n",
      "2025-02-16 19:30:04,753 - INFO - Precision: 0.7458\n",
      "2025-02-16 19:30:04,754 - INFO - Recall: 0.7719\n",
      "2025-02-16 19:30:04,760 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:30:04,761 - INFO - Accuracy: 0.8199\n",
      "2025-02-16 19:30:04,761 - INFO - F1_score: 0.5437\n",
      "2025-02-16 19:30:04,762 - INFO - Precision: 0.6222\n",
      "2025-02-16 19:30:04,764 - INFO - Recall: 0.4828\n",
      "2025-02-16 19:30:04,769 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:30:04,769 - INFO - Accuracy: 0.7893\n",
      "2025-02-16 19:30:04,770 - INFO - F1_score: 0.4660\n",
      "2025-02-16 19:30:04,771 - INFO - Precision: 0.3692\n",
      "2025-02-16 19:30:04,773 - INFO - Recall: 0.6316\n",
      "2025-02-16 19:30:04,778 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:30:04,778 - INFO - Accuracy: 0.8238\n",
      "2025-02-16 19:30:04,779 - INFO - F1_score: 0.4889\n",
      "2025-02-16 19:30:04,780 - INFO - Precision: 0.3929\n",
      "2025-02-16 19:30:04,781 - INFO - Recall: 0.6471\n",
      "2025-02-16 19:30:04,783 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:30:08,595 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:30:08,596 - INFO - Memory usage after evaluation end: 3881.75 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   1%|          | 1/100 [05:10<4:17:36, 156.13s/it, Train Loss=1.4713, Val Loss=0.0483, Accuracy=0.7663]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:30:15,798 - INFO - New best accuracy: 0.7663\n",
      "2025-02-16 19:30:16,858 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 2/100 [05:11<4:13:53, 155.44s/it, Train Loss=1.4713, Val Loss=0.0483, Accuracy=0.7663]\n",
      "Epoch 3:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.4680]\u001b[A\n",
      "Epoch 3:   1%|          | 1/148 [00:00<02:12,  1.11it/s, training_loss=1.4680]\u001b[A\n",
      "Epoch 3:   1%|          | 1/148 [00:01<02:12,  1.11it/s, training_loss=1.2389]\u001b[A\n",
      "Epoch 3:   1%|▏         | 2/148 [00:01<02:12,  1.10it/s, training_loss=1.2389]\u001b[A\n",
      "Epoch 3:   1%|▏         | 2/148 [00:02<02:12,  1.10it/s, training_loss=1.6273]\u001b[A\n",
      "Epoch 3:   2%|▏         | 3/148 [00:02<02:11,  1.10it/s, training_loss=1.6273]\u001b[A\n",
      "Epoch 3:   2%|▏         | 3/148 [00:03<02:11,  1.10it/s, training_loss=1.7014]\u001b[A\n",
      "Epoch 3:   3%|▎         | 4/148 [00:03<02:10,  1.10it/s, training_loss=1.7014]\u001b[A\n",
      "Epoch 3:   3%|▎         | 4/148 [00:04<02:10,  1.10it/s, training_loss=1.3102]\u001b[A\n",
      "Epoch 3:   3%|▎         | 5/148 [00:04<02:10,  1.10it/s, training_loss=1.3102]\u001b[A\n",
      "Epoch 3:   3%|▎         | 5/148 [00:05<02:10,  1.10it/s, training_loss=1.2826]\u001b[A\n",
      "Epoch 3:   4%|▍         | 6/148 [00:05<02:09,  1.10it/s, training_loss=1.2826]\u001b[A\n",
      "Epoch 3:   4%|▍         | 6/148 [00:06<02:09,  1.10it/s, training_loss=1.5797]\u001b[A\n",
      "Epoch 3:   5%|▍         | 7/148 [00:06<02:08,  1.10it/s, training_loss=1.5797]\u001b[A\n",
      "Epoch 3:   5%|▍         | 7/148 [00:07<02:08,  1.10it/s, training_loss=1.5303]\u001b[A\n",
      "Epoch 3:   5%|▌         | 8/148 [00:07<02:07,  1.10it/s, training_loss=1.5303]\u001b[A\n",
      "Epoch 3:   5%|▌         | 8/148 [00:08<02:07,  1.10it/s, training_loss=1.3281]\u001b[A\n",
      "Epoch 3:   6%|▌         | 9/148 [00:08<02:07,  1.09it/s, training_loss=1.3281]\u001b[A\n",
      "Epoch 3:   6%|▌         | 9/148 [00:09<02:07,  1.09it/s, training_loss=1.5345]\u001b[A\n",
      "Epoch 3:   7%|▋         | 10/148 [00:09<02:06,  1.09it/s, training_loss=1.5345]\u001b[A\n",
      "Epoch 3:   7%|▋         | 10/148 [00:10<02:06,  1.09it/s, training_loss=1.5924]\u001b[A\n",
      "Epoch 3:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.5924]\u001b[A\n",
      "Epoch 3:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 3:   8%|▊         | 12/148 [00:10<02:04,  1.09it/s, training_loss=1.5524]\u001b[A\n",
      "Epoch 3:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.4662]\u001b[A\n",
      "Epoch 3:   9%|▉         | 13/148 [00:11<02:03,  1.10it/s, training_loss=1.4662]\u001b[A\n",
      "Epoch 3:   9%|▉         | 13/148 [00:12<02:03,  1.10it/s, training_loss=1.7048]\u001b[A\n",
      "Epoch 3:   9%|▉         | 14/148 [00:12<02:02,  1.09it/s, training_loss=1.7048]\u001b[A\n",
      "Epoch 3:   9%|▉         | 14/148 [00:13<02:02,  1.09it/s, training_loss=1.5951]\u001b[A\n",
      "Epoch 3:  10%|█         | 15/148 [00:13<02:01,  1.09it/s, training_loss=1.5951]\u001b[A\n",
      "Epoch 3:  10%|█         | 15/148 [00:14<02:01,  1.09it/s, training_loss=1.6181]\u001b[A\n",
      "Epoch 3:  11%|█         | 16/148 [00:14<02:01,  1.09it/s, training_loss=1.6181]\u001b[A\n",
      "Epoch 3:  11%|█         | 16/148 [00:15<02:01,  1.09it/s, training_loss=1.3813]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 17/148 [00:15<02:00,  1.09it/s, training_loss=1.3813]\u001b[A\n",
      "Epoch 3:  11%|█▏        | 17/148 [00:16<02:00,  1.09it/s, training_loss=1.5989]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 18/148 [00:16<01:59,  1.09it/s, training_loss=1.5989]\u001b[A\n",
      "Epoch 3:  12%|█▏        | 18/148 [00:17<01:59,  1.09it/s, training_loss=1.6118]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 19/148 [00:17<01:57,  1.09it/s, training_loss=1.6118]\u001b[A\n",
      "Epoch 3:  13%|█▎        | 19/148 [00:18<01:57,  1.09it/s, training_loss=1.3894]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 20/148 [00:18<01:57,  1.09it/s, training_loss=1.3894]\u001b[A\n",
      "Epoch 3:  14%|█▎        | 20/148 [00:19<01:57,  1.09it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 21/148 [00:19<01:56,  1.09it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 3:  14%|█▍        | 21/148 [00:20<01:56,  1.09it/s, training_loss=1.3560]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 22/148 [00:20<01:55,  1.09it/s, training_loss=1.3560]\u001b[A\n",
      "Epoch 3:  15%|█▍        | 22/148 [00:21<01:55,  1.09it/s, training_loss=1.2113]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 23/148 [00:21<01:54,  1.09it/s, training_loss=1.2113]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 23/148 [00:21<01:54,  1.09it/s, training_loss=1.2281]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 24/148 [00:21<01:54,  1.08it/s, training_loss=1.2281]\u001b[A\n",
      "Epoch 3:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=1.2531]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 25/148 [00:22<01:53,  1.08it/s, training_loss=1.2531]\u001b[A\n",
      "Epoch 3:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.7012]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 26/148 [00:23<01:52,  1.09it/s, training_loss=1.7012]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 26/148 [00:24<01:52,  1.09it/s, training_loss=1.2469]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 27/148 [00:24<01:51,  1.09it/s, training_loss=1.2469]\u001b[A\n",
      "Epoch 3:  18%|█▊        | 27/148 [00:25<01:51,  1.09it/s, training_loss=1.4950]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 28/148 [00:25<01:50,  1.09it/s, training_loss=1.4950]\u001b[A\n",
      "Epoch 3:  19%|█▉        | 28/148 [00:26<01:50,  1.09it/s, training_loss=1.7209]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 29/148 [00:26<01:49,  1.09it/s, training_loss=1.7209]\u001b[A\n",
      "Epoch 3:  20%|█▉        | 29/148 [00:27<01:49,  1.09it/s, training_loss=1.2031]\u001b[A\n",
      "Epoch 3:  20%|██        | 30/148 [00:27<01:48,  1.09it/s, training_loss=1.2031]\u001b[A\n",
      "Epoch 3:  20%|██        | 30/148 [00:28<01:48,  1.09it/s, training_loss=1.0322]\u001b[A\n",
      "Epoch 3:  21%|██        | 31/148 [00:28<01:47,  1.09it/s, training_loss=1.0322]\u001b[A\n",
      "Epoch 3:  21%|██        | 31/148 [00:29<01:47,  1.09it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 32/148 [00:29<01:46,  1.09it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 32/148 [00:30<01:46,  1.09it/s, training_loss=1.4933]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 33/148 [00:30<01:45,  1.09it/s, training_loss=1.4933]\u001b[A\n",
      "Epoch 3:  22%|██▏       | 33/148 [00:31<01:45,  1.09it/s, training_loss=1.4100]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 34/148 [00:31<01:44,  1.09it/s, training_loss=1.4100]\u001b[A\n",
      "Epoch 3:  23%|██▎       | 34/148 [00:32<01:44,  1.09it/s, training_loss=1.6052]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 35/148 [00:32<01:43,  1.09it/s, training_loss=1.6052]\u001b[A\n",
      "Epoch 3:  24%|██▎       | 35/148 [00:32<01:43,  1.09it/s, training_loss=1.5551]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 36/148 [00:32<01:42,  1.09it/s, training_loss=1.5551]\u001b[A\n",
      "Epoch 3:  24%|██▍       | 36/148 [00:33<01:42,  1.09it/s, training_loss=1.4854]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 37/148 [00:33<01:41,  1.09it/s, training_loss=1.4854]\u001b[A\n",
      "Epoch 3:  25%|██▌       | 37/148 [00:34<01:41,  1.09it/s, training_loss=1.4268]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 38/148 [00:34<01:40,  1.09it/s, training_loss=1.4268]\u001b[A\n",
      "Epoch 3:  26%|██▌       | 38/148 [00:35<01:40,  1.09it/s, training_loss=1.3269]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 39/148 [00:35<01:40,  1.09it/s, training_loss=1.3269]\u001b[A\n",
      "Epoch 3:  26%|██▋       | 39/148 [00:36<01:40,  1.09it/s, training_loss=1.6385]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 40/148 [00:36<01:39,  1.09it/s, training_loss=1.6385]\u001b[A\n",
      "Epoch 3:  27%|██▋       | 40/148 [00:37<01:39,  1.09it/s, training_loss=1.4076]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=1.4076]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=1.6265]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=1.6265]\u001b[A\n",
      "Epoch 3:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=1.5298]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 43/148 [00:39<01:36,  1.09it/s, training_loss=1.5298]\u001b[A\n",
      "Epoch 3:  29%|██▉       | 43/148 [00:40<01:36,  1.09it/s, training_loss=1.1416]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 44/148 [00:40<01:35,  1.09it/s, training_loss=1.1416]\u001b[A\n",
      "Epoch 3:  30%|██▉       | 44/148 [00:41<01:35,  1.09it/s, training_loss=1.6413]\u001b[A\n",
      "Epoch 3:  30%|███       | 45/148 [00:41<01:34,  1.09it/s, training_loss=1.6413]\u001b[A\n",
      "Epoch 3:  30%|███       | 45/148 [00:42<01:34,  1.09it/s, training_loss=1.2459]\u001b[A\n",
      "Epoch 3:  31%|███       | 46/148 [00:42<01:33,  1.09it/s, training_loss=1.2459]\u001b[A\n",
      "Epoch 3:  31%|███       | 46/148 [00:43<01:33,  1.09it/s, training_loss=1.4687]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.4687]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.3341]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 48/148 [00:43<01:31,  1.09it/s, training_loss=1.3341]\u001b[A\n",
      "Epoch 3:  32%|███▏      | 48/148 [00:44<01:31,  1.09it/s, training_loss=1.5624]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 49/148 [00:44<01:30,  1.09it/s, training_loss=1.5624]\u001b[A\n",
      "Epoch 3:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=1.5351]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 50/148 [00:45<01:29,  1.09it/s, training_loss=1.5351]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=1.6626]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 51/148 [00:46<01:28,  1.09it/s, training_loss=1.6626]\u001b[A\n",
      "Epoch 3:  34%|███▍      | 51/148 [00:47<01:28,  1.09it/s, training_loss=1.4434]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 52/148 [00:47<01:27,  1.09it/s, training_loss=1.4434]\u001b[A\n",
      "Epoch 3:  35%|███▌      | 52/148 [00:48<01:27,  1.09it/s, training_loss=1.5226]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 53/148 [00:48<01:26,  1.10it/s, training_loss=1.5226]\u001b[A\n",
      "Epoch 3:  36%|███▌      | 53/148 [00:49<01:26,  1.10it/s, training_loss=1.4467]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 54/148 [00:49<01:25,  1.10it/s, training_loss=1.4467]\u001b[A\n",
      "Epoch 3:  36%|███▋      | 54/148 [00:50<01:25,  1.10it/s, training_loss=1.5193]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 55/148 [00:50<01:24,  1.10it/s, training_loss=1.5193]\u001b[A\n",
      "Epoch 3:  37%|███▋      | 55/148 [00:51<01:24,  1.10it/s, training_loss=1.6054]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 56/148 [00:51<01:23,  1.10it/s, training_loss=1.6054]\u001b[A\n",
      "Epoch 3:  38%|███▊      | 56/148 [00:52<01:23,  1.10it/s, training_loss=1.5883]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 57/148 [00:52<01:22,  1.10it/s, training_loss=1.5883]\u001b[A\n",
      "Epoch 3:  39%|███▊      | 57/148 [00:53<01:22,  1.10it/s, training_loss=1.4863]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 58/148 [00:53<01:22,  1.09it/s, training_loss=1.4863]\u001b[A\n",
      "Epoch 3:  39%|███▉      | 58/148 [00:54<01:22,  1.09it/s, training_loss=1.3934]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 59/148 [00:54<01:21,  1.09it/s, training_loss=1.3934]\u001b[A\n",
      "Epoch 3:  40%|███▉      | 59/148 [00:54<01:21,  1.09it/s, training_loss=1.3937]\u001b[A\n",
      "Epoch 3:  41%|████      | 60/148 [00:54<01:20,  1.09it/s, training_loss=1.3937]\u001b[A\n",
      "Epoch 3:  41%|████      | 60/148 [00:55<01:20,  1.09it/s, training_loss=1.5856]\u001b[A\n",
      "Epoch 3:  41%|████      | 61/148 [00:55<01:19,  1.10it/s, training_loss=1.5856]\u001b[A\n",
      "Epoch 3:  41%|████      | 61/148 [00:56<01:19,  1.10it/s, training_loss=1.1679]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 62/148 [00:56<01:18,  1.10it/s, training_loss=1.1679]\u001b[A\n",
      "Epoch 3:  42%|████▏     | 62/148 [00:57<01:18,  1.10it/s, training_loss=1.6112]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 63/148 [00:57<01:17,  1.10it/s, training_loss=1.6112]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 63/148 [00:58<01:17,  1.10it/s, training_loss=1.5654]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 64/148 [00:58<01:16,  1.10it/s, training_loss=1.5654]\u001b[A\n",
      "Epoch 3:  43%|████▎     | 64/148 [00:59<01:16,  1.10it/s, training_loss=1.1696]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 65/148 [00:59<01:15,  1.10it/s, training_loss=1.1696]\u001b[A\n",
      "Epoch 3:  44%|████▍     | 65/148 [01:00<01:15,  1.10it/s, training_loss=1.5911]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 66/148 [01:00<01:14,  1.10it/s, training_loss=1.5911]\u001b[A\n",
      "Epoch 3:  45%|████▍     | 66/148 [01:01<01:14,  1.10it/s, training_loss=1.4254]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 67/148 [01:01<01:13,  1.10it/s, training_loss=1.4254]\u001b[A\n",
      "Epoch 3:  45%|████▌     | 67/148 [01:02<01:13,  1.10it/s, training_loss=1.1819]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 68/148 [01:02<01:13,  1.10it/s, training_loss=1.1819]\u001b[A\n",
      "Epoch 3:  46%|████▌     | 68/148 [01:03<01:13,  1.10it/s, training_loss=1.6346]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 69/148 [01:03<01:11,  1.10it/s, training_loss=1.6346]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 69/148 [01:04<01:11,  1.10it/s, training_loss=1.4890]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 70/148 [01:04<01:10,  1.10it/s, training_loss=1.4890]\u001b[A\n",
      "Epoch 3:  47%|████▋     | 70/148 [01:04<01:10,  1.10it/s, training_loss=1.4669]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 71/148 [01:04<01:10,  1.10it/s, training_loss=1.4669]\u001b[A\n",
      "Epoch 3:  48%|████▊     | 71/148 [01:05<01:10,  1.10it/s, training_loss=1.2906]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 72/148 [01:05<01:09,  1.10it/s, training_loss=1.2906]\u001b[A\n",
      "Epoch 3:  49%|████▊     | 72/148 [01:06<01:09,  1.10it/s, training_loss=1.0723]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 73/148 [01:06<01:08,  1.10it/s, training_loss=1.0723]\u001b[A\n",
      "Epoch 3:  49%|████▉     | 73/148 [01:07<01:08,  1.10it/s, training_loss=1.0824]\u001b[A\n",
      "Epoch 3:  50%|█████     | 74/148 [01:07<01:07,  1.10it/s, training_loss=1.0824]\u001b[A\n",
      "Epoch 3:  50%|█████     | 74/148 [01:08<01:07,  1.10it/s, training_loss=1.5573]\u001b[A\n",
      "Epoch 3:  51%|█████     | 75/148 [01:08<01:06,  1.10it/s, training_loss=1.5573]\u001b[A\n",
      "Epoch 3:  51%|█████     | 75/148 [01:09<01:06,  1.10it/s, training_loss=1.5462]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 76/148 [01:09<01:05,  1.10it/s, training_loss=1.5462]\u001b[A\n",
      "Epoch 3:  51%|█████▏    | 76/148 [01:10<01:05,  1.10it/s, training_loss=1.5626]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 77/148 [01:10<01:04,  1.10it/s, training_loss=1.5626]\u001b[A\n",
      "Epoch 3:  52%|█████▏    | 77/148 [01:11<01:04,  1.10it/s, training_loss=1.1773]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 78/148 [01:11<01:04,  1.09it/s, training_loss=1.1773]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 78/148 [01:12<01:04,  1.09it/s, training_loss=1.4929]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 79/148 [01:12<01:03,  1.09it/s, training_loss=1.4929]\u001b[A\n",
      "Epoch 3:  53%|█████▎    | 79/148 [01:13<01:03,  1.09it/s, training_loss=1.4240]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.4240]\u001b[A\n",
      "Epoch 3:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.5231]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 81/148 [01:14<01:01,  1.10it/s, training_loss=1.5231]\u001b[A\n",
      "Epoch 3:  55%|█████▍    | 81/148 [01:15<01:01,  1.10it/s, training_loss=1.5297]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.5297]\u001b[A\n",
      "Epoch 3:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.4035]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 83/148 [01:15<00:59,  1.09it/s, training_loss=1.4035]\u001b[A\n",
      "Epoch 3:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=1.6995]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 84/148 [01:16<00:58,  1.09it/s, training_loss=1.6995]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=1.1624]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 85/148 [01:17<00:57,  1.09it/s, training_loss=1.1624]\u001b[A\n",
      "Epoch 3:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.4226]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 86/148 [01:18<00:56,  1.09it/s, training_loss=1.4226]\u001b[A\n",
      "Epoch 3:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.7933]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 87/148 [01:19<00:55,  1.10it/s, training_loss=1.7933]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 87/148 [01:20<00:55,  1.10it/s, training_loss=1.6084]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 88/148 [01:20<00:54,  1.09it/s, training_loss=1.6084]\u001b[A\n",
      "Epoch 3:  59%|█████▉    | 88/148 [01:21<00:54,  1.09it/s, training_loss=1.5741]\u001b[A\n",
      "Epoch 3:  60%|██████    | 89/148 [01:21<00:53,  1.10it/s, training_loss=1.5741]\u001b[A\n",
      "Epoch 3:  60%|██████    | 89/148 [01:22<00:53,  1.10it/s, training_loss=1.1358]\u001b[A\n",
      "Epoch 3:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=1.1358]\u001b[A\n",
      "Epoch 3:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=1.4337]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 91/148 [01:23<00:52,  1.10it/s, training_loss=1.4337]\u001b[A\n",
      "Epoch 3:  61%|██████▏   | 91/148 [01:24<00:52,  1.10it/s, training_loss=1.5750]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 92/148 [01:24<00:51,  1.10it/s, training_loss=1.5750]\u001b[A\n",
      "Epoch 3:  62%|██████▏   | 92/148 [01:25<00:51,  1.10it/s, training_loss=1.2803]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.2803]\u001b[A\n",
      "Epoch 3:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.6783]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 94/148 [01:25<00:49,  1.09it/s, training_loss=1.6783]\u001b[A\n",
      "Epoch 3:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=1.5839]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 95/148 [01:26<00:48,  1.10it/s, training_loss=1.5839]\u001b[A\n",
      "Epoch 3:  64%|██████▍   | 95/148 [01:27<00:48,  1.10it/s, training_loss=1.1040]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 96/148 [01:27<00:47,  1.10it/s, training_loss=1.1040]\u001b[A\n",
      "Epoch 3:  65%|██████▍   | 96/148 [01:28<00:47,  1.10it/s, training_loss=1.6233]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 97/148 [01:28<00:46,  1.10it/s, training_loss=1.6233]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 97/148 [01:29<00:46,  1.10it/s, training_loss=1.5920]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 98/148 [01:29<00:45,  1.10it/s, training_loss=1.5920]\u001b[A\n",
      "Epoch 3:  66%|██████▌   | 98/148 [01:30<00:45,  1.10it/s, training_loss=1.4415]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 99/148 [01:30<00:44,  1.10it/s, training_loss=1.4415]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 99/148 [01:31<00:44,  1.10it/s, training_loss=1.1044]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 100/148 [01:31<00:43,  1.09it/s, training_loss=1.1044]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 100/148 [01:32<00:43,  1.09it/s, training_loss=1.0207]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 101/148 [01:32<00:42,  1.09it/s, training_loss=1.0207]\u001b[A\n",
      "Epoch 3:  68%|██████▊   | 101/148 [01:33<00:42,  1.09it/s, training_loss=1.5390]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.5390]\u001b[A\n",
      "Epoch 3:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=1.5886]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 103/148 [01:34<00:41,  1.10it/s, training_loss=1.5886]\u001b[A\n",
      "Epoch 3:  70%|██████▉   | 103/148 [01:35<00:41,  1.10it/s, training_loss=1.5648]\u001b[A\n",
      "Epoch 3:  70%|███████   | 104/148 [01:35<00:40,  1.10it/s, training_loss=1.5648]\u001b[A\n",
      "Epoch 3:  70%|███████   | 104/148 [01:36<00:40,  1.10it/s, training_loss=1.5117]\u001b[A\n",
      "Epoch 3:  71%|███████   | 105/148 [01:36<00:39,  1.10it/s, training_loss=1.5117]\u001b[A\n",
      "Epoch 3:  71%|███████   | 105/148 [01:36<00:39,  1.10it/s, training_loss=1.2468]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 106/148 [01:36<00:38,  1.09it/s, training_loss=1.2468]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.6313]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 107/148 [01:37<00:37,  1.09it/s, training_loss=1.6313]\u001b[A\n",
      "Epoch 3:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=1.5490]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 108/148 [01:38<00:36,  1.09it/s, training_loss=1.5490]\u001b[A\n",
      "Epoch 3:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=1.2954]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 109/148 [01:39<00:35,  1.09it/s, training_loss=1.2954]\u001b[A\n",
      "Epoch 3:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.6346]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 110/148 [01:40<00:34,  1.10it/s, training_loss=1.6346]\u001b[A\n",
      "Epoch 3:  74%|███████▍  | 110/148 [01:41<00:34,  1.10it/s, training_loss=1.6088]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 111/148 [01:41<00:33,  1.10it/s, training_loss=1.6088]\u001b[A\n",
      "Epoch 3:  75%|███████▌  | 111/148 [01:42<00:33,  1.10it/s, training_loss=1.0881]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 112/148 [01:42<00:32,  1.09it/s, training_loss=1.0881]\u001b[A\n",
      "Epoch 3:  76%|███████▌  | 112/148 [01:43<00:32,  1.09it/s, training_loss=1.4880]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 113/148 [01:43<00:31,  1.09it/s, training_loss=1.4880]\u001b[A\n",
      "Epoch 3:  76%|███████▋  | 113/148 [01:44<00:31,  1.09it/s, training_loss=1.4588]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.4588]\u001b[A\n",
      "Epoch 3:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.5800]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.5800]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=1.5094]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.5094]\u001b[A\n",
      "Epoch 3:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.5871]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 117/148 [01:46<00:28,  1.09it/s, training_loss=1.5871]\u001b[A\n",
      "Epoch 3:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.3961]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 118/148 [01:47<00:27,  1.08it/s, training_loss=1.3961]\u001b[A\n",
      "Epoch 3:  80%|███████▉  | 118/148 [01:48<00:27,  1.08it/s, training_loss=1.1752]\u001b[A\n",
      "Epoch 3:  80%|████████  | 119/148 [01:48<00:26,  1.08it/s, training_loss=1.1752]\u001b[A\n",
      "Epoch 3:  80%|████████  | 119/148 [01:49<00:26,  1.08it/s, training_loss=1.4867]\u001b[A\n",
      "Epoch 3:  81%|████████  | 120/148 [01:49<00:25,  1.09it/s, training_loss=1.4867]\u001b[A\n",
      "Epoch 3:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.5174]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 121/148 [01:50<00:24,  1.09it/s, training_loss=1.5174]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.3538]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 122/148 [01:51<00:24,  1.08it/s, training_loss=1.3538]\u001b[A\n",
      "Epoch 3:  82%|████████▏ | 122/148 [01:52<00:24,  1.08it/s, training_loss=1.5441]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 123/148 [01:52<00:22,  1.09it/s, training_loss=1.5441]\u001b[A\n",
      "Epoch 3:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=1.3295]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 124/148 [01:53<00:22,  1.09it/s, training_loss=1.3295]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 124/148 [01:54<00:22,  1.09it/s, training_loss=1.5070]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 125/148 [01:54<00:21,  1.09it/s, training_loss=1.5070]\u001b[A\n",
      "Epoch 3:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=1.2609]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 126/148 [01:55<00:20,  1.10it/s, training_loss=1.2609]\u001b[A\n",
      "Epoch 3:  85%|████████▌ | 126/148 [01:56<00:20,  1.10it/s, training_loss=1.0871]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 127/148 [01:56<00:19,  1.10it/s, training_loss=1.0871]\u001b[A\n",
      "Epoch 3:  86%|████████▌ | 127/148 [01:57<00:19,  1.10it/s, training_loss=1.4432]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 128/148 [01:57<00:18,  1.10it/s, training_loss=1.4432]\u001b[A\n",
      "Epoch 3:  86%|████████▋ | 128/148 [01:58<00:18,  1.10it/s, training_loss=1.1316]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.1316]\u001b[A\n",
      "Epoch 3:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.5664]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 130/148 [01:58<00:16,  1.09it/s, training_loss=1.5664]\u001b[A\n",
      "Epoch 3:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.0881]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 131/148 [01:59<00:15,  1.09it/s, training_loss=1.0881]\u001b[A\n",
      "Epoch 3:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.4781]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 132/148 [02:00<00:14,  1.09it/s, training_loss=1.4781]\u001b[A\n",
      "Epoch 3:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.2545]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 133/148 [02:01<00:13,  1.09it/s, training_loss=1.2545]\u001b[A\n",
      "Epoch 3:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.4118]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 134/148 [02:02<00:12,  1.09it/s, training_loss=1.4118]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.6471]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 135/148 [02:03<00:11,  1.09it/s, training_loss=1.6471]\u001b[A\n",
      "Epoch 3:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=1.4495]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 136/148 [02:04<00:11,  1.09it/s, training_loss=1.4495]\u001b[A\n",
      "Epoch 3:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=0.9917]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=0.9917]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.4542]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.4542]\u001b[A\n",
      "Epoch 3:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=0.8777]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=0.8777]\u001b[A\n",
      "Epoch 3:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.1002]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=1.1002]\u001b[A\n",
      "Epoch 3:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=1.5843]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=1.5843]\u001b[A\n",
      "Epoch 3:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=1.5474]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 142/148 [02:09<00:05,  1.09it/s, training_loss=1.5474]\u001b[A\n",
      "Epoch 3:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=1.5146]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 143/148 [02:10<00:04,  1.10it/s, training_loss=1.5146]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 143/148 [02:11<00:04,  1.10it/s, training_loss=1.6291]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 144/148 [02:11<00:03,  1.10it/s, training_loss=1.6291]\u001b[A\n",
      "Epoch 3:  97%|█████████▋| 144/148 [02:12<00:03,  1.10it/s, training_loss=1.2494]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 145/148 [02:12<00:02,  1.09it/s, training_loss=1.2494]\u001b[A\n",
      "Epoch 3:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=1.4677]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 146/148 [02:13<00:01,  1.09it/s, training_loss=1.4677]\u001b[A\n",
      "Epoch 3:  99%|█████████▊| 146/148 [02:14<00:01,  1.09it/s, training_loss=1.6004]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 147/148 [02:14<00:00,  1.09it/s, training_loss=1.6004]\u001b[A\n",
      "Epoch 3:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.5352]\u001b[A\n",
      "Epoch 3: 100%|██████████| 148/148 [02:15<00:00,  1.18it/s, training_loss=1.5352]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:32:32,049 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:32:32,050 - INFO - Memory usage after evaluation start: 3882.00 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:06,  3.72it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.65it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.63it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.61it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.61it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.62it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.60it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.60it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.60it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.59it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.59it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.59it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:32:39,298 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 19:32:39,314 - INFO - Class 'Drama': Optimal threshold = 0.500, F1 Score = 0.540\n",
      "2025-02-16 19:32:39,329 - INFO - Class 'Horor': Optimal threshold = 0.750, F1 Score = 0.741\n",
      "2025-02-16 19:32:39,345 - INFO - Class 'Komedi': Optimal threshold = 0.600, F1 Score = 0.606\n",
      "2025-02-16 19:32:39,361 - INFO - Class 'Laga': Optimal threshold = 0.500, F1 Score = 0.407\n",
      "2025-02-16 19:32:39,377 - INFO - Class 'Romantis': Optimal threshold = 0.650, F1 Score = 0.493\n",
      "2025-02-16 19:32:39,405 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:32:39,411 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:32:39,412 - INFO - Accuracy: 0.6475\n",
      "2025-02-16 19:32:39,413 - INFO - F1_score: 0.5400\n",
      "2025-02-16 19:32:39,414 - INFO - Precision: 0.4286\n",
      "2025-02-16 19:32:39,414 - INFO - Recall: 0.7297\n",
      "2025-02-16 19:32:39,422 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:32:39,423 - INFO - Accuracy: 0.8659\n",
      "2025-02-16 19:32:39,423 - INFO - F1_score: 0.7407\n",
      "2025-02-16 19:32:39,424 - INFO - Precision: 0.6410\n",
      "2025-02-16 19:32:39,425 - INFO - Recall: 0.8772\n",
      "2025-02-16 19:32:39,432 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:32:39,433 - INFO - Accuracy: 0.8008\n",
      "2025-02-16 19:32:39,435 - INFO - F1_score: 0.6061\n",
      "2025-02-16 19:32:39,435 - INFO - Precision: 0.5405\n",
      "2025-02-16 19:32:39,436 - INFO - Recall: 0.6897\n",
      "2025-02-16 19:32:39,442 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:32:39,443 - INFO - Accuracy: 0.7203\n",
      "2025-02-16 19:32:39,444 - INFO - F1_score: 0.4065\n",
      "2025-02-16 19:32:39,445 - INFO - Precision: 0.2941\n",
      "2025-02-16 19:32:39,446 - INFO - Recall: 0.6579\n",
      "2025-02-16 19:32:39,453 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:32:39,454 - INFO - Accuracy: 0.8582\n",
      "2025-02-16 19:32:39,455 - INFO - F1_score: 0.4932\n",
      "2025-02-16 19:32:39,455 - INFO - Precision: 0.4615\n",
      "2025-02-16 19:32:39,456 - INFO - Recall: 0.5294\n",
      "2025-02-16 19:32:39,459 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:32:43,338 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:32:43,340 - INFO - Memory usage after evaluation end: 3887.63 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   2%|▏         | 2/100 [07:44<4:13:53, 155.44s/it, Train Loss=1.4407, Val Loss=0.0481, Accuracy=0.7785]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:32:50,578 - INFO - New best accuracy: 0.7785\n",
      "2025-02-16 19:32:51,529 - INFO - Learning rate: 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [07:45<4:10:43, 155.09s/it, Train Loss=1.4407, Val Loss=0.0481, Accuracy=0.7785]\n",
      "Epoch 4:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.3065]\u001b[A\n",
      "Epoch 4:   1%|          | 1/148 [00:00<02:13,  1.11it/s, training_loss=1.3065]\u001b[A\n",
      "Epoch 4:   1%|          | 1/148 [00:01<02:13,  1.11it/s, training_loss=1.0766]\u001b[A\n",
      "Epoch 4:   1%|▏         | 2/148 [00:01<02:12,  1.10it/s, training_loss=1.0766]\u001b[A\n",
      "Epoch 4:   1%|▏         | 2/148 [00:02<02:12,  1.10it/s, training_loss=1.7053]\u001b[A\n",
      "Epoch 4:   2%|▏         | 3/148 [00:02<02:12,  1.10it/s, training_loss=1.7053]\u001b[A\n",
      "Epoch 4:   2%|▏         | 3/148 [00:03<02:12,  1.10it/s, training_loss=1.3649]\u001b[A\n",
      "Epoch 4:   3%|▎         | 4/148 [00:03<02:11,  1.09it/s, training_loss=1.3649]\u001b[A\n",
      "Epoch 4:   3%|▎         | 4/148 [00:04<02:11,  1.09it/s, training_loss=1.3751]\u001b[A\n",
      "Epoch 4:   3%|▎         | 5/148 [00:04<02:11,  1.09it/s, training_loss=1.3751]\u001b[A\n",
      "Epoch 4:   3%|▎         | 5/148 [00:05<02:11,  1.09it/s, training_loss=1.0628]\u001b[A\n",
      "Epoch 4:   4%|▍         | 6/148 [00:05<02:10,  1.09it/s, training_loss=1.0628]\u001b[A\n",
      "Epoch 4:   4%|▍         | 6/148 [00:06<02:10,  1.09it/s, training_loss=1.5440]\u001b[A\n",
      "Epoch 4:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=1.5440]\u001b[A\n",
      "Epoch 4:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=1.6416]\u001b[A\n",
      "Epoch 4:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=1.6416]\u001b[A\n",
      "Epoch 4:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=1.5518]\u001b[A\n",
      "Epoch 4:   6%|▌         | 9/148 [00:08<02:07,  1.09it/s, training_loss=1.5518]\u001b[A\n",
      "Epoch 4:   6%|▌         | 9/148 [00:09<02:07,  1.09it/s, training_loss=1.3792]\u001b[A\n",
      "Epoch 4:   7%|▋         | 10/148 [00:09<02:06,  1.09it/s, training_loss=1.3792]\u001b[A\n",
      "Epoch 4:   7%|▋         | 10/148 [00:10<02:06,  1.09it/s, training_loss=1.6392]\u001b[A\n",
      "Epoch 4:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.6392]\u001b[A\n",
      "Epoch 4:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.2779]\u001b[A\n",
      "Epoch 4:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.2779]\u001b[A\n",
      "Epoch 4:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.5931]\u001b[A\n",
      "Epoch 4:   9%|▉         | 13/148 [00:11<02:03,  1.09it/s, training_loss=1.5931]\u001b[A\n",
      "Epoch 4:   9%|▉         | 13/148 [00:12<02:03,  1.09it/s, training_loss=1.5418]\u001b[A\n",
      "Epoch 4:   9%|▉         | 14/148 [00:12<02:02,  1.09it/s, training_loss=1.5418]\u001b[A\n",
      "Epoch 4:   9%|▉         | 14/148 [00:13<02:02,  1.09it/s, training_loss=1.1443]\u001b[A\n",
      "Epoch 4:  10%|█         | 15/148 [00:13<02:02,  1.09it/s, training_loss=1.1443]\u001b[A\n",
      "Epoch 4:  10%|█         | 15/148 [00:14<02:02,  1.09it/s, training_loss=1.7030]\u001b[A\n",
      "Epoch 4:  11%|█         | 16/148 [00:14<02:00,  1.09it/s, training_loss=1.7030]\u001b[A\n",
      "Epoch 4:  11%|█         | 16/148 [00:15<02:00,  1.09it/s, training_loss=1.6252]\u001b[A\n",
      "Epoch 4:  11%|█▏        | 17/148 [00:15<01:59,  1.09it/s, training_loss=1.6252]\u001b[A\n",
      "Epoch 4:  11%|█▏        | 17/148 [00:16<01:59,  1.09it/s, training_loss=1.5937]\u001b[A\n",
      "Epoch 4:  12%|█▏        | 18/148 [00:16<01:59,  1.09it/s, training_loss=1.5937]\u001b[A\n",
      "Epoch 4:  12%|█▏        | 18/148 [00:17<01:59,  1.09it/s, training_loss=1.2069]\u001b[A\n",
      "Epoch 4:  13%|█▎        | 19/148 [00:17<01:58,  1.09it/s, training_loss=1.2069]\u001b[A\n",
      "Epoch 4:  13%|█▎        | 19/148 [00:18<01:58,  1.09it/s, training_loss=1.6415]\u001b[A\n",
      "Epoch 4:  14%|█▎        | 20/148 [00:18<01:57,  1.09it/s, training_loss=1.6415]\u001b[A\n",
      "Epoch 4:  14%|█▎        | 20/148 [00:19<01:57,  1.09it/s, training_loss=1.2577]\u001b[A\n",
      "Epoch 4:  14%|█▍        | 21/148 [00:19<01:57,  1.08it/s, training_loss=1.2577]\u001b[A\n",
      "Epoch 4:  14%|█▍        | 21/148 [00:20<01:57,  1.08it/s, training_loss=1.2009]\u001b[A\n",
      "Epoch 4:  15%|█▍        | 22/148 [00:20<01:56,  1.08it/s, training_loss=1.2009]\u001b[A\n",
      "Epoch 4:  15%|█▍        | 22/148 [00:21<01:56,  1.08it/s, training_loss=1.6390]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 23/148 [00:21<01:55,  1.09it/s, training_loss=1.6390]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 23/148 [00:22<01:55,  1.09it/s, training_loss=1.2281]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 24/148 [00:22<01:54,  1.09it/s, training_loss=1.2281]\u001b[A\n",
      "Epoch 4:  16%|█▌        | 24/148 [00:22<01:54,  1.09it/s, training_loss=1.5243]\u001b[A\n",
      "Epoch 4:  17%|█▋        | 25/148 [00:22<01:53,  1.09it/s, training_loss=1.5243]\u001b[A\n",
      "Epoch 4:  17%|█▋        | 25/148 [00:23<01:53,  1.09it/s, training_loss=1.1784]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 26/148 [00:23<01:52,  1.09it/s, training_loss=1.1784]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 26/148 [00:24<01:52,  1.09it/s, training_loss=1.1282]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 27/148 [00:24<01:51,  1.09it/s, training_loss=1.1282]\u001b[A\n",
      "Epoch 4:  18%|█▊        | 27/148 [00:25<01:51,  1.09it/s, training_loss=1.0911]\u001b[A\n",
      "Epoch 4:  19%|█▉        | 28/148 [00:25<01:50,  1.09it/s, training_loss=1.0911]\u001b[A\n",
      "Epoch 4:  19%|█▉        | 28/148 [00:26<01:50,  1.09it/s, training_loss=1.1044]\u001b[A\n",
      "Epoch 4:  20%|█▉        | 29/148 [00:26<01:49,  1.08it/s, training_loss=1.1044]\u001b[A\n",
      "Epoch 4:  20%|█▉        | 29/148 [00:27<01:49,  1.08it/s, training_loss=1.2508]\u001b[A\n",
      "Epoch 4:  20%|██        | 30/148 [00:27<01:48,  1.09it/s, training_loss=1.2508]\u001b[A\n",
      "Epoch 4:  20%|██        | 30/148 [00:28<01:48,  1.09it/s, training_loss=1.2468]\u001b[A\n",
      "Epoch 4:  21%|██        | 31/148 [00:28<01:47,  1.09it/s, training_loss=1.2468]\u001b[A\n",
      "Epoch 4:  21%|██        | 31/148 [00:29<01:47,  1.09it/s, training_loss=1.5139]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 32/148 [00:29<01:46,  1.09it/s, training_loss=1.5139]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 32/148 [00:30<01:46,  1.09it/s, training_loss=1.2858]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 33/148 [00:30<01:46,  1.08it/s, training_loss=1.2858]\u001b[A\n",
      "Epoch 4:  22%|██▏       | 33/148 [00:31<01:46,  1.08it/s, training_loss=1.5378]\u001b[A\n",
      "Epoch 4:  23%|██▎       | 34/148 [00:31<01:44,  1.09it/s, training_loss=1.5378]\u001b[A\n",
      "Epoch 4:  23%|██▎       | 34/148 [00:32<01:44,  1.09it/s, training_loss=1.5912]\u001b[A\n",
      "Epoch 4:  24%|██▎       | 35/148 [00:32<01:43,  1.09it/s, training_loss=1.5912]\u001b[A\n",
      "Epoch 4:  24%|██▎       | 35/148 [00:33<01:43,  1.09it/s, training_loss=1.3753]\u001b[A\n",
      "Epoch 4:  24%|██▍       | 36/148 [00:33<01:42,  1.09it/s, training_loss=1.3753]\u001b[A\n",
      "Epoch 4:  24%|██▍       | 36/148 [00:33<01:42,  1.09it/s, training_loss=1.2279]\u001b[A\n",
      "Epoch 4:  25%|██▌       | 37/148 [00:33<01:41,  1.09it/s, training_loss=1.2279]\u001b[A\n",
      "Epoch 4:  25%|██▌       | 37/148 [00:34<01:41,  1.09it/s, training_loss=1.5992]\u001b[A\n",
      "Epoch 4:  26%|██▌       | 38/148 [00:34<01:41,  1.09it/s, training_loss=1.5992]\u001b[A\n",
      "Epoch 4:  26%|██▌       | 38/148 [00:35<01:41,  1.09it/s, training_loss=1.1752]\u001b[A\n",
      "Epoch 4:  26%|██▋       | 39/148 [00:35<01:39,  1.09it/s, training_loss=1.1752]\u001b[A\n",
      "Epoch 4:  26%|██▋       | 39/148 [00:36<01:39,  1.09it/s, training_loss=1.5009]\u001b[A\n",
      "Epoch 4:  27%|██▋       | 40/148 [00:36<01:38,  1.09it/s, training_loss=1.5009]\u001b[A\n",
      "Epoch 4:  27%|██▋       | 40/148 [00:37<01:38,  1.09it/s, training_loss=1.1261]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 41/148 [00:37<01:37,  1.09it/s, training_loss=1.1261]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 41/148 [00:38<01:37,  1.09it/s, training_loss=1.5861]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=1.5861]\u001b[A\n",
      "Epoch 4:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=1.5291]\u001b[A\n",
      "Epoch 4:  29%|██▉       | 43/148 [00:39<01:36,  1.09it/s, training_loss=1.5291]\u001b[A\n",
      "Epoch 4:  29%|██▉       | 43/148 [00:40<01:36,  1.09it/s, training_loss=1.4251]\u001b[A\n",
      "Epoch 4:  30%|██▉       | 44/148 [00:40<01:35,  1.09it/s, training_loss=1.4251]\u001b[A\n",
      "Epoch 4:  30%|██▉       | 44/148 [00:41<01:35,  1.09it/s, training_loss=1.4878]\u001b[A\n",
      "Epoch 4:  30%|███       | 45/148 [00:41<01:34,  1.09it/s, training_loss=1.4878]\u001b[A\n",
      "Epoch 4:  30%|███       | 45/148 [00:42<01:34,  1.09it/s, training_loss=1.6063]\u001b[A\n",
      "Epoch 4:  31%|███       | 46/148 [00:42<01:33,  1.09it/s, training_loss=1.6063]\u001b[A\n",
      "Epoch 4:  31%|███       | 46/148 [00:43<01:33,  1.09it/s, training_loss=1.6038]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.6038]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.6897]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 48/148 [00:44<01:31,  1.09it/s, training_loss=1.6897]\u001b[A\n",
      "Epoch 4:  32%|███▏      | 48/148 [00:44<01:31,  1.09it/s, training_loss=1.5487]\u001b[A\n",
      "Epoch 4:  33%|███▎      | 49/148 [00:44<01:30,  1.10it/s, training_loss=1.5487]\u001b[A\n",
      "Epoch 4:  33%|███▎      | 49/148 [00:45<01:30,  1.10it/s, training_loss=1.1634]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 50/148 [00:45<01:29,  1.09it/s, training_loss=1.1634]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=1.5389]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 51/148 [00:46<01:28,  1.10it/s, training_loss=1.5389]\u001b[A\n",
      "Epoch 4:  34%|███▍      | 51/148 [00:47<01:28,  1.10it/s, training_loss=1.5865]\u001b[A\n",
      "Epoch 4:  35%|███▌      | 52/148 [00:47<01:27,  1.09it/s, training_loss=1.5865]\u001b[A\n",
      "Epoch 4:  35%|███▌      | 52/148 [00:48<01:27,  1.09it/s, training_loss=1.2062]\u001b[A\n",
      "Epoch 4:  36%|███▌      | 53/148 [00:48<01:27,  1.09it/s, training_loss=1.2062]\u001b[A\n",
      "Epoch 4:  36%|███▌      | 53/148 [00:49<01:27,  1.09it/s, training_loss=1.0252]\u001b[A\n",
      "Epoch 4:  36%|███▋      | 54/148 [00:49<01:26,  1.09it/s, training_loss=1.0252]\u001b[A\n",
      "Epoch 4:  36%|███▋      | 54/148 [00:50<01:26,  1.09it/s, training_loss=1.5593]\u001b[A\n",
      "Epoch 4:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.5593]\u001b[A\n",
      "Epoch 4:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.5518]\u001b[A\n",
      "Epoch 4:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=1.5518]\u001b[A\n",
      "Epoch 4:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.0249]\u001b[A\n",
      "Epoch 4:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.0249]\u001b[A\n",
      "Epoch 4:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=1.1143]\u001b[A\n",
      "Epoch 4:  39%|███▉      | 58/148 [00:53<01:22,  1.09it/s, training_loss=1.1143]\u001b[A\n",
      "Epoch 4:  39%|███▉      | 58/148 [00:54<01:22,  1.09it/s, training_loss=1.1340]\u001b[A\n",
      "Epoch 4:  40%|███▉      | 59/148 [00:54<01:21,  1.10it/s, training_loss=1.1340]\u001b[A\n",
      "Epoch 4:  40%|███▉      | 59/148 [00:55<01:21,  1.10it/s, training_loss=1.1529]\u001b[A\n",
      "Epoch 4:  41%|████      | 60/148 [00:55<01:20,  1.10it/s, training_loss=1.1529]\u001b[A\n",
      "Epoch 4:  41%|████      | 60/148 [00:55<01:20,  1.10it/s, training_loss=0.9788]\u001b[A\n",
      "Epoch 4:  41%|████      | 61/148 [00:55<01:19,  1.10it/s, training_loss=0.9788]\u001b[A\n",
      "Epoch 4:  41%|████      | 61/148 [00:56<01:19,  1.10it/s, training_loss=1.2183]\u001b[A\n",
      "Epoch 4:  42%|████▏     | 62/148 [00:56<01:18,  1.10it/s, training_loss=1.2183]\u001b[A\n",
      "Epoch 4:  42%|████▏     | 62/148 [00:57<01:18,  1.10it/s, training_loss=1.2078]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 63/148 [00:57<01:17,  1.09it/s, training_loss=1.2078]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 63/148 [00:58<01:17,  1.09it/s, training_loss=1.6679]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 64/148 [00:58<01:16,  1.10it/s, training_loss=1.6679]\u001b[A\n",
      "Epoch 4:  43%|████▎     | 64/148 [00:59<01:16,  1.10it/s, training_loss=1.0462]\u001b[A\n",
      "Epoch 4:  44%|████▍     | 65/148 [00:59<01:15,  1.10it/s, training_loss=1.0462]\u001b[A\n",
      "Epoch 4:  44%|████▍     | 65/148 [01:00<01:15,  1.10it/s, training_loss=1.4857]\u001b[A\n",
      "Epoch 4:  45%|████▍     | 66/148 [01:00<01:14,  1.10it/s, training_loss=1.4857]\u001b[A\n",
      "Epoch 4:  45%|████▍     | 66/148 [01:01<01:14,  1.10it/s, training_loss=1.1404]\u001b[A\n",
      "Epoch 4:  45%|████▌     | 67/148 [01:01<01:14,  1.09it/s, training_loss=1.1404]\u001b[A\n",
      "Epoch 4:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=1.5144]\u001b[A\n",
      "Epoch 4:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=1.5144]\u001b[A\n",
      "Epoch 4:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=1.2095]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 69/148 [01:03<01:12,  1.10it/s, training_loss=1.2095]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 69/148 [01:04<01:12,  1.10it/s, training_loss=1.5273]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 70/148 [01:04<01:11,  1.10it/s, training_loss=1.5273]\u001b[A\n",
      "Epoch 4:  47%|████▋     | 70/148 [01:05<01:11,  1.10it/s, training_loss=1.3145]\u001b[A\n",
      "Epoch 4:  48%|████▊     | 71/148 [01:05<01:10,  1.10it/s, training_loss=1.3145]\u001b[A\n",
      "Epoch 4:  48%|████▊     | 71/148 [01:05<01:10,  1.10it/s, training_loss=1.3001]\u001b[A\n",
      "Epoch 4:  49%|████▊     | 72/148 [01:05<01:09,  1.10it/s, training_loss=1.3001]\u001b[A\n",
      "Epoch 4:  49%|████▊     | 72/148 [01:06<01:09,  1.10it/s, training_loss=1.5940]\u001b[A\n",
      "Epoch 4:  49%|████▉     | 73/148 [01:06<01:08,  1.10it/s, training_loss=1.5940]\u001b[A\n",
      "Epoch 4:  49%|████▉     | 73/148 [01:07<01:08,  1.10it/s, training_loss=1.5610]\u001b[A\n",
      "Epoch 4:  50%|█████     | 74/148 [01:07<01:07,  1.10it/s, training_loss=1.5610]\u001b[A\n",
      "Epoch 4:  50%|█████     | 74/148 [01:08<01:07,  1.10it/s, training_loss=1.6627]\u001b[A\n",
      "Epoch 4:  51%|█████     | 75/148 [01:08<01:06,  1.10it/s, training_loss=1.6627]\u001b[A\n",
      "Epoch 4:  51%|█████     | 75/148 [01:09<01:06,  1.10it/s, training_loss=1.3851]\u001b[A\n",
      "Epoch 4:  51%|█████▏    | 76/148 [01:09<01:05,  1.10it/s, training_loss=1.3851]\u001b[A\n",
      "Epoch 4:  51%|█████▏    | 76/148 [01:10<01:05,  1.10it/s, training_loss=1.5487]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 77/148 [01:10<01:04,  1.10it/s, training_loss=1.5487]\u001b[A\n",
      "Epoch 4:  52%|█████▏    | 77/148 [01:11<01:04,  1.10it/s, training_loss=1.5154]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 78/148 [01:11<01:03,  1.10it/s, training_loss=1.5154]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 78/148 [01:12<01:03,  1.10it/s, training_loss=1.3746]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 79/148 [01:12<01:02,  1.10it/s, training_loss=1.3746]\u001b[A\n",
      "Epoch 4:  53%|█████▎    | 79/148 [01:13<01:02,  1.10it/s, training_loss=1.0976]\u001b[A\n",
      "Epoch 4:  54%|█████▍    | 80/148 [01:13<01:01,  1.10it/s, training_loss=1.0976]\u001b[A\n",
      "Epoch 4:  54%|█████▍    | 80/148 [01:14<01:01,  1.10it/s, training_loss=1.3431]\u001b[A\n",
      "Epoch 4:  55%|█████▍    | 81/148 [01:14<01:00,  1.10it/s, training_loss=1.3431]\u001b[A\n",
      "Epoch 4:  55%|█████▍    | 81/148 [01:15<01:00,  1.10it/s, training_loss=1.2887]\u001b[A\n",
      "Epoch 4:  55%|█████▌    | 82/148 [01:15<01:00,  1.10it/s, training_loss=1.2887]\u001b[A\n",
      "Epoch 4:  55%|█████▌    | 82/148 [01:15<01:00,  1.10it/s, training_loss=1.6759]\u001b[A\n",
      "Epoch 4:  56%|█████▌    | 83/148 [01:15<00:59,  1.10it/s, training_loss=1.6759]\u001b[A\n",
      "Epoch 4:  56%|█████▌    | 83/148 [01:16<00:59,  1.10it/s, training_loss=1.0865]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 84/148 [01:16<00:58,  1.10it/s, training_loss=1.0865]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 84/148 [01:17<00:58,  1.10it/s, training_loss=1.1278]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 85/148 [01:17<00:57,  1.09it/s, training_loss=1.1278]\u001b[A\n",
      "Epoch 4:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.5749]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 86/148 [01:18<00:56,  1.09it/s, training_loss=1.5749]\u001b[A\n",
      "Epoch 4:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.5698]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 87/148 [01:19<00:55,  1.09it/s, training_loss=1.5698]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 87/148 [01:20<00:55,  1.09it/s, training_loss=1.1374]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 88/148 [01:20<00:55,  1.09it/s, training_loss=1.1374]\u001b[A\n",
      "Epoch 4:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.0575]\u001b[A\n",
      "Epoch 4:  60%|██████    | 89/148 [01:21<00:54,  1.09it/s, training_loss=1.0575]\u001b[A\n",
      "Epoch 4:  60%|██████    | 89/148 [01:22<00:54,  1.09it/s, training_loss=1.2403]\u001b[A\n",
      "Epoch 4:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=1.2403]\u001b[A\n",
      "Epoch 4:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=1.2812]\u001b[A\n",
      "Epoch 4:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=1.2812]\u001b[A\n",
      "Epoch 4:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.2742]\u001b[A\n",
      "Epoch 4:  62%|██████▏   | 92/148 [01:24<00:51,  1.10it/s, training_loss=1.2742]\u001b[A\n",
      "Epoch 4:  62%|██████▏   | 92/148 [01:25<00:51,  1.10it/s, training_loss=1.5547]\u001b[A\n",
      "Epoch 4:  63%|██████▎   | 93/148 [01:25<00:50,  1.10it/s, training_loss=1.5547]\u001b[A\n",
      "Epoch 4:  63%|██████▎   | 93/148 [01:26<00:50,  1.10it/s, training_loss=1.1586]\u001b[A\n",
      "Epoch 4:  64%|██████▎   | 94/148 [01:26<00:49,  1.10it/s, training_loss=1.1586]\u001b[A\n",
      "Epoch 4:  64%|██████▎   | 94/148 [01:26<00:49,  1.10it/s, training_loss=1.0911]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 95/148 [01:26<00:48,  1.10it/s, training_loss=1.0911]\u001b[A\n",
      "Epoch 4:  64%|██████▍   | 95/148 [01:27<00:48,  1.10it/s, training_loss=1.0878]\u001b[A\n",
      "Epoch 4:  65%|██████▍   | 96/148 [01:27<00:47,  1.09it/s, training_loss=1.0878]\u001b[A\n",
      "Epoch 4:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.0986]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 97/148 [01:28<00:46,  1.09it/s, training_loss=1.0986]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.4941]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 98/148 [01:29<00:45,  1.09it/s, training_loss=1.4941]\u001b[A\n",
      "Epoch 4:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=1.1012]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 99/148 [01:30<00:44,  1.09it/s, training_loss=1.1012]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=1.1418]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 100/148 [01:31<00:44,  1.09it/s, training_loss=1.1418]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 100/148 [01:32<00:44,  1.09it/s, training_loss=1.1813]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 101/148 [01:32<00:43,  1.09it/s, training_loss=1.1813]\u001b[A\n",
      "Epoch 4:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.6505]\u001b[A\n",
      "Epoch 4:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.6505]\u001b[A\n",
      "Epoch 4:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=1.3615]\u001b[A\n",
      "Epoch 4:  70%|██████▉   | 103/148 [01:34<00:41,  1.09it/s, training_loss=1.3615]\u001b[A\n",
      "Epoch 4:  70%|██████▉   | 103/148 [01:35<00:41,  1.09it/s, training_loss=1.5871]\u001b[A\n",
      "Epoch 4:  70%|███████   | 104/148 [01:35<00:40,  1.09it/s, training_loss=1.5871]\u001b[A\n",
      "Epoch 4:  70%|███████   | 104/148 [01:36<00:40,  1.09it/s, training_loss=1.6319]\u001b[A\n",
      "Epoch 4:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=1.6319]\u001b[A\n",
      "Epoch 4:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.4693]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 106/148 [01:37<00:38,  1.10it/s, training_loss=1.4693]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 106/148 [01:37<00:38,  1.10it/s, training_loss=1.5459]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 107/148 [01:37<00:37,  1.10it/s, training_loss=1.5459]\u001b[A\n",
      "Epoch 4:  72%|███████▏  | 107/148 [01:38<00:37,  1.10it/s, training_loss=1.3328]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 108/148 [01:38<00:36,  1.09it/s, training_loss=1.3328]\u001b[A\n",
      "Epoch 4:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=1.3105]\u001b[A\n",
      "Epoch 4:  74%|███████▎  | 109/148 [01:39<00:35,  1.09it/s, training_loss=1.3105]\u001b[A\n",
      "Epoch 4:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.1699]\u001b[A\n",
      "Epoch 4:  74%|███████▍  | 110/148 [01:40<00:34,  1.09it/s, training_loss=1.1699]\u001b[A\n",
      "Epoch 4:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.1078]\u001b[A\n",
      "Epoch 4:  75%|███████▌  | 111/148 [01:41<00:33,  1.09it/s, training_loss=1.1078]\u001b[A\n",
      "Epoch 4:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=1.1715]\u001b[A\n",
      "Epoch 4:  76%|███████▌  | 112/148 [01:42<00:33,  1.09it/s, training_loss=1.1715]\u001b[A\n",
      "Epoch 4:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.4942]\u001b[A\n",
      "Epoch 4:  76%|███████▋  | 113/148 [01:43<00:32,  1.09it/s, training_loss=1.4942]\u001b[A\n",
      "Epoch 4:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.6125]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.6125]\u001b[A\n",
      "Epoch 4:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.5520]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 115/148 [01:45<00:30,  1.10it/s, training_loss=1.5520]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 115/148 [01:46<00:30,  1.10it/s, training_loss=1.3749]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.3749]\u001b[A\n",
      "Epoch 4:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=0.9958]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=0.9958]\u001b[A\n",
      "Epoch 4:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=0.9849]\u001b[A\n",
      "Epoch 4:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=0.9849]\u001b[A\n",
      "Epoch 4:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=1.0857]\u001b[A\n",
      "Epoch 4:  80%|████████  | 119/148 [01:48<00:26,  1.08it/s, training_loss=1.0857]\u001b[A\n",
      "Epoch 4:  80%|████████  | 119/148 [01:49<00:26,  1.08it/s, training_loss=1.5768]\u001b[A\n",
      "Epoch 4:  81%|████████  | 120/148 [01:49<00:25,  1.09it/s, training_loss=1.5768]\u001b[A\n",
      "Epoch 4:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.1315]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 121/148 [01:50<00:24,  1.08it/s, training_loss=1.1315]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 121/148 [01:51<00:24,  1.08it/s, training_loss=1.5274]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 122/148 [01:51<00:23,  1.09it/s, training_loss=1.5274]\u001b[A\n",
      "Epoch 4:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=0.9827]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 123/148 [01:52<00:23,  1.09it/s, training_loss=0.9827]\u001b[A\n",
      "Epoch 4:  83%|████████▎ | 123/148 [01:53<00:23,  1.09it/s, training_loss=1.2077]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 124/148 [01:53<00:22,  1.09it/s, training_loss=1.2077]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 124/148 [01:54<00:22,  1.09it/s, training_loss=1.6018]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 125/148 [01:54<00:21,  1.09it/s, training_loss=1.6018]\u001b[A\n",
      "Epoch 4:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=1.3383]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 126/148 [01:55<00:20,  1.08it/s, training_loss=1.3383]\u001b[A\n",
      "Epoch 4:  85%|████████▌ | 126/148 [01:56<00:20,  1.08it/s, training_loss=1.5940]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=1.5940]\u001b[A\n",
      "Epoch 4:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.3149]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.3149]\u001b[A\n",
      "Epoch 4:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.5160]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.5160]\u001b[A\n",
      "Epoch 4:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=1.3460]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.3460]\u001b[A\n",
      "Epoch 4:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.4173]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 131/148 [01:59<00:15,  1.09it/s, training_loss=1.4173]\u001b[A\n",
      "Epoch 4:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.2798]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 132/148 [02:00<00:14,  1.09it/s, training_loss=1.2798]\u001b[A\n",
      "Epoch 4:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.0823]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 133/148 [02:01<00:13,  1.09it/s, training_loss=1.0823]\u001b[A\n",
      "Epoch 4:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.1725]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 134/148 [02:02<00:12,  1.09it/s, training_loss=1.1725]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.5879]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 135/148 [02:03<00:11,  1.09it/s, training_loss=1.5879]\u001b[A\n",
      "Epoch 4:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=1.2938]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 136/148 [02:04<00:11,  1.09it/s, training_loss=1.2938]\u001b[A\n",
      "Epoch 4:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.1679]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=1.1679]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.2178]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.2178]\u001b[A\n",
      "Epoch 4:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.3479]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.3479]\u001b[A\n",
      "Epoch 4:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.3995]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=1.3995]\u001b[A\n",
      "Epoch 4:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=1.1150]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=1.1150]\u001b[A\n",
      "Epoch 4:  95%|█████████▌| 141/148 [02:10<00:06,  1.09it/s, training_loss=1.5686]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=1.5686]\u001b[A\n",
      "Epoch 4:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=1.0783]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 143/148 [02:10<00:04,  1.10it/s, training_loss=1.0783]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 143/148 [02:11<00:04,  1.10it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 144/148 [02:11<00:03,  1.10it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 4:  97%|█████████▋| 144/148 [02:12<00:03,  1.10it/s, training_loss=1.6959]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 145/148 [02:12<00:02,  1.10it/s, training_loss=1.6959]\u001b[A\n",
      "Epoch 4:  98%|█████████▊| 145/148 [02:13<00:02,  1.10it/s, training_loss=1.0309]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 146/148 [02:13<00:01,  1.09it/s, training_loss=1.0309]\u001b[A\n",
      "Epoch 4:  99%|█████████▊| 146/148 [02:14<00:01,  1.09it/s, training_loss=1.6300]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 147/148 [02:14<00:00,  1.09it/s, training_loss=1.6300]\u001b[A\n",
      "Epoch 4:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.1027]\u001b[A\n",
      "Epoch 4: 100%|██████████| 148/148 [02:15<00:00,  1.19it/s, training_loss=1.1027]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:35:06,858 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:35:06,860 - INFO - Memory usage after evaluation start: 3887.88 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.69it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.65it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.62it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.61it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.62it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.62it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.63it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.62it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.62it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.62it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.59it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:35:14,100 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 19:35:14,114 - INFO - Class 'Drama': Optimal threshold = 0.650, F1 Score = 0.520\n",
      "2025-02-16 19:35:14,128 - INFO - Class 'Horor': Optimal threshold = 0.600, F1 Score = 0.742\n",
      "2025-02-16 19:35:14,142 - INFO - Class 'Komedi': Optimal threshold = 0.600, F1 Score = 0.578\n",
      "2025-02-16 19:35:14,156 - INFO - Class 'Laga': Optimal threshold = 0.550, F1 Score = 0.393\n",
      "2025-02-16 19:35:14,172 - INFO - Class 'Romantis': Optimal threshold = 0.600, F1 Score = 0.514\n",
      "2025-02-16 19:35:14,196 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:35:14,201 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:35:14,202 - INFO - Accuracy: 0.6820\n",
      "2025-02-16 19:35:14,202 - INFO - F1_score: 0.5202\n",
      "2025-02-16 19:35:14,203 - INFO - Precision: 0.4545\n",
      "2025-02-16 19:35:14,204 - INFO - Recall: 0.6081\n",
      "2025-02-16 19:35:14,211 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:35:14,211 - INFO - Accuracy: 0.8774\n",
      "2025-02-16 19:35:14,212 - INFO - F1_score: 0.7419\n",
      "2025-02-16 19:35:14,213 - INFO - Precision: 0.6866\n",
      "2025-02-16 19:35:14,214 - INFO - Recall: 0.8070\n",
      "2025-02-16 19:35:14,220 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:35:14,221 - INFO - Accuracy: 0.7816\n",
      "2025-02-16 19:35:14,221 - INFO - F1_score: 0.5778\n",
      "2025-02-16 19:35:14,223 - INFO - Precision: 0.5065\n",
      "2025-02-16 19:35:14,223 - INFO - Recall: 0.6724\n",
      "2025-02-16 19:35:14,229 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:35:14,230 - INFO - Accuracy: 0.7165\n",
      "2025-02-16 19:35:14,230 - INFO - F1_score: 0.3934\n",
      "2025-02-16 19:35:14,231 - INFO - Precision: 0.2857\n",
      "2025-02-16 19:35:14,233 - INFO - Recall: 0.6316\n",
      "2025-02-16 19:35:14,238 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:35:14,239 - INFO - Accuracy: 0.8621\n",
      "2025-02-16 19:35:14,239 - INFO - F1_score: 0.5135\n",
      "2025-02-16 19:35:14,240 - INFO - Precision: 0.4750\n",
      "2025-02-16 19:35:14,241 - INFO - Recall: 0.5588\n",
      "2025-02-16 19:35:14,243 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:35:18,082 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:35:18,084 - INFO - Memory usage after evaluation end: 3893.38 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   3%|▎         | 3/100 [10:19<4:10:43, 155.09s/it, Train Loss=1.3552, Val Loss=0.0469, Accuracy=0.7839]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:35:25,291 - INFO - New best accuracy: 0.7839\n",
      "2025-02-16 19:35:26,393 - INFO - Learning rate: 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 4/100 [10:20<4:07:59, 155.00s/it, Train Loss=1.3552, Val Loss=0.0469, Accuracy=0.7839]\n",
      "Epoch 5:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.2095]\u001b[A\n",
      "Epoch 5:   1%|          | 1/148 [00:00<02:15,  1.09it/s, training_loss=1.2095]\u001b[A\n",
      "Epoch 5:   1%|          | 1/148 [00:01<02:15,  1.09it/s, training_loss=1.5343]\u001b[A\n",
      "Epoch 5:   1%|▏         | 2/148 [00:01<02:13,  1.10it/s, training_loss=1.5343]\u001b[A\n",
      "Epoch 5:   1%|▏         | 2/148 [00:02<02:13,  1.10it/s, training_loss=1.6707]\u001b[A\n",
      "Epoch 5:   2%|▏         | 3/148 [00:02<02:13,  1.09it/s, training_loss=1.6707]\u001b[A\n",
      "Epoch 5:   2%|▏         | 3/148 [00:03<02:13,  1.09it/s, training_loss=0.9994]\u001b[A\n",
      "Epoch 5:   3%|▎         | 4/148 [00:03<02:11,  1.10it/s, training_loss=0.9994]\u001b[A\n",
      "Epoch 5:   3%|▎         | 4/148 [00:04<02:11,  1.10it/s, training_loss=0.9855]\u001b[A\n",
      "Epoch 5:   3%|▎         | 5/148 [00:04<02:10,  1.09it/s, training_loss=0.9855]\u001b[A\n",
      "Epoch 5:   3%|▎         | 5/148 [00:05<02:10,  1.09it/s, training_loss=1.1893]\u001b[A\n",
      "Epoch 5:   4%|▍         | 6/148 [00:05<02:09,  1.09it/s, training_loss=1.1893]\u001b[A\n",
      "Epoch 5:   4%|▍         | 6/148 [00:06<02:09,  1.09it/s, training_loss=1.5973]\u001b[A\n",
      "Epoch 5:   5%|▍         | 7/148 [00:06<02:08,  1.10it/s, training_loss=1.5973]\u001b[A\n",
      "Epoch 5:   5%|▍         | 7/148 [00:07<02:08,  1.10it/s, training_loss=1.5634]\u001b[A\n",
      "Epoch 5:   5%|▌         | 8/148 [00:07<02:07,  1.10it/s, training_loss=1.5634]\u001b[A\n",
      "Epoch 5:   5%|▌         | 8/148 [00:08<02:07,  1.10it/s, training_loss=1.6199]\u001b[A\n",
      "Epoch 5:   6%|▌         | 9/148 [00:08<02:06,  1.10it/s, training_loss=1.6199]\u001b[A\n",
      "Epoch 5:   6%|▌         | 9/148 [00:09<02:06,  1.10it/s, training_loss=1.5869]\u001b[A\n",
      "Epoch 5:   7%|▋         | 10/148 [00:09<02:06,  1.09it/s, training_loss=1.5869]\u001b[A\n",
      "Epoch 5:   7%|▋         | 10/148 [00:10<02:06,  1.09it/s, training_loss=1.1435]\u001b[A\n",
      "Epoch 5:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.1435]\u001b[A\n",
      "Epoch 5:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 5:   8%|▊         | 12/148 [00:10<02:04,  1.10it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 5:   8%|▊         | 12/148 [00:11<02:04,  1.10it/s, training_loss=1.5792]\u001b[A\n",
      "Epoch 5:   9%|▉         | 13/148 [00:11<02:03,  1.10it/s, training_loss=1.5792]\u001b[A\n",
      "Epoch 5:   9%|▉         | 13/148 [00:12<02:03,  1.10it/s, training_loss=1.6105]\u001b[A\n",
      "Epoch 5:   9%|▉         | 14/148 [00:12<02:02,  1.10it/s, training_loss=1.6105]\u001b[A\n",
      "Epoch 5:   9%|▉         | 14/148 [00:13<02:02,  1.10it/s, training_loss=1.5149]\u001b[A\n",
      "Epoch 5:  10%|█         | 15/148 [00:13<02:01,  1.09it/s, training_loss=1.5149]\u001b[A\n",
      "Epoch 5:  10%|█         | 15/148 [00:14<02:01,  1.09it/s, training_loss=1.5268]\u001b[A\n",
      "Epoch 5:  11%|█         | 16/148 [00:14<02:00,  1.09it/s, training_loss=1.5268]\u001b[A\n",
      "Epoch 5:  11%|█         | 16/148 [00:15<02:00,  1.09it/s, training_loss=0.9260]\u001b[A\n",
      "Epoch 5:  11%|█▏        | 17/148 [00:15<01:59,  1.09it/s, training_loss=0.9260]\u001b[A\n",
      "Epoch 5:  11%|█▏        | 17/148 [00:16<01:59,  1.09it/s, training_loss=1.1643]\u001b[A\n",
      "Epoch 5:  12%|█▏        | 18/148 [00:16<01:59,  1.09it/s, training_loss=1.1643]\u001b[A\n",
      "Epoch 5:  12%|█▏        | 18/148 [00:17<01:59,  1.09it/s, training_loss=1.5519]\u001b[A\n",
      "Epoch 5:  13%|█▎        | 19/148 [00:17<01:58,  1.09it/s, training_loss=1.5519]\u001b[A\n",
      "Epoch 5:  13%|█▎        | 19/148 [00:18<01:58,  1.09it/s, training_loss=1.2228]\u001b[A\n",
      "Epoch 5:  14%|█▎        | 20/148 [00:18<01:57,  1.09it/s, training_loss=1.2228]\u001b[A\n",
      "Epoch 5:  14%|█▎        | 20/148 [00:19<01:57,  1.09it/s, training_loss=1.5430]\u001b[A\n",
      "Epoch 5:  14%|█▍        | 21/148 [00:19<01:56,  1.09it/s, training_loss=1.5430]\u001b[A\n",
      "Epoch 5:  14%|█▍        | 21/148 [00:20<01:56,  1.09it/s, training_loss=1.5742]\u001b[A\n",
      "Epoch 5:  15%|█▍        | 22/148 [00:20<01:55,  1.09it/s, training_loss=1.5742]\u001b[A\n",
      "Epoch 5:  15%|█▍        | 22/148 [00:21<01:55,  1.09it/s, training_loss=1.0325]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 23/148 [00:21<01:55,  1.09it/s, training_loss=1.0325]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 23/148 [00:22<01:55,  1.09it/s, training_loss=1.0752]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=1.0752]\u001b[A\n",
      "Epoch 5:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=1.0078]\u001b[A\n",
      "Epoch 5:  17%|█▋        | 25/148 [00:22<01:53,  1.08it/s, training_loss=1.0078]\u001b[A\n",
      "Epoch 5:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.4747]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 26/148 [00:23<01:52,  1.09it/s, training_loss=1.4747]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 26/148 [00:24<01:52,  1.09it/s, training_loss=1.6296]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 27/148 [00:24<01:51,  1.09it/s, training_loss=1.6296]\u001b[A\n",
      "Epoch 5:  18%|█▊        | 27/148 [00:25<01:51,  1.09it/s, training_loss=1.1122]\u001b[A\n",
      "Epoch 5:  19%|█▉        | 28/148 [00:25<01:51,  1.08it/s, training_loss=1.1122]\u001b[A\n",
      "Epoch 5:  19%|█▉        | 28/148 [00:26<01:51,  1.08it/s, training_loss=1.1782]\u001b[A\n",
      "Epoch 5:  20%|█▉        | 29/148 [00:26<01:50,  1.08it/s, training_loss=1.1782]\u001b[A\n",
      "Epoch 5:  20%|█▉        | 29/148 [00:27<01:50,  1.08it/s, training_loss=1.5830]\u001b[A\n",
      "Epoch 5:  20%|██        | 30/148 [00:27<01:48,  1.08it/s, training_loss=1.5830]\u001b[A\n",
      "Epoch 5:  20%|██        | 30/148 [00:28<01:48,  1.08it/s, training_loss=1.2058]\u001b[A\n",
      "Epoch 5:  21%|██        | 31/148 [00:28<01:48,  1.08it/s, training_loss=1.2058]\u001b[A\n",
      "Epoch 5:  21%|██        | 31/148 [00:29<01:48,  1.08it/s, training_loss=1.2552]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 32/148 [00:29<01:47,  1.08it/s, training_loss=1.2552]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 32/148 [00:30<01:47,  1.08it/s, training_loss=1.5031]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 33/148 [00:30<01:45,  1.09it/s, training_loss=1.5031]\u001b[A\n",
      "Epoch 5:  22%|██▏       | 33/148 [00:31<01:45,  1.09it/s, training_loss=1.6425]\u001b[A\n",
      "Epoch 5:  23%|██▎       | 34/148 [00:31<01:44,  1.09it/s, training_loss=1.6425]\u001b[A\n",
      "Epoch 5:  23%|██▎       | 34/148 [00:32<01:44,  1.09it/s, training_loss=1.1038]\u001b[A\n",
      "Epoch 5:  24%|██▎       | 35/148 [00:32<01:44,  1.08it/s, training_loss=1.1038]\u001b[A\n",
      "Epoch 5:  24%|██▎       | 35/148 [00:33<01:44,  1.08it/s, training_loss=1.2250]\u001b[A\n",
      "Epoch 5:  24%|██▍       | 36/148 [00:33<01:43,  1.08it/s, training_loss=1.2250]\u001b[A\n",
      "Epoch 5:  24%|██▍       | 36/148 [00:34<01:43,  1.08it/s, training_loss=1.1018]\u001b[A\n",
      "Epoch 5:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=1.1018]\u001b[A\n",
      "Epoch 5:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=1.4319]\u001b[A\n",
      "Epoch 5:  26%|██▌       | 38/148 [00:34<01:41,  1.09it/s, training_loss=1.4319]\u001b[A\n",
      "Epoch 5:  26%|██▌       | 38/148 [00:35<01:41,  1.09it/s, training_loss=1.0830]\u001b[A\n",
      "Epoch 5:  26%|██▋       | 39/148 [00:35<01:40,  1.08it/s, training_loss=1.0830]\u001b[A\n",
      "Epoch 5:  26%|██▋       | 39/148 [00:36<01:40,  1.08it/s, training_loss=1.6420]\u001b[A\n",
      "Epoch 5:  27%|██▋       | 40/148 [00:36<01:39,  1.09it/s, training_loss=1.6420]\u001b[A\n",
      "Epoch 5:  27%|██▋       | 40/148 [00:37<01:39,  1.09it/s, training_loss=1.6871]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=1.6871]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=1.3998]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=1.3998]\u001b[A\n",
      "Epoch 5:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=1.6191]\u001b[A\n",
      "Epoch 5:  29%|██▉       | 43/148 [00:39<01:36,  1.09it/s, training_loss=1.6191]\u001b[A\n",
      "Epoch 5:  29%|██▉       | 43/148 [00:40<01:36,  1.09it/s, training_loss=1.5536]\u001b[A\n",
      "Epoch 5:  30%|██▉       | 44/148 [00:40<01:35,  1.09it/s, training_loss=1.5536]\u001b[A\n",
      "Epoch 5:  30%|██▉       | 44/148 [00:41<01:35,  1.09it/s, training_loss=1.5082]\u001b[A\n",
      "Epoch 5:  30%|███       | 45/148 [00:41<01:34,  1.10it/s, training_loss=1.5082]\u001b[A\n",
      "Epoch 5:  30%|███       | 45/148 [00:42<01:34,  1.10it/s, training_loss=1.0815]\u001b[A\n",
      "Epoch 5:  31%|███       | 46/148 [00:42<01:33,  1.09it/s, training_loss=1.0815]\u001b[A\n",
      "Epoch 5:  31%|███       | 46/148 [00:43<01:33,  1.09it/s, training_loss=0.9842]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=0.9842]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.3384]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 48/148 [00:44<01:31,  1.09it/s, training_loss=1.3384]\u001b[A\n",
      "Epoch 5:  32%|███▏      | 48/148 [00:45<01:31,  1.09it/s, training_loss=1.5877]\u001b[A\n",
      "Epoch 5:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=1.5877]\u001b[A\n",
      "Epoch 5:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=0.9437]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 50/148 [00:45<01:29,  1.09it/s, training_loss=0.9437]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=1.6563]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 51/148 [00:46<01:28,  1.09it/s, training_loss=1.6563]\u001b[A\n",
      "Epoch 5:  34%|███▍      | 51/148 [00:47<01:28,  1.09it/s, training_loss=1.6150]\u001b[A\n",
      "Epoch 5:  35%|███▌      | 52/148 [00:47<01:27,  1.09it/s, training_loss=1.6150]\u001b[A\n",
      "Epoch 5:  35%|███▌      | 52/148 [00:48<01:27,  1.09it/s, training_loss=1.4793]\u001b[A\n",
      "Epoch 5:  36%|███▌      | 53/148 [00:48<01:26,  1.09it/s, training_loss=1.4793]\u001b[A\n",
      "Epoch 5:  36%|███▌      | 53/148 [00:49<01:26,  1.09it/s, training_loss=1.5210]\u001b[A\n",
      "Epoch 5:  36%|███▋      | 54/148 [00:49<01:26,  1.09it/s, training_loss=1.5210]\u001b[A\n",
      "Epoch 5:  36%|███▋      | 54/148 [00:50<01:26,  1.09it/s, training_loss=1.6233]\u001b[A\n",
      "Epoch 5:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.6233]\u001b[A\n",
      "Epoch 5:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=0.9566]\u001b[A\n",
      "Epoch 5:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=0.9566]\u001b[A\n",
      "Epoch 5:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.5676]\u001b[A\n",
      "Epoch 5:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.5676]\u001b[A\n",
      "Epoch 5:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=0.9203]\u001b[A\n",
      "Epoch 5:  39%|███▉      | 58/148 [00:53<01:22,  1.09it/s, training_loss=0.9203]\u001b[A\n",
      "Epoch 5:  39%|███▉      | 58/148 [00:54<01:22,  1.09it/s, training_loss=0.9351]\u001b[A\n",
      "Epoch 5:  40%|███▉      | 59/148 [00:54<01:21,  1.09it/s, training_loss=0.9351]\u001b[A\n",
      "Epoch 5:  40%|███▉      | 59/148 [00:55<01:21,  1.09it/s, training_loss=0.9477]\u001b[A\n",
      "Epoch 5:  41%|████      | 60/148 [00:55<01:21,  1.08it/s, training_loss=0.9477]\u001b[A\n",
      "Epoch 5:  41%|████      | 60/148 [00:56<01:21,  1.08it/s, training_loss=1.6210]\u001b[A\n",
      "Epoch 5:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=1.6210]\u001b[A\n",
      "Epoch 5:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=1.5506]\u001b[A\n",
      "Epoch 5:  42%|████▏     | 62/148 [00:56<01:18,  1.09it/s, training_loss=1.5506]\u001b[A\n",
      "Epoch 5:  42%|████▏     | 62/148 [00:57<01:18,  1.09it/s, training_loss=1.1823]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 63/148 [00:57<01:18,  1.08it/s, training_loss=1.1823]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 63/148 [00:58<01:18,  1.08it/s, training_loss=1.1369]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 64/148 [00:58<01:17,  1.08it/s, training_loss=1.1369]\u001b[A\n",
      "Epoch 5:  43%|████▎     | 64/148 [00:59<01:17,  1.08it/s, training_loss=1.5610]\u001b[A\n",
      "Epoch 5:  44%|████▍     | 65/148 [00:59<01:16,  1.09it/s, training_loss=1.5610]\u001b[A\n",
      "Epoch 5:  44%|████▍     | 65/148 [01:00<01:16,  1.09it/s, training_loss=1.6224]\u001b[A\n",
      "Epoch 5:  45%|████▍     | 66/148 [01:00<01:15,  1.09it/s, training_loss=1.6224]\u001b[A\n",
      "Epoch 5:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=1.6825]\u001b[A\n",
      "Epoch 5:  45%|████▌     | 67/148 [01:01<01:14,  1.09it/s, training_loss=1.6825]\u001b[A\n",
      "Epoch 5:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=1.0839]\u001b[A\n",
      "Epoch 5:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=1.0839]\u001b[A\n",
      "Epoch 5:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=0.9769]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=0.9769]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=1.5887]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=1.5887]\u001b[A\n",
      "Epoch 5:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=1.6310]\u001b[A\n",
      "Epoch 5:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=1.6310]\u001b[A\n",
      "Epoch 5:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.6782]\u001b[A\n",
      "Epoch 5:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=1.6782]\u001b[A\n",
      "Epoch 5:  49%|████▊     | 72/148 [01:07<01:09,  1.09it/s, training_loss=1.5764]\u001b[A\n",
      "Epoch 5:  49%|████▉     | 73/148 [01:07<01:08,  1.10it/s, training_loss=1.5764]\u001b[A\n",
      "Epoch 5:  49%|████▉     | 73/148 [01:07<01:08,  1.10it/s, training_loss=1.4893]\u001b[A\n",
      "Epoch 5:  50%|█████     | 74/148 [01:07<01:07,  1.09it/s, training_loss=1.4893]\u001b[A\n",
      "Epoch 5:  50%|█████     | 74/148 [01:08<01:07,  1.09it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 5:  51%|█████     | 75/148 [01:08<01:06,  1.09it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 5:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.0812]\u001b[A\n",
      "Epoch 5:  51%|█████▏    | 76/148 [01:09<01:05,  1.09it/s, training_loss=1.0812]\u001b[A\n",
      "Epoch 5:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=1.0923]\u001b[A\n",
      "Epoch 5:  52%|█████▏    | 77/148 [01:10<01:04,  1.09it/s, training_loss=1.0923]\u001b[A\n",
      "Epoch 5:  52%|█████▏    | 77/148 [01:11<01:04,  1.09it/s, training_loss=1.0679]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 78/148 [01:11<01:04,  1.09it/s, training_loss=1.0679]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 78/148 [01:12<01:04,  1.09it/s, training_loss=1.3245]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 79/148 [01:12<01:03,  1.09it/s, training_loss=1.3245]\u001b[A\n",
      "Epoch 5:  53%|█████▎    | 79/148 [01:13<01:03,  1.09it/s, training_loss=1.1141]\u001b[A\n",
      "Epoch 5:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.1141]\u001b[A\n",
      "Epoch 5:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.2440]\u001b[A\n",
      "Epoch 5:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=1.2440]\u001b[A\n",
      "Epoch 5:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=1.0571]\u001b[A\n",
      "Epoch 5:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.0571]\u001b[A\n",
      "Epoch 5:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.5564]\u001b[A\n",
      "Epoch 5:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=1.5564]\u001b[A\n",
      "Epoch 5:  56%|█████▌    | 83/148 [01:17<00:59,  1.09it/s, training_loss=0.9423]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=0.9423]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 84/148 [01:18<00:58,  1.09it/s, training_loss=1.1360]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.1360]\u001b[A\n",
      "Epoch 5:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.1550]\u001b[A\n",
      "Epoch 5:  58%|█████▊    | 86/148 [01:18<00:56,  1.09it/s, training_loss=1.1550]\u001b[A\n",
      "Epoch 5:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=0.9858]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 87/148 [01:19<00:55,  1.09it/s, training_loss=0.9858]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 87/148 [01:20<00:55,  1.09it/s, training_loss=1.6741]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 88/148 [01:20<00:54,  1.09it/s, training_loss=1.6741]\u001b[A\n",
      "Epoch 5:  59%|█████▉    | 88/148 [01:21<00:54,  1.09it/s, training_loss=1.5875]\u001b[A\n",
      "Epoch 5:  60%|██████    | 89/148 [01:21<00:53,  1.10it/s, training_loss=1.5875]\u001b[A\n",
      "Epoch 5:  60%|██████    | 89/148 [01:22<00:53,  1.10it/s, training_loss=1.2857]\u001b[A\n",
      "Epoch 5:  61%|██████    | 90/148 [01:22<00:52,  1.10it/s, training_loss=1.2857]\u001b[A\n",
      "Epoch 5:  61%|██████    | 90/148 [01:23<00:52,  1.10it/s, training_loss=1.6537]\u001b[A\n",
      "Epoch 5:  61%|██████▏   | 91/148 [01:23<00:52,  1.10it/s, training_loss=1.6537]\u001b[A\n",
      "Epoch 5:  61%|██████▏   | 91/148 [01:24<00:52,  1.10it/s, training_loss=1.1057]\u001b[A\n",
      "Epoch 5:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.1057]\u001b[A\n",
      "Epoch 5:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=1.6368]\u001b[A\n",
      "Epoch 5:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.6368]\u001b[A\n",
      "Epoch 5:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.5451]\u001b[A\n",
      "Epoch 5:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=1.5451]\u001b[A\n",
      "Epoch 5:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.0516]\u001b[A\n",
      "Epoch 5:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.0516]\u001b[A\n",
      "Epoch 5:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=1.1466]\u001b[A\n",
      "Epoch 5:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.1466]\u001b[A\n",
      "Epoch 5:  65%|██████▍   | 96/148 [01:29<00:47,  1.09it/s, training_loss=1.0378]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.0378]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.0091]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 98/148 [01:29<00:45,  1.09it/s, training_loss=1.0091]\u001b[A\n",
      "Epoch 5:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=1.5134]\u001b[A\n",
      "Epoch 5:  67%|██████▋   | 99/148 [01:30<00:44,  1.09it/s, training_loss=1.5134]\u001b[A\n",
      "Epoch 5:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=1.5096]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 100/148 [01:31<00:43,  1.10it/s, training_loss=1.5096]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 100/148 [01:32<00:43,  1.10it/s, training_loss=1.4910]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 101/148 [01:32<00:42,  1.10it/s, training_loss=1.4910]\u001b[A\n",
      "Epoch 5:  68%|██████▊   | 101/148 [01:33<00:42,  1.10it/s, training_loss=1.5532]\u001b[A\n",
      "Epoch 5:  69%|██████▉   | 102/148 [01:33<00:41,  1.10it/s, training_loss=1.5532]\u001b[A\n",
      "Epoch 5:  69%|██████▉   | 102/148 [01:34<00:41,  1.10it/s, training_loss=1.6483]\u001b[A\n",
      "Epoch 5:  70%|██████▉   | 103/148 [01:34<00:41,  1.10it/s, training_loss=1.6483]\u001b[A\n",
      "Epoch 5:  70%|██████▉   | 103/148 [01:35<00:41,  1.10it/s, training_loss=1.5578]\u001b[A\n",
      "Epoch 5:  70%|███████   | 104/148 [01:35<00:40,  1.10it/s, training_loss=1.5578]\u001b[A\n",
      "Epoch 5:  70%|███████   | 104/148 [01:36<00:40,  1.10it/s, training_loss=1.1094]\u001b[A\n",
      "Epoch 5:  71%|███████   | 105/148 [01:36<00:39,  1.10it/s, training_loss=1.1094]\u001b[A\n",
      "Epoch 5:  71%|███████   | 105/148 [01:37<00:39,  1.10it/s, training_loss=1.0999]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 106/148 [01:37<00:38,  1.10it/s, training_loss=1.0999]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 106/148 [01:38<00:38,  1.10it/s, training_loss=1.5445]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 107/148 [01:38<00:37,  1.10it/s, training_loss=1.5445]\u001b[A\n",
      "Epoch 5:  72%|███████▏  | 107/148 [01:39<00:37,  1.10it/s, training_loss=0.8866]\u001b[A\n",
      "Epoch 5:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=0.8866]\u001b[A\n",
      "Epoch 5:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=1.6854]\u001b[A\n",
      "Epoch 5:  74%|███████▎  | 109/148 [01:39<00:35,  1.09it/s, training_loss=1.6854]\u001b[A\n",
      "Epoch 5:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.5506]\u001b[A\n",
      "Epoch 5:  74%|███████▍  | 110/148 [01:40<00:34,  1.09it/s, training_loss=1.5506]\u001b[A\n",
      "Epoch 5:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.0877]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 111/148 [01:41<00:33,  1.09it/s, training_loss=1.0877]\u001b[A\n",
      "Epoch 5:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=1.5843]\u001b[A\n",
      "Epoch 5:  76%|███████▌  | 112/148 [01:42<00:33,  1.09it/s, training_loss=1.5843]\u001b[A\n",
      "Epoch 5:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.1563]\u001b[A\n",
      "Epoch 5:  76%|███████▋  | 113/148 [01:43<00:32,  1.09it/s, training_loss=1.1563]\u001b[A\n",
      "Epoch 5:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.5875]\u001b[A\n",
      "Epoch 5:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.5875]\u001b[A\n",
      "Epoch 5:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.3363]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.3363]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=1.5430]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.5430]\u001b[A\n",
      "Epoch 5:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=1.4755]\u001b[A\n",
      "Epoch 5:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.4755]\u001b[A\n",
      "Epoch 5:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=1.5132]\u001b[A\n",
      "Epoch 5:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=1.5132]\u001b[A\n",
      "Epoch 5:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.1038]\u001b[A\n",
      "Epoch 5:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.1038]\u001b[A\n",
      "Epoch 5:  80%|████████  | 119/148 [01:50<00:26,  1.09it/s, training_loss=1.5231]\u001b[A\n",
      "Epoch 5:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.5231]\u001b[A\n",
      "Epoch 5:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.7638]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 121/148 [01:50<00:24,  1.09it/s, training_loss=1.7638]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.2219]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 122/148 [01:51<00:23,  1.09it/s, training_loss=1.2219]\u001b[A\n",
      "Epoch 5:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.1243]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 123/148 [01:52<00:22,  1.09it/s, training_loss=1.1243]\u001b[A\n",
      "Epoch 5:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=1.6937]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 124/148 [01:53<00:21,  1.09it/s, training_loss=1.6937]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 124/148 [01:54<00:21,  1.09it/s, training_loss=1.6255]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 125/148 [01:54<00:21,  1.09it/s, training_loss=1.6255]\u001b[A\n",
      "Epoch 5:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=0.9721]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 126/148 [01:55<00:20,  1.09it/s, training_loss=0.9721]\u001b[A\n",
      "Epoch 5:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=0.9540]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=0.9540]\u001b[A\n",
      "Epoch 5:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.2414]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 128/148 [01:57<00:18,  1.08it/s, training_loss=1.2414]\u001b[A\n",
      "Epoch 5:  86%|████████▋ | 128/148 [01:58<00:18,  1.08it/s, training_loss=1.5488]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.5488]\u001b[A\n",
      "Epoch 5:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=1.6172]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.6172]\u001b[A\n",
      "Epoch 5:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=1.0276]\u001b[A\n",
      "Epoch 5:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.0276]\u001b[A\n",
      "Epoch 5:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=1.5965]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.5965]\u001b[A\n",
      "Epoch 5:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.2019]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 133/148 [02:01<00:13,  1.09it/s, training_loss=1.2019]\u001b[A\n",
      "Epoch 5:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.5230]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 134/148 [02:02<00:12,  1.09it/s, training_loss=1.5230]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=0.9750]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 135/148 [02:03<00:11,  1.09it/s, training_loss=0.9750]\u001b[A\n",
      "Epoch 5:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=1.1995]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 136/148 [02:04<00:11,  1.09it/s, training_loss=1.1995]\u001b[A\n",
      "Epoch 5:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.5439]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=1.5439]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.2425]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.2425]\u001b[A\n",
      "Epoch 5:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.0351]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.0351]\u001b[A\n",
      "Epoch 5:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.5749]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=1.5749]\u001b[A\n",
      "Epoch 5:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=1.5197]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=1.5197]\u001b[A\n",
      "Epoch 5:  95%|█████████▌| 141/148 [02:10<00:06,  1.09it/s, training_loss=1.5446]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=1.5446]\u001b[A\n",
      "Epoch 5:  96%|█████████▌| 142/148 [02:11<00:05,  1.09it/s, training_loss=1.0227]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.0227]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=1.3996]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=1.3996]\u001b[A\n",
      "Epoch 5:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 145/148 [02:12<00:02,  1.09it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 5:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=1.0732]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 146/148 [02:13<00:01,  1.08it/s, training_loss=1.0732]\u001b[A\n",
      "Epoch 5:  99%|█████████▊| 146/148 [02:14<00:01,  1.08it/s, training_loss=0.8760]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 147/148 [02:14<00:00,  1.09it/s, training_loss=0.8760]\u001b[A\n",
      "Epoch 5:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.0354]\u001b[A\n",
      "Epoch 5: 100%|██████████| 148/148 [02:15<00:00,  1.18it/s, training_loss=1.0354]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:37:41,922 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:37:41,923 - INFO - Memory usage after evaluation start: 3893.80 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:06,  3.72it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.66it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.65it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.62it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.61it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.60it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.59it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.60it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.60it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.59it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.58it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.58it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.59it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.60it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.60it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.60it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.61it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:37:49,175 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 19:37:49,193 - INFO - Class 'Drama': Optimal threshold = 0.650, F1 Score = 0.519\n",
      "2025-02-16 19:37:49,209 - INFO - Class 'Horor': Optimal threshold = 0.700, F1 Score = 0.772\n",
      "2025-02-16 19:37:49,225 - INFO - Class 'Komedi': Optimal threshold = 0.650, F1 Score = 0.590\n",
      "2025-02-16 19:37:49,240 - INFO - Class 'Laga': Optimal threshold = 0.450, F1 Score = 0.415\n",
      "2025-02-16 19:37:49,256 - INFO - Class 'Romantis': Optimal threshold = 0.700, F1 Score = 0.541\n",
      "2025-02-16 19:37:49,281 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:37:49,287 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:37:49,288 - INFO - Accuracy: 0.7088\n",
      "2025-02-16 19:37:49,288 - INFO - F1_score: 0.5190\n",
      "2025-02-16 19:37:49,289 - INFO - Precision: 0.4881\n",
      "2025-02-16 19:37:49,290 - INFO - Recall: 0.5541\n",
      "2025-02-16 19:37:49,297 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:37:49,298 - INFO - Accuracy: 0.9004\n",
      "2025-02-16 19:37:49,298 - INFO - F1_score: 0.7719\n",
      "2025-02-16 19:37:49,299 - INFO - Precision: 0.7719\n",
      "2025-02-16 19:37:49,300 - INFO - Recall: 0.7719\n",
      "2025-02-16 19:37:49,307 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:37:49,307 - INFO - Accuracy: 0.7816\n",
      "2025-02-16 19:37:49,309 - INFO - F1_score: 0.5899\n",
      "2025-02-16 19:37:49,309 - INFO - Precision: 0.5062\n",
      "2025-02-16 19:37:49,310 - INFO - Recall: 0.7069\n",
      "2025-02-16 19:37:49,317 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:37:49,318 - INFO - Accuracy: 0.7088\n",
      "2025-02-16 19:37:49,318 - INFO - F1_score: 0.4154\n",
      "2025-02-16 19:37:49,320 - INFO - Precision: 0.2935\n",
      "2025-02-16 19:37:49,320 - INFO - Recall: 0.7105\n",
      "2025-02-16 19:37:49,327 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:37:49,327 - INFO - Accuracy: 0.8697\n",
      "2025-02-16 19:37:49,328 - INFO - F1_score: 0.5405\n",
      "2025-02-16 19:37:49,329 - INFO - Precision: 0.5000\n",
      "2025-02-16 19:37:49,330 - INFO - Recall: 0.5882\n",
      "2025-02-16 19:37:49,333 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:37:53,427 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:37:53,428 - INFO - Memory usage after evaluation end: 3899.43 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   4%|▍         | 4/100 [12:54<4:07:59, 155.00s/it, Train Loss=1.3408, Val Loss=0.0482, Accuracy=0.7939]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:38:00,681 - INFO - New best accuracy: 0.7939\n",
      "2025-02-16 19:38:01,675 - INFO - Learning rate: 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   5%|▌         | 5/100 [12:57<4:06:18, 155.56s/it, Train Loss=1.3408, Val Loss=0.0482, Accuracy=0.7939]\n",
      "Epoch 6:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.1523]\u001b[A\n",
      "Epoch 6:   1%|          | 1/148 [00:00<02:20,  1.05it/s, training_loss=1.1523]\u001b[A\n",
      "Epoch 6:   1%|          | 1/148 [00:01<02:20,  1.05it/s, training_loss=1.5845]\u001b[A\n",
      "Epoch 6:   1%|▏         | 2/148 [00:01<02:15,  1.08it/s, training_loss=1.5845]\u001b[A\n",
      "Epoch 6:   1%|▏         | 2/148 [00:02<02:15,  1.08it/s, training_loss=1.0609]\u001b[A\n",
      "Epoch 6:   2%|▏         | 3/148 [00:02<02:13,  1.08it/s, training_loss=1.0609]\u001b[A\n",
      "Epoch 6:   2%|▏         | 3/148 [00:03<02:13,  1.08it/s, training_loss=0.9931]\u001b[A\n",
      "Epoch 6:   3%|▎         | 4/148 [00:03<02:12,  1.09it/s, training_loss=0.9931]\u001b[A\n",
      "Epoch 6:   3%|▎         | 4/148 [00:04<02:12,  1.09it/s, training_loss=1.1156]\u001b[A\n",
      "Epoch 6:   3%|▎         | 5/148 [00:04<02:10,  1.09it/s, training_loss=1.1156]\u001b[A\n",
      "Epoch 6:   3%|▎         | 5/148 [00:05<02:10,  1.09it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 6:   4%|▍         | 6/148 [00:05<02:10,  1.09it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 6:   4%|▍         | 6/148 [00:06<02:10,  1.09it/s, training_loss=1.5895]\u001b[A\n",
      "Epoch 6:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=1.5895]\u001b[A\n",
      "Epoch 6:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=1.5660]\u001b[A\n",
      "Epoch 6:   5%|▌         | 8/148 [00:07<02:07,  1.09it/s, training_loss=1.5660]\u001b[A\n",
      "Epoch 6:   5%|▌         | 8/148 [00:08<02:07,  1.09it/s, training_loss=1.5288]\u001b[A\n",
      "Epoch 6:   6%|▌         | 9/148 [00:08<02:06,  1.09it/s, training_loss=1.5288]\u001b[A\n",
      "Epoch 6:   6%|▌         | 9/148 [00:09<02:06,  1.09it/s, training_loss=1.5817]\u001b[A\n",
      "Epoch 6:   7%|▋         | 10/148 [00:09<02:06,  1.10it/s, training_loss=1.5817]\u001b[A\n",
      "Epoch 6:   7%|▋         | 10/148 [00:10<02:06,  1.10it/s, training_loss=1.6083]\u001b[A\n",
      "Epoch 6:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.6083]\u001b[A\n",
      "Epoch 6:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.5651]\u001b[A\n",
      "Epoch 6:   8%|▊         | 12/148 [00:10<02:04,  1.10it/s, training_loss=1.5651]\u001b[A\n",
      "Epoch 6:   8%|▊         | 12/148 [00:11<02:04,  1.10it/s, training_loss=1.1098]\u001b[A\n",
      "Epoch 6:   9%|▉         | 13/148 [00:11<02:04,  1.09it/s, training_loss=1.1098]\u001b[A\n",
      "Epoch 6:   9%|▉         | 13/148 [00:12<02:04,  1.09it/s, training_loss=1.1738]\u001b[A\n",
      "Epoch 6:   9%|▉         | 14/148 [00:12<02:03,  1.09it/s, training_loss=1.1738]\u001b[A\n",
      "Epoch 6:   9%|▉         | 14/148 [00:13<02:03,  1.09it/s, training_loss=0.9531]\u001b[A\n",
      "Epoch 6:  10%|█         | 15/148 [00:13<02:02,  1.08it/s, training_loss=0.9531]\u001b[A\n",
      "Epoch 6:  10%|█         | 15/148 [00:14<02:02,  1.08it/s, training_loss=1.3693]\u001b[A\n",
      "Epoch 6:  11%|█         | 16/148 [00:14<02:01,  1.08it/s, training_loss=1.3693]\u001b[A\n",
      "Epoch 6:  11%|█         | 16/148 [00:15<02:01,  1.08it/s, training_loss=1.2956]\u001b[A\n",
      "Epoch 6:  11%|█▏        | 17/148 [00:15<02:00,  1.08it/s, training_loss=1.2956]\u001b[A\n",
      "Epoch 6:  11%|█▏        | 17/148 [00:16<02:00,  1.08it/s, training_loss=1.5699]\u001b[A\n",
      "Epoch 6:  12%|█▏        | 18/148 [00:16<01:59,  1.09it/s, training_loss=1.5699]\u001b[A\n",
      "Epoch 6:  12%|█▏        | 18/148 [00:17<01:59,  1.09it/s, training_loss=0.9599]\u001b[A\n",
      "Epoch 6:  13%|█▎        | 19/148 [00:17<01:58,  1.09it/s, training_loss=0.9599]\u001b[A\n",
      "Epoch 6:  13%|█▎        | 19/148 [00:18<01:58,  1.09it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 6:  14%|█▎        | 20/148 [00:18<01:57,  1.09it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 6:  14%|█▎        | 20/148 [00:19<01:57,  1.09it/s, training_loss=1.6175]\u001b[A\n",
      "Epoch 6:  14%|█▍        | 21/148 [00:19<01:57,  1.08it/s, training_loss=1.6175]\u001b[A\n",
      "Epoch 6:  14%|█▍        | 21/148 [00:20<01:57,  1.08it/s, training_loss=1.5763]\u001b[A\n",
      "Epoch 6:  15%|█▍        | 22/148 [00:20<01:55,  1.09it/s, training_loss=1.5763]\u001b[A\n",
      "Epoch 6:  15%|█▍        | 22/148 [00:21<01:55,  1.09it/s, training_loss=1.3036]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 23/148 [00:21<01:54,  1.09it/s, training_loss=1.3036]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 23/148 [00:22<01:54,  1.09it/s, training_loss=1.0521]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=1.0521]\u001b[A\n",
      "Epoch 6:  16%|█▌        | 24/148 [00:23<01:54,  1.08it/s, training_loss=1.6054]\u001b[A\n",
      "Epoch 6:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.6054]\u001b[A\n",
      "Epoch 6:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.0822]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 26/148 [00:23<01:52,  1.09it/s, training_loss=1.0822]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 26/148 [00:24<01:52,  1.09it/s, training_loss=1.6670]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 27/148 [00:24<01:51,  1.09it/s, training_loss=1.6670]\u001b[A\n",
      "Epoch 6:  18%|█▊        | 27/148 [00:25<01:51,  1.09it/s, training_loss=1.1300]\u001b[A\n",
      "Epoch 6:  19%|█▉        | 28/148 [00:25<01:50,  1.09it/s, training_loss=1.1300]\u001b[A\n",
      "Epoch 6:  19%|█▉        | 28/148 [00:26<01:50,  1.09it/s, training_loss=1.0662]\u001b[A\n",
      "Epoch 6:  20%|█▉        | 29/148 [00:26<01:49,  1.08it/s, training_loss=1.0662]\u001b[A\n",
      "Epoch 6:  20%|█▉        | 29/148 [00:27<01:49,  1.08it/s, training_loss=1.5649]\u001b[A\n",
      "Epoch 6:  20%|██        | 30/148 [00:27<01:48,  1.08it/s, training_loss=1.5649]\u001b[A\n",
      "Epoch 6:  20%|██        | 30/148 [00:28<01:48,  1.08it/s, training_loss=0.9191]\u001b[A\n",
      "Epoch 6:  21%|██        | 31/148 [00:28<01:47,  1.09it/s, training_loss=0.9191]\u001b[A\n",
      "Epoch 6:  21%|██        | 31/148 [00:29<01:47,  1.09it/s, training_loss=1.6053]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 32/148 [00:29<01:46,  1.09it/s, training_loss=1.6053]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 32/148 [00:30<01:46,  1.09it/s, training_loss=1.5904]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 33/148 [00:30<01:45,  1.09it/s, training_loss=1.5904]\u001b[A\n",
      "Epoch 6:  22%|██▏       | 33/148 [00:31<01:45,  1.09it/s, training_loss=1.1217]\u001b[A\n",
      "Epoch 6:  23%|██▎       | 34/148 [00:31<01:44,  1.09it/s, training_loss=1.1217]\u001b[A\n",
      "Epoch 6:  23%|██▎       | 34/148 [00:32<01:44,  1.09it/s, training_loss=1.5244]\u001b[A\n",
      "Epoch 6:  24%|██▎       | 35/148 [00:32<01:43,  1.09it/s, training_loss=1.5244]\u001b[A\n",
      "Epoch 6:  24%|██▎       | 35/148 [00:33<01:43,  1.09it/s, training_loss=1.4236]\u001b[A\n",
      "Epoch 6:  24%|██▍       | 36/148 [00:33<01:42,  1.09it/s, training_loss=1.4236]\u001b[A\n",
      "Epoch 6:  24%|██▍       | 36/148 [00:34<01:42,  1.09it/s, training_loss=1.6812]\u001b[A\n",
      "Epoch 6:  25%|██▌       | 37/148 [00:34<01:42,  1.09it/s, training_loss=1.6812]\u001b[A\n",
      "Epoch 6:  25%|██▌       | 37/148 [00:34<01:42,  1.09it/s, training_loss=1.0767]\u001b[A\n",
      "Epoch 6:  26%|██▌       | 38/148 [00:34<01:41,  1.08it/s, training_loss=1.0767]\u001b[A\n",
      "Epoch 6:  26%|██▌       | 38/148 [00:35<01:41,  1.08it/s, training_loss=1.5368]\u001b[A\n",
      "Epoch 6:  26%|██▋       | 39/148 [00:35<01:40,  1.09it/s, training_loss=1.5368]\u001b[A\n",
      "Epoch 6:  26%|██▋       | 39/148 [00:36<01:40,  1.09it/s, training_loss=1.6654]\u001b[A\n",
      "Epoch 6:  27%|██▋       | 40/148 [00:36<01:39,  1.09it/s, training_loss=1.6654]\u001b[A\n",
      "Epoch 6:  27%|██▋       | 40/148 [00:37<01:39,  1.09it/s, training_loss=1.0987]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=1.0987]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 6:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=1.5502]\u001b[A\n",
      "Epoch 6:  29%|██▉       | 43/148 [00:39<01:36,  1.09it/s, training_loss=1.5502]\u001b[A\n",
      "Epoch 6:  29%|██▉       | 43/148 [00:40<01:36,  1.09it/s, training_loss=1.5073]\u001b[A\n",
      "Epoch 6:  30%|██▉       | 44/148 [00:40<01:35,  1.09it/s, training_loss=1.5073]\u001b[A\n",
      "Epoch 6:  30%|██▉       | 44/148 [00:41<01:35,  1.09it/s, training_loss=0.9349]\u001b[A\n",
      "Epoch 6:  30%|███       | 45/148 [00:41<01:35,  1.08it/s, training_loss=0.9349]\u001b[A\n",
      "Epoch 6:  30%|███       | 45/148 [00:42<01:35,  1.08it/s, training_loss=1.5004]\u001b[A\n",
      "Epoch 6:  31%|███       | 46/148 [00:42<01:34,  1.08it/s, training_loss=1.5004]\u001b[A\n",
      "Epoch 6:  31%|███       | 46/148 [00:43<01:34,  1.08it/s, training_loss=1.0193]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 47/148 [00:43<01:33,  1.09it/s, training_loss=1.0193]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 47/148 [00:44<01:33,  1.09it/s, training_loss=1.5759]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 48/148 [00:44<01:32,  1.09it/s, training_loss=1.5759]\u001b[A\n",
      "Epoch 6:  32%|███▏      | 48/148 [00:45<01:32,  1.09it/s, training_loss=0.9688]\u001b[A\n",
      "Epoch 6:  33%|███▎      | 49/148 [00:45<01:31,  1.09it/s, training_loss=0.9688]\u001b[A\n",
      "Epoch 6:  33%|███▎      | 49/148 [00:46<01:31,  1.09it/s, training_loss=1.6150]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 50/148 [00:46<01:30,  1.09it/s, training_loss=1.6150]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 50/148 [00:46<01:30,  1.09it/s, training_loss=1.6637]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 51/148 [00:46<01:29,  1.09it/s, training_loss=1.6637]\u001b[A\n",
      "Epoch 6:  34%|███▍      | 51/148 [00:47<01:29,  1.09it/s, training_loss=1.5736]\u001b[A\n",
      "Epoch 6:  35%|███▌      | 52/148 [00:47<01:27,  1.09it/s, training_loss=1.5736]\u001b[A\n",
      "Epoch 6:  35%|███▌      | 52/148 [00:48<01:27,  1.09it/s, training_loss=1.5365]\u001b[A\n",
      "Epoch 6:  36%|███▌      | 53/148 [00:48<01:26,  1.09it/s, training_loss=1.5365]\u001b[A\n",
      "Epoch 6:  36%|███▌      | 53/148 [00:49<01:26,  1.09it/s, training_loss=1.5714]\u001b[A\n",
      "Epoch 6:  36%|███▋      | 54/148 [00:49<01:25,  1.10it/s, training_loss=1.5714]\u001b[A\n",
      "Epoch 6:  36%|███▋      | 54/148 [00:50<01:25,  1.10it/s, training_loss=1.1800]\u001b[A\n",
      "Epoch 6:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.1800]\u001b[A\n",
      "Epoch 6:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.5408]\u001b[A\n",
      "Epoch 6:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=1.5408]\u001b[A\n",
      "Epoch 6:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.0586]\u001b[A\n",
      "Epoch 6:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.0586]\u001b[A\n",
      "Epoch 6:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=0.9373]\u001b[A\n",
      "Epoch 6:  39%|███▉      | 58/148 [00:53<01:22,  1.08it/s, training_loss=0.9373]\u001b[A\n",
      "Epoch 6:  39%|███▉      | 58/148 [00:54<01:22,  1.08it/s, training_loss=1.0228]\u001b[A\n",
      "Epoch 6:  40%|███▉      | 59/148 [00:54<01:22,  1.08it/s, training_loss=1.0228]\u001b[A\n",
      "Epoch 6:  40%|███▉      | 59/148 [00:55<01:22,  1.08it/s, training_loss=1.5442]\u001b[A\n",
      "Epoch 6:  41%|████      | 60/148 [00:55<01:20,  1.09it/s, training_loss=1.5442]\u001b[A\n",
      "Epoch 6:  41%|████      | 60/148 [00:56<01:20,  1.09it/s, training_loss=0.8946]\u001b[A\n",
      "Epoch 6:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=0.8946]\u001b[A\n",
      "Epoch 6:  41%|████      | 61/148 [00:57<01:19,  1.09it/s, training_loss=1.5667]\u001b[A\n",
      "Epoch 6:  42%|████▏     | 62/148 [00:57<01:18,  1.09it/s, training_loss=1.5667]\u001b[A\n",
      "Epoch 6:  42%|████▏     | 62/148 [00:57<01:18,  1.09it/s, training_loss=0.8924]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 63/148 [00:57<01:17,  1.09it/s, training_loss=0.8924]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 63/148 [00:58<01:17,  1.09it/s, training_loss=1.5069]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 64/148 [00:58<01:16,  1.09it/s, training_loss=1.5069]\u001b[A\n",
      "Epoch 6:  43%|████▎     | 64/148 [00:59<01:16,  1.09it/s, training_loss=1.6010]\u001b[A\n",
      "Epoch 6:  44%|████▍     | 65/148 [00:59<01:15,  1.09it/s, training_loss=1.6010]\u001b[A\n",
      "Epoch 6:  44%|████▍     | 65/148 [01:00<01:15,  1.09it/s, training_loss=0.8607]\u001b[A\n",
      "Epoch 6:  45%|████▍     | 66/148 [01:00<01:15,  1.09it/s, training_loss=0.8607]\u001b[A\n",
      "Epoch 6:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=1.6462]\u001b[A\n",
      "Epoch 6:  45%|████▌     | 67/148 [01:01<01:14,  1.09it/s, training_loss=1.6462]\u001b[A\n",
      "Epoch 6:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=1.4228]\u001b[A\n",
      "Epoch 6:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=1.4228]\u001b[A\n",
      "Epoch 6:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=0.8620]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=0.8620]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=0.9797]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=0.9797]\u001b[A\n",
      "Epoch 6:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=0.8367]\u001b[A\n",
      "Epoch 6:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=0.8367]\u001b[A\n",
      "Epoch 6:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.5885]\u001b[A\n",
      "Epoch 6:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=1.5885]\u001b[A\n",
      "Epoch 6:  49%|████▊     | 72/148 [01:07<01:09,  1.09it/s, training_loss=1.0348]\u001b[A\n",
      "Epoch 6:  49%|████▉     | 73/148 [01:07<01:08,  1.09it/s, training_loss=1.0348]\u001b[A\n",
      "Epoch 6:  49%|████▉     | 73/148 [01:08<01:08,  1.09it/s, training_loss=1.2474]\u001b[A\n",
      "Epoch 6:  50%|█████     | 74/148 [01:08<01:07,  1.09it/s, training_loss=1.2474]\u001b[A\n",
      "Epoch 6:  50%|█████     | 74/148 [01:08<01:07,  1.09it/s, training_loss=0.9773]\u001b[A\n",
      "Epoch 6:  51%|█████     | 75/148 [01:08<01:06,  1.09it/s, training_loss=0.9773]\u001b[A\n",
      "Epoch 6:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.5538]\u001b[A\n",
      "Epoch 6:  51%|█████▏    | 76/148 [01:09<01:05,  1.09it/s, training_loss=1.5538]\u001b[A\n",
      "Epoch 6:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=0.8868]\u001b[A\n",
      "Epoch 6:  52%|█████▏    | 77/148 [01:10<01:04,  1.09it/s, training_loss=0.8868]\u001b[A\n",
      "Epoch 6:  52%|█████▏    | 77/148 [01:11<01:04,  1.09it/s, training_loss=1.2688]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 78/148 [01:11<01:04,  1.09it/s, training_loss=1.2688]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 78/148 [01:12<01:04,  1.09it/s, training_loss=1.5261]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 79/148 [01:12<01:02,  1.10it/s, training_loss=1.5261]\u001b[A\n",
      "Epoch 6:  53%|█████▎    | 79/148 [01:13<01:02,  1.10it/s, training_loss=1.1565]\u001b[A\n",
      "Epoch 6:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.1565]\u001b[A\n",
      "Epoch 6:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.4952]\u001b[A\n",
      "Epoch 6:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=1.4952]\u001b[A\n",
      "Epoch 6:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=0.9135]\u001b[A\n",
      "Epoch 6:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=0.9135]\u001b[A\n",
      "Epoch 6:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.6151]\u001b[A\n",
      "Epoch 6:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=1.6151]\u001b[A\n",
      "Epoch 6:  56%|█████▌    | 83/148 [01:17<00:59,  1.09it/s, training_loss=1.3246]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=1.3246]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 84/148 [01:18<00:58,  1.09it/s, training_loss=1.5527]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.5527]\u001b[A\n",
      "Epoch 6:  57%|█████▋    | 85/148 [01:19<00:57,  1.09it/s, training_loss=1.0300]\u001b[A\n",
      "Epoch 6:  58%|█████▊    | 86/148 [01:19<00:57,  1.08it/s, training_loss=1.0300]\u001b[A\n",
      "Epoch 6:  58%|█████▊    | 86/148 [01:19<00:57,  1.08it/s, training_loss=1.3374]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 87/148 [01:19<00:56,  1.08it/s, training_loss=1.3374]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 87/148 [01:20<00:56,  1.08it/s, training_loss=0.9156]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 88/148 [01:20<00:55,  1.09it/s, training_loss=0.9156]\u001b[A\n",
      "Epoch 6:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.6013]\u001b[A\n",
      "Epoch 6:  60%|██████    | 89/148 [01:21<00:54,  1.09it/s, training_loss=1.6013]\u001b[A\n",
      "Epoch 6:  60%|██████    | 89/148 [01:22<00:54,  1.09it/s, training_loss=0.9165]\u001b[A\n",
      "Epoch 6:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=0.9165]\u001b[A\n",
      "Epoch 6:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=0.9258]\u001b[A\n",
      "Epoch 6:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=0.9258]\u001b[A\n",
      "Epoch 6:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.0339]\u001b[A\n",
      "Epoch 6:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.0339]\u001b[A\n",
      "Epoch 6:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=0.9550]\u001b[A\n",
      "Epoch 6:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=0.9550]\u001b[A\n",
      "Epoch 6:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=0.9655]\u001b[A\n",
      "Epoch 6:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=0.9655]\u001b[A\n",
      "Epoch 6:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.1270]\u001b[A\n",
      "Epoch 6:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.1270]\u001b[A\n",
      "Epoch 6:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=0.8966]\u001b[A\n",
      "Epoch 6:  65%|██████▍   | 96/148 [01:28<00:47,  1.08it/s, training_loss=0.8966]\u001b[A\n",
      "Epoch 6:  65%|██████▍   | 96/148 [01:29<00:47,  1.08it/s, training_loss=1.4264]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.4264]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 97/148 [01:30<00:46,  1.09it/s, training_loss=0.8812]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=0.8812]\u001b[A\n",
      "Epoch 6:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=1.5548]\u001b[A\n",
      "Epoch 6:  67%|██████▋   | 99/148 [01:30<00:44,  1.09it/s, training_loss=1.5548]\u001b[A\n",
      "Epoch 6:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=0.9808]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 100/148 [01:31<00:44,  1.09it/s, training_loss=0.9808]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 100/148 [01:32<00:44,  1.09it/s, training_loss=1.5375]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 101/148 [01:32<00:43,  1.09it/s, training_loss=1.5375]\u001b[A\n",
      "Epoch 6:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.6201]\u001b[A\n",
      "Epoch 6:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.6201]\u001b[A\n",
      "Epoch 6:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=0.9469]\u001b[A\n",
      "Epoch 6:  70%|██████▉   | 103/148 [01:34<00:41,  1.09it/s, training_loss=0.9469]\u001b[A\n",
      "Epoch 6:  70%|██████▉   | 103/148 [01:35<00:41,  1.09it/s, training_loss=0.9819]\u001b[A\n",
      "Epoch 6:  70%|███████   | 104/148 [01:35<00:40,  1.09it/s, training_loss=0.9819]\u001b[A\n",
      "Epoch 6:  70%|███████   | 104/148 [01:36<00:40,  1.09it/s, training_loss=1.6037]\u001b[A\n",
      "Epoch 6:  71%|███████   | 105/148 [01:36<00:39,  1.10it/s, training_loss=1.6037]\u001b[A\n",
      "Epoch 6:  71%|███████   | 105/148 [01:37<00:39,  1.10it/s, training_loss=1.6168]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 106/148 [01:37<00:38,  1.10it/s, training_loss=1.6168]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 106/148 [01:38<00:38,  1.10it/s, training_loss=0.9275]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=0.9275]\u001b[A\n",
      "Epoch 6:  72%|███████▏  | 107/148 [01:39<00:37,  1.09it/s, training_loss=0.9396]\u001b[A\n",
      "Epoch 6:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=0.9396]\u001b[A\n",
      "Epoch 6:  73%|███████▎  | 108/148 [01:40<00:36,  1.09it/s, training_loss=1.5633]\u001b[A\n",
      "Epoch 6:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.5633]\u001b[A\n",
      "Epoch 6:  74%|███████▎  | 109/148 [01:41<00:35,  1.09it/s, training_loss=1.3483]\u001b[A\n",
      "Epoch 6:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.3483]\u001b[A\n",
      "Epoch 6:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.2347]\u001b[A\n",
      "Epoch 6:  75%|███████▌  | 111/148 [01:41<00:34,  1.08it/s, training_loss=1.2347]\u001b[A\n",
      "Epoch 6:  75%|███████▌  | 111/148 [01:42<00:34,  1.08it/s, training_loss=1.5537]\u001b[A\n",
      "Epoch 6:  76%|███████▌  | 112/148 [01:42<00:33,  1.09it/s, training_loss=1.5537]\u001b[A\n",
      "Epoch 6:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.6182]\u001b[A\n",
      "Epoch 6:  76%|███████▋  | 113/148 [01:43<00:32,  1.09it/s, training_loss=1.6182]\u001b[A\n",
      "Epoch 6:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.2272]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.2272]\u001b[A\n",
      "Epoch 6:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.1183]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.1183]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=0.8732]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=0.8732]\u001b[A\n",
      "Epoch 6:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=0.9297]\u001b[A\n",
      "Epoch 6:  79%|███████▉  | 117/148 [01:47<00:28,  1.08it/s, training_loss=0.9297]\u001b[A\n",
      "Epoch 6:  79%|███████▉  | 117/148 [01:48<00:28,  1.08it/s, training_loss=1.1424]\u001b[A\n",
      "Epoch 6:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=1.1424]\u001b[A\n",
      "Epoch 6:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.5896]\u001b[A\n",
      "Epoch 6:  80%|████████  | 119/148 [01:49<00:26,  1.08it/s, training_loss=1.5896]\u001b[A\n",
      "Epoch 6:  80%|████████  | 119/148 [01:50<00:26,  1.08it/s, training_loss=1.4596]\u001b[A\n",
      "Epoch 6:  81%|████████  | 120/148 [01:50<00:25,  1.08it/s, training_loss=1.4596]\u001b[A\n",
      "Epoch 6:  81%|████████  | 120/148 [01:51<00:25,  1.08it/s, training_loss=1.0439]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.0439]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 121/148 [01:52<00:24,  1.09it/s, training_loss=1.4978]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.4978]\u001b[A\n",
      "Epoch 6:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.5530]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 123/148 [01:52<00:22,  1.09it/s, training_loss=1.5530]\u001b[A\n",
      "Epoch 6:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=1.0249]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 124/148 [01:53<00:22,  1.09it/s, training_loss=1.0249]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 124/148 [01:54<00:22,  1.09it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 125/148 [01:54<00:21,  1.09it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 6:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=1.1360]\u001b[A\n",
      "Epoch 6:  85%|████████▌ | 126/148 [01:55<00:20,  1.09it/s, training_loss=1.1360]\u001b[A\n",
      "Epoch 6:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=0.8915]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=0.8915]\u001b[A\n",
      "Epoch 6:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.5801]\u001b[A\n",
      "Epoch 6:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.5801]\u001b[A\n",
      "Epoch 6:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.0266]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.0266]\u001b[A\n",
      "Epoch 6:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=1.1383]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.1383]\u001b[A\n",
      "Epoch 6:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=1.1571]\u001b[A\n",
      "Epoch 6:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.1571]\u001b[A\n",
      "Epoch 6:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=0.8373]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=0.8373]\u001b[A\n",
      "Epoch 6:  89%|████████▉ | 132/148 [02:02<00:14,  1.09it/s, training_loss=0.9590]\u001b[A\n",
      "Epoch 6:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=0.9590]\u001b[A\n",
      "Epoch 6:  90%|████████▉ | 133/148 [02:03<00:13,  1.09it/s, training_loss=1.5680]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.5680]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.5338]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 135/148 [02:03<00:11,  1.09it/s, training_loss=1.5338]\u001b[A\n",
      "Epoch 6:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=1.4829]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 136/148 [02:04<00:10,  1.09it/s, training_loss=1.4829]\u001b[A\n",
      "Epoch 6:  92%|█████████▏| 136/148 [02:05<00:10,  1.09it/s, training_loss=1.0821]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=1.0821]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.5934]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.5934]\u001b[A\n",
      "Epoch 6:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.5796]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.5796]\u001b[A\n",
      "Epoch 6:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=0.8321]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=0.8321]\u001b[A\n",
      "Epoch 6:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=1.1170]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=1.1170]\u001b[A\n",
      "Epoch 6:  95%|█████████▌| 141/148 [02:10<00:06,  1.09it/s, training_loss=0.9340]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=0.9340]\u001b[A\n",
      "Epoch 6:  96%|█████████▌| 142/148 [02:11<00:05,  1.09it/s, training_loss=0.9998]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=0.9998]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=1.6109]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=1.6109]\u001b[A\n",
      "Epoch 6:  97%|█████████▋| 144/148 [02:13<00:03,  1.09it/s, training_loss=1.5734]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=1.5734]\u001b[A\n",
      "Epoch 6:  98%|█████████▊| 145/148 [02:14<00:02,  1.09it/s, training_loss=1.5889]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 146/148 [02:14<00:01,  1.09it/s, training_loss=1.5889]\u001b[A\n",
      "Epoch 6:  99%|█████████▊| 146/148 [02:15<00:01,  1.09it/s, training_loss=1.1391]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.1391]\u001b[A\n",
      "Epoch 6:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=0.9290]\u001b[A\n",
      "Epoch 6: 100%|██████████| 148/148 [02:15<00:00,  1.18it/s, training_loss=0.9290]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:40:18,662 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:40:18,664 - INFO - Memory usage after evaluation start: 3926.55 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.69it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.62it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.60it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.61it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.60it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.60it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.60it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.61it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:40:25,910 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 19:40:25,925 - INFO - Class 'Drama': Optimal threshold = 0.500, F1 Score = 0.539\n",
      "2025-02-16 19:40:25,939 - INFO - Class 'Horor': Optimal threshold = 0.750, F1 Score = 0.759\n",
      "2025-02-16 19:40:25,953 - INFO - Class 'Komedi': Optimal threshold = 0.600, F1 Score = 0.557\n",
      "2025-02-16 19:40:25,967 - INFO - Class 'Laga': Optimal threshold = 0.550, F1 Score = 0.376\n",
      "2025-02-16 19:40:25,981 - INFO - Class 'Romantis': Optimal threshold = 0.700, F1 Score = 0.548\n",
      "2025-02-16 19:40:26,004 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:40:26,009 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:40:26,010 - INFO - Accuracy: 0.6398\n",
      "2025-02-16 19:40:26,010 - INFO - F1_score: 0.5392\n",
      "2025-02-16 19:40:26,011 - INFO - Precision: 0.4231\n",
      "2025-02-16 19:40:26,012 - INFO - Recall: 0.7432\n",
      "2025-02-16 19:40:26,018 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:40:26,018 - INFO - Accuracy: 0.8927\n",
      "2025-02-16 19:40:26,019 - INFO - F1_score: 0.7586\n",
      "2025-02-16 19:40:26,020 - INFO - Precision: 0.7458\n",
      "2025-02-16 19:40:26,021 - INFO - Recall: 0.7719\n",
      "2025-02-16 19:40:26,027 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:40:26,027 - INFO - Accuracy: 0.7625\n",
      "2025-02-16 19:40:26,028 - INFO - F1_score: 0.5571\n",
      "2025-02-16 19:40:26,029 - INFO - Precision: 0.4756\n",
      "2025-02-16 19:40:26,030 - INFO - Recall: 0.6724\n",
      "2025-02-16 19:40:26,036 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:40:26,036 - INFO - Accuracy: 0.6820\n",
      "2025-02-16 19:40:26,037 - INFO - F1_score: 0.3759\n",
      "2025-02-16 19:40:26,038 - INFO - Precision: 0.2632\n",
      "2025-02-16 19:40:26,039 - INFO - Recall: 0.6579\n",
      "2025-02-16 19:40:26,044 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:40:26,045 - INFO - Accuracy: 0.8736\n",
      "2025-02-16 19:40:26,046 - INFO - F1_score: 0.5479\n",
      "2025-02-16 19:40:26,046 - INFO - Precision: 0.5128\n",
      "2025-02-16 19:40:26,047 - INFO - Recall: 0.5882\n",
      "2025-02-16 19:40:26,050 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:40:29,972 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:40:29,973 - INFO - Memory usage after evaluation end: 3931.80 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   5%|▌         | 5/100 [15:31<4:06:18, 155.56s/it, Train Loss=1.2832, Val Loss=0.0506, Accuracy=0.7701]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:40:37,212 - INFO - Learning rate: 5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 6/100 [15:31<4:03:01, 155.12s/it, Train Loss=1.2832, Val Loss=0.0506, Accuracy=0.7701]\n",
      "Epoch 7:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=0.8773]\u001b[A\n",
      "Epoch 7:   1%|          | 1/148 [00:00<02:14,  1.09it/s, training_loss=0.8773]\u001b[A\n",
      "Epoch 7:   1%|          | 1/148 [00:01<02:14,  1.09it/s, training_loss=1.5267]\u001b[A\n",
      "Epoch 7:   1%|▏         | 2/148 [00:01<02:13,  1.09it/s, training_loss=1.5267]\u001b[A\n",
      "Epoch 7:   1%|▏         | 2/148 [00:02<02:13,  1.09it/s, training_loss=1.0047]\u001b[A\n",
      "Epoch 7:   2%|▏         | 3/148 [00:02<02:12,  1.09it/s, training_loss=1.0047]\u001b[A\n",
      "Epoch 7:   2%|▏         | 3/148 [00:03<02:12,  1.09it/s, training_loss=1.0603]\u001b[A\n",
      "Epoch 7:   3%|▎         | 4/148 [00:03<02:11,  1.09it/s, training_loss=1.0603]\u001b[A\n",
      "Epoch 7:   3%|▎         | 4/148 [00:04<02:11,  1.09it/s, training_loss=0.9727]\u001b[A\n",
      "Epoch 7:   3%|▎         | 5/148 [00:04<02:10,  1.09it/s, training_loss=0.9727]\u001b[A\n",
      "Epoch 7:   3%|▎         | 5/148 [00:05<02:10,  1.09it/s, training_loss=1.3344]\u001b[A\n",
      "Epoch 7:   4%|▍         | 6/148 [00:05<02:10,  1.09it/s, training_loss=1.3344]\u001b[A\n",
      "Epoch 7:   4%|▍         | 6/148 [00:06<02:10,  1.09it/s, training_loss=0.8589]\u001b[A\n",
      "Epoch 7:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=0.8589]\u001b[A\n",
      "Epoch 7:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=1.6061]\u001b[A\n",
      "Epoch 7:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=1.6061]\u001b[A\n",
      "Epoch 7:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=1.4834]\u001b[A\n",
      "Epoch 7:   6%|▌         | 9/148 [00:08<02:07,  1.09it/s, training_loss=1.4834]\u001b[A\n",
      "Epoch 7:   6%|▌         | 9/148 [00:09<02:07,  1.09it/s, training_loss=0.9584]\u001b[A\n",
      "Epoch 7:   7%|▋         | 10/148 [00:09<02:06,  1.09it/s, training_loss=0.9584]\u001b[A\n",
      "Epoch 7:   7%|▋         | 10/148 [00:10<02:06,  1.09it/s, training_loss=1.0408]\u001b[A\n",
      "Epoch 7:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.0408]\u001b[A\n",
      "Epoch 7:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.5943]\u001b[A\n",
      "Epoch 7:   8%|▊         | 12/148 [00:10<02:04,  1.09it/s, training_loss=1.5943]\u001b[A\n",
      "Epoch 7:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.1189]\u001b[A\n",
      "Epoch 7:   9%|▉         | 13/148 [00:11<02:04,  1.09it/s, training_loss=1.1189]\u001b[A\n",
      "Epoch 7:   9%|▉         | 13/148 [00:12<02:04,  1.09it/s, training_loss=0.9566]\u001b[A\n",
      "Epoch 7:   9%|▉         | 14/148 [00:12<02:03,  1.09it/s, training_loss=0.9566]\u001b[A\n",
      "Epoch 7:   9%|▉         | 14/148 [00:13<02:03,  1.09it/s, training_loss=1.1192]\u001b[A\n",
      "Epoch 7:  10%|█         | 15/148 [00:13<02:02,  1.08it/s, training_loss=1.1192]\u001b[A\n",
      "Epoch 7:  10%|█         | 15/148 [00:14<02:02,  1.08it/s, training_loss=1.1482]\u001b[A\n",
      "Epoch 7:  11%|█         | 16/148 [00:14<02:01,  1.09it/s, training_loss=1.1482]\u001b[A\n",
      "Epoch 7:  11%|█         | 16/148 [00:15<02:01,  1.09it/s, training_loss=1.5717]\u001b[A\n",
      "Epoch 7:  11%|█▏        | 17/148 [00:15<02:00,  1.09it/s, training_loss=1.5717]\u001b[A\n",
      "Epoch 7:  11%|█▏        | 17/148 [00:16<02:00,  1.09it/s, training_loss=1.1889]\u001b[A\n",
      "Epoch 7:  12%|█▏        | 18/148 [00:16<02:00,  1.08it/s, training_loss=1.1889]\u001b[A\n",
      "Epoch 7:  12%|█▏        | 18/148 [00:17<02:00,  1.08it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 7:  13%|█▎        | 19/148 [00:17<01:59,  1.08it/s, training_loss=1.5553]\u001b[A\n",
      "Epoch 7:  13%|█▎        | 19/148 [00:18<01:59,  1.08it/s, training_loss=1.5098]\u001b[A\n",
      "Epoch 7:  14%|█▎        | 20/148 [00:18<01:57,  1.09it/s, training_loss=1.5098]\u001b[A\n",
      "Epoch 7:  14%|█▎        | 20/148 [00:19<01:57,  1.09it/s, training_loss=1.0860]\u001b[A\n",
      "Epoch 7:  14%|█▍        | 21/148 [00:19<01:57,  1.08it/s, training_loss=1.0860]\u001b[A\n",
      "Epoch 7:  14%|█▍        | 21/148 [00:20<01:57,  1.08it/s, training_loss=0.9247]\u001b[A\n",
      "Epoch 7:  15%|█▍        | 22/148 [00:20<01:56,  1.08it/s, training_loss=0.9247]\u001b[A\n",
      "Epoch 7:  15%|█▍        | 22/148 [00:21<01:56,  1.08it/s, training_loss=1.5797]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 23/148 [00:21<01:55,  1.08it/s, training_loss=1.5797]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 23/148 [00:22<01:55,  1.08it/s, training_loss=0.9980]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=0.9980]\u001b[A\n",
      "Epoch 7:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=1.0278]\u001b[A\n",
      "Epoch 7:  17%|█▋        | 25/148 [00:22<01:53,  1.08it/s, training_loss=1.0278]\u001b[A\n",
      "Epoch 7:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=0.9161]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 26/148 [00:23<01:52,  1.09it/s, training_loss=0.9161]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 26/148 [00:24<01:52,  1.09it/s, training_loss=1.3678]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 27/148 [00:24<01:51,  1.09it/s, training_loss=1.3678]\u001b[A\n",
      "Epoch 7:  18%|█▊        | 27/148 [00:25<01:51,  1.09it/s, training_loss=0.9466]\u001b[A\n",
      "Epoch 7:  19%|█▉        | 28/148 [00:25<01:50,  1.09it/s, training_loss=0.9466]\u001b[A\n",
      "Epoch 7:  19%|█▉        | 28/148 [00:26<01:50,  1.09it/s, training_loss=1.6683]\u001b[A\n",
      "Epoch 7:  20%|█▉        | 29/148 [00:26<01:49,  1.09it/s, training_loss=1.6683]\u001b[A\n",
      "Epoch 7:  20%|█▉        | 29/148 [00:27<01:49,  1.09it/s, training_loss=1.5849]\u001b[A\n",
      "Epoch 7:  20%|██        | 30/148 [00:27<01:47,  1.09it/s, training_loss=1.5849]\u001b[A\n",
      "Epoch 7:  20%|██        | 30/148 [00:28<01:47,  1.09it/s, training_loss=0.9321]\u001b[A\n",
      "Epoch 7:  21%|██        | 31/148 [00:28<01:46,  1.09it/s, training_loss=0.9321]\u001b[A\n",
      "Epoch 7:  21%|██        | 31/148 [00:29<01:46,  1.09it/s, training_loss=1.5952]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 32/148 [00:29<01:45,  1.10it/s, training_loss=1.5952]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 32/148 [00:30<01:45,  1.10it/s, training_loss=1.5276]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 33/148 [00:30<01:44,  1.10it/s, training_loss=1.5276]\u001b[A\n",
      "Epoch 7:  22%|██▏       | 33/148 [00:31<01:44,  1.10it/s, training_loss=1.1531]\u001b[A\n",
      "Epoch 7:  23%|██▎       | 34/148 [00:31<01:44,  1.09it/s, training_loss=1.1531]\u001b[A\n",
      "Epoch 7:  23%|██▎       | 34/148 [00:32<01:44,  1.09it/s, training_loss=1.5882]\u001b[A\n",
      "Epoch 7:  24%|██▎       | 35/148 [00:32<01:43,  1.10it/s, training_loss=1.5882]\u001b[A\n",
      "Epoch 7:  24%|██▎       | 35/148 [00:33<01:43,  1.10it/s, training_loss=1.0191]\u001b[A\n",
      "Epoch 7:  24%|██▍       | 36/148 [00:33<01:42,  1.09it/s, training_loss=1.0191]\u001b[A\n",
      "Epoch 7:  24%|██▍       | 36/148 [00:33<01:42,  1.09it/s, training_loss=0.8541]\u001b[A\n",
      "Epoch 7:  25%|██▌       | 37/148 [00:33<01:42,  1.08it/s, training_loss=0.8541]\u001b[A\n",
      "Epoch 7:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=0.8592]\u001b[A\n",
      "Epoch 7:  26%|██▌       | 38/148 [00:34<01:41,  1.09it/s, training_loss=0.8592]\u001b[A\n",
      "Epoch 7:  26%|██▌       | 38/148 [00:35<01:41,  1.09it/s, training_loss=1.5973]\u001b[A\n",
      "Epoch 7:  26%|██▋       | 39/148 [00:35<01:40,  1.09it/s, training_loss=1.5973]\u001b[A\n",
      "Epoch 7:  26%|██▋       | 39/148 [00:36<01:40,  1.09it/s, training_loss=0.9887]\u001b[A\n",
      "Epoch 7:  27%|██▋       | 40/148 [00:36<01:39,  1.09it/s, training_loss=0.9887]\u001b[A\n",
      "Epoch 7:  27%|██▋       | 40/148 [00:37<01:39,  1.09it/s, training_loss=1.5327]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=1.5327]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=0.9690]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=0.9690]\u001b[A\n",
      "Epoch 7:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=1.3970]\u001b[A\n",
      "Epoch 7:  29%|██▉       | 43/148 [00:39<01:35,  1.09it/s, training_loss=1.3970]\u001b[A\n",
      "Epoch 7:  29%|██▉       | 43/148 [00:40<01:35,  1.09it/s, training_loss=1.1550]\u001b[A\n",
      "Epoch 7:  30%|██▉       | 44/148 [00:40<01:34,  1.10it/s, training_loss=1.1550]\u001b[A\n",
      "Epoch 7:  30%|██▉       | 44/148 [00:41<01:34,  1.10it/s, training_loss=1.5335]\u001b[A\n",
      "Epoch 7:  30%|███       | 45/148 [00:41<01:33,  1.10it/s, training_loss=1.5335]\u001b[A\n",
      "Epoch 7:  30%|███       | 45/148 [00:42<01:33,  1.10it/s, training_loss=1.1798]\u001b[A\n",
      "Epoch 7:  31%|███       | 46/148 [00:42<01:33,  1.10it/s, training_loss=1.1798]\u001b[A\n",
      "Epoch 7:  31%|███       | 46/148 [00:43<01:33,  1.10it/s, training_loss=1.3664]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.3664]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.6461]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 48/148 [00:44<01:31,  1.09it/s, training_loss=1.6461]\u001b[A\n",
      "Epoch 7:  32%|███▏      | 48/148 [00:44<01:31,  1.09it/s, training_loss=0.9527]\u001b[A\n",
      "Epoch 7:  33%|███▎      | 49/148 [00:44<01:30,  1.09it/s, training_loss=0.9527]\u001b[A\n",
      "Epoch 7:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=1.0886]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 50/148 [00:45<01:29,  1.09it/s, training_loss=1.0886]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=1.0647]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 51/148 [00:46<01:29,  1.09it/s, training_loss=1.0647]\u001b[A\n",
      "Epoch 7:  34%|███▍      | 51/148 [00:47<01:29,  1.09it/s, training_loss=1.5606]\u001b[A\n",
      "Epoch 7:  35%|███▌      | 52/148 [00:47<01:28,  1.09it/s, training_loss=1.5606]\u001b[A\n",
      "Epoch 7:  35%|███▌      | 52/148 [00:48<01:28,  1.09it/s, training_loss=0.9430]\u001b[A\n",
      "Epoch 7:  36%|███▌      | 53/148 [00:48<01:27,  1.08it/s, training_loss=0.9430]\u001b[A\n",
      "Epoch 7:  36%|███▌      | 53/148 [00:49<01:27,  1.08it/s, training_loss=1.5826]\u001b[A\n",
      "Epoch 7:  36%|███▋      | 54/148 [00:49<01:26,  1.08it/s, training_loss=1.5826]\u001b[A\n",
      "Epoch 7:  36%|███▋      | 54/148 [00:50<01:26,  1.08it/s, training_loss=1.5034]\u001b[A\n",
      "Epoch 7:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.5034]\u001b[A\n",
      "Epoch 7:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.6240]\u001b[A\n",
      "Epoch 7:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=1.6240]\u001b[A\n",
      "Epoch 7:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.6042]\u001b[A\n",
      "Epoch 7:  39%|███▊      | 57/148 [00:52<01:23,  1.10it/s, training_loss=1.6042]\u001b[A\n",
      "Epoch 7:  39%|███▊      | 57/148 [00:53<01:23,  1.10it/s, training_loss=1.0539]\u001b[A\n",
      "Epoch 7:  39%|███▉      | 58/148 [00:53<01:22,  1.10it/s, training_loss=1.0539]\u001b[A\n",
      "Epoch 7:  39%|███▉      | 58/148 [00:54<01:22,  1.10it/s, training_loss=0.9437]\u001b[A\n",
      "Epoch 7:  40%|███▉      | 59/148 [00:54<01:21,  1.10it/s, training_loss=0.9437]\u001b[A\n",
      "Epoch 7:  40%|███▉      | 59/148 [00:55<01:21,  1.10it/s, training_loss=1.6684]\u001b[A\n",
      "Epoch 7:  41%|████      | 60/148 [00:55<01:20,  1.10it/s, training_loss=1.6684]\u001b[A\n",
      "Epoch 7:  41%|████      | 60/148 [00:55<01:20,  1.10it/s, training_loss=0.8606]\u001b[A\n",
      "Epoch 7:  41%|████      | 61/148 [00:55<01:19,  1.10it/s, training_loss=0.8606]\u001b[A\n",
      "Epoch 7:  41%|████      | 61/148 [00:56<01:19,  1.10it/s, training_loss=1.7176]\u001b[A\n",
      "Epoch 7:  42%|████▏     | 62/148 [00:56<01:18,  1.10it/s, training_loss=1.7176]\u001b[A\n",
      "Epoch 7:  42%|████▏     | 62/148 [00:57<01:18,  1.10it/s, training_loss=0.9770]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 63/148 [00:57<01:17,  1.09it/s, training_loss=0.9770]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 63/148 [00:58<01:17,  1.09it/s, training_loss=0.9196]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 64/148 [00:58<01:16,  1.09it/s, training_loss=0.9196]\u001b[A\n",
      "Epoch 7:  43%|████▎     | 64/148 [00:59<01:16,  1.09it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 7:  44%|████▍     | 65/148 [00:59<01:15,  1.09it/s, training_loss=1.5916]\u001b[A\n",
      "Epoch 7:  44%|████▍     | 65/148 [01:00<01:15,  1.09it/s, training_loss=0.8594]\u001b[A\n",
      "Epoch 7:  45%|████▍     | 66/148 [01:00<01:14,  1.10it/s, training_loss=0.8594]\u001b[A\n",
      "Epoch 7:  45%|████▍     | 66/148 [01:01<01:14,  1.10it/s, training_loss=0.9938]\u001b[A\n",
      "Epoch 7:  45%|████▌     | 67/148 [01:01<01:14,  1.09it/s, training_loss=0.9938]\u001b[A\n",
      "Epoch 7:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=0.9982]\u001b[A\n",
      "Epoch 7:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=0.9982]\u001b[A\n",
      "Epoch 7:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=0.9497]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=0.9497]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=0.8999]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=0.8999]\u001b[A\n",
      "Epoch 7:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=1.2472]\u001b[A\n",
      "Epoch 7:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=1.2472]\u001b[A\n",
      "Epoch 7:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 7:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 7:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=1.6127]\u001b[A\n",
      "Epoch 7:  49%|████▉     | 73/148 [01:06<01:08,  1.09it/s, training_loss=1.6127]\u001b[A\n",
      "Epoch 7:  49%|████▉     | 73/148 [01:07<01:08,  1.09it/s, training_loss=1.0021]\u001b[A\n",
      "Epoch 7:  50%|█████     | 74/148 [01:07<01:07,  1.09it/s, training_loss=1.0021]\u001b[A\n",
      "Epoch 7:  50%|█████     | 74/148 [01:08<01:07,  1.09it/s, training_loss=1.4949]\u001b[A\n",
      "Epoch 7:  51%|█████     | 75/148 [01:08<01:06,  1.10it/s, training_loss=1.4949]\u001b[A\n",
      "Epoch 7:  51%|█████     | 75/148 [01:09<01:06,  1.10it/s, training_loss=1.5017]\u001b[A\n",
      "Epoch 7:  51%|█████▏    | 76/148 [01:09<01:05,  1.10it/s, training_loss=1.5017]\u001b[A\n",
      "Epoch 7:  51%|█████▏    | 76/148 [01:10<01:05,  1.10it/s, training_loss=1.5732]\u001b[A\n",
      "Epoch 7:  52%|█████▏    | 77/148 [01:10<01:04,  1.10it/s, training_loss=1.5732]\u001b[A\n",
      "Epoch 7:  52%|█████▏    | 77/148 [01:11<01:04,  1.10it/s, training_loss=1.5831]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 78/148 [01:11<01:03,  1.10it/s, training_loss=1.5831]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 78/148 [01:12<01:03,  1.10it/s, training_loss=1.5855]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 79/148 [01:12<01:02,  1.10it/s, training_loss=1.5855]\u001b[A\n",
      "Epoch 7:  53%|█████▎    | 79/148 [01:13<01:02,  1.10it/s, training_loss=1.3250]\u001b[A\n",
      "Epoch 7:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.3250]\u001b[A\n",
      "Epoch 7:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=1.4751]\u001b[A\n",
      "Epoch 7:  55%|█████▍    | 81/148 [01:14<01:01,  1.10it/s, training_loss=1.4751]\u001b[A\n",
      "Epoch 7:  55%|█████▍    | 81/148 [01:15<01:01,  1.10it/s, training_loss=1.4830]\u001b[A\n",
      "Epoch 7:  55%|█████▌    | 82/148 [01:15<01:00,  1.10it/s, training_loss=1.4830]\u001b[A\n",
      "Epoch 7:  55%|█████▌    | 82/148 [01:16<01:00,  1.10it/s, training_loss=0.9344]\u001b[A\n",
      "Epoch 7:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=0.9344]\u001b[A\n",
      "Epoch 7:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=1.5416]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 84/148 [01:16<00:58,  1.10it/s, training_loss=1.5416]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 84/148 [01:17<00:58,  1.10it/s, training_loss=1.6608]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 85/148 [01:17<00:57,  1.10it/s, training_loss=1.6608]\u001b[A\n",
      "Epoch 7:  57%|█████▋    | 85/148 [01:18<00:57,  1.10it/s, training_loss=1.6476]\u001b[A\n",
      "Epoch 7:  58%|█████▊    | 86/148 [01:18<00:56,  1.10it/s, training_loss=1.6476]\u001b[A\n",
      "Epoch 7:  58%|█████▊    | 86/148 [01:19<00:56,  1.10it/s, training_loss=0.9750]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 87/148 [01:19<00:55,  1.09it/s, training_loss=0.9750]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 87/148 [01:20<00:55,  1.09it/s, training_loss=1.6199]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 88/148 [01:20<00:54,  1.10it/s, training_loss=1.6199]\u001b[A\n",
      "Epoch 7:  59%|█████▉    | 88/148 [01:21<00:54,  1.10it/s, training_loss=1.5833]\u001b[A\n",
      "Epoch 7:  60%|██████    | 89/148 [01:21<00:53,  1.10it/s, training_loss=1.5833]\u001b[A\n",
      "Epoch 7:  60%|██████    | 89/148 [01:22<00:53,  1.10it/s, training_loss=0.9963]\u001b[A\n",
      "Epoch 7:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=0.9963]\u001b[A\n",
      "Epoch 7:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=0.9751]\u001b[A\n",
      "Epoch 7:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=0.9751]\u001b[A\n",
      "Epoch 7:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.0772]\u001b[A\n",
      "Epoch 7:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.0772]\u001b[A\n",
      "Epoch 7:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=1.1932]\u001b[A\n",
      "Epoch 7:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=1.1932]\u001b[A\n",
      "Epoch 7:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.5837]\u001b[A\n",
      "Epoch 7:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=1.5837]\u001b[A\n",
      "Epoch 7:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.2050]\u001b[A\n",
      "Epoch 7:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.2050]\u001b[A\n",
      "Epoch 7:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=0.8723]\u001b[A\n",
      "Epoch 7:  65%|██████▍   | 96/148 [01:27<00:47,  1.09it/s, training_loss=0.8723]\u001b[A\n",
      "Epoch 7:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.5410]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 97/148 [01:28<00:46,  1.09it/s, training_loss=1.5410]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.2188]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 98/148 [01:29<00:45,  1.09it/s, training_loss=1.2188]\u001b[A\n",
      "Epoch 7:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=1.5901]\u001b[A\n",
      "Epoch 7:  67%|██████▋   | 99/148 [01:30<00:44,  1.09it/s, training_loss=1.5901]\u001b[A\n",
      "Epoch 7:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=0.8713]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 100/148 [01:31<00:43,  1.10it/s, training_loss=0.8713]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 100/148 [01:32<00:43,  1.10it/s, training_loss=1.5509]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 101/148 [01:32<00:42,  1.10it/s, training_loss=1.5509]\u001b[A\n",
      "Epoch 7:  68%|██████▊   | 101/148 [01:33<00:42,  1.10it/s, training_loss=1.5716]\u001b[A\n",
      "Epoch 7:  69%|██████▉   | 102/148 [01:33<00:41,  1.10it/s, training_loss=1.5716]\u001b[A\n",
      "Epoch 7:  69%|██████▉   | 102/148 [01:34<00:41,  1.10it/s, training_loss=1.0216]\u001b[A\n",
      "Epoch 7:  70%|██████▉   | 103/148 [01:34<00:40,  1.10it/s, training_loss=1.0216]\u001b[A\n",
      "Epoch 7:  70%|██████▉   | 103/148 [01:35<00:40,  1.10it/s, training_loss=1.4861]\u001b[A\n",
      "Epoch 7:  70%|███████   | 104/148 [01:35<00:39,  1.10it/s, training_loss=1.4861]\u001b[A\n",
      "Epoch 7:  70%|███████   | 104/148 [01:36<00:39,  1.10it/s, training_loss=1.1561]\u001b[A\n",
      "Epoch 7:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=1.1561]\u001b[A\n",
      "Epoch 7:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.6041]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.6041]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=0.9624]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=0.9624]\u001b[A\n",
      "Epoch 7:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=1.5663]\u001b[A\n",
      "Epoch 7:  73%|███████▎  | 108/148 [01:38<00:36,  1.09it/s, training_loss=1.5663]\u001b[A\n",
      "Epoch 7:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=1.0266]\u001b[A\n",
      "Epoch 7:  74%|███████▎  | 109/148 [01:39<00:35,  1.09it/s, training_loss=1.0266]\u001b[A\n",
      "Epoch 7:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.6108]\u001b[A\n",
      "Epoch 7:  74%|███████▍  | 110/148 [01:40<00:34,  1.09it/s, training_loss=1.6108]\u001b[A\n",
      "Epoch 7:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.0566]\u001b[A\n",
      "Epoch 7:  75%|███████▌  | 111/148 [01:41<00:33,  1.09it/s, training_loss=1.0566]\u001b[A\n",
      "Epoch 7:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=1.1169]\u001b[A\n",
      "Epoch 7:  76%|███████▌  | 112/148 [01:42<00:32,  1.09it/s, training_loss=1.1169]\u001b[A\n",
      "Epoch 7:  76%|███████▌  | 112/148 [01:43<00:32,  1.09it/s, training_loss=1.5771]\u001b[A\n",
      "Epoch 7:  76%|███████▋  | 113/148 [01:43<00:31,  1.10it/s, training_loss=1.5771]\u001b[A\n",
      "Epoch 7:  76%|███████▋  | 113/148 [01:44<00:31,  1.10it/s, training_loss=1.4605]\u001b[A\n",
      "Epoch 7:  77%|███████▋  | 114/148 [01:44<00:31,  1.10it/s, training_loss=1.4605]\u001b[A\n",
      "Epoch 7:  77%|███████▋  | 114/148 [01:45<00:31,  1.10it/s, training_loss=1.0345]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.0345]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=1.0397]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.0397]\u001b[A\n",
      "Epoch 7:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=1.5529]\u001b[A\n",
      "Epoch 7:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.5529]\u001b[A\n",
      "Epoch 7:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=0.9779]\u001b[A\n",
      "Epoch 7:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=0.9779]\u001b[A\n",
      "Epoch 7:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=1.5582]\u001b[A\n",
      "Epoch 7:  80%|████████  | 119/148 [01:48<00:26,  1.09it/s, training_loss=1.5582]\u001b[A\n",
      "Epoch 7:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=0.9640]\u001b[A\n",
      "Epoch 7:  81%|████████  | 120/148 [01:49<00:25,  1.09it/s, training_loss=0.9640]\u001b[A\n",
      "Epoch 7:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.4580]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 121/148 [01:50<00:24,  1.09it/s, training_loss=1.4580]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.6077]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 122/148 [01:51<00:23,  1.10it/s, training_loss=1.6077]\u001b[A\n",
      "Epoch 7:  82%|████████▏ | 122/148 [01:52<00:23,  1.10it/s, training_loss=0.9092]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 123/148 [01:52<00:22,  1.09it/s, training_loss=0.9092]\u001b[A\n",
      "Epoch 7:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=1.5357]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 124/148 [01:53<00:21,  1.09it/s, training_loss=1.5357]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 124/148 [01:54<00:21,  1.09it/s, training_loss=1.5583]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 125/148 [01:54<00:20,  1.10it/s, training_loss=1.5583]\u001b[A\n",
      "Epoch 7:  84%|████████▍ | 125/148 [01:55<00:20,  1.10it/s, training_loss=1.3519]\u001b[A\n",
      "Epoch 7:  85%|████████▌ | 126/148 [01:55<00:20,  1.10it/s, training_loss=1.3519]\u001b[A\n",
      "Epoch 7:  85%|████████▌ | 126/148 [01:56<00:20,  1.10it/s, training_loss=0.8912]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=0.8912]\u001b[A\n",
      "Epoch 7:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.1023]\u001b[A\n",
      "Epoch 7:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.1023]\u001b[A\n",
      "Epoch 7:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.0944]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.0944]\u001b[A\n",
      "Epoch 7:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=0.8961]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=0.8961]\u001b[A\n",
      "Epoch 7:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.6342]\u001b[A\n",
      "Epoch 7:  89%|████████▊ | 131/148 [01:59<00:15,  1.09it/s, training_loss=1.6342]\u001b[A\n",
      "Epoch 7:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.5831]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 132/148 [02:00<00:14,  1.09it/s, training_loss=1.5831]\u001b[A\n",
      "Epoch 7:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 133/148 [02:01<00:13,  1.09it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 7:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=0.8946]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 134/148 [02:02<00:12,  1.08it/s, training_loss=0.8946]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 134/148 [02:03<00:12,  1.08it/s, training_loss=1.1904]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 135/148 [02:03<00:11,  1.08it/s, training_loss=1.1904]\u001b[A\n",
      "Epoch 7:  91%|█████████ | 135/148 [02:04<00:11,  1.08it/s, training_loss=0.8817]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 136/148 [02:04<00:11,  1.09it/s, training_loss=0.8817]\u001b[A\n",
      "Epoch 7:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.6489]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=1.6489]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.3519]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.3519]\u001b[A\n",
      "Epoch 7:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.5606]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.5606]\u001b[A\n",
      "Epoch 7:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.6021]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=1.6021]\u001b[A\n",
      "Epoch 7:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=1.5287]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=1.5287]\u001b[A\n",
      "Epoch 7:  95%|█████████▌| 141/148 [02:10<00:06,  1.09it/s, training_loss=0.9043]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=0.9043]\u001b[A\n",
      "Epoch 7:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=1.5880]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 143/148 [02:10<00:04,  1.09it/s, training_loss=1.5880]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.5993]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 144/148 [02:11<00:03,  1.10it/s, training_loss=1.5993]\u001b[A\n",
      "Epoch 7:  97%|█████████▋| 144/148 [02:12<00:03,  1.10it/s, training_loss=1.5333]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 145/148 [02:12<00:02,  1.09it/s, training_loss=1.5333]\u001b[A\n",
      "Epoch 7:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=0.9291]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 146/148 [02:13<00:01,  1.09it/s, training_loss=0.9291]\u001b[A\n",
      "Epoch 7:  99%|█████████▊| 146/148 [02:14<00:01,  1.09it/s, training_loss=1.5201]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 147/148 [02:14<00:00,  1.09it/s, training_loss=1.5201]\u001b[A\n",
      "Epoch 7:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.4656]\u001b[A\n",
      "Epoch 7: 100%|██████████| 148/148 [02:15<00:00,  1.19it/s, training_loss=1.4656]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:42:52,533 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:42:52,534 - INFO - Memory usage after evaluation start: 3931.93 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:06,  3.72it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.64it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.61it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.61it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.61it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.62it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.62it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.60it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.62it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.61it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:42:59,770 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 19:42:59,784 - INFO - Class 'Drama': Optimal threshold = 0.500, F1 Score = 0.536\n",
      "2025-02-16 19:42:59,799 - INFO - Class 'Horor': Optimal threshold = 0.700, F1 Score = 0.773\n",
      "2025-02-16 19:42:59,813 - INFO - Class 'Komedi': Optimal threshold = 0.700, F1 Score = 0.559\n",
      "2025-02-16 19:42:59,826 - INFO - Class 'Laga': Optimal threshold = 0.600, F1 Score = 0.348\n",
      "2025-02-16 19:42:59,840 - INFO - Class 'Romantis': Optimal threshold = 0.750, F1 Score = 0.548\n",
      "2025-02-16 19:42:59,863 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:42:59,868 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:42:59,869 - INFO - Accuracy: 0.5824\n",
      "2025-02-16 19:42:59,870 - INFO - F1_score: 0.5362\n",
      "2025-02-16 19:42:59,870 - INFO - Precision: 0.3913\n",
      "2025-02-16 19:42:59,871 - INFO - Recall: 0.8514\n",
      "2025-02-16 19:42:59,877 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:42:59,877 - INFO - Accuracy: 0.8966\n",
      "2025-02-16 19:42:59,878 - INFO - F1_score: 0.7731\n",
      "2025-02-16 19:42:59,879 - INFO - Precision: 0.7419\n",
      "2025-02-16 19:42:59,880 - INFO - Recall: 0.8070\n",
      "2025-02-16 19:42:59,886 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:42:59,887 - INFO - Accuracy: 0.8123\n",
      "2025-02-16 19:42:59,888 - INFO - F1_score: 0.5586\n",
      "2025-02-16 19:42:59,888 - INFO - Precision: 0.5849\n",
      "2025-02-16 19:42:59,889 - INFO - Recall: 0.5345\n",
      "2025-02-16 19:42:59,895 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:42:59,896 - INFO - Accuracy: 0.7701\n",
      "2025-02-16 19:42:59,896 - INFO - F1_score: 0.3478\n",
      "2025-02-16 19:42:59,897 - INFO - Precision: 0.2963\n",
      "2025-02-16 19:42:59,898 - INFO - Recall: 0.4211\n",
      "2025-02-16 19:42:59,904 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:42:59,904 - INFO - Accuracy: 0.8736\n",
      "2025-02-16 19:42:59,905 - INFO - F1_score: 0.5479\n",
      "2025-02-16 19:42:59,905 - INFO - Precision: 0.5128\n",
      "2025-02-16 19:42:59,906 - INFO - Recall: 0.5882\n",
      "2025-02-16 19:42:59,909 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:43:03,737 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:43:03,739 - INFO - Memory usage after evaluation end: 3937.68 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   6%|▌         | 6/100 [18:05<4:03:01, 155.12s/it, Train Loss=1.2782, Val Loss=0.0509, Accuracy=0.7870]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:43:10,973 - INFO - Learning rate: 2.5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   7%|▋         | 7/100 [18:05<3:59:44, 154.67s/it, Train Loss=1.2782, Val Loss=0.0509, Accuracy=0.7870]\n",
      "Epoch 8:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.3324]\u001b[A\n",
      "Epoch 8:   1%|          | 1/148 [00:00<02:15,  1.08it/s, training_loss=1.3324]\u001b[A\n",
      "Epoch 8:   1%|          | 1/148 [00:01<02:15,  1.08it/s, training_loss=0.9637]\u001b[A\n",
      "Epoch 8:   1%|▏         | 2/148 [00:01<02:13,  1.09it/s, training_loss=0.9637]\u001b[A\n",
      "Epoch 8:   1%|▏         | 2/148 [00:02<02:13,  1.09it/s, training_loss=1.5575]\u001b[A\n",
      "Epoch 8:   2%|▏         | 3/148 [00:02<02:12,  1.10it/s, training_loss=1.5575]\u001b[A\n",
      "Epoch 8:   2%|▏         | 3/148 [00:03<02:12,  1.10it/s, training_loss=0.9150]\u001b[A\n",
      "Epoch 8:   3%|▎         | 4/148 [00:03<02:13,  1.08it/s, training_loss=0.9150]\u001b[A\n",
      "Epoch 8:   3%|▎         | 4/148 [00:04<02:13,  1.08it/s, training_loss=1.1439]\u001b[A\n",
      "Epoch 8:   3%|▎         | 5/148 [00:04<02:12,  1.08it/s, training_loss=1.1439]\u001b[A\n",
      "Epoch 8:   3%|▎         | 5/148 [00:05<02:12,  1.08it/s, training_loss=0.9624]\u001b[A\n",
      "Epoch 8:   4%|▍         | 6/148 [00:05<02:10,  1.09it/s, training_loss=0.9624]\u001b[A\n",
      "Epoch 8:   4%|▍         | 6/148 [00:06<02:10,  1.09it/s, training_loss=1.0549]\u001b[A\n",
      "Epoch 8:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=1.0549]\u001b[A\n",
      "Epoch 8:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=1.4379]\u001b[A\n",
      "Epoch 8:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=1.4379]\u001b[A\n",
      "Epoch 8:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=1.6170]\u001b[A\n",
      "Epoch 8:   6%|▌         | 9/148 [00:08<02:06,  1.10it/s, training_loss=1.6170]\u001b[A\n",
      "Epoch 8:   6%|▌         | 9/148 [00:09<02:06,  1.10it/s, training_loss=1.5309]\u001b[A\n",
      "Epoch 8:   7%|▋         | 10/148 [00:09<02:05,  1.10it/s, training_loss=1.5309]\u001b[A\n",
      "Epoch 8:   7%|▋         | 10/148 [00:10<02:05,  1.10it/s, training_loss=0.8261]\u001b[A\n",
      "Epoch 8:   7%|▋         | 11/148 [00:10<02:05,  1.10it/s, training_loss=0.8261]\u001b[A\n",
      "Epoch 8:   7%|▋         | 11/148 [00:10<02:05,  1.10it/s, training_loss=1.6309]\u001b[A\n",
      "Epoch 8:   8%|▊         | 12/148 [00:10<02:04,  1.10it/s, training_loss=1.6309]\u001b[A\n",
      "Epoch 8:   8%|▊         | 12/148 [00:11<02:04,  1.10it/s, training_loss=0.9680]\u001b[A\n",
      "Epoch 8:   9%|▉         | 13/148 [00:11<02:04,  1.09it/s, training_loss=0.9680]\u001b[A\n",
      "Epoch 8:   9%|▉         | 13/148 [00:12<02:04,  1.09it/s, training_loss=0.8134]\u001b[A\n",
      "Epoch 8:   9%|▉         | 14/148 [00:12<02:03,  1.09it/s, training_loss=0.8134]\u001b[A\n",
      "Epoch 8:   9%|▉         | 14/148 [00:13<02:03,  1.09it/s, training_loss=0.8917]\u001b[A\n",
      "Epoch 8:  10%|█         | 15/148 [00:13<02:02,  1.08it/s, training_loss=0.8917]\u001b[A\n",
      "Epoch 8:  10%|█         | 15/148 [00:14<02:02,  1.08it/s, training_loss=1.6051]\u001b[A\n",
      "Epoch 8:  11%|█         | 16/148 [00:14<02:01,  1.09it/s, training_loss=1.6051]\u001b[A\n",
      "Epoch 8:  11%|█         | 16/148 [00:15<02:01,  1.09it/s, training_loss=1.5750]\u001b[A\n",
      "Epoch 8:  11%|█▏        | 17/148 [00:15<02:00,  1.09it/s, training_loss=1.5750]\u001b[A\n",
      "Epoch 8:  11%|█▏        | 17/148 [00:16<02:00,  1.09it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 8:  12%|█▏        | 18/148 [00:16<01:59,  1.09it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 8:  12%|█▏        | 18/148 [00:17<01:59,  1.09it/s, training_loss=1.5417]\u001b[A\n",
      "Epoch 8:  13%|█▎        | 19/148 [00:17<01:58,  1.09it/s, training_loss=1.5417]\u001b[A\n",
      "Epoch 8:  13%|█▎        | 19/148 [00:18<01:58,  1.09it/s, training_loss=1.0080]\u001b[A\n",
      "Epoch 8:  14%|█▎        | 20/148 [00:18<01:57,  1.09it/s, training_loss=1.0080]\u001b[A\n",
      "Epoch 8:  14%|█▎        | 20/148 [00:19<01:57,  1.09it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 8:  14%|█▍        | 21/148 [00:19<01:56,  1.09it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 8:  14%|█▍        | 21/148 [00:20<01:56,  1.09it/s, training_loss=0.9357]\u001b[A\n",
      "Epoch 8:  15%|█▍        | 22/148 [00:20<01:55,  1.09it/s, training_loss=0.9357]\u001b[A\n",
      "Epoch 8:  15%|█▍        | 22/148 [00:21<01:55,  1.09it/s, training_loss=1.5544]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 23/148 [00:21<01:54,  1.09it/s, training_loss=1.5544]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 23/148 [00:22<01:54,  1.09it/s, training_loss=1.5257]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 24/148 [00:22<01:53,  1.09it/s, training_loss=1.5257]\u001b[A\n",
      "Epoch 8:  16%|█▌        | 24/148 [00:22<01:53,  1.09it/s, training_loss=1.5093]\u001b[A\n",
      "Epoch 8:  17%|█▋        | 25/148 [00:22<01:52,  1.09it/s, training_loss=1.5093]\u001b[A\n",
      "Epoch 8:  17%|█▋        | 25/148 [00:23<01:52,  1.09it/s, training_loss=1.4697]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 26/148 [00:23<01:51,  1.09it/s, training_loss=1.4697]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 26/148 [00:24<01:51,  1.09it/s, training_loss=0.8980]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 27/148 [00:24<01:51,  1.08it/s, training_loss=0.8980]\u001b[A\n",
      "Epoch 8:  18%|█▊        | 27/148 [00:25<01:51,  1.08it/s, training_loss=1.5724]\u001b[A\n",
      "Epoch 8:  19%|█▉        | 28/148 [00:25<01:50,  1.09it/s, training_loss=1.5724]\u001b[A\n",
      "Epoch 8:  19%|█▉        | 28/148 [00:26<01:50,  1.09it/s, training_loss=0.8937]\u001b[A\n",
      "Epoch 8:  20%|█▉        | 29/148 [00:26<01:49,  1.09it/s, training_loss=0.8937]\u001b[A\n",
      "Epoch 8:  20%|█▉        | 29/148 [00:27<01:49,  1.09it/s, training_loss=1.5993]\u001b[A\n",
      "Epoch 8:  20%|██        | 30/148 [00:27<01:48,  1.09it/s, training_loss=1.5993]\u001b[A\n",
      "Epoch 8:  20%|██        | 30/148 [00:28<01:48,  1.09it/s, training_loss=1.6562]\u001b[A\n",
      "Epoch 8:  21%|██        | 31/148 [00:28<01:47,  1.09it/s, training_loss=1.6562]\u001b[A\n",
      "Epoch 8:  21%|██        | 31/148 [00:29<01:47,  1.09it/s, training_loss=0.9967]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 32/148 [00:29<01:47,  1.08it/s, training_loss=0.9967]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 32/148 [00:30<01:47,  1.08it/s, training_loss=1.5756]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 33/148 [00:30<01:45,  1.09it/s, training_loss=1.5756]\u001b[A\n",
      "Epoch 8:  22%|██▏       | 33/148 [00:31<01:45,  1.09it/s, training_loss=1.4877]\u001b[A\n",
      "Epoch 8:  23%|██▎       | 34/148 [00:31<01:44,  1.09it/s, training_loss=1.4877]\u001b[A\n",
      "Epoch 8:  23%|██▎       | 34/148 [00:32<01:44,  1.09it/s, training_loss=0.9465]\u001b[A\n",
      "Epoch 8:  24%|██▎       | 35/148 [00:32<01:44,  1.08it/s, training_loss=0.9465]\u001b[A\n",
      "Epoch 8:  24%|██▎       | 35/148 [00:33<01:44,  1.08it/s, training_loss=1.5396]\u001b[A\n",
      "Epoch 8:  24%|██▍       | 36/148 [00:33<01:43,  1.08it/s, training_loss=1.5396]\u001b[A\n",
      "Epoch 8:  24%|██▍       | 36/148 [00:33<01:43,  1.08it/s, training_loss=1.0247]\u001b[A\n",
      "Epoch 8:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=1.0247]\u001b[A\n",
      "Epoch 8:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=1.0869]\u001b[A\n",
      "Epoch 8:  26%|██▌       | 38/148 [00:34<01:42,  1.07it/s, training_loss=1.0869]\u001b[A\n",
      "Epoch 8:  26%|██▌       | 38/148 [00:35<01:42,  1.07it/s, training_loss=0.8681]\u001b[A\n",
      "Epoch 8:  26%|██▋       | 39/148 [00:35<01:41,  1.08it/s, training_loss=0.8681]\u001b[A\n",
      "Epoch 8:  26%|██▋       | 39/148 [00:36<01:41,  1.08it/s, training_loss=1.5571]\u001b[A\n",
      "Epoch 8:  27%|██▋       | 40/148 [00:36<01:39,  1.08it/s, training_loss=1.5571]\u001b[A\n",
      "Epoch 8:  27%|██▋       | 40/148 [00:37<01:39,  1.08it/s, training_loss=1.5485]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=1.5485]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=1.0470]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=1.0470]\u001b[A\n",
      "Epoch 8:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=1.4663]\u001b[A\n",
      "Epoch 8:  29%|██▉       | 43/148 [00:39<01:36,  1.09it/s, training_loss=1.4663]\u001b[A\n",
      "Epoch 8:  29%|██▉       | 43/148 [00:40<01:36,  1.09it/s, training_loss=0.9702]\u001b[A\n",
      "Epoch 8:  30%|██▉       | 44/148 [00:40<01:35,  1.09it/s, training_loss=0.9702]\u001b[A\n",
      "Epoch 8:  30%|██▉       | 44/148 [00:41<01:35,  1.09it/s, training_loss=0.8179]\u001b[A\n",
      "Epoch 8:  30%|███       | 45/148 [00:41<01:34,  1.09it/s, training_loss=0.8179]\u001b[A\n",
      "Epoch 8:  30%|███       | 45/148 [00:42<01:34,  1.09it/s, training_loss=1.5907]\u001b[A\n",
      "Epoch 8:  31%|███       | 46/148 [00:42<01:33,  1.09it/s, training_loss=1.5907]\u001b[A\n",
      "Epoch 8:  31%|███       | 46/148 [00:43<01:33,  1.09it/s, training_loss=1.3705]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.3705]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.0233]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 48/148 [00:44<01:32,  1.09it/s, training_loss=1.0233]\u001b[A\n",
      "Epoch 8:  32%|███▏      | 48/148 [00:45<01:32,  1.09it/s, training_loss=1.6106]\u001b[A\n",
      "Epoch 8:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=1.6106]\u001b[A\n",
      "Epoch 8:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=0.9569]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 50/148 [00:45<01:30,  1.09it/s, training_loss=0.9569]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 50/148 [00:46<01:30,  1.09it/s, training_loss=1.5024]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 51/148 [00:46<01:29,  1.09it/s, training_loss=1.5024]\u001b[A\n",
      "Epoch 8:  34%|███▍      | 51/148 [00:47<01:29,  1.09it/s, training_loss=0.9496]\u001b[A\n",
      "Epoch 8:  35%|███▌      | 52/148 [00:47<01:28,  1.09it/s, training_loss=0.9496]\u001b[A\n",
      "Epoch 8:  35%|███▌      | 52/148 [00:48<01:28,  1.09it/s, training_loss=1.6034]\u001b[A\n",
      "Epoch 8:  36%|███▌      | 53/148 [00:48<01:27,  1.09it/s, training_loss=1.6034]\u001b[A\n",
      "Epoch 8:  36%|███▌      | 53/148 [00:49<01:27,  1.09it/s, training_loss=1.3307]\u001b[A\n",
      "Epoch 8:  36%|███▋      | 54/148 [00:49<01:26,  1.09it/s, training_loss=1.3307]\u001b[A\n",
      "Epoch 8:  36%|███▋      | 54/148 [00:50<01:26,  1.09it/s, training_loss=0.8478]\u001b[A\n",
      "Epoch 8:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=0.8478]\u001b[A\n",
      "Epoch 8:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.0332]\u001b[A\n",
      "Epoch 8:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=1.0332]\u001b[A\n",
      "Epoch 8:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=1.6583]\u001b[A\n",
      "Epoch 8:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.6583]\u001b[A\n",
      "Epoch 8:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=1.4649]\u001b[A\n",
      "Epoch 8:  39%|███▉      | 58/148 [00:53<01:22,  1.09it/s, training_loss=1.4649]\u001b[A\n",
      "Epoch 8:  39%|███▉      | 58/148 [00:54<01:22,  1.09it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 8:  40%|███▉      | 59/148 [00:54<01:21,  1.09it/s, training_loss=1.0265]\u001b[A\n",
      "Epoch 8:  40%|███▉      | 59/148 [00:55<01:21,  1.09it/s, training_loss=1.5887]\u001b[A\n",
      "Epoch 8:  41%|████      | 60/148 [00:55<01:20,  1.09it/s, training_loss=1.5887]\u001b[A\n",
      "Epoch 8:  41%|████      | 60/148 [00:56<01:20,  1.09it/s, training_loss=0.8450]\u001b[A\n",
      "Epoch 8:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=0.8450]\u001b[A\n",
      "Epoch 8:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=0.8712]\u001b[A\n",
      "Epoch 8:  42%|████▏     | 62/148 [00:56<01:19,  1.08it/s, training_loss=0.8712]\u001b[A\n",
      "Epoch 8:  42%|████▏     | 62/148 [00:57<01:19,  1.08it/s, training_loss=0.8474]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 63/148 [00:57<01:18,  1.09it/s, training_loss=0.8474]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 63/148 [00:58<01:18,  1.09it/s, training_loss=1.0156]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 64/148 [00:58<01:17,  1.09it/s, training_loss=1.0156]\u001b[A\n",
      "Epoch 8:  43%|████▎     | 64/148 [00:59<01:17,  1.09it/s, training_loss=1.0083]\u001b[A\n",
      "Epoch 8:  44%|████▍     | 65/148 [00:59<01:16,  1.09it/s, training_loss=1.0083]\u001b[A\n",
      "Epoch 8:  44%|████▍     | 65/148 [01:00<01:16,  1.09it/s, training_loss=0.8045]\u001b[A\n",
      "Epoch 8:  45%|████▍     | 66/148 [01:00<01:15,  1.09it/s, training_loss=0.8045]\u001b[A\n",
      "Epoch 8:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=1.5301]\u001b[A\n",
      "Epoch 8:  45%|████▌     | 67/148 [01:01<01:13,  1.10it/s, training_loss=1.5301]\u001b[A\n",
      "Epoch 8:  45%|████▌     | 67/148 [01:02<01:13,  1.10it/s, training_loss=1.2708]\u001b[A\n",
      "Epoch 8:  46%|████▌     | 68/148 [01:02<01:12,  1.10it/s, training_loss=1.2708]\u001b[A\n",
      "Epoch 8:  46%|████▌     | 68/148 [01:03<01:12,  1.10it/s, training_loss=1.6226]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 69/148 [01:03<01:11,  1.10it/s, training_loss=1.6226]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 69/148 [01:04<01:11,  1.10it/s, training_loss=1.5926]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=1.5926]\u001b[A\n",
      "Epoch 8:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=0.9614]\u001b[A\n",
      "Epoch 8:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=0.9614]\u001b[A\n",
      "Epoch 8:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=0.9497]\u001b[A\n",
      "Epoch 8:  49%|████▊     | 72/148 [01:06<01:09,  1.09it/s, training_loss=0.9497]\u001b[A\n",
      "Epoch 8:  49%|████▊     | 72/148 [01:07<01:09,  1.09it/s, training_loss=1.6757]\u001b[A\n",
      "Epoch 8:  49%|████▉     | 73/148 [01:07<01:08,  1.10it/s, training_loss=1.6757]\u001b[A\n",
      "Epoch 8:  49%|████▉     | 73/148 [01:07<01:08,  1.10it/s, training_loss=1.5397]\u001b[A\n",
      "Epoch 8:  50%|█████     | 74/148 [01:07<01:07,  1.10it/s, training_loss=1.5397]\u001b[A\n",
      "Epoch 8:  50%|█████     | 74/148 [01:08<01:07,  1.10it/s, training_loss=1.6013]\u001b[A\n",
      "Epoch 8:  51%|█████     | 75/148 [01:08<01:06,  1.09it/s, training_loss=1.6013]\u001b[A\n",
      "Epoch 8:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.5562]\u001b[A\n",
      "Epoch 8:  51%|█████▏    | 76/148 [01:09<01:05,  1.09it/s, training_loss=1.5562]\u001b[A\n",
      "Epoch 8:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=1.4963]\u001b[A\n",
      "Epoch 8:  52%|█████▏    | 77/148 [01:10<01:04,  1.10it/s, training_loss=1.4963]\u001b[A\n",
      "Epoch 8:  52%|█████▏    | 77/148 [01:11<01:04,  1.10it/s, training_loss=1.1059]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 78/148 [01:11<01:03,  1.10it/s, training_loss=1.1059]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 78/148 [01:12<01:03,  1.10it/s, training_loss=1.6222]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 79/148 [01:12<01:03,  1.10it/s, training_loss=1.6222]\u001b[A\n",
      "Epoch 8:  53%|█████▎    | 79/148 [01:13<01:03,  1.10it/s, training_loss=0.8825]\u001b[A\n",
      "Epoch 8:  54%|█████▍    | 80/148 [01:13<01:02,  1.10it/s, training_loss=0.8825]\u001b[A\n",
      "Epoch 8:  54%|█████▍    | 80/148 [01:14<01:02,  1.10it/s, training_loss=0.9840]\u001b[A\n",
      "Epoch 8:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=0.9840]\u001b[A\n",
      "Epoch 8:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=1.5992]\u001b[A\n",
      "Epoch 8:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.5992]\u001b[A\n",
      "Epoch 8:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.5482]\u001b[A\n",
      "Epoch 8:  56%|█████▌    | 83/148 [01:16<00:59,  1.10it/s, training_loss=1.5482]\u001b[A\n",
      "Epoch 8:  56%|█████▌    | 83/148 [01:17<00:59,  1.10it/s, training_loss=0.8835]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=0.8835]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=1.0686]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.0686]\u001b[A\n",
      "Epoch 8:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.0756]\u001b[A\n",
      "Epoch 8:  58%|█████▊    | 86/148 [01:18<00:56,  1.09it/s, training_loss=1.0756]\u001b[A\n",
      "Epoch 8:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.5423]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 87/148 [01:19<00:55,  1.09it/s, training_loss=1.5423]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 87/148 [01:20<00:55,  1.09it/s, training_loss=0.8611]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 88/148 [01:20<00:55,  1.09it/s, training_loss=0.8611]\u001b[A\n",
      "Epoch 8:  59%|█████▉    | 88/148 [01:21<00:55,  1.09it/s, training_loss=1.6524]\u001b[A\n",
      "Epoch 8:  60%|██████    | 89/148 [01:21<00:53,  1.10it/s, training_loss=1.6524]\u001b[A\n",
      "Epoch 8:  60%|██████    | 89/148 [01:22<00:53,  1.10it/s, training_loss=1.5544]\u001b[A\n",
      "Epoch 8:  61%|██████    | 90/148 [01:22<00:52,  1.10it/s, training_loss=1.5544]\u001b[A\n",
      "Epoch 8:  61%|██████    | 90/148 [01:23<00:52,  1.10it/s, training_loss=1.4510]\u001b[A\n",
      "Epoch 8:  61%|██████▏   | 91/148 [01:23<00:52,  1.10it/s, training_loss=1.4510]\u001b[A\n",
      "Epoch 8:  61%|██████▏   | 91/148 [01:24<00:52,  1.10it/s, training_loss=0.9644]\u001b[A\n",
      "Epoch 8:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=0.9644]\u001b[A\n",
      "Epoch 8:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=0.8950]\u001b[A\n",
      "Epoch 8:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=0.8950]\u001b[A\n",
      "Epoch 8:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.5481]\u001b[A\n",
      "Epoch 8:  64%|██████▎   | 94/148 [01:26<00:49,  1.10it/s, training_loss=1.5481]\u001b[A\n",
      "Epoch 8:  64%|██████▎   | 94/148 [01:27<00:49,  1.10it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 8:  64%|██████▍   | 95/148 [01:27<00:48,  1.10it/s, training_loss=1.6206]\u001b[A\n",
      "Epoch 8:  64%|██████▍   | 95/148 [01:28<00:48,  1.10it/s, training_loss=1.2349]\u001b[A\n",
      "Epoch 8:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.2349]\u001b[A\n",
      "Epoch 8:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.4045]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 97/148 [01:28<00:46,  1.09it/s, training_loss=1.4045]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.5922]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 98/148 [01:29<00:45,  1.09it/s, training_loss=1.5922]\u001b[A\n",
      "Epoch 8:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=0.8624]\u001b[A\n",
      "Epoch 8:  67%|██████▋   | 99/148 [01:30<00:44,  1.09it/s, training_loss=0.8624]\u001b[A\n",
      "Epoch 8:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=1.0060]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 100/148 [01:31<00:44,  1.09it/s, training_loss=1.0060]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 100/148 [01:32<00:44,  1.09it/s, training_loss=1.3959]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 101/148 [01:32<00:43,  1.09it/s, training_loss=1.3959]\u001b[A\n",
      "Epoch 8:  68%|██████▊   | 101/148 [01:33<00:43,  1.09it/s, training_loss=1.2596]\u001b[A\n",
      "Epoch 8:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.2596]\u001b[A\n",
      "Epoch 8:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=1.0183]\u001b[A\n",
      "Epoch 8:  70%|██████▉   | 103/148 [01:34<00:41,  1.09it/s, training_loss=1.0183]\u001b[A\n",
      "Epoch 8:  70%|██████▉   | 103/148 [01:35<00:41,  1.09it/s, training_loss=1.5602]\u001b[A\n",
      "Epoch 8:  70%|███████   | 104/148 [01:35<00:40,  1.09it/s, training_loss=1.5602]\u001b[A\n",
      "Epoch 8:  70%|███████   | 104/148 [01:36<00:40,  1.09it/s, training_loss=0.9156]\u001b[A\n",
      "Epoch 8:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=0.9156]\u001b[A\n",
      "Epoch 8:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.6352]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.6352]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=1.1187]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=1.1187]\u001b[A\n",
      "Epoch 8:  72%|███████▏  | 107/148 [01:39<00:37,  1.09it/s, training_loss=0.8932]\u001b[A\n",
      "Epoch 8:  73%|███████▎  | 108/148 [01:39<00:36,  1.08it/s, training_loss=0.8932]\u001b[A\n",
      "Epoch 8:  73%|███████▎  | 108/148 [01:40<00:36,  1.08it/s, training_loss=0.9409]\u001b[A\n",
      "Epoch 8:  74%|███████▎  | 109/148 [01:40<00:35,  1.08it/s, training_loss=0.9409]\u001b[A\n",
      "Epoch 8:  74%|███████▎  | 109/148 [01:40<00:35,  1.08it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 8:  74%|███████▍  | 110/148 [01:40<00:34,  1.09it/s, training_loss=1.5781]\u001b[A\n",
      "Epoch 8:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.4037]\u001b[A\n",
      "Epoch 8:  75%|███████▌  | 111/148 [01:41<00:33,  1.09it/s, training_loss=1.4037]\u001b[A\n",
      "Epoch 8:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=0.9708]\u001b[A\n",
      "Epoch 8:  76%|███████▌  | 112/148 [01:42<00:33,  1.09it/s, training_loss=0.9708]\u001b[A\n",
      "Epoch 8:  76%|███████▌  | 112/148 [01:43<00:33,  1.09it/s, training_loss=1.0590]\u001b[A\n",
      "Epoch 8:  76%|███████▋  | 113/148 [01:43<00:32,  1.08it/s, training_loss=1.0590]\u001b[A\n",
      "Epoch 8:  76%|███████▋  | 113/148 [01:44<00:32,  1.08it/s, training_loss=1.0836]\u001b[A\n",
      "Epoch 8:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.0836]\u001b[A\n",
      "Epoch 8:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=0.8922]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=0.8922]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=1.5895]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=1.5895]\u001b[A\n",
      "Epoch 8:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=1.4972]\u001b[A\n",
      "Epoch 8:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.4972]\u001b[A\n",
      "Epoch 8:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=1.4845]\u001b[A\n",
      "Epoch 8:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=1.4845]\u001b[A\n",
      "Epoch 8:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.6200]\u001b[A\n",
      "Epoch 8:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.6200]\u001b[A\n",
      "Epoch 8:  80%|████████  | 119/148 [01:50<00:26,  1.09it/s, training_loss=1.5638]\u001b[A\n",
      "Epoch 8:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.5638]\u001b[A\n",
      "Epoch 8:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=0.8846]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 121/148 [01:50<00:24,  1.10it/s, training_loss=0.8846]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 121/148 [01:51<00:24,  1.10it/s, training_loss=0.9377]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 122/148 [01:51<00:23,  1.09it/s, training_loss=0.9377]\u001b[A\n",
      "Epoch 8:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.6469]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 123/148 [01:52<00:22,  1.09it/s, training_loss=1.6469]\u001b[A\n",
      "Epoch 8:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=1.0004]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 124/148 [01:53<00:21,  1.10it/s, training_loss=1.0004]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 124/148 [01:54<00:21,  1.10it/s, training_loss=1.5854]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 125/148 [01:54<00:20,  1.10it/s, training_loss=1.5854]\u001b[A\n",
      "Epoch 8:  84%|████████▍ | 125/148 [01:55<00:20,  1.10it/s, training_loss=0.9754]\u001b[A\n",
      "Epoch 8:  85%|████████▌ | 126/148 [01:55<00:20,  1.09it/s, training_loss=0.9754]\u001b[A\n",
      "Epoch 8:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=1.6035]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 127/148 [01:56<00:19,  1.10it/s, training_loss=1.6035]\u001b[A\n",
      "Epoch 8:  86%|████████▌ | 127/148 [01:57<00:19,  1.10it/s, training_loss=0.9207]\u001b[A\n",
      "Epoch 8:  86%|████████▋ | 128/148 [01:57<00:18,  1.10it/s, training_loss=0.9207]\u001b[A\n",
      "Epoch 8:  86%|████████▋ | 128/148 [01:58<00:18,  1.10it/s, training_loss=0.8628]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=0.8628]\u001b[A\n",
      "Epoch 8:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=0.9330]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=0.9330]\u001b[A\n",
      "Epoch 8:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=0.8955]\u001b[A\n",
      "Epoch 8:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=0.8955]\u001b[A\n",
      "Epoch 8:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=1.6372]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.6372]\u001b[A\n",
      "Epoch 8:  89%|████████▉ | 132/148 [02:02<00:14,  1.09it/s, training_loss=0.8199]\u001b[A\n",
      "Epoch 8:  90%|████████▉ | 133/148 [02:02<00:13,  1.08it/s, training_loss=0.8199]\u001b[A\n",
      "Epoch 8:  90%|████████▉ | 133/148 [02:02<00:13,  1.08it/s, training_loss=1.4598]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 134/148 [02:02<00:12,  1.09it/s, training_loss=1.4598]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.4814]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 135/148 [02:03<00:11,  1.09it/s, training_loss=1.4814]\u001b[A\n",
      "Epoch 8:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=1.4868]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 136/148 [02:04<00:10,  1.09it/s, training_loss=1.4868]\u001b[A\n",
      "Epoch 8:  92%|█████████▏| 136/148 [02:05<00:10,  1.09it/s, training_loss=0.9816]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=0.9816]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.0185]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.0185]\u001b[A\n",
      "Epoch 8:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.5574]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 139/148 [02:07<00:08,  1.10it/s, training_loss=1.5574]\u001b[A\n",
      "Epoch 8:  94%|█████████▍| 139/148 [02:08<00:08,  1.10it/s, training_loss=0.8998]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=0.8998]\u001b[A\n",
      "Epoch 8:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=0.9772]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=0.9772]\u001b[A\n",
      "Epoch 8:  95%|█████████▌| 141/148 [02:10<00:06,  1.09it/s, training_loss=0.9065]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=0.9065]\u001b[A\n",
      "Epoch 8:  96%|█████████▌| 142/148 [02:11<00:05,  1.09it/s, training_loss=0.9195]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=0.9195]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=0.9464]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=0.9464]\u001b[A\n",
      "Epoch 8:  97%|█████████▋| 144/148 [02:12<00:03,  1.09it/s, training_loss=0.9631]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 145/148 [02:12<00:02,  1.09it/s, training_loss=0.9631]\u001b[A\n",
      "Epoch 8:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=1.5326]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 146/148 [02:13<00:01,  1.09it/s, training_loss=1.5326]\u001b[A\n",
      "Epoch 8:  99%|█████████▊| 146/148 [02:14<00:01,  1.09it/s, training_loss=1.5406]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 147/148 [02:14<00:00,  1.10it/s, training_loss=1.5406]\u001b[A\n",
      "Epoch 8:  99%|█████████▉| 147/148 [02:15<00:00,  1.10it/s, training_loss=1.5986]\u001b[A\n",
      "Epoch 8: 100%|██████████| 148/148 [02:15<00:00,  1.19it/s, training_loss=1.5986]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:45:26,464 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:45:26,465 - INFO - Memory usage after evaluation start: 3938.05 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.68it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.64it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.60it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.60it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.60it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.60it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.60it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:05,  3.59it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.59it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.58it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.59it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.60it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.60it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.59it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:45:33,726 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 19:45:33,741 - INFO - Class 'Drama': Optimal threshold = 0.500, F1 Score = 0.533\n",
      "2025-02-16 19:45:33,756 - INFO - Class 'Horor': Optimal threshold = 0.700, F1 Score = 0.784\n",
      "2025-02-16 19:45:33,770 - INFO - Class 'Komedi': Optimal threshold = 0.700, F1 Score = 0.571\n",
      "2025-02-16 19:45:33,784 - INFO - Class 'Laga': Optimal threshold = 0.550, F1 Score = 0.358\n",
      "2025-02-16 19:45:33,797 - INFO - Class 'Romantis': Optimal threshold = 0.600, F1 Score = 0.513\n",
      "2025-02-16 19:45:33,823 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:45:33,830 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:45:33,830 - INFO - Accuracy: 0.6245\n",
      "2025-02-16 19:45:33,831 - INFO - F1_score: 0.5333\n",
      "2025-02-16 19:45:33,832 - INFO - Precision: 0.4118\n",
      "2025-02-16 19:45:33,833 - INFO - Recall: 0.7568\n",
      "2025-02-16 19:45:33,839 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:45:33,840 - INFO - Accuracy: 0.8966\n",
      "2025-02-16 19:45:33,842 - INFO - F1_score: 0.7840\n",
      "2025-02-16 19:45:33,842 - INFO - Precision: 0.7206\n",
      "2025-02-16 19:45:33,843 - INFO - Recall: 0.8596\n",
      "2025-02-16 19:45:33,850 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:45:33,851 - INFO - Accuracy: 0.7816\n",
      "2025-02-16 19:45:33,852 - INFO - F1_score: 0.5714\n",
      "2025-02-16 19:45:33,853 - INFO - Precision: 0.5067\n",
      "2025-02-16 19:45:33,854 - INFO - Recall: 0.6552\n",
      "2025-02-16 19:45:33,861 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:45:33,861 - INFO - Accuracy: 0.7663\n",
      "2025-02-16 19:45:33,862 - INFO - F1_score: 0.3579\n",
      "2025-02-16 19:45:33,863 - INFO - Precision: 0.2982\n",
      "2025-02-16 19:45:33,864 - INFO - Recall: 0.4474\n",
      "2025-02-16 19:45:33,870 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:45:33,870 - INFO - Accuracy: 0.8544\n",
      "2025-02-16 19:45:33,871 - INFO - F1_score: 0.5128\n",
      "2025-02-16 19:45:33,872 - INFO - Precision: 0.4545\n",
      "2025-02-16 19:45:33,872 - INFO - Recall: 0.5882\n",
      "2025-02-16 19:45:33,874 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:45:37,885 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:45:37,887 - INFO - Memory usage after evaluation end: 3943.68 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   7%|▋         | 7/100 [20:39<3:59:44, 154.67s/it, Train Loss=1.2512, Val Loss=0.0519, Accuracy=0.7847]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:45:45,143 - INFO - Learning rate: 2.5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 8/100 [20:39<3:56:55, 154.51s/it, Train Loss=1.2512, Val Loss=0.0519, Accuracy=0.7847]\n",
      "Epoch 9:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=0.9016]\u001b[A\n",
      "Epoch 9:   1%|          | 1/148 [00:00<02:14,  1.10it/s, training_loss=0.9016]\u001b[A\n",
      "Epoch 9:   1%|          | 1/148 [00:01<02:14,  1.10it/s, training_loss=0.9711]\u001b[A\n",
      "Epoch 9:   1%|▏         | 2/148 [00:01<02:13,  1.09it/s, training_loss=0.9711]\u001b[A\n",
      "Epoch 9:   1%|▏         | 2/148 [00:02<02:13,  1.09it/s, training_loss=0.8829]\u001b[A\n",
      "Epoch 9:   2%|▏         | 3/148 [00:02<02:11,  1.10it/s, training_loss=0.8829]\u001b[A\n",
      "Epoch 9:   2%|▏         | 3/148 [00:03<02:11,  1.10it/s, training_loss=1.6129]\u001b[A\n",
      "Epoch 9:   3%|▎         | 4/148 [00:03<02:11,  1.10it/s, training_loss=1.6129]\u001b[A\n",
      "Epoch 9:   3%|▎         | 4/148 [00:04<02:11,  1.10it/s, training_loss=1.6124]\u001b[A\n",
      "Epoch 9:   3%|▎         | 5/148 [00:04<02:10,  1.10it/s, training_loss=1.6124]\u001b[A\n",
      "Epoch 9:   3%|▎         | 5/148 [00:05<02:10,  1.10it/s, training_loss=0.8404]\u001b[A\n",
      "Epoch 9:   4%|▍         | 6/148 [00:05<02:10,  1.09it/s, training_loss=0.8404]\u001b[A\n",
      "Epoch 9:   4%|▍         | 6/148 [00:06<02:10,  1.09it/s, training_loss=1.1394]\u001b[A\n",
      "Epoch 9:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=1.1394]\u001b[A\n",
      "Epoch 9:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=0.9589]\u001b[A\n",
      "Epoch 9:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=0.9589]\u001b[A\n",
      "Epoch 9:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=1.5274]\u001b[A\n",
      "Epoch 9:   6%|▌         | 9/148 [00:08<02:07,  1.09it/s, training_loss=1.5274]\u001b[A\n",
      "Epoch 9:   6%|▌         | 9/148 [00:09<02:07,  1.09it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 9:   7%|▋         | 10/148 [00:09<02:06,  1.09it/s, training_loss=1.5053]\u001b[A\n",
      "Epoch 9:   7%|▋         | 10/148 [00:10<02:06,  1.09it/s, training_loss=1.4978]\u001b[A\n",
      "Epoch 9:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.4978]\u001b[A\n",
      "Epoch 9:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=0.8272]\u001b[A\n",
      "Epoch 9:   8%|▊         | 12/148 [00:10<02:04,  1.09it/s, training_loss=0.8272]\u001b[A\n",
      "Epoch 9:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.0140]\u001b[A\n",
      "Epoch 9:   9%|▉         | 13/148 [00:11<02:04,  1.09it/s, training_loss=1.0140]\u001b[A\n",
      "Epoch 9:   9%|▉         | 13/148 [00:12<02:04,  1.09it/s, training_loss=1.6436]\u001b[A\n",
      "Epoch 9:   9%|▉         | 14/148 [00:12<02:02,  1.09it/s, training_loss=1.6436]\u001b[A\n",
      "Epoch 9:   9%|▉         | 14/148 [00:13<02:02,  1.09it/s, training_loss=1.6699]\u001b[A\n",
      "Epoch 9:  10%|█         | 15/148 [00:13<02:01,  1.09it/s, training_loss=1.6699]\u001b[A\n",
      "Epoch 9:  10%|█         | 15/148 [00:14<02:01,  1.09it/s, training_loss=0.8874]\u001b[A\n",
      "Epoch 9:  11%|█         | 16/148 [00:14<02:01,  1.08it/s, training_loss=0.8874]\u001b[A\n",
      "Epoch 9:  11%|█         | 16/148 [00:15<02:01,  1.08it/s, training_loss=1.0019]\u001b[A\n",
      "Epoch 9:  11%|█▏        | 17/148 [00:15<02:00,  1.08it/s, training_loss=1.0019]\u001b[A\n",
      "Epoch 9:  11%|█▏        | 17/148 [00:16<02:00,  1.08it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 9:  12%|█▏        | 18/148 [00:16<01:59,  1.08it/s, training_loss=1.1846]\u001b[A\n",
      "Epoch 9:  12%|█▏        | 18/148 [00:17<01:59,  1.08it/s, training_loss=1.0505]\u001b[A\n",
      "Epoch 9:  13%|█▎        | 19/148 [00:17<01:58,  1.08it/s, training_loss=1.0505]\u001b[A\n",
      "Epoch 9:  13%|█▎        | 19/148 [00:18<01:58,  1.08it/s, training_loss=0.9536]\u001b[A\n",
      "Epoch 9:  14%|█▎        | 20/148 [00:18<01:58,  1.08it/s, training_loss=0.9536]\u001b[A\n",
      "Epoch 9:  14%|█▎        | 20/148 [00:19<01:58,  1.08it/s, training_loss=0.9349]\u001b[A\n",
      "Epoch 9:  14%|█▍        | 21/148 [00:19<01:57,  1.08it/s, training_loss=0.9349]\u001b[A\n",
      "Epoch 9:  14%|█▍        | 21/148 [00:20<01:57,  1.08it/s, training_loss=0.8443]\u001b[A\n",
      "Epoch 9:  15%|█▍        | 22/148 [00:20<01:56,  1.08it/s, training_loss=0.8443]\u001b[A\n",
      "Epoch 9:  15%|█▍        | 22/148 [00:21<01:56,  1.08it/s, training_loss=1.5379]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 23/148 [00:21<01:55,  1.08it/s, training_loss=1.5379]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 23/148 [00:22<01:55,  1.08it/s, training_loss=1.0387]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 24/148 [00:22<01:55,  1.08it/s, training_loss=1.0387]\u001b[A\n",
      "Epoch 9:  16%|█▌        | 24/148 [00:22<01:55,  1.08it/s, training_loss=1.5903]\u001b[A\n",
      "Epoch 9:  17%|█▋        | 25/148 [00:22<01:53,  1.08it/s, training_loss=1.5903]\u001b[A\n",
      "Epoch 9:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 26/148 [00:23<01:52,  1.08it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 26/148 [00:24<01:52,  1.08it/s, training_loss=1.6138]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 27/148 [00:24<01:51,  1.08it/s, training_loss=1.6138]\u001b[A\n",
      "Epoch 9:  18%|█▊        | 27/148 [00:25<01:51,  1.08it/s, training_loss=1.5431]\u001b[A\n",
      "Epoch 9:  19%|█▉        | 28/148 [00:25<01:50,  1.09it/s, training_loss=1.5431]\u001b[A\n",
      "Epoch 9:  19%|█▉        | 28/148 [00:26<01:50,  1.09it/s, training_loss=1.6264]\u001b[A\n",
      "Epoch 9:  20%|█▉        | 29/148 [00:26<01:49,  1.09it/s, training_loss=1.6264]\u001b[A\n",
      "Epoch 9:  20%|█▉        | 29/148 [00:27<01:49,  1.09it/s, training_loss=1.5627]\u001b[A\n",
      "Epoch 9:  20%|██        | 30/148 [00:27<01:48,  1.09it/s, training_loss=1.5627]\u001b[A\n",
      "Epoch 9:  20%|██        | 30/148 [00:28<01:48,  1.09it/s, training_loss=1.0858]\u001b[A\n",
      "Epoch 9:  21%|██        | 31/148 [00:28<01:47,  1.09it/s, training_loss=1.0858]\u001b[A\n",
      "Epoch 9:  21%|██        | 31/148 [00:29<01:47,  1.09it/s, training_loss=1.1235]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 32/148 [00:29<01:46,  1.09it/s, training_loss=1.1235]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 32/148 [00:30<01:46,  1.09it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 33/148 [00:30<01:45,  1.09it/s, training_loss=1.6115]\u001b[A\n",
      "Epoch 9:  22%|██▏       | 33/148 [00:31<01:45,  1.09it/s, training_loss=1.6101]\u001b[A\n",
      "Epoch 9:  23%|██▎       | 34/148 [00:31<01:44,  1.09it/s, training_loss=1.6101]\u001b[A\n",
      "Epoch 9:  23%|██▎       | 34/148 [00:32<01:44,  1.09it/s, training_loss=0.9180]\u001b[A\n",
      "Epoch 9:  24%|██▎       | 35/148 [00:32<01:43,  1.09it/s, training_loss=0.9180]\u001b[A\n",
      "Epoch 9:  24%|██▎       | 35/148 [00:33<01:43,  1.09it/s, training_loss=1.5618]\u001b[A\n",
      "Epoch 9:  24%|██▍       | 36/148 [00:33<01:42,  1.09it/s, training_loss=1.5618]\u001b[A\n",
      "Epoch 9:  24%|██▍       | 36/148 [00:34<01:42,  1.09it/s, training_loss=0.8761]\u001b[A\n",
      "Epoch 9:  25%|██▌       | 37/148 [00:34<01:41,  1.09it/s, training_loss=0.8761]\u001b[A\n",
      "Epoch 9:  25%|██▌       | 37/148 [00:34<01:41,  1.09it/s, training_loss=1.5095]\u001b[A\n",
      "Epoch 9:  26%|██▌       | 38/148 [00:34<01:41,  1.09it/s, training_loss=1.5095]\u001b[A\n",
      "Epoch 9:  26%|██▌       | 38/148 [00:35<01:41,  1.09it/s, training_loss=1.5683]\u001b[A\n",
      "Epoch 9:  26%|██▋       | 39/148 [00:35<01:39,  1.09it/s, training_loss=1.5683]\u001b[A\n",
      "Epoch 9:  26%|██▋       | 39/148 [00:36<01:39,  1.09it/s, training_loss=1.0591]\u001b[A\n",
      "Epoch 9:  27%|██▋       | 40/148 [00:36<01:39,  1.09it/s, training_loss=1.0591]\u001b[A\n",
      "Epoch 9:  27%|██▋       | 40/148 [00:37<01:39,  1.09it/s, training_loss=0.9660]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=0.9660]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=0.8580]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=0.8580]\u001b[A\n",
      "Epoch 9:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=0.9110]\u001b[A\n",
      "Epoch 9:  29%|██▉       | 43/148 [00:39<01:36,  1.09it/s, training_loss=0.9110]\u001b[A\n",
      "Epoch 9:  29%|██▉       | 43/148 [00:40<01:36,  1.09it/s, training_loss=1.6203]\u001b[A\n",
      "Epoch 9:  30%|██▉       | 44/148 [00:40<01:35,  1.09it/s, training_loss=1.6203]\u001b[A\n",
      "Epoch 9:  30%|██▉       | 44/148 [00:41<01:35,  1.09it/s, training_loss=1.0522]\u001b[A\n",
      "Epoch 9:  30%|███       | 45/148 [00:41<01:34,  1.09it/s, training_loss=1.0522]\u001b[A\n",
      "Epoch 9:  30%|███       | 45/148 [00:42<01:34,  1.09it/s, training_loss=0.8490]\u001b[A\n",
      "Epoch 9:  31%|███       | 46/148 [00:42<01:33,  1.09it/s, training_loss=0.8490]\u001b[A\n",
      "Epoch 9:  31%|███       | 46/148 [00:43<01:33,  1.09it/s, training_loss=1.5537]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.5537]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.5431]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 48/148 [00:44<01:31,  1.09it/s, training_loss=1.5431]\u001b[A\n",
      "Epoch 9:  32%|███▏      | 48/148 [00:45<01:31,  1.09it/s, training_loss=0.9509]\u001b[A\n",
      "Epoch 9:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=0.9509]\u001b[A\n",
      "Epoch 9:  33%|███▎      | 49/148 [00:45<01:30,  1.09it/s, training_loss=0.8753]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 50/148 [00:45<01:30,  1.09it/s, training_loss=0.8753]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 50/148 [00:46<01:30,  1.09it/s, training_loss=1.1006]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 51/148 [00:46<01:29,  1.08it/s, training_loss=1.1006]\u001b[A\n",
      "Epoch 9:  34%|███▍      | 51/148 [00:47<01:29,  1.08it/s, training_loss=1.0192]\u001b[A\n",
      "Epoch 9:  35%|███▌      | 52/148 [00:47<01:28,  1.09it/s, training_loss=1.0192]\u001b[A\n",
      "Epoch 9:  35%|███▌      | 52/148 [00:48<01:28,  1.09it/s, training_loss=1.6688]\u001b[A\n",
      "Epoch 9:  36%|███▌      | 53/148 [00:48<01:27,  1.09it/s, training_loss=1.6688]\u001b[A\n",
      "Epoch 9:  36%|███▌      | 53/148 [00:49<01:27,  1.09it/s, training_loss=0.8304]\u001b[A\n",
      "Epoch 9:  36%|███▋      | 54/148 [00:49<01:26,  1.09it/s, training_loss=0.8304]\u001b[A\n",
      "Epoch 9:  36%|███▋      | 54/148 [00:50<01:26,  1.09it/s, training_loss=1.4451]\u001b[A\n",
      "Epoch 9:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=1.4451]\u001b[A\n",
      "Epoch 9:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.5698]\u001b[A\n",
      "Epoch 9:  38%|███▊      | 56/148 [00:51<01:24,  1.09it/s, training_loss=1.5698]\u001b[A\n",
      "Epoch 9:  38%|███▊      | 56/148 [00:52<01:24,  1.09it/s, training_loss=0.8747]\u001b[A\n",
      "Epoch 9:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=0.8747]\u001b[A\n",
      "Epoch 9:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=1.5035]\u001b[A\n",
      "Epoch 9:  39%|███▉      | 58/148 [00:53<01:22,  1.09it/s, training_loss=1.5035]\u001b[A\n",
      "Epoch 9:  39%|███▉      | 58/148 [00:54<01:22,  1.09it/s, training_loss=0.8778]\u001b[A\n",
      "Epoch 9:  40%|███▉      | 59/148 [00:54<01:21,  1.09it/s, training_loss=0.8778]\u001b[A\n",
      "Epoch 9:  40%|███▉      | 59/148 [00:55<01:21,  1.09it/s, training_loss=0.9364]\u001b[A\n",
      "Epoch 9:  41%|████      | 60/148 [00:55<01:20,  1.09it/s, training_loss=0.9364]\u001b[A\n",
      "Epoch 9:  41%|████      | 60/148 [00:56<01:20,  1.09it/s, training_loss=1.6910]\u001b[A\n",
      "Epoch 9:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=1.6910]\u001b[A\n",
      "Epoch 9:  41%|████      | 61/148 [00:56<01:19,  1.09it/s, training_loss=0.8126]\u001b[A\n",
      "Epoch 9:  42%|████▏     | 62/148 [00:56<01:18,  1.10it/s, training_loss=0.8126]\u001b[A\n",
      "Epoch 9:  42%|████▏     | 62/148 [00:57<01:18,  1.10it/s, training_loss=1.0545]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 63/148 [00:57<01:17,  1.09it/s, training_loss=1.0545]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 63/148 [00:58<01:17,  1.09it/s, training_loss=0.8750]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 64/148 [00:58<01:16,  1.09it/s, training_loss=0.8750]\u001b[A\n",
      "Epoch 9:  43%|████▎     | 64/148 [00:59<01:16,  1.09it/s, training_loss=1.4522]\u001b[A\n",
      "Epoch 9:  44%|████▍     | 65/148 [00:59<01:15,  1.09it/s, training_loss=1.4522]\u001b[A\n",
      "Epoch 9:  44%|████▍     | 65/148 [01:00<01:15,  1.09it/s, training_loss=0.8742]\u001b[A\n",
      "Epoch 9:  45%|████▍     | 66/148 [01:00<01:15,  1.09it/s, training_loss=0.8742]\u001b[A\n",
      "Epoch 9:  45%|████▍     | 66/148 [01:01<01:15,  1.09it/s, training_loss=1.5267]\u001b[A\n",
      "Epoch 9:  45%|████▌     | 67/148 [01:01<01:14,  1.09it/s, training_loss=1.5267]\u001b[A\n",
      "Epoch 9:  45%|████▌     | 67/148 [01:02<01:14,  1.09it/s, training_loss=1.0890]\u001b[A\n",
      "Epoch 9:  46%|████▌     | 68/148 [01:02<01:13,  1.09it/s, training_loss=1.0890]\u001b[A\n",
      "Epoch 9:  46%|████▌     | 68/148 [01:03<01:13,  1.09it/s, training_loss=1.5284]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 69/148 [01:03<01:12,  1.09it/s, training_loss=1.5284]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 69/148 [01:04<01:12,  1.09it/s, training_loss=1.0193]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 70/148 [01:04<01:11,  1.09it/s, training_loss=1.0193]\u001b[A\n",
      "Epoch 9:  47%|████▋     | 70/148 [01:05<01:11,  1.09it/s, training_loss=1.0271]\u001b[A\n",
      "Epoch 9:  48%|████▊     | 71/148 [01:05<01:10,  1.09it/s, training_loss=1.0271]\u001b[A\n",
      "Epoch 9:  48%|████▊     | 71/148 [01:06<01:10,  1.09it/s, training_loss=1.0440]\u001b[A\n",
      "Epoch 9:  49%|████▊     | 72/148 [01:06<01:09,  1.10it/s, training_loss=1.0440]\u001b[A\n",
      "Epoch 9:  49%|████▊     | 72/148 [01:06<01:09,  1.10it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 9:  49%|████▉     | 73/148 [01:06<01:08,  1.10it/s, training_loss=1.5051]\u001b[A\n",
      "Epoch 9:  49%|████▉     | 73/148 [01:07<01:08,  1.10it/s, training_loss=0.8402]\u001b[A\n",
      "Epoch 9:  50%|█████     | 74/148 [01:07<01:07,  1.10it/s, training_loss=0.8402]\u001b[A\n",
      "Epoch 9:  50%|█████     | 74/148 [01:08<01:07,  1.10it/s, training_loss=1.4224]\u001b[A\n",
      "Epoch 9:  51%|█████     | 75/148 [01:08<01:06,  1.09it/s, training_loss=1.4224]\u001b[A\n",
      "Epoch 9:  51%|█████     | 75/148 [01:09<01:06,  1.09it/s, training_loss=1.5635]\u001b[A\n",
      "Epoch 9:  51%|█████▏    | 76/148 [01:09<01:05,  1.09it/s, training_loss=1.5635]\u001b[A\n",
      "Epoch 9:  51%|█████▏    | 76/148 [01:10<01:05,  1.09it/s, training_loss=0.9123]\u001b[A\n",
      "Epoch 9:  52%|█████▏    | 77/148 [01:10<01:04,  1.09it/s, training_loss=0.9123]\u001b[A\n",
      "Epoch 9:  52%|█████▏    | 77/148 [01:11<01:04,  1.09it/s, training_loss=1.6182]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 78/148 [01:11<01:03,  1.10it/s, training_loss=1.6182]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 78/148 [01:12<01:03,  1.10it/s, training_loss=1.6577]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 79/148 [01:12<01:02,  1.10it/s, training_loss=1.6577]\u001b[A\n",
      "Epoch 9:  53%|█████▎    | 79/148 [01:13<01:02,  1.10it/s, training_loss=1.5078]\u001b[A\n",
      "Epoch 9:  54%|█████▍    | 80/148 [01:13<01:01,  1.10it/s, training_loss=1.5078]\u001b[A\n",
      "Epoch 9:  54%|█████▍    | 80/148 [01:14<01:01,  1.10it/s, training_loss=0.9022]\u001b[A\n",
      "Epoch 9:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=0.9022]\u001b[A\n",
      "Epoch 9:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=0.8737]\u001b[A\n",
      "Epoch 9:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=0.8737]\u001b[A\n",
      "Epoch 9:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.5618]\u001b[A\n",
      "Epoch 9:  56%|█████▌    | 83/148 [01:16<00:59,  1.10it/s, training_loss=1.5618]\u001b[A\n",
      "Epoch 9:  56%|█████▌    | 83/148 [01:17<00:59,  1.10it/s, training_loss=1.6300]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 84/148 [01:17<00:58,  1.10it/s, training_loss=1.6300]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 84/148 [01:17<00:58,  1.10it/s, training_loss=0.9116]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 85/148 [01:17<00:57,  1.09it/s, training_loss=0.9116]\u001b[A\n",
      "Epoch 9:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=0.9518]\u001b[A\n",
      "Epoch 9:  58%|█████▊    | 86/148 [01:18<00:56,  1.09it/s, training_loss=0.9518]\u001b[A\n",
      "Epoch 9:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.5321]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 87/148 [01:19<00:55,  1.09it/s, training_loss=1.5321]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 87/148 [01:20<00:55,  1.09it/s, training_loss=0.8746]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 88/148 [01:20<00:54,  1.09it/s, training_loss=0.8746]\u001b[A\n",
      "Epoch 9:  59%|█████▉    | 88/148 [01:21<00:54,  1.09it/s, training_loss=1.5907]\u001b[A\n",
      "Epoch 9:  60%|██████    | 89/148 [01:21<00:54,  1.09it/s, training_loss=1.5907]\u001b[A\n",
      "Epoch 9:  60%|██████    | 89/148 [01:22<00:54,  1.09it/s, training_loss=1.0143]\u001b[A\n",
      "Epoch 9:  61%|██████    | 90/148 [01:22<00:53,  1.09it/s, training_loss=1.0143]\u001b[A\n",
      "Epoch 9:  61%|██████    | 90/148 [01:23<00:53,  1.09it/s, training_loss=0.8515]\u001b[A\n",
      "Epoch 9:  61%|██████▏   | 91/148 [01:23<00:52,  1.09it/s, training_loss=0.8515]\u001b[A\n",
      "Epoch 9:  61%|██████▏   | 91/148 [01:24<00:52,  1.09it/s, training_loss=1.0643]\u001b[A\n",
      "Epoch 9:  62%|██████▏   | 92/148 [01:24<00:51,  1.09it/s, training_loss=1.0643]\u001b[A\n",
      "Epoch 9:  62%|██████▏   | 92/148 [01:25<00:51,  1.09it/s, training_loss=0.9526]\u001b[A\n",
      "Epoch 9:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=0.9526]\u001b[A\n",
      "Epoch 9:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.5196]\u001b[A\n",
      "Epoch 9:  64%|██████▎   | 94/148 [01:26<00:49,  1.09it/s, training_loss=1.5196]\u001b[A\n",
      "Epoch 9:  64%|██████▎   | 94/148 [01:27<00:49,  1.09it/s, training_loss=1.0312]\u001b[A\n",
      "Epoch 9:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.0312]\u001b[A\n",
      "Epoch 9:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=1.5458]\u001b[A\n",
      "Epoch 9:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.5458]\u001b[A\n",
      "Epoch 9:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.0658]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 97/148 [01:28<00:46,  1.09it/s, training_loss=1.0658]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 97/148 [01:29<00:46,  1.09it/s, training_loss=1.0063]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 98/148 [01:29<00:45,  1.09it/s, training_loss=1.0063]\u001b[A\n",
      "Epoch 9:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=0.9178]\u001b[A\n",
      "Epoch 9:  67%|██████▋   | 99/148 [01:30<00:44,  1.09it/s, training_loss=0.9178]\u001b[A\n",
      "Epoch 9:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=1.5301]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 100/148 [01:31<00:43,  1.09it/s, training_loss=1.5301]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 100/148 [01:32<00:43,  1.09it/s, training_loss=1.5789]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 101/148 [01:32<00:42,  1.10it/s, training_loss=1.5789]\u001b[A\n",
      "Epoch 9:  68%|██████▊   | 101/148 [01:33<00:42,  1.10it/s, training_loss=1.6470]\u001b[A\n",
      "Epoch 9:  69%|██████▉   | 102/148 [01:33<00:42,  1.09it/s, training_loss=1.6470]\u001b[A\n",
      "Epoch 9:  69%|██████▉   | 102/148 [01:34<00:42,  1.09it/s, training_loss=0.8577]\u001b[A\n",
      "Epoch 9:  70%|██████▉   | 103/148 [01:34<00:41,  1.09it/s, training_loss=0.8577]\u001b[A\n",
      "Epoch 9:  70%|██████▉   | 103/148 [01:35<00:41,  1.09it/s, training_loss=1.0843]\u001b[A\n",
      "Epoch 9:  70%|███████   | 104/148 [01:35<00:40,  1.09it/s, training_loss=1.0843]\u001b[A\n",
      "Epoch 9:  70%|███████   | 104/148 [01:36<00:40,  1.09it/s, training_loss=1.5671]\u001b[A\n",
      "Epoch 9:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=1.5671]\u001b[A\n",
      "Epoch 9:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=1.0371]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=1.0371]\u001b[A\n",
      "Epoch 9:  72%|███████▏  | 107/148 [01:39<00:37,  1.09it/s, training_loss=0.8075]\u001b[A\n",
      "Epoch 9:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=0.8075]\u001b[A\n",
      "Epoch 9:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=1.0037]\u001b[A\n",
      "Epoch 9:  74%|███████▎  | 109/148 [01:39<00:35,  1.09it/s, training_loss=1.0037]\u001b[A\n",
      "Epoch 9:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=1.0127]\u001b[A\n",
      "Epoch 9:  74%|███████▍  | 110/148 [01:40<00:34,  1.09it/s, training_loss=1.0127]\u001b[A\n",
      "Epoch 9:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.4271]\u001b[A\n",
      "Epoch 9:  75%|███████▌  | 111/148 [01:41<00:33,  1.09it/s, training_loss=1.4271]\u001b[A\n",
      "Epoch 9:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=1.0020]\u001b[A\n",
      "Epoch 9:  76%|███████▌  | 112/148 [01:42<00:32,  1.09it/s, training_loss=1.0020]\u001b[A\n",
      "Epoch 9:  76%|███████▌  | 112/148 [01:43<00:32,  1.09it/s, training_loss=0.8658]\u001b[A\n",
      "Epoch 9:  76%|███████▋  | 113/148 [01:43<00:32,  1.09it/s, training_loss=0.8658]\u001b[A\n",
      "Epoch 9:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=0.8590]\u001b[A\n",
      "Epoch 9:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=0.8590]\u001b[A\n",
      "Epoch 9:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.5922]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.5922]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=0.8412]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=0.8412]\u001b[A\n",
      "Epoch 9:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=1.4920]\u001b[A\n",
      "Epoch 9:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.4920]\u001b[A\n",
      "Epoch 9:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=0.9697]\u001b[A\n",
      "Epoch 9:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=0.9697]\u001b[A\n",
      "Epoch 9:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.5837]\u001b[A\n",
      "Epoch 9:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.5837]\u001b[A\n",
      "Epoch 9:  80%|████████  | 119/148 [01:50<00:26,  1.09it/s, training_loss=0.9730]\u001b[A\n",
      "Epoch 9:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=0.9730]\u001b[A\n",
      "Epoch 9:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.1091]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 121/148 [01:50<00:24,  1.08it/s, training_loss=1.1091]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 121/148 [01:51<00:24,  1.08it/s, training_loss=1.5238]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 122/148 [01:51<00:24,  1.08it/s, training_loss=1.5238]\u001b[A\n",
      "Epoch 9:  82%|████████▏ | 122/148 [01:52<00:24,  1.08it/s, training_loss=1.5057]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 123/148 [01:52<00:23,  1.09it/s, training_loss=1.5057]\u001b[A\n",
      "Epoch 9:  83%|████████▎ | 123/148 [01:53<00:23,  1.09it/s, training_loss=0.9767]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 124/148 [01:53<00:22,  1.08it/s, training_loss=0.9767]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 124/148 [01:54<00:22,  1.08it/s, training_loss=1.5480]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 125/148 [01:54<00:21,  1.08it/s, training_loss=1.5480]\u001b[A\n",
      "Epoch 9:  84%|████████▍ | 125/148 [01:55<00:21,  1.08it/s, training_loss=0.9144]\u001b[A\n",
      "Epoch 9:  85%|████████▌ | 126/148 [01:55<00:20,  1.09it/s, training_loss=0.9144]\u001b[A\n",
      "Epoch 9:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=1.5292]\u001b[A\n",
      "Epoch 9:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=1.5292]\u001b[A\n",
      "Epoch 9:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.5198]\u001b[A\n",
      "Epoch 9:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.5198]\u001b[A\n",
      "Epoch 9:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.3160]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.3160]\u001b[A\n",
      "Epoch 9:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=1.6112]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.6112]\u001b[A\n",
      "Epoch 9:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=1.5165]\u001b[A\n",
      "Epoch 9:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.5165]\u001b[A\n",
      "Epoch 9:  89%|████████▊ | 131/148 [02:01<00:15,  1.09it/s, training_loss=0.9440]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=0.9440]\u001b[A\n",
      "Epoch 9:  89%|████████▉ | 132/148 [02:02<00:14,  1.09it/s, training_loss=1.4971]\u001b[A\n",
      "Epoch 9:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=1.4971]\u001b[A\n",
      "Epoch 9:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=0.9536]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 134/148 [02:02<00:12,  1.08it/s, training_loss=0.9536]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 134/148 [02:03<00:12,  1.08it/s, training_loss=0.8425]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 135/148 [02:03<00:11,  1.09it/s, training_loss=0.8425]\u001b[A\n",
      "Epoch 9:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=1.4885]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 136/148 [02:04<00:11,  1.09it/s, training_loss=1.4885]\u001b[A\n",
      "Epoch 9:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.6490]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=1.6490]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.4948]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.4948]\u001b[A\n",
      "Epoch 9:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.5570]\u001b[A\n",
      "Epoch 9:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=0.9472]\u001b[A\n",
      "Epoch 9:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=0.9472]\u001b[A\n",
      "Epoch 9:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=1.5333]\u001b[A\n",
      "Epoch 9:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=1.5333]\u001b[A\n",
      "Epoch 9:  95%|█████████▌| 141/148 [02:10<00:06,  1.09it/s, training_loss=1.5179]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=1.5179]\u001b[A\n",
      "Epoch 9:  96%|█████████▌| 142/148 [02:11<00:05,  1.09it/s, training_loss=1.5171]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.5171]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=1.5128]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 144/148 [02:12<00:03,  1.10it/s, training_loss=1.5128]\u001b[A\n",
      "Epoch 9:  97%|█████████▋| 144/148 [02:12<00:03,  1.10it/s, training_loss=1.5384]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 145/148 [02:13<00:02,  1.10it/s, training_loss=1.5384]\u001b[A\n",
      "Epoch 9:  98%|█████████▊| 145/148 [02:13<00:02,  1.10it/s, training_loss=0.8874]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 146/148 [02:13<00:01,  1.09it/s, training_loss=0.8874]\u001b[A\n",
      "Epoch 9:  99%|█████████▊| 146/148 [02:14<00:01,  1.09it/s, training_loss=1.5812]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 147/148 [02:14<00:00,  1.10it/s, training_loss=1.5812]\u001b[A\n",
      "Epoch 9:  99%|█████████▉| 147/148 [02:15<00:00,  1.10it/s, training_loss=0.8492]\u001b[A\n",
      "Epoch 9: 100%|██████████| 148/148 [02:15<00:00,  1.19it/s, training_loss=0.8492]\u001b[A\n",
      "                                                                                \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:48:00,656 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:48:00,659 - INFO - Memory usage after evaluation start: 3943.80 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.70it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.66it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.61it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.62it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.60it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.60it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.60it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.60it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.60it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.59it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.59it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.60it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.59it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.60it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.62it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.62it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.62it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:48:07,907 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 19:48:07,921 - INFO - Class 'Drama': Optimal threshold = 0.500, F1 Score = 0.560\n",
      "2025-02-16 19:48:07,935 - INFO - Class 'Horor': Optimal threshold = 0.600, F1 Score = 0.768\n",
      "2025-02-16 19:48:07,950 - INFO - Class 'Komedi': Optimal threshold = 0.650, F1 Score = 0.535\n",
      "2025-02-16 19:48:07,964 - INFO - Class 'Laga': Optimal threshold = 0.550, F1 Score = 0.351\n",
      "2025-02-16 19:48:07,977 - INFO - Class 'Romantis': Optimal threshold = 0.700, F1 Score = 0.563\n",
      "2025-02-16 19:48:08,000 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:48:08,006 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:48:08,007 - INFO - Accuracy: 0.6513\n",
      "2025-02-16 19:48:08,007 - INFO - F1_score: 0.5604\n",
      "2025-02-16 19:48:08,008 - INFO - Precision: 0.4361\n",
      "2025-02-16 19:48:08,010 - INFO - Recall: 0.7838\n",
      "2025-02-16 19:48:08,015 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:48:08,016 - INFO - Accuracy: 0.8889\n",
      "2025-02-16 19:48:08,017 - INFO - F1_score: 0.7680\n",
      "2025-02-16 19:48:08,017 - INFO - Precision: 0.7059\n",
      "2025-02-16 19:48:08,018 - INFO - Recall: 0.8421\n",
      "2025-02-16 19:48:08,024 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:48:08,025 - INFO - Accuracy: 0.7471\n",
      "2025-02-16 19:48:08,025 - INFO - F1_score: 0.5352\n",
      "2025-02-16 19:48:08,026 - INFO - Precision: 0.4524\n",
      "2025-02-16 19:48:08,027 - INFO - Recall: 0.6552\n",
      "2025-02-16 19:48:08,033 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:48:08,033 - INFO - Accuracy: 0.7165\n",
      "2025-02-16 19:48:08,034 - INFO - F1_score: 0.3509\n",
      "2025-02-16 19:48:08,034 - INFO - Precision: 0.2632\n",
      "2025-02-16 19:48:08,035 - INFO - Recall: 0.5263\n",
      "2025-02-16 19:48:08,041 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:48:08,042 - INFO - Accuracy: 0.8812\n",
      "2025-02-16 19:48:08,042 - INFO - F1_score: 0.5634\n",
      "2025-02-16 19:48:08,043 - INFO - Precision: 0.5405\n",
      "2025-02-16 19:48:08,043 - INFO - Recall: 0.5882\n",
      "2025-02-16 19:48:08,045 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:48:11,942 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:48:11,943 - INFO - Memory usage after evaluation end: 3949.43 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   8%|▊         | 8/100 [23:13<3:56:55, 154.51s/it, Train Loss=1.2364, Val Loss=0.0523, Accuracy=0.7770]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:48:19,189 - INFO - Learning rate: 2.5e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [23:13<3:54:07, 154.37s/it, Train Loss=1.2364, Val Loss=0.0523, Accuracy=0.7770]\n",
      "Epoch 10:   0%|          | 0/148 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:   0%|          | 0/148 [00:00<?, ?it/s, training_loss=1.1094]\u001b[A\n",
      "Epoch 10:   1%|          | 1/148 [00:00<02:13,  1.10it/s, training_loss=1.1094]\u001b[A\n",
      "Epoch 10:   1%|          | 1/148 [00:01<02:13,  1.10it/s, training_loss=1.0440]\u001b[A\n",
      "Epoch 10:   1%|▏         | 2/148 [00:01<02:13,  1.10it/s, training_loss=1.0440]\u001b[A\n",
      "Epoch 10:   1%|▏         | 2/148 [00:02<02:13,  1.10it/s, training_loss=0.9161]\u001b[A\n",
      "Epoch 10:   2%|▏         | 3/148 [00:02<02:12,  1.09it/s, training_loss=0.9161]\u001b[A\n",
      "Epoch 10:   2%|▏         | 3/148 [00:03<02:12,  1.09it/s, training_loss=1.6043]\u001b[A\n",
      "Epoch 10:   3%|▎         | 4/148 [00:03<02:11,  1.10it/s, training_loss=1.6043]\u001b[A\n",
      "Epoch 10:   3%|▎         | 4/148 [00:04<02:11,  1.10it/s, training_loss=0.9361]\u001b[A\n",
      "Epoch 10:   3%|▎         | 5/148 [00:04<02:10,  1.09it/s, training_loss=0.9361]\u001b[A\n",
      "Epoch 10:   3%|▎         | 5/148 [00:05<02:10,  1.09it/s, training_loss=1.0480]\u001b[A\n",
      "Epoch 10:   4%|▍         | 6/148 [00:05<02:10,  1.09it/s, training_loss=1.0480]\u001b[A\n",
      "Epoch 10:   4%|▍         | 6/148 [00:06<02:10,  1.09it/s, training_loss=0.9936]\u001b[A\n",
      "Epoch 10:   5%|▍         | 7/148 [00:06<02:09,  1.09it/s, training_loss=0.9936]\u001b[A\n",
      "Epoch 10:   5%|▍         | 7/148 [00:07<02:09,  1.09it/s, training_loss=0.8380]\u001b[A\n",
      "Epoch 10:   5%|▌         | 8/148 [00:07<02:08,  1.09it/s, training_loss=0.8380]\u001b[A\n",
      "Epoch 10:   5%|▌         | 8/148 [00:08<02:08,  1.09it/s, training_loss=0.9258]\u001b[A\n",
      "Epoch 10:   6%|▌         | 9/148 [00:08<02:08,  1.08it/s, training_loss=0.9258]\u001b[A\n",
      "Epoch 10:   6%|▌         | 9/148 [00:09<02:08,  1.08it/s, training_loss=0.9014]\u001b[A\n",
      "Epoch 10:   7%|▋         | 10/148 [00:09<02:06,  1.09it/s, training_loss=0.9014]\u001b[A\n",
      "Epoch 10:   7%|▋         | 10/148 [00:10<02:06,  1.09it/s, training_loss=1.5374]\u001b[A\n",
      "Epoch 10:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.5374]\u001b[A\n",
      "Epoch 10:   7%|▋         | 11/148 [00:10<02:05,  1.09it/s, training_loss=1.6747]\u001b[A\n",
      "Epoch 10:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.6747]\u001b[A\n",
      "Epoch 10:   8%|▊         | 12/148 [00:11<02:04,  1.09it/s, training_loss=1.3172]\u001b[A\n",
      "Epoch 10:   9%|▉         | 13/148 [00:11<02:03,  1.09it/s, training_loss=1.3172]\u001b[A\n",
      "Epoch 10:   9%|▉         | 13/148 [00:12<02:03,  1.09it/s, training_loss=1.6100]\u001b[A\n",
      "Epoch 10:   9%|▉         | 14/148 [00:12<02:02,  1.09it/s, training_loss=1.6100]\u001b[A\n",
      "Epoch 10:   9%|▉         | 14/148 [00:13<02:02,  1.09it/s, training_loss=0.9942]\u001b[A\n",
      "Epoch 10:  10%|█         | 15/148 [00:13<02:01,  1.09it/s, training_loss=0.9942]\u001b[A\n",
      "Epoch 10:  10%|█         | 15/148 [00:14<02:01,  1.09it/s, training_loss=0.9781]\u001b[A\n",
      "Epoch 10:  11%|█         | 16/148 [00:14<02:01,  1.09it/s, training_loss=0.9781]\u001b[A\n",
      "Epoch 10:  11%|█         | 16/148 [00:15<02:01,  1.09it/s, training_loss=1.6843]\u001b[A\n",
      "Epoch 10:  11%|█▏        | 17/148 [00:15<02:00,  1.09it/s, training_loss=1.6843]\u001b[A\n",
      "Epoch 10:  11%|█▏        | 17/148 [00:16<02:00,  1.09it/s, training_loss=1.4234]\u001b[A\n",
      "Epoch 10:  12%|█▏        | 18/148 [00:16<01:59,  1.09it/s, training_loss=1.4234]\u001b[A\n",
      "Epoch 10:  12%|█▏        | 18/148 [00:17<01:59,  1.09it/s, training_loss=1.6188]\u001b[A\n",
      "Epoch 10:  13%|█▎        | 19/148 [00:17<01:58,  1.09it/s, training_loss=1.6188]\u001b[A\n",
      "Epoch 10:  13%|█▎        | 19/148 [00:18<01:58,  1.09it/s, training_loss=0.8436]\u001b[A\n",
      "Epoch 10:  14%|█▎        | 20/148 [00:18<01:58,  1.08it/s, training_loss=0.8436]\u001b[A\n",
      "Epoch 10:  14%|█▎        | 20/148 [00:19<01:58,  1.08it/s, training_loss=1.5615]\u001b[A\n",
      "Epoch 10:  14%|█▍        | 21/148 [00:19<01:56,  1.09it/s, training_loss=1.5615]\u001b[A\n",
      "Epoch 10:  14%|█▍        | 21/148 [00:20<01:56,  1.09it/s, training_loss=0.8831]\u001b[A\n",
      "Epoch 10:  15%|█▍        | 22/148 [00:20<01:55,  1.09it/s, training_loss=0.8831]\u001b[A\n",
      "Epoch 10:  15%|█▍        | 22/148 [00:21<01:55,  1.09it/s, training_loss=0.8249]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 23/148 [00:21<01:55,  1.09it/s, training_loss=0.8249]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 23/148 [00:22<01:55,  1.09it/s, training_loss=0.8888]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=0.8888]\u001b[A\n",
      "Epoch 10:  16%|█▌        | 24/148 [00:22<01:54,  1.08it/s, training_loss=0.8602]\u001b[A\n",
      "Epoch 10:  17%|█▋        | 25/148 [00:22<01:53,  1.08it/s, training_loss=0.8602]\u001b[A\n",
      "Epoch 10:  17%|█▋        | 25/148 [00:23<01:53,  1.08it/s, training_loss=1.6116]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 26/148 [00:23<01:52,  1.08it/s, training_loss=1.6116]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 26/148 [00:24<01:52,  1.08it/s, training_loss=0.8596]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 27/148 [00:24<01:51,  1.08it/s, training_loss=0.8596]\u001b[A\n",
      "Epoch 10:  18%|█▊        | 27/148 [00:25<01:51,  1.08it/s, training_loss=0.8794]\u001b[A\n",
      "Epoch 10:  19%|█▉        | 28/148 [00:25<01:51,  1.08it/s, training_loss=0.8794]\u001b[A\n",
      "Epoch 10:  19%|█▉        | 28/148 [00:26<01:51,  1.08it/s, training_loss=0.9425]\u001b[A\n",
      "Epoch 10:  20%|█▉        | 29/148 [00:26<01:50,  1.08it/s, training_loss=0.9425]\u001b[A\n",
      "Epoch 10:  20%|█▉        | 29/148 [00:27<01:50,  1.08it/s, training_loss=1.4881]\u001b[A\n",
      "Epoch 10:  20%|██        | 30/148 [00:27<01:49,  1.08it/s, training_loss=1.4881]\u001b[A\n",
      "Epoch 10:  20%|██        | 30/148 [00:28<01:49,  1.08it/s, training_loss=0.9591]\u001b[A\n",
      "Epoch 10:  21%|██        | 31/148 [00:28<01:48,  1.08it/s, training_loss=0.9591]\u001b[A\n",
      "Epoch 10:  21%|██        | 31/148 [00:29<01:48,  1.08it/s, training_loss=0.8906]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 32/148 [00:29<01:47,  1.08it/s, training_loss=0.8906]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 32/148 [00:30<01:47,  1.08it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 33/148 [00:30<01:45,  1.09it/s, training_loss=1.5939]\u001b[A\n",
      "Epoch 10:  22%|██▏       | 33/148 [00:31<01:45,  1.09it/s, training_loss=1.5386]\u001b[A\n",
      "Epoch 10:  23%|██▎       | 34/148 [00:31<01:44,  1.09it/s, training_loss=1.5386]\u001b[A\n",
      "Epoch 10:  23%|██▎       | 34/148 [00:32<01:44,  1.09it/s, training_loss=0.8352]\u001b[A\n",
      "Epoch 10:  24%|██▎       | 35/148 [00:32<01:43,  1.09it/s, training_loss=0.8352]\u001b[A\n",
      "Epoch 10:  24%|██▎       | 35/148 [00:33<01:43,  1.09it/s, training_loss=0.9555]\u001b[A\n",
      "Epoch 10:  24%|██▍       | 36/148 [00:33<01:43,  1.08it/s, training_loss=0.9555]\u001b[A\n",
      "Epoch 10:  24%|██▍       | 36/148 [00:34<01:43,  1.08it/s, training_loss=0.9107]\u001b[A\n",
      "Epoch 10:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=0.9107]\u001b[A\n",
      "Epoch 10:  25%|██▌       | 37/148 [00:34<01:42,  1.08it/s, training_loss=1.0151]\u001b[A\n",
      "Epoch 10:  26%|██▌       | 38/148 [00:34<01:41,  1.08it/s, training_loss=1.0151]\u001b[A\n",
      "Epoch 10:  26%|██▌       | 38/148 [00:35<01:41,  1.08it/s, training_loss=1.0740]\u001b[A\n",
      "Epoch 10:  26%|██▋       | 39/148 [00:35<01:40,  1.08it/s, training_loss=1.0740]\u001b[A\n",
      "Epoch 10:  26%|██▋       | 39/148 [00:36<01:40,  1.08it/s, training_loss=1.5245]\u001b[A\n",
      "Epoch 10:  27%|██▋       | 40/148 [00:36<01:39,  1.09it/s, training_loss=1.5245]\u001b[A\n",
      "Epoch 10:  27%|██▋       | 40/148 [00:37<01:39,  1.09it/s, training_loss=1.0037]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 41/148 [00:37<01:38,  1.09it/s, training_loss=1.0037]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 41/148 [00:38<01:38,  1.09it/s, training_loss=1.0572]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 42/148 [00:38<01:37,  1.09it/s, training_loss=1.0572]\u001b[A\n",
      "Epoch 10:  28%|██▊       | 42/148 [00:39<01:37,  1.09it/s, training_loss=0.9936]\u001b[A\n",
      "Epoch 10:  29%|██▉       | 43/148 [00:39<01:36,  1.09it/s, training_loss=0.9936]\u001b[A\n",
      "Epoch 10:  29%|██▉       | 43/148 [00:40<01:36,  1.09it/s, training_loss=0.8675]\u001b[A\n",
      "Epoch 10:  30%|██▉       | 44/148 [00:40<01:35,  1.09it/s, training_loss=0.8675]\u001b[A\n",
      "Epoch 10:  30%|██▉       | 44/148 [00:41<01:35,  1.09it/s, training_loss=1.1698]\u001b[A\n",
      "Epoch 10:  30%|███       | 45/148 [00:41<01:34,  1.09it/s, training_loss=1.1698]\u001b[A\n",
      "Epoch 10:  30%|███       | 45/148 [00:42<01:34,  1.09it/s, training_loss=0.8851]\u001b[A\n",
      "Epoch 10:  31%|███       | 46/148 [00:42<01:34,  1.08it/s, training_loss=0.8851]\u001b[A\n",
      "Epoch 10:  31%|███       | 46/148 [00:43<01:34,  1.08it/s, training_loss=1.5108]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 47/148 [00:43<01:32,  1.09it/s, training_loss=1.5108]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 47/148 [00:44<01:32,  1.09it/s, training_loss=1.0444]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 48/148 [00:44<01:32,  1.08it/s, training_loss=1.0444]\u001b[A\n",
      "Epoch 10:  32%|███▏      | 48/148 [00:45<01:32,  1.08it/s, training_loss=1.6322]\u001b[A\n",
      "Epoch 10:  33%|███▎      | 49/148 [00:45<01:31,  1.09it/s, training_loss=1.6322]\u001b[A\n",
      "Epoch 10:  33%|███▎      | 49/148 [00:46<01:31,  1.09it/s, training_loss=1.0621]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=1.0621]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 50/148 [00:46<01:29,  1.09it/s, training_loss=0.8560]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 51/148 [00:46<01:28,  1.09it/s, training_loss=0.8560]\u001b[A\n",
      "Epoch 10:  34%|███▍      | 51/148 [00:47<01:28,  1.09it/s, training_loss=1.5551]\u001b[A\n",
      "Epoch 10:  35%|███▌      | 52/148 [00:47<01:27,  1.09it/s, training_loss=1.5551]\u001b[A\n",
      "Epoch 10:  35%|███▌      | 52/148 [00:48<01:27,  1.09it/s, training_loss=1.1520]\u001b[A\n",
      "Epoch 10:  36%|███▌      | 53/148 [00:48<01:26,  1.09it/s, training_loss=1.1520]\u001b[A\n",
      "Epoch 10:  36%|███▌      | 53/148 [00:49<01:26,  1.09it/s, training_loss=1.0186]\u001b[A\n",
      "Epoch 10:  36%|███▋      | 54/148 [00:49<01:25,  1.09it/s, training_loss=1.0186]\u001b[A\n",
      "Epoch 10:  36%|███▋      | 54/148 [00:50<01:25,  1.09it/s, training_loss=0.9215]\u001b[A\n",
      "Epoch 10:  37%|███▋      | 55/148 [00:50<01:25,  1.09it/s, training_loss=0.9215]\u001b[A\n",
      "Epoch 10:  37%|███▋      | 55/148 [00:51<01:25,  1.09it/s, training_loss=1.0907]\u001b[A\n",
      "Epoch 10:  38%|███▊      | 56/148 [00:51<01:23,  1.10it/s, training_loss=1.0907]\u001b[A\n",
      "Epoch 10:  38%|███▊      | 56/148 [00:52<01:23,  1.10it/s, training_loss=1.5959]\u001b[A\n",
      "Epoch 10:  39%|███▊      | 57/148 [00:52<01:23,  1.09it/s, training_loss=1.5959]\u001b[A\n",
      "Epoch 10:  39%|███▊      | 57/148 [00:53<01:23,  1.09it/s, training_loss=1.0172]\u001b[A\n",
      "Epoch 10:  39%|███▉      | 58/148 [00:53<01:21,  1.10it/s, training_loss=1.0172]\u001b[A\n",
      "Epoch 10:  39%|███▉      | 58/148 [00:54<01:21,  1.10it/s, training_loss=1.5177]\u001b[A\n",
      "Epoch 10:  40%|███▉      | 59/148 [00:54<01:21,  1.10it/s, training_loss=1.5177]\u001b[A\n",
      "Epoch 10:  40%|███▉      | 59/148 [00:55<01:21,  1.10it/s, training_loss=0.9388]\u001b[A\n",
      "Epoch 10:  41%|████      | 60/148 [00:55<01:20,  1.10it/s, training_loss=0.9388]\u001b[A\n",
      "Epoch 10:  41%|████      | 60/148 [00:56<01:20,  1.10it/s, training_loss=1.5948]\u001b[A\n",
      "Epoch 10:  41%|████      | 61/148 [00:56<01:19,  1.10it/s, training_loss=1.5948]\u001b[A\n",
      "Epoch 10:  41%|████      | 61/148 [00:56<01:19,  1.10it/s, training_loss=1.5546]\u001b[A\n",
      "Epoch 10:  42%|████▏     | 62/148 [00:56<01:18,  1.10it/s, training_loss=1.5546]\u001b[A\n",
      "Epoch 10:  42%|████▏     | 62/148 [00:57<01:18,  1.10it/s, training_loss=1.0332]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 63/148 [00:57<01:17,  1.10it/s, training_loss=1.0332]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 63/148 [00:58<01:17,  1.10it/s, training_loss=1.5857]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 64/148 [00:58<01:16,  1.10it/s, training_loss=1.5857]\u001b[A\n",
      "Epoch 10:  43%|████▎     | 64/148 [00:59<01:16,  1.10it/s, training_loss=1.4981]\u001b[A\n",
      "Epoch 10:  44%|████▍     | 65/148 [00:59<01:15,  1.10it/s, training_loss=1.4981]\u001b[A\n",
      "Epoch 10:  44%|████▍     | 65/148 [01:00<01:15,  1.10it/s, training_loss=1.5476]\u001b[A\n",
      "Epoch 10:  45%|████▍     | 66/148 [01:00<01:14,  1.10it/s, training_loss=1.5476]\u001b[A\n",
      "Epoch 10:  45%|████▍     | 66/148 [01:01<01:14,  1.10it/s, training_loss=1.5525]\u001b[A\n",
      "Epoch 10:  45%|████▌     | 67/148 [01:01<01:13,  1.10it/s, training_loss=1.5525]\u001b[A\n",
      "Epoch 10:  45%|████▌     | 67/148 [01:02<01:13,  1.10it/s, training_loss=1.6503]\u001b[A\n",
      "Epoch 10:  46%|████▌     | 68/148 [01:02<01:12,  1.10it/s, training_loss=1.6503]\u001b[A\n",
      "Epoch 10:  46%|████▌     | 68/148 [01:03<01:12,  1.10it/s, training_loss=1.5609]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 69/148 [01:03<01:11,  1.10it/s, training_loss=1.5609]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 69/148 [01:04<01:11,  1.10it/s, training_loss=1.5414]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 70/148 [01:04<01:10,  1.10it/s, training_loss=1.5414]\u001b[A\n",
      "Epoch 10:  47%|████▋     | 70/148 [01:05<01:10,  1.10it/s, training_loss=1.6505]\u001b[A\n",
      "Epoch 10:  48%|████▊     | 71/148 [01:05<01:10,  1.10it/s, training_loss=1.6505]\u001b[A\n",
      "Epoch 10:  48%|████▊     | 71/148 [01:06<01:10,  1.10it/s, training_loss=0.8483]\u001b[A\n",
      "Epoch 10:  49%|████▊     | 72/148 [01:06<01:09,  1.10it/s, training_loss=0.8483]\u001b[A\n",
      "Epoch 10:  49%|████▊     | 72/148 [01:06<01:09,  1.10it/s, training_loss=0.8498]\u001b[A\n",
      "Epoch 10:  49%|████▉     | 73/148 [01:06<01:08,  1.10it/s, training_loss=0.8498]\u001b[A\n",
      "Epoch 10:  49%|████▉     | 73/148 [01:07<01:08,  1.10it/s, training_loss=0.9848]\u001b[A\n",
      "Epoch 10:  50%|█████     | 74/148 [01:07<01:07,  1.09it/s, training_loss=0.9848]\u001b[A\n",
      "Epoch 10:  50%|█████     | 74/148 [01:08<01:07,  1.09it/s, training_loss=1.5253]\u001b[A\n",
      "Epoch 10:  51%|█████     | 75/148 [01:08<01:06,  1.10it/s, training_loss=1.5253]\u001b[A\n",
      "Epoch 10:  51%|█████     | 75/148 [01:09<01:06,  1.10it/s, training_loss=1.7000]\u001b[A\n",
      "Epoch 10:  51%|█████▏    | 76/148 [01:09<01:05,  1.10it/s, training_loss=1.7000]\u001b[A\n",
      "Epoch 10:  51%|█████▏    | 76/148 [01:10<01:05,  1.10it/s, training_loss=0.8405]\u001b[A\n",
      "Epoch 10:  52%|█████▏    | 77/148 [01:10<01:04,  1.09it/s, training_loss=0.8405]\u001b[A\n",
      "Epoch 10:  52%|█████▏    | 77/148 [01:11<01:04,  1.09it/s, training_loss=0.8128]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 78/148 [01:11<01:04,  1.09it/s, training_loss=0.8128]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 78/148 [01:12<01:04,  1.09it/s, training_loss=1.5782]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 79/148 [01:12<01:03,  1.09it/s, training_loss=1.5782]\u001b[A\n",
      "Epoch 10:  53%|█████▎    | 79/148 [01:13<01:03,  1.09it/s, training_loss=1.5161]\u001b[A\n",
      "Epoch 10:  54%|█████▍    | 80/148 [01:13<01:02,  1.09it/s, training_loss=1.5161]\u001b[A\n",
      "Epoch 10:  54%|█████▍    | 80/148 [01:14<01:02,  1.09it/s, training_loss=0.9968]\u001b[A\n",
      "Epoch 10:  55%|█████▍    | 81/148 [01:14<01:01,  1.09it/s, training_loss=0.9968]\u001b[A\n",
      "Epoch 10:  55%|█████▍    | 81/148 [01:15<01:01,  1.09it/s, training_loss=1.0240]\u001b[A\n",
      "Epoch 10:  55%|█████▌    | 82/148 [01:15<01:00,  1.09it/s, training_loss=1.0240]\u001b[A\n",
      "Epoch 10:  55%|█████▌    | 82/148 [01:16<01:00,  1.09it/s, training_loss=1.6221]\u001b[A\n",
      "Epoch 10:  56%|█████▌    | 83/148 [01:16<00:59,  1.09it/s, training_loss=1.6221]\u001b[A\n",
      "Epoch 10:  56%|█████▌    | 83/148 [01:17<00:59,  1.09it/s, training_loss=0.8767]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=0.8767]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 84/148 [01:17<00:58,  1.09it/s, training_loss=1.6557]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 85/148 [01:17<00:57,  1.09it/s, training_loss=1.6557]\u001b[A\n",
      "Epoch 10:  57%|█████▋    | 85/148 [01:18<00:57,  1.09it/s, training_loss=1.6223]\u001b[A\n",
      "Epoch 10:  58%|█████▊    | 86/148 [01:18<00:56,  1.09it/s, training_loss=1.6223]\u001b[A\n",
      "Epoch 10:  58%|█████▊    | 86/148 [01:19<00:56,  1.09it/s, training_loss=1.2427]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 87/148 [01:19<00:55,  1.09it/s, training_loss=1.2427]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 87/148 [01:20<00:55,  1.09it/s, training_loss=0.8585]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 88/148 [01:20<00:54,  1.09it/s, training_loss=0.8585]\u001b[A\n",
      "Epoch 10:  59%|█████▉    | 88/148 [01:21<00:54,  1.09it/s, training_loss=1.6102]\u001b[A\n",
      "Epoch 10:  60%|██████    | 89/148 [01:21<00:53,  1.10it/s, training_loss=1.6102]\u001b[A\n",
      "Epoch 10:  60%|██████    | 89/148 [01:22<00:53,  1.10it/s, training_loss=1.5856]\u001b[A\n",
      "Epoch 10:  61%|██████    | 90/148 [01:22<00:52,  1.10it/s, training_loss=1.5856]\u001b[A\n",
      "Epoch 10:  61%|██████    | 90/148 [01:23<00:52,  1.10it/s, training_loss=1.5437]\u001b[A\n",
      "Epoch 10:  61%|██████▏   | 91/148 [01:23<00:51,  1.10it/s, training_loss=1.5437]\u001b[A\n",
      "Epoch 10:  61%|██████▏   | 91/148 [01:24<00:51,  1.10it/s, training_loss=0.8751]\u001b[A\n",
      "Epoch 10:  62%|██████▏   | 92/148 [01:24<00:51,  1.10it/s, training_loss=0.8751]\u001b[A\n",
      "Epoch 10:  62%|██████▏   | 92/148 [01:25<00:51,  1.10it/s, training_loss=0.9666]\u001b[A\n",
      "Epoch 10:  63%|██████▎   | 93/148 [01:25<00:50,  1.09it/s, training_loss=0.9666]\u001b[A\n",
      "Epoch 10:  63%|██████▎   | 93/148 [01:26<00:50,  1.09it/s, training_loss=1.5517]\u001b[A\n",
      "Epoch 10:  64%|██████▎   | 94/148 [01:26<00:49,  1.10it/s, training_loss=1.5517]\u001b[A\n",
      "Epoch 10:  64%|██████▎   | 94/148 [01:27<00:49,  1.10it/s, training_loss=1.6238]\u001b[A\n",
      "Epoch 10:  64%|██████▍   | 95/148 [01:27<00:48,  1.09it/s, training_loss=1.6238]\u001b[A\n",
      "Epoch 10:  64%|██████▍   | 95/148 [01:28<00:48,  1.09it/s, training_loss=1.6109]\u001b[A\n",
      "Epoch 10:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.6109]\u001b[A\n",
      "Epoch 10:  65%|██████▍   | 96/148 [01:28<00:47,  1.09it/s, training_loss=1.5941]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 97/148 [01:28<00:46,  1.10it/s, training_loss=1.5941]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 97/148 [01:29<00:46,  1.10it/s, training_loss=0.8923]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 98/148 [01:29<00:45,  1.09it/s, training_loss=0.8923]\u001b[A\n",
      "Epoch 10:  66%|██████▌   | 98/148 [01:30<00:45,  1.09it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 10:  67%|██████▋   | 99/148 [01:30<00:44,  1.09it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 10:  67%|██████▋   | 99/148 [01:31<00:44,  1.09it/s, training_loss=1.5249]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 100/148 [01:31<00:43,  1.09it/s, training_loss=1.5249]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 100/148 [01:32<00:43,  1.09it/s, training_loss=0.8305]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 101/148 [01:32<00:42,  1.09it/s, training_loss=0.8305]\u001b[A\n",
      "Epoch 10:  68%|██████▊   | 101/148 [01:33<00:42,  1.09it/s, training_loss=1.6075]\u001b[A\n",
      "Epoch 10:  69%|██████▉   | 102/148 [01:33<00:41,  1.10it/s, training_loss=1.6075]\u001b[A\n",
      "Epoch 10:  69%|██████▉   | 102/148 [01:34<00:41,  1.10it/s, training_loss=1.5221]\u001b[A\n",
      "Epoch 10:  70%|██████▉   | 103/148 [01:34<00:41,  1.09it/s, training_loss=1.5221]\u001b[A\n",
      "Epoch 10:  70%|██████▉   | 103/148 [01:35<00:41,  1.09it/s, training_loss=1.5434]\u001b[A\n",
      "Epoch 10:  70%|███████   | 104/148 [01:35<00:40,  1.09it/s, training_loss=1.5434]\u001b[A\n",
      "Epoch 10:  70%|███████   | 104/148 [01:36<00:40,  1.09it/s, training_loss=0.8453]\u001b[A\n",
      "Epoch 10:  71%|███████   | 105/148 [01:36<00:39,  1.09it/s, training_loss=0.8453]\u001b[A\n",
      "Epoch 10:  71%|███████   | 105/148 [01:37<00:39,  1.09it/s, training_loss=1.6662]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 106/148 [01:37<00:38,  1.09it/s, training_loss=1.6662]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 106/148 [01:38<00:38,  1.09it/s, training_loss=0.8621]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=0.8621]\u001b[A\n",
      "Epoch 10:  72%|███████▏  | 107/148 [01:38<00:37,  1.09it/s, training_loss=1.5928]\u001b[A\n",
      "Epoch 10:  73%|███████▎  | 108/148 [01:38<00:36,  1.09it/s, training_loss=1.5928]\u001b[A\n",
      "Epoch 10:  73%|███████▎  | 108/148 [01:39<00:36,  1.09it/s, training_loss=0.9846]\u001b[A\n",
      "Epoch 10:  74%|███████▎  | 109/148 [01:39<00:35,  1.09it/s, training_loss=0.9846]\u001b[A\n",
      "Epoch 10:  74%|███████▎  | 109/148 [01:40<00:35,  1.09it/s, training_loss=0.9652]\u001b[A\n",
      "Epoch 10:  74%|███████▍  | 110/148 [01:40<00:34,  1.09it/s, training_loss=0.9652]\u001b[A\n",
      "Epoch 10:  74%|███████▍  | 110/148 [01:41<00:34,  1.09it/s, training_loss=1.5709]\u001b[A\n",
      "Epoch 10:  75%|███████▌  | 111/148 [01:41<00:33,  1.09it/s, training_loss=1.5709]\u001b[A\n",
      "Epoch 10:  75%|███████▌  | 111/148 [01:42<00:33,  1.09it/s, training_loss=0.9238]\u001b[A\n",
      "Epoch 10:  76%|███████▌  | 112/148 [01:42<00:32,  1.09it/s, training_loss=0.9238]\u001b[A\n",
      "Epoch 10:  76%|███████▌  | 112/148 [01:43<00:32,  1.09it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 10:  76%|███████▋  | 113/148 [01:43<00:32,  1.09it/s, training_loss=1.6147]\u001b[A\n",
      "Epoch 10:  76%|███████▋  | 113/148 [01:44<00:32,  1.09it/s, training_loss=1.6594]\u001b[A\n",
      "Epoch 10:  77%|███████▋  | 114/148 [01:44<00:31,  1.09it/s, training_loss=1.6594]\u001b[A\n",
      "Epoch 10:  77%|███████▋  | 114/148 [01:45<00:31,  1.09it/s, training_loss=1.5313]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 115/148 [01:45<00:30,  1.09it/s, training_loss=1.5313]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 115/148 [01:46<00:30,  1.09it/s, training_loss=0.9118]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 116/148 [01:46<00:29,  1.09it/s, training_loss=0.9118]\u001b[A\n",
      "Epoch 10:  78%|███████▊  | 116/148 [01:47<00:29,  1.09it/s, training_loss=1.5025]\u001b[A\n",
      "Epoch 10:  79%|███████▉  | 117/148 [01:47<00:28,  1.09it/s, training_loss=1.5025]\u001b[A\n",
      "Epoch 10:  79%|███████▉  | 117/148 [01:48<00:28,  1.09it/s, training_loss=1.5227]\u001b[A\n",
      "Epoch 10:  80%|███████▉  | 118/148 [01:48<00:27,  1.09it/s, training_loss=1.5227]\u001b[A\n",
      "Epoch 10:  80%|███████▉  | 118/148 [01:49<00:27,  1.09it/s, training_loss=1.3553]\u001b[A\n",
      "Epoch 10:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.3553]\u001b[A\n",
      "Epoch 10:  80%|████████  | 119/148 [01:49<00:26,  1.09it/s, training_loss=1.6614]\u001b[A\n",
      "Epoch 10:  81%|████████  | 120/148 [01:49<00:25,  1.09it/s, training_loss=1.6614]\u001b[A\n",
      "Epoch 10:  81%|████████  | 120/148 [01:50<00:25,  1.09it/s, training_loss=1.0078]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 121/148 [01:50<00:24,  1.09it/s, training_loss=1.0078]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 121/148 [01:51<00:24,  1.09it/s, training_loss=1.5726]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 122/148 [01:51<00:23,  1.09it/s, training_loss=1.5726]\u001b[A\n",
      "Epoch 10:  82%|████████▏ | 122/148 [01:52<00:23,  1.09it/s, training_loss=1.6009]\u001b[A\n",
      "Epoch 10:  83%|████████▎ | 123/148 [01:52<00:22,  1.09it/s, training_loss=1.6009]\u001b[A\n",
      "Epoch 10:  83%|████████▎ | 123/148 [01:53<00:22,  1.09it/s, training_loss=1.2286]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 124/148 [01:53<00:21,  1.09it/s, training_loss=1.2286]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 124/148 [01:54<00:21,  1.09it/s, training_loss=0.8746]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 125/148 [01:54<00:21,  1.09it/s, training_loss=0.8746]\u001b[A\n",
      "Epoch 10:  84%|████████▍ | 125/148 [01:55<00:21,  1.09it/s, training_loss=0.8518]\u001b[A\n",
      "Epoch 10:  85%|████████▌ | 126/148 [01:55<00:20,  1.09it/s, training_loss=0.8518]\u001b[A\n",
      "Epoch 10:  85%|████████▌ | 126/148 [01:56<00:20,  1.09it/s, training_loss=0.8272]\u001b[A\n",
      "Epoch 10:  86%|████████▌ | 127/148 [01:56<00:19,  1.09it/s, training_loss=0.8272]\u001b[A\n",
      "Epoch 10:  86%|████████▌ | 127/148 [01:57<00:19,  1.09it/s, training_loss=1.5966]\u001b[A\n",
      "Epoch 10:  86%|████████▋ | 128/148 [01:57<00:18,  1.09it/s, training_loss=1.5966]\u001b[A\n",
      "Epoch 10:  86%|████████▋ | 128/148 [01:58<00:18,  1.09it/s, training_loss=1.4852]\u001b[A\n",
      "Epoch 10:  87%|████████▋ | 129/148 [01:58<00:17,  1.09it/s, training_loss=1.4852]\u001b[A\n",
      "Epoch 10:  87%|████████▋ | 129/148 [01:59<00:17,  1.09it/s, training_loss=1.4837]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 130/148 [01:59<00:16,  1.09it/s, training_loss=1.4837]\u001b[A\n",
      "Epoch 10:  88%|████████▊ | 130/148 [02:00<00:16,  1.09it/s, training_loss=0.8752]\u001b[A\n",
      "Epoch 10:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=0.8752]\u001b[A\n",
      "Epoch 10:  89%|████████▊ | 131/148 [02:00<00:15,  1.09it/s, training_loss=1.4944]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=1.4944]\u001b[A\n",
      "Epoch 10:  89%|████████▉ | 132/148 [02:01<00:14,  1.09it/s, training_loss=0.8265]\u001b[A\n",
      "Epoch 10:  90%|████████▉ | 133/148 [02:01<00:13,  1.09it/s, training_loss=0.8265]\u001b[A\n",
      "Epoch 10:  90%|████████▉ | 133/148 [02:02<00:13,  1.09it/s, training_loss=0.9713]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 134/148 [02:02<00:12,  1.09it/s, training_loss=0.9713]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 134/148 [02:03<00:12,  1.09it/s, training_loss=1.5696]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 135/148 [02:03<00:11,  1.09it/s, training_loss=1.5696]\u001b[A\n",
      "Epoch 10:  91%|█████████ | 135/148 [02:04<00:11,  1.09it/s, training_loss=0.8707]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 136/148 [02:04<00:11,  1.09it/s, training_loss=0.8707]\u001b[A\n",
      "Epoch 10:  92%|█████████▏| 136/148 [02:05<00:11,  1.09it/s, training_loss=1.5295]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 137/148 [02:05<00:10,  1.09it/s, training_loss=1.5295]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 137/148 [02:06<00:10,  1.09it/s, training_loss=1.6349]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 138/148 [02:06<00:09,  1.09it/s, training_loss=1.6349]\u001b[A\n",
      "Epoch 10:  93%|█████████▎| 138/148 [02:07<00:09,  1.09it/s, training_loss=1.5920]\u001b[A\n",
      "Epoch 10:  94%|█████████▍| 139/148 [02:07<00:08,  1.09it/s, training_loss=1.5920]\u001b[A\n",
      "Epoch 10:  94%|█████████▍| 139/148 [02:08<00:08,  1.09it/s, training_loss=1.5950]\u001b[A\n",
      "Epoch 10:  95%|█████████▍| 140/148 [02:08<00:07,  1.09it/s, training_loss=1.5950]\u001b[A\n",
      "Epoch 10:  95%|█████████▍| 140/148 [02:09<00:07,  1.09it/s, training_loss=0.9501]\u001b[A\n",
      "Epoch 10:  95%|█████████▌| 141/148 [02:09<00:06,  1.09it/s, training_loss=0.9501]\u001b[A\n",
      "Epoch 10:  95%|█████████▌| 141/148 [02:10<00:06,  1.09it/s, training_loss=0.9257]\u001b[A\n",
      "Epoch 10:  96%|█████████▌| 142/148 [02:10<00:05,  1.09it/s, training_loss=0.9257]\u001b[A\n",
      "Epoch 10:  96%|█████████▌| 142/148 [02:11<00:05,  1.09it/s, training_loss=1.5409]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 143/148 [02:11<00:04,  1.09it/s, training_loss=1.5409]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 143/148 [02:12<00:04,  1.09it/s, training_loss=0.8892]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 144/148 [02:12<00:03,  1.08it/s, training_loss=0.8892]\u001b[A\n",
      "Epoch 10:  97%|█████████▋| 144/148 [02:12<00:03,  1.08it/s, training_loss=1.6571]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 145/148 [02:12<00:02,  1.09it/s, training_loss=1.6571]\u001b[A\n",
      "Epoch 10:  98%|█████████▊| 145/148 [02:13<00:02,  1.09it/s, training_loss=0.8986]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 146/148 [02:13<00:01,  1.08it/s, training_loss=0.8986]\u001b[A\n",
      "Epoch 10:  99%|█████████▊| 146/148 [02:14<00:01,  1.08it/s, training_loss=0.8206]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 147/148 [02:14<00:00,  1.09it/s, training_loss=0.8206]\u001b[A\n",
      "Epoch 10:  99%|█████████▉| 147/148 [02:15<00:00,  1.09it/s, training_loss=1.4657]\u001b[A\n",
      "Epoch 10: 100%|██████████| 148/148 [02:15<00:00,  1.18it/s, training_loss=1.4657]\u001b[A\n",
      "                                                                                 \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:50:34,667 - INFO - Starting model evaluation...\n",
      "2025-02-16 19:50:34,668 - INFO - Memory usage after evaluation start: 3949.55 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating:   0%|          | 0/27 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating:   4%|▎         | 1/27 [00:00<00:07,  3.70it/s]\u001b[A\n",
      "Evaluating:   7%|▋         | 2/27 [00:00<00:06,  3.63it/s]\u001b[A\n",
      "Evaluating:  11%|█         | 3/27 [00:00<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  15%|█▍        | 4/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  19%|█▊        | 5/27 [00:01<00:06,  3.62it/s]\u001b[A\n",
      "Evaluating:  22%|██▏       | 6/27 [00:01<00:05,  3.62it/s]\u001b[A\n",
      "Evaluating:  26%|██▌       | 7/27 [00:01<00:05,  3.61it/s]\u001b[A\n",
      "Evaluating:  30%|██▉       | 8/27 [00:02<00:05,  3.62it/s]\u001b[A\n",
      "Evaluating:  33%|███▎      | 9/27 [00:02<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  37%|███▋      | 10/27 [00:02<00:04,  3.61it/s]\u001b[A\n",
      "Evaluating:  41%|████      | 11/27 [00:03<00:04,  3.62it/s]\u001b[A\n",
      "Evaluating:  44%|████▍     | 12/27 [00:03<00:04,  3.62it/s]\u001b[A\n",
      "Evaluating:  48%|████▊     | 13/27 [00:03<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  52%|█████▏    | 14/27 [00:03<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  56%|█████▌    | 15/27 [00:04<00:03,  3.62it/s]\u001b[A\n",
      "Evaluating:  59%|█████▉    | 16/27 [00:04<00:03,  3.61it/s]\u001b[A\n",
      "Evaluating:  63%|██████▎   | 17/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  67%|██████▋   | 18/27 [00:04<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  70%|███████   | 19/27 [00:05<00:02,  3.61it/s]\u001b[A\n",
      "Evaluating:  74%|███████▍  | 20/27 [00:05<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  78%|███████▊  | 21/27 [00:05<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  81%|████████▏ | 22/27 [00:06<00:01,  3.60it/s]\u001b[A\n",
      "Evaluating:  85%|████████▌ | 23/27 [00:06<00:01,  3.61it/s]\u001b[A\n",
      "Evaluating:  89%|████████▉ | 24/27 [00:06<00:00,  3.60it/s]\u001b[A\n",
      "Evaluating:  93%|█████████▎| 25/27 [00:06<00:00,  3.59it/s]\u001b[A\n",
      "Evaluating: 100%|██████████| 27/27 [00:07<00:00,  3.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:50:41,909 - INFO - Optimizing classification thresholds...\n",
      "2025-02-16 19:50:41,924 - INFO - Class 'Drama': Optimal threshold = 0.600, F1 Score = 0.547\n",
      "2025-02-16 19:50:41,937 - INFO - Class 'Horor': Optimal threshold = 0.700, F1 Score = 0.772\n",
      "2025-02-16 19:50:41,950 - INFO - Class 'Komedi': Optimal threshold = 0.600, F1 Score = 0.612\n",
      "2025-02-16 19:50:41,963 - INFO - Class 'Laga': Optimal threshold = 0.550, F1 Score = 0.355\n",
      "2025-02-16 19:50:41,976 - INFO - Class 'Romantis': Optimal threshold = 0.600, F1 Score = 0.571\n",
      "2025-02-16 19:50:41,998 - INFO - \n",
      "Per-genre Performance Metrics:\n",
      "2025-02-16 19:50:42,003 - INFO - \n",
      "Metrics for Drama:\n",
      "2025-02-16 19:50:42,003 - INFO - Accuracy: 0.6513\n",
      "2025-02-16 19:50:42,004 - INFO - F1_score: 0.5473\n",
      "2025-02-16 19:50:42,006 - INFO - Precision: 0.4331\n",
      "2025-02-16 19:50:42,007 - INFO - Recall: 0.7432\n",
      "2025-02-16 19:50:42,012 - INFO - \n",
      "Metrics for Horor:\n",
      "2025-02-16 19:50:42,013 - INFO - Accuracy: 0.8889\n",
      "2025-02-16 19:50:42,014 - INFO - F1_score: 0.7717\n",
      "2025-02-16 19:50:42,014 - INFO - Precision: 0.7000\n",
      "2025-02-16 19:50:42,015 - INFO - Recall: 0.8596\n",
      "2025-02-16 19:50:42,021 - INFO - \n",
      "Metrics for Komedi:\n",
      "2025-02-16 19:50:42,021 - INFO - Accuracy: 0.8008\n",
      "2025-02-16 19:50:42,022 - INFO - F1_score: 0.6119\n",
      "2025-02-16 19:50:42,023 - INFO - Precision: 0.5395\n",
      "2025-02-16 19:50:42,023 - INFO - Recall: 0.7069\n",
      "2025-02-16 19:50:42,029 - INFO - \n",
      "Metrics for Laga:\n",
      "2025-02-16 19:50:42,030 - INFO - Accuracy: 0.7356\n",
      "2025-02-16 19:50:42,030 - INFO - F1_score: 0.3551\n",
      "2025-02-16 19:50:42,031 - INFO - Precision: 0.2754\n",
      "2025-02-16 19:50:42,032 - INFO - Recall: 0.5000\n",
      "2025-02-16 19:50:42,038 - INFO - \n",
      "Metrics for Romantis:\n",
      "2025-02-16 19:50:42,038 - INFO - Accuracy: 0.8851\n",
      "2025-02-16 19:50:42,039 - INFO - F1_score: 0.5714\n",
      "2025-02-16 19:50:42,040 - INFO - Precision: 0.5556\n",
      "2025-02-16 19:50:42,041 - INFO - Recall: 0.5882\n",
      "2025-02-16 19:50:42,043 - INFO - Generating detailed confusion matrices for each genre...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:50:45,849 - INFO - Confusion matrices saved in: /kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices\n",
      "2025-02-16 19:50:45,851 - INFO - Memory usage after evaluation end: 3955.30 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [25:47<3:54:07, 154.37s/it, Train Loss=1.2474, Val Loss=0.0517, Accuracy=0.7923]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:50:53,065 - INFO - \n",
      "Early stopping triggered after 10 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Progress:   9%|▉         | 9/100 [25:47<4:20:44, 171.92s/it, Train Loss=1.2474, Val Loss=0.0517, Accuracy=0.7923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:50:55,010 - INFO - Saved training history plots to /kaggle/working/logs/experiments/20250216_171623/plots/training_history.png\n",
      "2025-02-16 19:50:55,011 - INFO - Training history saved successfully\n",
      "2025-02-16 19:50:57,465 - INFO - \n",
      "Testing model on a sample...\n",
      "2025-02-16 19:50:57,474 - INFO - Loading and preprocessing data...\n",
      "2025-02-16 19:50:57,475 - INFO - Memory usage after start: 3959.05 MB\n",
      "2025-02-16 19:50:57,488 - INFO - Successfully loaded data using utf-8 encoding\n",
      "2025-02-16 19:50:57,489 - INFO - Memory usage after data loading: 3959.05 MB\n",
      "2025-02-16 19:50:57,490 - INFO - Taking sample of 1 from 1738 total samples\n",
      "2025-02-16 19:50:57,491 - INFO - \n",
      "Sample data:\n",
      "2025-02-16 19:50:57,492 - INFO - \n",
      "Sample 1:\n",
      "2025-02-16 19:50:57,493 - INFO - Synopsis: Setelah kematian yang tampak, Siena mampu melihat tanda-tanda bahwa orang-orang akan meninggal. Namu...\n",
      "2025-02-16 19:50:57,494 - INFO - Genre: Horor\n",
      "2025-02-16 19:50:57,495 - INFO - \n",
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2534.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:50:57,501 - INFO - Memory usage after preprocessing: 3959.05 MB\n",
      "2025-02-16 19:50:57,551 - INFO - \n",
      "Sample prediction results:\n",
      "2025-02-16 19:50:57,552 - INFO - Sample text: setelah kematian yang tampak siena mampu melihat tanda tanda bahwa orang orang akan meninggal namun ...\n",
      "2025-02-16 19:50:57,552 - INFO - Genre: Horor, Probability: 0.9183, Threshold Used: 0.700\n",
      "2025-02-16 19:50:57,555 - INFO - \n",
      "Training completed successfully!\n",
      "2025-02-16 19:50:57,555 - INFO - All results and models saved in: /kaggle/working/logs/experiments/20250216_171623\n",
      "2025-02-16 19:50:57,556 - INFO - \n",
      "Cleaning up resources...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-16 19:50:58,831 - INFO - Cleaning up resources...\n"
     ]
    }
   ],
   "source": [
    "# BAGIAN KEEMPAT - Training dan Hyperparameter Optimization\n",
    "\n",
    "class ModelTrainer:\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def train_model(sample_size: Optional[int] = None) -> Tuple:\n",
    "        Config.SAMPLE_SIZE = sample_size\n",
    "        logging.info(\"Starting model training\")\n",
    "        log_memory(\"training start\")\n",
    "\n",
    "        try:\n",
    "            # Load dan preprocess data\n",
    "            df = DataProcessor.load_and_preprocess_data(Config.DATA_PATH, Config.SAMPLE_SIZE)\n",
    "            logging.info(f\"\\nDataset statistics:\")\n",
    "            logging.info(f\"Total samples after preprocessing: {len(df)}\")\n",
    "\n",
    "            # Prepare data\n",
    "            mlb = MultiLabelBinarizer()\n",
    "            X_train, X_test, y_train, y_test = DataProcessor.prepare_data(df, mlb)\n",
    "\n",
    "            # Initialize threshold optimizer and performance tracker\n",
    "            threshold_optimizer = DynamicThresholdOptimizer(len(mlb.classes_))\n",
    "            performance_tracker = PerformanceTracker(len(mlb.classes_), mlb.classes_)\n",
    "\n",
    "            # Log genre distribution\n",
    "            genre_labels = mlb.fit_transform(df['genre'])\n",
    "            genre_counts = genre_labels.sum(axis=0)\n",
    "            for genre, count in zip(mlb.classes_, genre_counts):\n",
    "                logging.info(f\"Genre '{genre}': {count} samples\")\n",
    "\n",
    "            logging.info(f\"\\nTraining set size: {len(X_train)}\")\n",
    "            logging.info(f\"Testing set size: {len(X_test)}\")\n",
    "\n",
    "            # Setup model dan data loaders\n",
    "            with ModelManager(*ModelSetup.setup_model_and_tokenizer(len(mlb.classes_))) as (model, tokenizer):\n",
    "                train_loader, val_loader = ModelSetup.setup_dataloaders(\n",
    "                    X_train, X_test, y_train, y_test,\n",
    "                    tokenizer, Config.MODEL_PARAMS['BATCH_SIZE']\n",
    "                )\n",
    "\n",
    "                # Training loop\n",
    "                best_val_loss = float('inf')\n",
    "                best_accuracy = 0.0\n",
    "                patience_counter = 0\n",
    "                training_losses = []\n",
    "                validation_losses = []\n",
    "                accuracies = []\n",
    "\n",
    "                optimizer = torch.optim.AdamW(\n",
    "                    model.parameters(),\n",
    "                    lr=Config.MODEL_PARAMS['LEARNING_RATE'],\n",
    "                    weight_decay=Config.MODEL_PARAMS['WEIGHT_DECAY']\n",
    "                )\n",
    "\n",
    "                scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                    optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "                )\n",
    "\n",
    "                epochs_range = tqdm(range(Config.MODEL_PARAMS['EPOCHS']), \n",
    "                                  desc=\"Training Progress\",\n",
    "                                  position=0, leave=True)\n",
    "                \n",
    "                for epoch in epochs_range:\n",
    "                    try:\n",
    "                        # Training phase\n",
    "                        model.train()\n",
    "                        epoch_metrics = ModelTrainer._train_epoch(\n",
    "                            model, train_loader, optimizer,\n",
    "                            epoch + 1\n",
    "                        )\n",
    "                        training_losses.append(epoch_metrics['train_loss'])\n",
    "\n",
    "                        # Evaluation phase with dynamic thresholding\n",
    "                        validation_metrics = ModelEvaluator.evaluate_model(\n",
    "                            model, val_loader, mlb,\n",
    "                            threshold_optimizer=threshold_optimizer,\n",
    "                            performance_tracker=performance_tracker,\n",
    "                            epoch=epoch\n",
    "                        )\n",
    "                        \n",
    "                        current_accuracy = validation_metrics['accuracy']\n",
    "                        accuracies.append(current_accuracy)\n",
    "\n",
    "                        # Validation loss calculation\n",
    "                        avg_val_loss = ModelTrainer._calculate_validation_loss(\n",
    "                            model, val_loader\n",
    "                        )\n",
    "                        validation_losses.append(avg_val_loss)\n",
    "\n",
    "                        # Update progress bar\n",
    "                        epochs_range.set_postfix({\n",
    "                            'Train Loss': f\"{epoch_metrics['train_loss']:.4f}\",\n",
    "                            'Val Loss': f\"{avg_val_loss:.4f}\",\n",
    "                            'Accuracy': f\"{current_accuracy:.4f}\"\n",
    "                        })\n",
    "\n",
    "                        # Model improvement check\n",
    "                        model_improved = ModelTrainer._check_model_improvement(\n",
    "                            model, tokenizer, current_accuracy, avg_val_loss,\n",
    "                            best_accuracy, best_val_loss\n",
    "                        )\n",
    "\n",
    "                        if model_improved:\n",
    "                            best_accuracy = max(best_accuracy, current_accuracy)\n",
    "                            best_val_loss = min(best_val_loss, avg_val_loss)\n",
    "                            patience_counter = 0\n",
    "                        else:\n",
    "                            patience_counter += 1\n",
    "\n",
    "                        # Early stopping check\n",
    "                        if patience_counter >= Config.MODEL_PARAMS['PATIENCE']:\n",
    "                            logging.info(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "                            break\n",
    "\n",
    "                        scheduler.step(avg_val_loss)\n",
    "                        logging.info(f\"Learning rate: {optimizer.param_groups[0]['lr']}\")\n",
    "\n",
    "                        # Clear GPU cache periodically\n",
    "                        if torch.cuda.is_available() and (epoch + 1) % 5 == 0:\n",
    "                            torch.cuda.empty_cache()\n",
    "                            gc.collect()\n",
    "\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Error during epoch {epoch + 1}: {str(e)}\")\n",
    "                        raise\n",
    "\n",
    "                # Save performance history and plots\n",
    "                performance_tracker.plot_performance_trends(Config.PLOTS_DIR)\n",
    "                performance_tracker.save_performance_history(Config.METRICS_DIR)\n",
    "                threshold_optimizer.save_threshold_history(Config.METRICS_DIR, mlb.classes_)\n",
    "\n",
    "                # Save training history\n",
    "                ModelTrainer._save_training_history(\n",
    "                    training_losses, validation_losses, accuracies,\n",
    "                    best_accuracy, best_val_loss, df, mlb,\n",
    "                    threshold_optimizer, performance_tracker\n",
    "                )\n",
    "\n",
    "                return model, tokenizer, mlb, threshold_optimizer\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in training: {str(e)}\")\n",
    "            raise\n",
    "        finally:\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "    @staticmethod\n",
    "    def _save_training_history(training_losses: List[float],\n",
    "                             validation_losses: List[float],\n",
    "                             accuracies: List[float],\n",
    "                             best_accuracy: float,\n",
    "                             best_val_loss: float,\n",
    "                             df: pd.DataFrame,\n",
    "                             mlb: MultiLabelBinarizer,\n",
    "                             threshold_optimizer: DynamicThresholdOptimizer,\n",
    "                             performance_tracker: PerformanceTracker) -> None:\n",
    "        \"\"\"Save training history and plot results with threshold and performance info\"\"\"\n",
    "        try:\n",
    "            # Initialize genre_labels\n",
    "            genre_labels = mlb.fit_transform(df['genre'])\n",
    "            \n",
    "            history_data = {\n",
    "                'model_info': {\n",
    "                    'classes': mlb.classes_.tolist(),\n",
    "                    'total_samples': len(df),\n",
    "                    'genre_distribution': {\n",
    "                        genre: int(count) for genre, count in zip(mlb.classes_, genre_labels.sum(axis=0))\n",
    "                    }\n",
    "                },\n",
    "                'training_config': {\n",
    "                    'batch_size': Config.MODEL_PARAMS['BATCH_SIZE'],\n",
    "                    'learning_rate': Config.MODEL_PARAMS['LEARNING_RATE'],\n",
    "                    'max_length': Config.MODEL_PARAMS['MAX_LENGTH'],\n",
    "                    'weight_decay': Config.MODEL_PARAMS['WEIGHT_DECAY'],\n",
    "                    'early_stopping': Config.MODEL_PARAMS['PATIENCE'],\n",
    "                    'mixup_prob': Config.MODEL_PARAMS['MIXUP_PROB'],\n",
    "                    'train_split': 1-Config.MODEL_PARAMS['TEST_SIZE'],\n",
    "                    'test_split': Config.MODEL_PARAMS['TEST_SIZE']\n",
    "                },\n",
    "                'training_history': {\n",
    "                    'epochs': list(range(1, len(training_losses) + 1)),\n",
    "                    'training_loss': [float(loss) for loss in training_losses],\n",
    "                    'validation_loss': [float(loss) for loss in validation_losses],\n",
    "                    'accuracy': [float(acc) for acc in accuracies],\n",
    "                    'best_accuracy': float(best_accuracy),\n",
    "                    'best_val_loss': float(best_val_loss)\n",
    "                },\n",
    "                'thresholding_info': {\n",
    "                    'final_thresholds': {\n",
    "                        mlb.classes_[i]: thresh for i, thresh in enumerate(threshold_optimizer.thresholds)\n",
    "                    },\n",
    "                    'best_thresholds': {\n",
    "                        mlb.classes_[i]: thresh for i, thresh in enumerate(threshold_optimizer.best_thresholds)\n",
    "                    },\n",
    "                    'best_f1_scores': {\n",
    "                        mlb.classes_[i]: score for i, score in enumerate(threshold_optimizer.best_f1_scores)\n",
    "                    }\n",
    "                },\n",
    "                'per_class_performance': performance_tracker.best_metrics\n",
    "            }\n",
    "    \n",
    "            # Save history to JSON\n",
    "            history_file = Config.METRICS_DIR / 'training_history.json'\n",
    "            with open(history_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(history_data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "            # Plot training history\n",
    "            Visualization.plot_training_history(history_data['training_history'])\n",
    "            logging.info(\"Training history saved successfully\")\n",
    "    \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving training history: {str(e)}\")\n",
    "            raise\n",
    "    @staticmethod\n",
    "    def _train_epoch(model: torch.nn.Module,\n",
    "                    train_loader: DataLoader,\n",
    "                    optimizer: torch.optim.Optimizer,\n",
    "                    epoch: int) -> Dict:\n",
    "        \"\"\"Train model for one epoch\"\"\"\n",
    "        total_loss = 0\n",
    "        steps = 0\n",
    "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}\",\n",
    "                          position=1, leave=False)\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            try:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if np.random.random() < Config.MODEL_PARAMS['MIXUP_PROB']:\n",
    "                    batch = DataAugmentation.apply_mixup(batch)\n",
    "\n",
    "                input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                loss = LossFunctions.label_smoothing_loss(\n",
    "                    outputs.logits, labels, Config.MODEL_PARAMS['SMOOTHING']\n",
    "                )\n",
    "\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "\n",
    "                total_loss += loss.item()\n",
    "                steps += 1\n",
    "                progress_bar.set_postfix({'training_loss': f'{loss.item():.4f}'})\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if \"out of memory\" in str(e):\n",
    "                    if torch.cuda.is_available():\n",
    "                        torch.cuda.empty_cache()\n",
    "                    logging.error(\"GPU out of memory during training. Try reducing batch size.\")\n",
    "                raise\n",
    "\n",
    "        return {'train_loss': total_loss / steps}\n",
    "\n",
    "    @staticmethod\n",
    "    def _calculate_validation_loss(model: torch.nn.Module,\n",
    "                                 val_loader: DataLoader) -> float:\n",
    "        \"\"\"Calculate validation loss\"\"\"\n",
    "        model.eval()\n",
    "        total_loss = 0\n",
    "        steps = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                try:\n",
    "                    input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                    attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                    labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                    outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                    loss = LossFunctions.focal_loss(outputs.logits, labels)\n",
    "                    total_loss += loss.item()\n",
    "                    steps += 1\n",
    "\n",
    "                except RuntimeError as e:\n",
    "                    if \"out of memory\" in str(e):\n",
    "                        if torch.cuda.is_available():\n",
    "                            torch.cuda.empty_cache()\n",
    "                        logging.error(\"GPU out of memory during validation. Try reducing batch size.\")\n",
    "                    raise\n",
    "\n",
    "        return total_loss / steps\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_model_improvement(model: torch.nn.Module,\n",
    "                               tokenizer,\n",
    "                               current_accuracy: float,\n",
    "                               current_loss: float,\n",
    "                               best_accuracy: float,\n",
    "                               best_loss: float) -> bool:\n",
    "        \"\"\"Check if model improved and save if necessary\"\"\"\n",
    "        improved = False\n",
    "\n",
    "        try:\n",
    "            if current_accuracy > best_accuracy:\n",
    "                logging.info(f\"New best accuracy: {current_accuracy:.4f}\")\n",
    "                model.save_pretrained(str(Config.MODEL_BEST_ACC))  # Convert to string for Colab\n",
    "                tokenizer.save_pretrained(str(Config.TOKENIZER_BEST_ACC))\n",
    "                improved = True\n",
    "\n",
    "            if current_loss < best_loss:\n",
    "                logging.info(f\"New best loss: {current_loss:.4f}\")\n",
    "                model.save_pretrained(str(Config.MODEL_BEST_LOSS))\n",
    "                tokenizer.save_pretrained(str(Config.TOKENIZER_BEST_LOSS))\n",
    "                improved = True\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "        return improved\n",
    "\n",
    "\n",
    "class HyperparameterOptimizer:\n",
    "    @staticmethod\n",
    "    @error_handler\n",
    "    def objective(trial: Trial, df: pd.DataFrame, mlb: MultiLabelBinarizer) -> float:\n",
    "        \"\"\"Objective function untuk Optuna optimization\"\"\"\n",
    "        try:\n",
    "            # Get trial parameters\n",
    "            params = HyperparameterOptimizer._get_trial_parameters(trial)\n",
    "\n",
    "            # Prepare data\n",
    "            X_train, X_test, y_train, y_test = DataProcessor.prepare_data(df, mlb)\n",
    "\n",
    "            # Setup model dan data loaders\n",
    "            with ModelManager(*ModelSetup.setup_model_and_tokenizer(len(mlb.classes_))) as (model, tokenizer):\n",
    "                train_loader, val_loader = ModelSetup.setup_dataloaders(\n",
    "                    X_train, X_test, y_train, y_test,\n",
    "                    tokenizer, params['batch_size']\n",
    "                )\n",
    "\n",
    "                # Training loop singkat untuk optimasi\n",
    "                best_val_metrics = HyperparameterOptimizer._train_trial(\n",
    "                    trial, model, train_loader, val_loader, mlb, params\n",
    "                )\n",
    "\n",
    "                # Clear GPU cache after each trial\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            return best_val_metrics['macro_f1']\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in optimization objective: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_trial_parameters(trial: Trial) -> Dict:\n",
    "        \"\"\"Get parameters for trial\"\"\"\n",
    "        params = {}\n",
    "        try:\n",
    "            # Batch size dari list nilai diskrit\n",
    "            params['batch_size'] = trial.suggest_categorical('batch_size',\n",
    "                Config.OPTIM_PARAMS['batch_size'])\n",
    "\n",
    "            # Learning rate dari list nilai diskrit\n",
    "            params['learning_rate'] = trial.suggest_categorical('learning_rate',\n",
    "                Config.OPTIM_PARAMS['learning_rate'])\n",
    "\n",
    "            # Weight decay dari list nilai diskrit\n",
    "            params['weight_decay'] = trial.suggest_categorical('weight_decay',\n",
    "                Config.OPTIM_PARAMS['weight_decay'])\n",
    "\n",
    "            # Mixup probability dari list nilai diskrit\n",
    "            params['mixup_prob'] = trial.suggest_categorical('mixup_prob',\n",
    "                Config.OPTIM_PARAMS['mixup_prob'])\n",
    "\n",
    "            # Smoothing dari list nilai diskrit\n",
    "            params['smoothing'] = trial.suggest_categorical('smoothing',\n",
    "                Config.OPTIM_PARAMS['smoothing'])\n",
    "\n",
    "            logging.info(f\"Trial parameter set: {params}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error getting trial parameters: {str(e)}\")\n",
    "            raise\n",
    "        return params\n",
    "\n",
    "    @staticmethod\n",
    "    def _train_trial(trial: Trial,\n",
    "                    model: torch.nn.Module,\n",
    "                    train_loader: DataLoader,\n",
    "                    val_loader: DataLoader,\n",
    "                    mlb: MultiLabelBinarizer,\n",
    "                    params: Dict) -> Dict:\n",
    "        \"\"\"Train model for one trial\"\"\"\n",
    "        try:\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                model.parameters(),\n",
    "                lr=params['learning_rate'],\n",
    "                weight_decay=params['weight_decay']\n",
    "            )\n",
    "\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=0.5, patience=2, verbose=True\n",
    "            )\n",
    "\n",
    "            best_val_metrics = None\n",
    "\n",
    "            for epoch in range(3):  # Reduced epochs for optimization\n",
    "                # Training\n",
    "                model.train()\n",
    "                total_loss = 0\n",
    "                steps = 0\n",
    "\n",
    "                progress_bar = tqdm(train_loader,\n",
    "                                  desc=f\"Epoch {epoch+1}/3\",\n",
    "                                  position=0,\n",
    "                                  leave=False)\n",
    "\n",
    "                for batch in progress_bar:\n",
    "                    try:\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        if np.random.random() < params['mixup_prob']:\n",
    "                            batch = DataAugmentation.apply_mixup(batch)\n",
    "\n",
    "                        input_ids = batch['input_ids'].to(Config.DEVICE)\n",
    "                        attention_mask = batch['attention_mask'].to(Config.DEVICE)\n",
    "                        labels = batch['labels'].to(Config.DEVICE)\n",
    "\n",
    "                        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                        loss = LossFunctions.label_smoothing_loss(\n",
    "                            outputs.logits, labels, params['smoothing']\n",
    "                        )\n",
    "\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                        total_loss += loss.item()\n",
    "                        steps += 1\n",
    "\n",
    "                        # Update progress bar\n",
    "                        progress_bar.set_postfix({\n",
    "                            'loss': f'{loss.item():.4f}',\n",
    "                            'avg_loss': f'{(total_loss/steps):.4f}'\n",
    "                        })\n",
    "\n",
    "                    except RuntimeError as e:\n",
    "                        if \"out of memory\" in str(e):\n",
    "                            if torch.cuda.is_available():\n",
    "                                torch.cuda.empty_cache()\n",
    "                            logging.error(\"GPU OOM in trial. Trying to recover...\")\n",
    "                            continue\n",
    "                        raise\n",
    "\n",
    "                avg_loss = total_loss / steps\n",
    "\n",
    "                # Evaluation\n",
    "                metrics = ModelEvaluator.evaluate_model(model, val_loader, mlb)\n",
    "                current_f1 = metrics['macro_f1']\n",
    "\n",
    "                logging.info(f\"Trial {trial.number}, Epoch {epoch+1}: \"\n",
    "                           f\"Loss = {avg_loss:.4f}, F1 = {current_f1:.4f}\")\n",
    "\n",
    "                if best_val_metrics is None or current_f1 > best_val_metrics['macro_f1']:\n",
    "                    best_val_metrics = metrics\n",
    "\n",
    "                scheduler.step(metrics['macro_f1'])\n",
    "\n",
    "                # Report intermediate value\n",
    "                trial.report(metrics['macro_f1'], epoch)\n",
    "\n",
    "                # Handle pruning based on the intermediate value\n",
    "                if trial.should_prune():\n",
    "                    raise optuna.TrialPruned()\n",
    "\n",
    "                # Clear GPU cache\n",
    "                if torch.cuda.is_available():\n",
    "                    torch.cuda.empty_cache()\n",
    "                    gc.collect()\n",
    "\n",
    "            return best_val_metrics\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in trial training: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def run_optimization(df: pd.DataFrame,\n",
    "                        mlb: MultiLabelBinarizer,\n",
    "                        n_trials: int = 30) -> Dict:\n",
    "\n",
    "        try:\n",
    "            study = optuna.create_study(\n",
    "                direction=\"maximize\",\n",
    "                sampler=optuna.samplers.TPESampler(seed=42),\n",
    "                pruner=optuna.pruners.MedianPruner()\n",
    "            )\n",
    "\n",
    "            objective_func = lambda trial: HyperparameterOptimizer.objective(trial, df, mlb)\n",
    "\n",
    "            logging.info(\"Starting hyperparameter optimization...\")\n",
    "            study.optimize(objective_func, n_trials=n_trials,\n",
    "                         callbacks=[lambda study, trial: gc.collect()])\n",
    "\n",
    "            # Log results\n",
    "            logging.info(\"\\nHyperparameter Optimization Results:\")\n",
    "            logging.info(f\"Best trial number: {study.best_trial.number}\")\n",
    "            logging.info(f\"Best F1-score: {study.best_trial.value:.4f}\")\n",
    "            logging.info(\"\\nBest hyperparameters:\")\n",
    "            for param, value in study.best_trial.params.items():\n",
    "                logging.info(f\"{param}: {value}\")\n",
    "\n",
    "            # Save study results\n",
    "            results_file = Config.METRICS_DIR / 'optuna_results.json'\n",
    "            results = {\n",
    "                'best_trial': {\n",
    "                    'number': study.best_trial.number,\n",
    "                    'value': study.best_trial.value,\n",
    "                    'params': study.best_trial.params\n",
    "                },\n",
    "                'all_trials': [\n",
    "                    {\n",
    "                        'number': trial.number,\n",
    "                        'value': trial.value,\n",
    "                        'params': trial.params\n",
    "                    }\n",
    "                    for trial in study.trials if trial.value is not None\n",
    "                ]\n",
    "            }\n",
    "\n",
    "            with open(results_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "            # Save visualizations\n",
    "            try:\n",
    "                # Optimization history plot\n",
    "                fig1 = optuna.visualization.plot_optimization_history(study)\n",
    "                fig1.write_image(str(Config.PLOTS_DIR / \"optuna_optimization_history.png\"))\n",
    "\n",
    "                # Parameter importance plot\n",
    "                fig2 = optuna.visualization.plot_param_importances(study)\n",
    "                fig2.write_image(str(Config.PLOTS_DIR / \"optuna_param_importances.png\"))\n",
    "\n",
    "                # Parameter relationships plot\n",
    "                fig3 = optuna.visualization.plot_parallel_coordinate(study)\n",
    "                fig3.write_image(str(Config.PLOTS_DIR / \"optuna_param_relationships.png\"))\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Could not create optimization plots: {str(e)}\")\n",
    "\n",
    "            return study.best_trial.params\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during optimization: {str(e)}\")\n",
    "            raise\n",
    "        finally:\n",
    "            # Clean up\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "\n",
    "# Fungsi get_args untuk Colab\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # Training parameters\n",
    "        self.sample_size = None  # Number of samples to use (default: use all data)\n",
    "        self.epochs = Config.MODEL_PARAMS['EPOCHS']\n",
    "        self.batch_size = Config.MODEL_PARAMS['BATCH_SIZE']\n",
    "        self.learning_rate = Config.MODEL_PARAMS['LEARNING_RATE']\n",
    "        self.max_length = Config.MODEL_PARAMS['MAX_LENGTH']\n",
    "\n",
    "        # Model configuration\n",
    "        self.test_size = Config.MODEL_PARAMS['TEST_SIZE']\n",
    "        self.weight_decay = Config.MODEL_PARAMS['WEIGHT_DECAY']\n",
    "        self.mixup_prob = Config.MODEL_PARAMS['MIXUP_PROB']\n",
    "        self.patience = Config.MODEL_PARAMS['PATIENCE']\n",
    "\n",
    "        # System configuration\n",
    "        self.output_dir = None\n",
    "        self.no_cuda = False\n",
    "        self.seed = 42\n",
    "\n",
    "        # Label Smoothing\n",
    "        self.smoothing = Config.MODEL_PARAMS['SMOOTHING']\n",
    "\n",
    "        # Optuna specific\n",
    "        self.n_trials = 20\n",
    "\n",
    "# Modifikasi fungsi get_args\n",
    "def get_args():\n",
    "    return Args()\n",
    "\n",
    "def main(args: Args) -> None:\n",
    "    \"\"\"Main function\"\"\"\n",
    "    try:\n",
    "        # Check environment first\n",
    "        if not check_environment():\n",
    "            raise RuntimeError(\"Environment check failed!\")\n",
    "\n",
    "        # Update configuration\n",
    "        Config.MODEL_PARAMS.update({\n",
    "            'EPOCHS': args.epochs,\n",
    "            'BATCH_SIZE': args.batch_size,\n",
    "            'LEARNING_RATE': args.learning_rate,\n",
    "            'MAX_LENGTH': args.max_length,\n",
    "            'TEST_SIZE': args.test_size,\n",
    "            'WEIGHT_DECAY': args.weight_decay,\n",
    "            'MIXUP_PROB': args.mixup_prob,\n",
    "            'PATIENCE': args.patience,\n",
    "            'SMOOTHING': args.smoothing\n",
    "        })\n",
    "\n",
    "        if args.no_cuda:\n",
    "            Config.DEVICE = torch.device('cpu')\n",
    "            logging.info(\"CUDA disabled by user\")\n",
    "\n",
    "        # Initialize logging dan experiment info\n",
    "        log_system_info()\n",
    "\n",
    "        logging.info(\"Starting movie genre classification with hyperparameter optimization\")\n",
    "        logging.info(f\"Using device: {Config.DEVICE}\")\n",
    "\n",
    "        # Log initial configuration\n",
    "        logging.info(\"\\nInitial Configuration:\")\n",
    "        logging.info(f\"Sample Size: {Config.SAMPLE_SIZE if Config.SAMPLE_SIZE else 'Full Dataset'}\")\n",
    "        for param, value in Config.MODEL_PARAMS.items():\n",
    "            logging.info(f\"{param}: {value}\")\n",
    "\n",
    "        # Load and preprocess data\n",
    "        logging.info(\"\\nLoading and preprocessing data...\")\n",
    "        df = DataProcessor.load_and_preprocess_data(Config.DATA_PATH, Config.SAMPLE_SIZE)\n",
    "        mlb = MultiLabelBinarizer()\n",
    "\n",
    "        # Run hyperparameter optimization\n",
    "        logging.info(\"\\nStarting hyperparameter optimization...\")\n",
    "        best_params = HyperparameterOptimizer.run_optimization(df, mlb, args.n_trials)\n",
    "\n",
    "        # Update configuration with best parameters\n",
    "        logging.info(\"\\nBest Hyperparameters found:\")\n",
    "        for param, value in best_params.items():\n",
    "            logging.info(f\"{param}: {value}\")\n",
    "            if param in Config.MODEL_PARAMS:\n",
    "                Config.MODEL_PARAMS[param] = value\n",
    "\n",
    "        # Train final model with best parameters\n",
    "        logging.info(\"\\nTraining final model with optimized parameters...\")\n",
    "        model, tokenizer, mlb, threshold_optimizer = ModelTrainer.train_model(Config.SAMPLE_SIZE)\n",
    "\n",
    "        # Test on a sample\n",
    "        logging.info(\"\\nTesting model on a sample...\")\n",
    "        df_sample = DataProcessor.load_and_preprocess_data(Config.DATA_PATH, sample_size=1)\n",
    "        sample_text = df_sample['sinopsis'].iloc[0]\n",
    "\n",
    "        model.eval()\n",
    "        inputs = tokenizer(\n",
    "            sample_text,\n",
    "            return_tensors='pt',\n",
    "            max_length=Config.MODEL_PARAMS['MAX_LENGTH'],\n",
    "            padding='max_length',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        input_ids = inputs['input_ids'].to(Config.DEVICE)\n",
    "        attention_mask = inputs['attention_mask'].to(Config.DEVICE)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            probs = torch.sigmoid(outputs.logits)\n",
    "            \n",
    "            # Gunakan threshold_optimizer untuk prediksi\n",
    "            raw_predictions = probs.cpu().numpy()\n",
    "            thresholded_preds = threshold_optimizer.apply_thresholds(raw_predictions)\n",
    "\n",
    "        # Buat prediksi dengan threshold yang dioptimalkan\n",
    "        predictions = []\n",
    "        for idx, pred in enumerate(thresholded_preds[0]):\n",
    "            if pred > 0:  # Karena sudah di-threshold\n",
    "                predictions.append({\n",
    "                    'genre': mlb.classes_[idx],\n",
    "                    'probability': float(probs[0][idx].item()),\n",
    "                    'threshold_used': threshold_optimizer.thresholds[idx]\n",
    "                })\n",
    "\n",
    "        predictions.sort(key=lambda x: x['probability'], reverse=True)\n",
    "\n",
    "        # Log prediction results dengan informasi threshold\n",
    "        logging.info(\"\\nSample prediction results:\")\n",
    "        logging.info(f\"Sample text: {sample_text[:100]}...\")\n",
    "        for pred in predictions:\n",
    "            logging.info(\n",
    "                f\"Genre: {pred['genre']}, \"\n",
    "                f\"Probability: {pred['probability']:.4f}, \"\n",
    "                f\"Threshold Used: {pred['threshold_used']:.3f}\"\n",
    "            )\n",
    "\n",
    "        # Save final configuration\n",
    "        final_config = {\n",
    "            'hyperparameters': best_params,\n",
    "            'model_info': {\n",
    "                'num_classes': len(mlb.classes_),\n",
    "                'classes': mlb.classes_.tolist()\n",
    "            },\n",
    "            'training_info': {\n",
    "                'device': str(Config.DEVICE),\n",
    "                'final_sample_size': len(df),\n",
    "                'optimization_trials': args.n_trials\n",
    "            },\n",
    "            'threshold_info': {\n",
    "                'final_thresholds': {\n",
    "                    class_name: float(thresh) \n",
    "                    for class_name, thresh in zip(mlb.classes_, threshold_optimizer.thresholds)\n",
    "                },\n",
    "                'best_f1_scores': {\n",
    "                    class_name: float(score)\n",
    "                    for class_name, score in zip(mlb.classes_, threshold_optimizer.best_f1_scores)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        with open(Config.EXPERIMENT_DIR / 'final_configuration.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(final_config, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "        logging.info(\"\\nTraining completed successfully!\")\n",
    "        logging.info(f\"All results and models saved in: {Config.EXPERIMENT_DIR}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"\\nTraining interrupted by user\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        logging.error(f\"\\nError during execution: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logging.info(\"\\nCleaning up resources...\")\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "\n",
    "# Entry point for Colab\n",
    "if __name__ == \"__main__\":\n",
    "    # Set random seeds for reproducibility\n",
    "    args = get_args()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    try:\n",
    "        main(args)\n",
    "    except KeyboardInterrupt:\n",
    "        logging.info(\"\\nTraining interrupted by user\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Training failed: {str(e)}\")\n",
    "        raise\n",
    "    finally:\n",
    "        logging.info(\"Cleaning up resources...\")\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c51beb77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T19:51:07.523671Z",
     "iopub.status.busy": "2025-02-16T19:51:07.523300Z",
     "iopub.status.idle": "2025-02-16T19:51:58.775437Z",
     "shell.execute_reply": "2025-02-16T19:51:58.774290Z"
    },
    "papermill": {
     "duration": 56.646229,
     "end_time": "2025-02-16T19:52:01.316212",
     "exception": false,
     "start_time": "2025-02-16T19:51:04.669983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: kaggle/working/logs/experiments/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/model/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/model/best_loss/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/model/best_loss/config.json (deflated 56%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/model/best_loss/model.safetensors (deflated 7%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/model/best_accuracy/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/model/best_accuracy/config.json (deflated 56%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/model/best_accuracy/model.safetensors (deflated 7%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/metrics/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/metrics/evaluation_metrics.json (deflated 68%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/metrics/performance_history.json (deflated 83%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/metrics/training_history.json (deflated 73%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/metrics/threshold_history.json (deflated 91%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/metrics/optuna_results.json (deflated 90%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/best_loss/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/best_loss/tokenizer.json (deflated 71%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/best_loss/special_tokens_map.json (deflated 42%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/best_loss/tokenizer_config.json (deflated 74%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/best_loss/vocab.txt (deflated 53%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/best_accuracy/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/best_accuracy/tokenizer.json (deflated 71%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/best_accuracy/special_tokens_map.json (deflated 42%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/best_accuracy/tokenizer_config.json (deflated 74%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/tokenizer/best_accuracy/vocab.txt (deflated 53%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/accuracies_trends.png (deflated 5%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/recalls_trends.png (deflated 4%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/precisions_trends.png (deflated 5%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices/ (stored 0%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices/confusion_matrix_Komedi.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices/confusion_matrix_Romantis.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices/confusion_matrix_Laga.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices/confusion_matrix_Horor.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/confusion_matrices/confusion_matrix_Drama.png (deflated 19%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/training_history.png (deflated 15%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/plots/f1_scores_trends.png (deflated 7%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/final_configuration.json (deflated 64%)\r\n",
      "  adding: kaggle/working/logs/experiments/20250216_171623/training.log (deflated 86%)\r\n"
     ]
    }
   ],
   "source": [
    "!zip -r folder.zip /kaggle/working/logs/experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1864621c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-16T19:52:07.124295Z",
     "iopub.status.busy": "2025-02-16T19:52:07.123964Z",
     "iopub.status.idle": "2025-02-16T19:52:07.129764Z",
     "shell.execute_reply": "2025-02-16T19:52:07.129073Z"
    },
    "papermill": {
     "duration": 2.884795,
     "end_time": "2025-02-16T19:52:07.131054",
     "exception": false,
     "start_time": "2025-02-16T19:52:04.246259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='folder.zip' target='_blank'>folder.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/folder.zip"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'folder.zip')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6639588,
     "sourceId": 10712322,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9375.586867,
   "end_time": "2025-02-16T19:52:12.908112",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-16T17:15:57.321245",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "08fc270eff94458481bb332b5228ace2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3ebcb4d80c4d4d069b974cd5608c1083",
        "IPY_MODEL_e74f4c09a31c4cb687b464dc21466ec6",
        "IPY_MODEL_6af68a562b13434c97f514e01f8e8a3f"
       ],
       "layout": "IPY_MODEL_c7b25b22482e4abebf3b81f6d098a845",
       "tabbable": null,
       "tooltip": null
      }
     },
     "0a98c22d68654c0194856badc01eb911": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "0cc2c563852f4de99c8b0394f68ab15d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_855c60f5f445446ca8b88d7f301e60ae",
        "IPY_MODEL_9f3494ed2b71415f8432ea51dd9c3a6e",
        "IPY_MODEL_a71af45d03f04409a5625bfea3740e36"
       ],
       "layout": "IPY_MODEL_ba47616bea2d4354bda83cead98f9f29",
       "tabbable": null,
       "tooltip": null
      }
     },
     "150e0ba25f3e4e25891b650b246bf404": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "19db927f495749a0bd7318629d7a7dd2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5b7f8e9551d04283ba7b0475d42a6f5b",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_62389454d55a4dfa8e52c19d380b2273",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "1ac876bd91b54155b1f90c65e0fa4719": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2d4509766b68454c985eaaa4a98945fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9b96b4ade3da481c9c5cc6860865467b",
       "placeholder": "​",
       "style": "IPY_MODEL_9fa60e29a5a04a50b093e51bdc48b29e",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.txt: 100%"
      }
     },
     "36509814834e4726b2db216d649078b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_e63c7d65336f4cea8e70c47b592549fe",
        "IPY_MODEL_57257be21ccb480e968a807c8d84f8c2",
        "IPY_MODEL_7290d6b8222b48e49c7e7d8cfbc3826b"
       ],
       "layout": "IPY_MODEL_c001796745844f27af771259476c1c76",
       "tabbable": null,
       "tooltip": null
      }
     },
     "39ac1b348c46488da287c2bc0e1fc92f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3e6ae689b3cd4c769bcd729d968ec626": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3ebcb4d80c4d4d069b974cd5608c1083": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_717e64b37309455584093cb726784efa",
       "placeholder": "​",
       "style": "IPY_MODEL_cde9ad9870f7421fa5f2c583e1b26226",
       "tabbable": null,
       "tooltip": null,
       "value": "pytorch_model.bin: 100%"
      }
     },
     "47303e300cd14df683e21527afb533e3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "57257be21ccb480e968a807c8d84f8c2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_90f0a8feaf7b4115b344dabfbbc9f33b",
       "max": 1534.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_0a98c22d68654c0194856badc01eb911",
       "tabbable": null,
       "tooltip": null,
       "value": 1534.0
      }
     },
     "57c086a45f1b4215a350646eda4e9d41": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "58f94986aa144835936d88c9f67c1a8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b7f8e9551d04283ba7b0475d42a6f5b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5e9326350aa442fbad70af278af7d2ad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_96ae7af86d0649a6bea5b26709e7e380",
       "placeholder": "​",
       "style": "IPY_MODEL_c9b28d1caffc470e85973a01db39873e",
       "tabbable": null,
       "tooltip": null,
       "value": " 229k/229k [00:00&lt;00:00, 4.89MB/s]"
      }
     },
     "60d91b17a0d149bfaf97ba18e21051be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "62389454d55a4dfa8e52c19d380b2273": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "67ef4724843e475c96480c500e6baccd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cc5c818e45b84cc9b32eb109a066ca40",
        "IPY_MODEL_19db927f495749a0bd7318629d7a7dd2",
        "IPY_MODEL_b0c8fae145784b8bbaff535ee6f9f367"
       ],
       "layout": "IPY_MODEL_58f94986aa144835936d88c9f67c1a8a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6af68a562b13434c97f514e01f8e8a3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b272d44788c442b28fa090645796beb0",
       "placeholder": "​",
       "style": "IPY_MODEL_b311c38fa6864544820a72daaf6bb61d",
       "tabbable": null,
       "tooltip": null,
       "value": " 498M/498M [00:02&lt;00:00, 238MB/s]"
      }
     },
     "717e64b37309455584093cb726784efa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7290d6b8222b48e49c7e7d8cfbc3826b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f48fb1a172a64277bf062e80722f93dc",
       "placeholder": "​",
       "style": "IPY_MODEL_bd9d8db79009426286b06cb974d6c35c",
       "tabbable": null,
       "tooltip": null,
       "value": " 1.53k/1.53k [00:00&lt;00:00, 174kB/s]"
      }
     },
     "7cc86b2b704e4dc391829a67615f6cde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2d4509766b68454c985eaaa4a98945fd",
        "IPY_MODEL_e9cbd1d85ec54d469ae2662328430308",
        "IPY_MODEL_5e9326350aa442fbad70af278af7d2ad"
       ],
       "layout": "IPY_MODEL_c6404a70e62c465a813e97b2d1d4a867",
       "tabbable": null,
       "tooltip": null
      }
     },
     "7d67cb24a78f4bcea5c5864d373eee1e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "855c60f5f445446ca8b88d7f301e60ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_39ac1b348c46488da287c2bc0e1fc92f",
       "placeholder": "​",
       "style": "IPY_MODEL_e1deeb61ddbb4af7975f491b32f95f4a",
       "tabbable": null,
       "tooltip": null,
       "value": "special_tokens_map.json: 100%"
      }
     },
     "8f08ee56a31c4f2691da45b8eb7bfaec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90f0a8feaf7b4115b344dabfbbc9f33b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96ae7af86d0649a6bea5b26709e7e380": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96eb16ea62cb49acbe76c82fb4c7c275": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9b96b4ade3da481c9c5cc6860865467b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c593e7a68c749a7b4fed1010c532b05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9f3494ed2b71415f8432ea51dd9c3a6e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d67cb24a78f4bcea5c5864d373eee1e",
       "max": 112.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c563b94e02604f1aae708bc236d6e6ff",
       "tabbable": null,
       "tooltip": null,
       "value": 112.0
      }
     },
     "9fa60e29a5a04a50b093e51bdc48b29e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a71af45d03f04409a5625bfea3740e36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8f08ee56a31c4f2691da45b8eb7bfaec",
       "placeholder": "​",
       "style": "IPY_MODEL_150e0ba25f3e4e25891b650b246bf404",
       "tabbable": null,
       "tooltip": null,
       "value": " 112/112 [00:00&lt;00:00, 12.3kB/s]"
      }
     },
     "b0c8fae145784b8bbaff535ee6f9f367": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_57c086a45f1b4215a350646eda4e9d41",
       "placeholder": "​",
       "style": "IPY_MODEL_1ac876bd91b54155b1f90c65e0fa4719",
       "tabbable": null,
       "tooltip": null,
       "value": " 2.00/2.00 [00:00&lt;00:00, 200B/s]"
      }
     },
     "b272d44788c442b28fa090645796beb0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b311c38fa6864544820a72daaf6bb61d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b61a2f5e80154027bc7be55fbfb58c04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "b762458f652d449ea5c7dcd75d11c14a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ba47616bea2d4354bda83cead98f9f29": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd9d8db79009426286b06cb974d6c35c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c001796745844f27af771259476c1c76": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c563b94e02604f1aae708bc236d6e6ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c6404a70e62c465a813e97b2d1d4a867": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7b25b22482e4abebf3b81f6d098a845": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c9b28d1caffc470e85973a01db39873e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cc5c818e45b84cc9b32eb109a066ca40": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9c593e7a68c749a7b4fed1010c532b05",
       "placeholder": "​",
       "style": "IPY_MODEL_96eb16ea62cb49acbe76c82fb4c7c275",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "cde9ad9870f7421fa5f2c583e1b26226": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e1deeb61ddbb4af7975f491b32f95f4a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "e63c7d65336f4cea8e70c47b592549fe": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_60d91b17a0d149bfaf97ba18e21051be",
       "placeholder": "​",
       "style": "IPY_MODEL_f4d3e47897464b95b0bb0d23c4aa3c36",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "e74f4c09a31c4cb687b464dc21466ec6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b762458f652d449ea5c7dcd75d11c14a",
       "max": 497810400.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3e6ae689b3cd4c769bcd729d968ec626",
       "tabbable": null,
       "tooltip": null,
       "value": 497810400.0
      }
     },
     "e9cbd1d85ec54d469ae2662328430308": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_47303e300cd14df683e21527afb533e3",
       "max": 229167.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_b61a2f5e80154027bc7be55fbfb58c04",
       "tabbable": null,
       "tooltip": null,
       "value": 229167.0
      }
     },
     "f48fb1a172a64277bf062e80722f93dc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4d3e47897464b95b0bb0d23c4aa3c36": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
